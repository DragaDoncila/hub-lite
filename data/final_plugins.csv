,display_name,version,created_at,modified_at,name,author,package_metadata_author_email,license,home,summary,package_metadata_requires_python,package_metadata_requires_dist,package_metadata_description,package_metadata_classifier,package_metadata_project_url,contributions_readers_0_command,contributions_writers_0_command,contributions_widgets_0_command,contributions_sample_data_0_command,contributions_readers_0_filename_patterns,contributions_writers_0_filename_extensions,contributions_writers_1_filename_extensions,home_pypi,home_github,home_other
0,acquifer-napari,0.0.2,2023-08-03,2023-08-03,acquifer-napari,Laurent Thomas,,GPL-3.0-only,https://github.com/acquifer/acquifer-napari,"Loader plugin for napari, to load Acquifer Imaging Machine datasets in napari, using dask for efficient lazy data-loading.",>=3.7,"['acquifer', 'napari', 'numpy', 'sortedcontainers', 'dask-image', 'xarray']","# acquifer-napari

The acquifer-napari plugin allows loading IM04 dataset directory, as multi-dimensional images in napari.  
Sliders for well, channel, time and Z are automatically rendered when there are more than 1 coordinates along the dimension.  
The plugin uses Dask-Image for efficient data-loading ""on request"" similar to the VirtualStack in ImageJ.  

## Installation
Via the napari plugin manager : acquifer-napari.
Or with pip : `pip install acquifer-napari`.

Use `pip install -e .` to install in developement mode, so any change in the source code is directly reflected.  
Use `npe2 list` to check that the plugin is correctly installed and visible by napari.  
For instance here, the package defines 1 command, which is a reader.  
One could have more commands, which would be implement other types.   
This should output something like following 
┌──────────────────────────────┬─────────┬──────┬───────────────────────────────────────────────────────────┐
│ Name                         │ Version │ Npe2 │ Contributions                                             │
├──────────────────────────────┼─────────┼──────┼───────────────────────────────────────────────────────────┤
│ acquifer-napari              │ 0.0.1   │ ✅   │ commands (1), readers (1)

The plugin should be installed in an environment with napari installed.  
Napari can be started with the `napari`command in a command prompt with a system wide python installation.  
Once installed, napari can be opened in a IPython interactive session with

```python
>> import napari
>> napari.Viewer()
```

## Configurations
The file `napari.yaml` in `acquifer_napari_plugin` defines what functions of the python package are visible to napari.  
The top level `name` field must be the same than the python package name defined in `setup.cfg`.
It first define a set of commands, which have a custom `id`, and a `python_name`, which is the actual location of the function in the python package (or module).  
Then the napari.yaml has optional subsections `readers`, `writers`, `widget`, to reference some of the commands previously defined, to notify napari that they implemente those standard functions.  
For instance I first define a command myReader pointing to myPackage.myReader, and I reference that command using the id it in the section readers  
See https://napari.org/stable/plugins/first_plugin.html#add-a-napari-yaml-manifest  


## Issues
If you encounter any problems, please [file an issue](https://github.com/Luxendo/acquifer-napari/issues) along with a detailed description.
","['Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: GNU General Public License v3 (GPLv3)']","['HomePage, https://acquifer.de', 'Twitter, https://twitter.com/myacquifer', 'Bug Tracker, https://github.com/Luxendo/acquifer-napari/issues', 'Documentation, https://github.com/Luxendo/acquifer-napari#README.md', 'Source Code, https://github.com/Luxendo/acquifer-napari']",acquifer-napari.get_reader,,,,['*'],,,https://pypi.org/project/acquifer-napari,https://github.com/acquifer/acquifer-napari,
1,affinder,0.3.2,2022-01-28,2023-08-08,affinder,Juan Nunez-Iglesias,juan.nunez-iglesias@monash.edu,BSD-3,https://github.com/jni/affinder,Quickly find the affine matrix mapping one image to another using manual correspondence points annotation,>=3.9,"['napari >=0.4.17', 'npe2 >=0.1.2', 'numpy', 'scikit-image', 'magicgui >=0.3.7', 'toolz', ""furo ; extra == 'docs'"", ""myst-parser ; extra == 'docs'"", ""coverage ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""scikit-image[data] ; extra == 'testing'"", ""napari[pyqt5] !=0.4.18 ; extra == 'testing'"", ""pygments !=2.16 ; extra == 'testing'"", ""zarr ; extra == 'testing'""]","# affinder

[![License](https://img.shields.io/pypi/l/affinder.svg?color=green)](https://github.com/napari/affinder/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/affinder.svg?color=green)](https://pypi.org/project/affinder)
[![Python Version](https://img.shields.io/pypi/pyversions/affinder.svg?color=green)](https://python.org)
[![tests](https://github.com/jni/affinder/workflows/tests/badge.svg)](https://github.com/jni/affinder/actions)
[![codecov](https://codecov.io/gh/jni/affinder/branch/main/graph/badge.svg)](https://codecov.io/gh/jni/affinder)

Quickly find the affine matrix mapping one image to another using manual correspondence points annotation

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/docs/plugins/index.html
-->

## Installation

You can install `affinder` via [pip]:

    pip install affinder

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""affinder"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/jni/affinder/issues
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 3 - Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']",,,,affinder.start_affinder,,,,,https://pypi.org/project/affinder,https://github.com/jni/affinder,
2,anchor-droplet-chip,0.4.4,2023-12-04,2023-12-04,anchor-droplet-chip,Andrey Aristov,aaristov@pasteur.fr,BSD-3-Clause,https://pypi.org/project/anchor-droplet-chip,Segment organoids and measure intensities,>=3.8,"['dask', 'fire', 'jupyterlab', 'matplotlib', 'napari', 'nd2', 'numpy', 'pandas', 'pyqt6', 'pytest-qt', 'pyyaml', 'scikit-image', 'scipy', 'seaborn', 'tifffile', 'zarr-tools', 'zenodo-get']","# ⚓ anchor-droplet-chip
## Measuring single-cell susceptibility to antibiotics within monoclonal fluorescent bacteria.

We are imaging the entire chip using 20x 0.7NA objective lens using automatic stitching in NIS.
Bright-field image 2D and TRITC-3D acquired. The 3D stack is converted to 2D using maximum projection in NIS or Fiji. Both channels are then merged together and saved as a tif stack. After that this package can be applied to detect the individual droplets and count the fluorescent cells.

As the chips are bonded to the coverslip manually, they contain a randon tilt and shift, so detecting individual droplets proved to be unreliable. The current approach consisnts of preparing a well-lebelled template bright-field image and a labelled mask and matching the experimental brightfield image to the template.
![Paper outline(1)](https://user-images.githubusercontent.com/11408456/178001287-513e6398-c4e0-4946-b38f-6cb98dc0ee6c.svg)

## Installation
```bash
pip install anchor-droplet-chip
```
## Usage

1. Notebook: `jupyter lab example.ipynb`
2. Napari plugin: see the menu `Plugins / andhor-droplet-chips / ...
3. Command line:

    `python -m adc.align --help`

    `python -m adc.count --help`

### Dowloading the raw data
Head to release page https://github.com/BaroudLab/anchor-droplet-chip/releases/tag/v0.0.1 and download files one by one.

Or

Execute the notebook example.ipynb - the data will be fetched automatically.

### Aligning the chips with the template and the mask

Day 1:
```bash
python -m adc.align day1/00ng_BF_TRITC_bin2.tif template_bin16_bf.tif labels_bin2.tif
```
This command will create the stack day1/00ng_BF_TRITC_bin2-aligned.tif, which can be viewed in Fiji.
![Screenshot of 00ng_BF_TRITC_bin2-aligned.tif](https://user-images.githubusercontent.com/11408456/176169270-3d494fc3-a771-4bf0-859e-c9cc853ce2d9.png)

Day 2:
```bash
python -m adc.align day2/00ng_BF_TRITC_bin2_24h.tif template_bin16_bf.tif labels_bin2.tif
```

### Counting the cells day 1 and day2
```
python -m adc.count day1/00ng_BF_TRITC_bin2-aligned.tif day1/counts.csv
python -m adc.count day2/00ng_BF_TRITC_bin2_24h-aligned.tif day2/counts.csv
```

### Combining the tables from 2 days
```
python adc.merge day1/counts.csv day2/counts.csv table.csv
```

### Plotting and fitting the probabilities


## Sample data

### Batch processing:

First you'll need to clone the repo locally and install it to have the scripts at hand.

```bash
git clone https://github.com/BaroudLab/anchor-droplet-chip.git

cd anchor-droplet-chip

pip install .
```
Make a data folder
```bash
mkdir data

```
Download the dataset from Zenodo https://zenodo.org/record/6940212
```bash
zenodo_get 6940212 -o data
```
Proceed with Snakemake pipeline to get tha table and plots. Be careful with the number of threads `-c` as a single thread can consume over 8 GBs of RAM.
```bash
snakemake -c4 -d data table.csv
```

# Napari plugin functionaluties

## nd2 reader

Open large nd2 file by drag-n-drop and select anchor-droplet-chip as a reader.
The reader plugin will aotimatically detect the subchannels and split them in different layers.
The reader will also extract the pixel size from metadata and save it as Layer.metadata[""pixel_size_um""]
The data itself is opened ad dask array using nd2 python library.

## Substack

Some datasets are so big, it's hard to even to open them, let alone doing processing in them.
`anchor-droplet-chip / Make a sub stack ` addresses this problem.
Upon opening the plugin you'll see all  dimensions of you dataset, and the axes will become named accordingly.
Simply choose the subset of data you need, and click ""Crop it!"". This will create a new layer with the subset of data.
Note that no new files are created in the process and in the background nd2 library lazy loading chunks of data from the original nd2 file.

## Populate ROIs along the line
Draw a line in the new shapes layer and call the widget. It will populate square ROIs along the line. Adjust the number of columns and rows. This way you can manually map the 2D wells on your chip.

## Crop ROIs
Use this widget to crop the mapped previously ROIs. The extracted crops can be saved as tifs.

## Split along axis

Allows to split any dataset along a selected axis and save the pieces as separate tifs (imagej format, so only TZCYX axes supported)
* Select the axis name
* Click Split it! and check the table with the names, shapes and paths.
* To change the prefix, set the folder by clicking at ""Choose folder""
* Once the table looks right, click ""Save tifs"" and wait. The colunm ""saved"" will be updated along the way.
![image](https://user-images.githubusercontent.com/11408456/214313498-5b1f8408-1fa3-4e24-810a-b9394e936c8e.png)
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: Implementation :: CPython', 'Topic :: Software Development :: Testing']","['Source Code, https://github.com/BaroudLab/anchor-droplet-chip']",anchor-droplet-chip.get_reader,,anchor-droplet-chip.DetectWells,anchor-droplet-chip.make_template,"['*.npy', '*.nd2', '*.zarr', '*.tif', '*.csv']",,,https://pypi.org/project/anchor-droplet-chip,,
3,annotrack,0.0.3,,,annotrack,Abigail S McGovern,abigail_mcgovern@hotmail.com,BSD-3-Clause,,napari plugin for annotating tracks to estimate error rates,>=3.7,"['dask', 'napari', 'numpy', 'zarr', 'pandas', ""sphinx ; extra == 'docs'"", ""nd2 ; extra == 'io'"", ""pytest ; extra == 'testing'""]","# annotrack
Annotrack is a napari plugin for annotating errors in object trajectories. The plugin will help you take a sample of track segments along with a small section of corresponding image and segmentation. Annotrack allows you to annotate three types of errors: (1) ID swap errors (track jumps between objects), (2) false starts (track starts on a pre-existing object) and false terminations (track ends but object still exists). By looking at the combined rates of false starts and false terminations you can assess track discontinutation errors. 

**Please note:** Images and segmentations must be in zarr format. Tracks should be in parquet format.  

## Installation 

There are three main ways to install annotrack:

### Install Using pip
*Please note that this is planned/under development*

Type the following into your terminal (MacOS or Ubuntu) or annaconda prompt (windows):

```bash
pip install annotrack
```

### Install
*Please note that this is planned/under development*

Type the following into your terminal (MacOS or Ubuntu) or annaconda prompt (windows):

```bash
install napari
napari
```

Once napari has opened (this may take a second the first time you open it), go to the pannel at the top of the screen and select the 'plugins' dropdown. Then select install/uninstall plugins. A new window will open showing available plugins. Either scroll down to or search 'annotrack' and click 'install'. 

### Install from Source Code
*please use this for now*

Type the following into your terminal (MacOS or Ubuntu) or annaconda prompt (windows):

```bash
git clone https://github.com/AbigailMcGovern/annotrack.git
cd annotrack
pip install .
```

## Opening Annotrack
Once annotrack is properly installed you will be able to open annotrack by opening napari. You can open napari through the command line (terminal (MacOS or Ubuntu) or annaconda prompt (windows)) as follows:

```bash
napari
```

You can find the annotrack widgets by selecting the dropdown 'plugins' at the pannel at the top of the screen and hovering over 'annotrack'.  

## Sample from CSV

To sample your tracks you will need to supply the file paths for the images, segmentations, and tracks. You supply this in a csv that is structured as shown below:

 ![csv_structure widget](https://github.com/AbigailMcGovern/annotrack/blob/main/media/csv_structure.png)

In this csv, you may also specify how many samples are to be taken from each file. If this is not provided, annotrack will use the value you supply to the `sample_from_csv` widget. The csv must contain a column that specifies a category to which each sample belongs (e.g., species, experimental condition, drug, etc.).  If this isnt important for your samples, just add a dummy category (e.g., sample_type : [A, A, A, A]). 

To access the widget and sample track segments, go to the top of the screen, go to **plugins > annotrack > sample_from_csv**. When the widget is displayed, select the csv file, select a directory into which to save results, and proivide a name for the summary data file (i.e., where your annotations will be written). 

 ![sample_from_csv widget](https://github.com/AbigailMcGovern/annotrack/blob/main/media/sample_from_csv.png)

### Widget parameters
- **path to csv**: 
        The path storing the info from which to generate the samples. 
        The CSV should have the columns: image_path, labels_path, tracks_path, <category_col>, 
        You can also add an optional n_samples column if you would like to 
        specify how many samples to take from each individual file. Otherwise, 
        the default ""n_samples"" you've supplied will be used.
- **output dir**: 
        Where will the output be saved?
- **output name**: 
        What will output summary files/directories be called?
- **n samples**: 
        How many samples to be obtained from each file. Will be overwritten
        if there is a valid integer number in the n_samples colum of the csv.
- **tzyx cols**: 
        What are the names of the columns denoting time (in frames) and coordinate
        positions (in pixels) in the file containing tracks? The order should be:
        t, z, y, x. 
- **id col**: 
        What is the name of the column denoting the specific ID for each tracked
        object?
- **scale**: 
        size of pixels (e.g., in um) for the z, y, and x coordinates (in that
        order)
- **frames**: 
        Approximate maximum number of frames of track segment. 
        Max frames = frames (if even) or frames - 1 (if odd)
- **box size**: 
        Approximate size of bounding box (in pixels). 
- **min track len**: 
        You can set a minimum track len to include in the search. 
        This can help to eliminate less useful data. This should be at least 1 to only include tracked objects. Set higher only if you are specifically interested in longer lived tracks. 
- **image channel**: 
        This denotes the index of the channel from which to get 
        image data (0: channel 1, 1: channel 2, 2: channel 3, 3: channel 4)

### Annotate Now?

In the case that we are annotating multiple conditions to compare, we want to show them in the one session in randomised order with the annotator blinded to where the sample has originated from. We want to be able to annotated unannotated data from the sample without having the burden of having to do this all at once. The annotations are therefore saved into the saved sample. A selected number of samples saved from the various tracking experiments can be annotated using the following code. If you re-execute this code, you will only be shown not yet annotated data, unless you request otherwise.

Keys to navagate and annotate samples
- '2' - move to next sample
- '1' - move to previous sample
- 'y' - annotate as correct (will move to the next sample automatically)
- 'n' - annotate as containing an error (will move to the next sample automatically)
- 'i' - annotate the frame following a ID swap error
- 't' - annotate the fame following an incorrect termination
- 'Shift-t' - annotate the frame containing a false start error
- 's' - annotate an error ('i', 't', or 'Shift-t') as being associated with a segmentation error (merge or split of objects)

When an error is associated the specific frame ('i', 't', 'Shift-t', or 's'), the frame number (within the original image) will be added to a list of errors for the sample within the sample's (.smpl) info data frame. E.g., you may have a list of ID swaps for your sampled track segment (`[108, 111, 112]`) and a corresponding list of segmentation error associations (`[108, 112]`). 

## Annotate Existing Sample
If you have already saved a sample and want to annotate it, you can load the sample data using the `annotate_existing_sample` widget. This might be useful if you want to have several annotators annotate the same sample. To access this widget, open napari

 ![annotate_existing_sample widget](https://github.com/AbigailMcGovern/annotrack/blob/main/media/annotate_existing_sample.png)

## Contributing and User Support

**User support:** If you have an issue with annotrack please add an issue (go to the Issues tab at the top of the GitHub page). If your issue is a bug, please include as much information as possible to help debug the problem. Examples of information include: details about the image and segmentation data (dimensions), number of images, number of samples you are trying to take. If you are requesting an improvement, try to be as clear as possible about what you need. 

**Contributing:** If you want to contribute to annotrack, please fork the repo and if you want to make changes make a pull request with as much detail about the change as possible. Please ensure any changes you want to make don't break the existing functions.
","['Programming Language :: Python :: 3', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Intended Audience :: Science/Research', 'Topic :: Scientific/Engineering', 'Topic :: Scientific/Engineering :: Image Processing', 'Framework :: napari']","['Bug Tracker, https://github.com/abigailmcgovern/annotrack/issues', 'Documentation, https://github.com/abigailmcgovern/annotrack#README.md', 'Source Code, https://github.com/abigailmcgovern/annotrack', 'User Support, https://github.com/abigailmcgovern/annotrack/issues']",,,annotrack.sample_from_csv,,,,,https://pypi.org/project/annotrack,,
4,napari ARCOS,0.1.3,2022-07-07,2024-02-15,arcos-gui,Benjamin Grädel,benjamin.graedel@unibe.ch,BSD-3-Clause,https://github.com/bgraedel/arcos-gui,A napari plugin to detect and visualize collective signaling events,>=3.8,"['arcos4py >=0.2.3', 'matplotlib >=3.3.4', 'napari >=0.4.14', 'numpy >=1.21.5', 'pandas >=1.3.5', 'pyarrow >=11.0.0', 'scikit-image >=0.18.1', 'scipy >=1.7.3', ""mkdocs ; extra == 'doc'"", ""mkdocs-include-markdown-plugin ; extra == 'doc'"", ""mkdocs-material ; extra == 'doc'"", ""mkdocs-material-extensions ; extra == 'doc'"", ""pyqt5 ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-mock ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'""]","# arcos-gui

[![License](https://img.shields.io/pypi/l/arcos-gui.svg?color=green)](https://github.com/bgraedel/arcos-gui/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/arcos-gui.svg)](https://pypi.org/project/arcos-gui)
[![conda-forge](https://img.shields.io/conda/vn/conda-forge/arcos-gui)](https://anaconda.org/conda-forge/arcos-gui)
[![Python Version](https://img.shields.io/pypi/pyversions/arcos-gui.svg?color=green?)](https://python.org)
[![tests](https://github.com/bgraedel/arcos-gui/workflows/tests/badge.svg)](https://github.com/bgraedel/arcos-gui/actions)
[![codecov](https://codecov.io/gh/bgraedel/arcos-gui/branch/main/graph/badge.svg)](https://codecov.io/gh/bgraedel/arcos-gui)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/arcos-gui)](https://napari-hub.org/plugins/arcos-gui)

A napari plugin to detect and visualize collective signaling events

----------------------------------
- Package specific Documentation: <https://bgraedel.github.io/arcos-gui>
- ARCOS documentation: <https://arcos.gitbook.io>

**A**utomated **R**ecognition of **C**ollective **S**ignalling (ARCOS) is an algorithm to identify collective spatial events in time series data.
It is available as an [R (ARCOS)](https://github.com/dmattek/ARCOS) and [python (arcos4py)](https://github.com/bgraedel/arcos4py) package.
ARCOS can identify and visualize collective protein activation in 2- and 3D cell cultures over time.

This plugin integrates ARCOS into napari. Users can import tracked time-series data in CSV format or load data from napari-layer properties (such as the ones generated with [napari-skimage-regionprops](https://www.napari-hub.org/plugins/napari-skimage-regionprops). The plugin
provides GUI elements to process this data with ARCOS. Layers containing the detected collective events are subsequently added to the viewer.

Following analysis, the user can export the output as a CSV file with the detected collective events or as a sequence of images to generate a movie.


![](https://github.com/bgraedel/arcos-gui/assets/100028238/66fa2afa-6f24-4cce-b29e-4279066c6c25)

[Watch full demo on youtube](https://www.youtube.com/watch?v=hG_z_BFcAiQ) (older plugin version)


# Installation

You can install `arcos-gui` via [pip]:

    pip install arcos-gui

Or via [conda-forge]:

    conda install -c conda-forge arcos-gui

## Usage

The plugin can be started from the napari menu `Plugins > ARCOS GUI`.
For detailed instructions on how to use the plugin, please refer to the [Usage section of the documentation](https://bgraedel.github.io/arcos-gui/Usage).

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.
See the [Contributing Guide](https://bgraedel.github.io/arcos-gui/Contributing) for more information.

## License

Distributed under the terms of the [BSD-3] license,
""arcos-gui"" is free and open-source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/bgraedel/arcos-gui/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/arcos-gui/
[conda-forge]: https://anaconda.org/conda-forge/arcos-gui
[PyPI]: https://pypi.org/

## Credits
We were able to develop this plugin in part due to funding from the [CZI napari Plugin Foundation Grant](https://chanzuckerberg.com/science/programs-resources/imaging/napari/detecting-and-quantifying-space-time-correlations-in-cell-signaling/).

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

## Citation

If you use this plugin in your research, please cite the following [paper](https://doi.org/10.1083/jcb.202207048):

    @article{10.1083/jcb.202207048,
        author = {Gagliardi, Paolo Armando and Grädel, Benjamin and Jacques, Marc-Antoine and Hinderling, Lucien and Ender, Pascal and Cohen, Andrew R. and Kastberger, Gerald and Pertz, Olivier and Dobrzyński, Maciej},
        title = ""{Automatic detection of spatio-temporal signaling patterns in cell collectives}"",
        journal = {Journal of Cell Biology},
        volume = {222},
        number = {10},
        pages = {e202207048},
        year = {2023},
        month = {07},
        abstract = ""{Increasing experimental evidence points to the physiological importance of space–time correlations in signaling of cell collectives. From wound healing to epithelial homeostasis to morphogenesis, coordinated activation of biomolecules between cells allows the collectives to perform more complex tasks and to better tackle environmental challenges. To capture this information exchange and to advance new theories of emergent phenomena, we created ARCOS, a computational method to detect and quantify collective signaling. We demonstrate ARCOS on cell and organism collectives with space–time correlations on different scales in 2D and 3D. We made a new observation that oncogenic mutations in the MAPK/ERK and PIK3CA/Akt pathways of MCF10A epithelial cells hyperstimulate intercellular ERK activity waves that are largely dependent on matrix metalloproteinase intercellular signaling. ARCOS is open-source and available as R and Python packages. It also includes a plugin for the napari image viewer to interactively quantify collective phenomena without prior programming experience.}"",
        issn = {0021-9525},
        doi = {10.1083/jcb.202207048},
        url = {https://doi.org/10.1083/jcb.202207048},
        eprint = {https://rupress.org/jcb/article-pdf/222/10/e202207048/1915749/jcb/_202207048.pdf},
    }
","['Development Status :: 4 - Beta', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Topic :: Software Development :: Testing']","['Bug Tracker, https://github.com/bgraedel/arcos-gui/issues', 'Documentation, https://bgraedel.github.io/arcos-gui/', 'Source Code, https://github.com/bgraedel/arcos-gui', 'User Support, https://github.com/bgraedel/arcos-gui/issues']",,,arcos-gui.MainWindow,arcos-gui.data.arcos_sample_data_1,,,,https://pypi.org/project/arcos-gui,https://github.com/bgraedel/arcos-gui,
5,napari avidaq,0.0.5,2022-08-19,2023-06-18,avidaq,Riley M Shea,RileyMShea@gmail.com,BSD-3-Clause,https://pypi.org/project/avidaq/,controls for napari and micromanger,>=3.8,"['magicgui', 'numpy', 'pycromanager', 'qtpy', ""twine ; extra == 'build'"", ""black ; extra == 'testing'"", ""ipykernel ; extra == 'testing'"", ""matplotlib ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'"", ""pyright ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""tox ; extra == 'testing'"", ""yappi ; extra == 'testing'""]","# avidaq

[![PyPI](https://img.shields.io/pypi/v/avidaq.svg?color=green)](https://pypi.org/project/avidaq)
[![Python Version](https://img.shields.io/pypi/pyversions/avidaq.svg?color=green)](https://python.org)
[![tests](https://github.com/optimax/avidaq/workflows/tests/badge.svg)](https://github.com/optimax/avidaq/actions)
[![codecov](https://codecov.io/gh/optimax/avidaq/branch/main/graph/badge.svg)](https://codecov.io/gh/optimax/avidaq)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/avidaq)](https://napari-hub.org/plugins/avidaq)

controls for napari and micromanger

---

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/index.html
-->

## Installation

### Standard installation

You can install `avidaq` via [pip]:

```shell
pip install napari[all] avidaq
```

### Install from plugin menu

Alternatively you can install `avidaq` via the [napari] plugin menu:

## ![napari-add-plugin](napari-add-plugin.png)

## Running

First start micromanager.  Make sure the server port checkbox is activated.

Then to start napari with the avidaq plugin active run:
`napari -w avidaq`

![](screenshot.png)

## Updating presets

MDA presets are stored in a json file in the user's home directory.

```shell

`C:\\Users\YourName\.avidaq\mda_presets.json`
```

This file should exist after plugin installation with some defaults. You do not need to create the file yourself.

Add or modify the values and reload napari to see the changes.

All parameter entries are optional, if not provided the default value will be used.

The parameter names and their descriptions can be found [here] (https://github.com/micro-manager/pycro-manager/blob/main/pycromanager/acq_util.py#L102-L115)

The format is as follows:

```json
{
    ""gui_display_name"": {
        ""parameter_name"": value,
        ""parameter_name"": value,
        ...
    },
    ""gui_display_name"": {
        ""parameter_name"": value,
        ""parameter_name"": value,
        ...
    },
    ...
}
```

defaults:

```json
{
  ""Basic"": {
    ""num_time_points"": 5,
    ""z_start"": 0,
    ""z_end"": 6,
    ""z_step"": 0.4
  },
  ""Simple"": {
    ""num_time_points"": 2,
    ""z_start"": 0,
    ""z_end"": 2,
    ""z_step"": 0.1
  },
  ""Detailed"": {
    ""num_time_points"": 10,
    ""z_start"": 0,
    ""z_end"": 12,
    ""z_step"": 0.2
  }
}
```

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

## Development

You should have python3.8 or higher installed.

1. clone this repo
2. create a virtual environment `python -m venv .venv && source .venv/bin/activate`
3. run `pip install -e '.[testing,build]'`
4. run `pre-commit install`

### To run unit tests

`pytest`

### typical workflow

1. edit code in `/src`
2. run napari -w avidaq
3. repeat

### Releasing to pypi


Project is automically built and deployed to pypi upon


---

[napari]: https://github.com/napari/napari
[cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[mit]: http://opensource.org/licenses/MIT
[bsd-3]: http://opensource.org/licenses/BSD-3-Clause
[gnu gpl v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[gnu lgpl v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[apache software license 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[mozilla public license 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[pypi]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing', 'Typing :: Typed']",,avidaq.get_reader,avidaq.write_multiple,avidaq.make_qwidget,avidaq.make_sample_data,['*.npy'],,['.npy'],https://pypi.org/project/avidaq/,,
6,bbii-decon,0.0.1,2022-02-11,2023-06-18,bbii-decon,"Graham Dellaire, Robert Haase",dellaire@Dal.Ca,BSD-3-Clause,https://github.com/gdellaire/bbii-decon,Projected Barzilai-Borwein Image Deconvolution with Infeasible Iterates (BBii-Decon),>=3.7,"['napari-plugin-engine (>=0.1.4)', 'numpy', 'pypher']","# BBii-Decon

[![License](https://img.shields.io/pypi/l/bbii-decon.svg?color=green)](https://github.com/gdellaire/bbii-decon/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/bbii-decon.svg?color=green)](https://pypi.org/project/bbii-decon)
[![Python Version](https://img.shields.io/pypi/pyversions/bbii-decon.svg?color=green)](https://python.org)
[![tests](https://github.com/gdellaire/bbii-decon/workflows/tests/badge.svg)](https://github.com/gdellaire/bbii-decon/actions)
[![codecov](https://codecov.io/gh/gdellaire/bbii-decon/branch/main/graph/badge.svg)](https://codecov.io/gh/gdellaire/bbii-decon)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/bbii-decon)](https://napari-hub.org/plugins/bbii-decon)

Projected Barzilai-Borwein Image Deconvolution with Infeasible Iterates (BBii-Decon)


The projected Barzilai-Borwein method of image deconvolution utilizing infeasible iterates (BBii-Decon), utilizes Barzilai-Borwein (BB) or projected BB (PBB) method and enforces a nonnegativity constraint, but allows for infeasible iterates between projections. This algorithm (BBii) results in faster convergence than the basic PBB method, while achieving better quality images, with reduced background than the unconstrained BB method (1). 

The code represented is based on the original BBii algorithm written in MatLab by Kathleen Fraser and Dirk Arnold, which was ported to python 3.8 by Graham Dellaire, Dirk Arnold and Kathleen Fraser for non-commercial use.

The first implementation shown here is for 2D deconvolution using a known 2D PSF of 256 X 256 pixels, and images of at least 256 pixels in one dimension. One file implements just the deconvolution of a blurred image, while the second file contains a modification of the BBii-Decon algorithm that has a built in heuristic for measuring image reconstruction error relative to a ground truth image. For general 2D deconvolution, either a theoretical 2D PSF (if you know the optical properties of your system) or the central in focus image of a fluorescent bead taken with the same imaging setup (lens, magnification, camera) can produce a suitable PSF.

### GPU-acceleration

For most 2D deconvolution, optimal results are obtained with 10 iterations of the algorithm. However, if processing takes too long, acceleration using graphics processing units (GPUs) may make sense, especially for processing larger images with >10 iterations or 3D images. (Note: At this time BBii-Decon is optimized for 2D deconvolution, with a 3D implementation planned in future). 

This plugin supports accelerated processing using the [cupy](https://cupy.dev) library. To make use of it, please follow 
[the instructions](https://docs.cupy.dev/en/stable/install.html#installing-cupy-from-conda-forge) to install cupy. 
Installation may look like this:
```
conda create --name cupy_p38 python=3.8
conda activate cupy_p38
conda install -c conda-forge cupy cudatoolkit=10.2
```

If cupy installation worked out, you will find another checkbox in the user interface. By activating it, processing 
should become faster by factor 5-10, depending on processed image data and use GPU hardware.

![img.png](https://github.com/gdellaire/BBii-Decon/raw/main/demo/use_GPU_checkbox.png)

## Usage - napari

You can use the BBii deconvolution from within napari by clicking the menu `Plugins > bbii-decon > bbii deconvolution`. 
In the dialog, select the PSF, the image to process (a) and click on `Run`. After a moment, the deconvolved image (b) 
will show up.

![img.png](https://github.com/gdellaire/BBii-Decon/raw/main/demo/screenshot_napari.png)

## Usage from python

You can also call the function from python. There is a full working example in [this notebook](demo/BBii_Decon_2D_2021.ipynb).

```
from bbii_decon import bbii

bbii(PSF, image, number_of_iterations = 15, tau = 1.0e-08, rho = 0.98)
```


## Citation
1) [Kathleen Fraser, Dirk V. Arnold, and Graham Dellaire (2014). Projected Barzilai-Borwein
method with infeasible iterates for nonnegative least-squares image deblurring. In Proceedings
of the Eleventh Conference on Computer and Robot Vision (CRV 2014), Montreal, Canada, pp.
189--194.](https://ieeexplore.ieee.org/abstract/document/6816842)

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/stable/index.html
-->

## Installation

You can install `bbii-decon` via [pip]:

    pip install bbii-decon


## Installation for developers

Clone the github repository:

```
conda install git

git clone https://github.com/gdellaire/BBii-Decon.git

cd BBii-Decon

pip install -e .
```

## Deployment to pypi

For deploying the plugin to the python package index (pypi), one needs a [pypi user account](https://pypi.org/account/register/) 
first. For deploying the plugin to pypi, one needs to install some tools:

```
python -m pip install --user --upgrade setuptools wheel
python -m pip install --user --upgrade twine
```

The following command allows us to package the souce code as a python wheel. Make sure that the 'dist' and 'build' folders are deleted before doing this:

```
python setup.py sdist bdist_wheel
```

This command ships the just generated to pypi:

```
python -m twine upload --repository pypi dist/*
```

[Read more about distributing your python package via pypi](https://realpython.com/pypi-publish-python-package/#publishing-to-pypi).


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""bbii-decon"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/gdellaire/bbii-decon/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/


","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/gdellaire/bbii-decon/issues', 'Documentation, https://github.com/gdellaire/bbii-decon#README.md', 'Source Code, https://github.com/gdellaire/bbii-decon', 'User Support, https://github.com/gdellaire/bbii-decon/issues']",,,bbii-decon.napari_experimental_provide_function,,,,,https://pypi.org/project/bbii-decon,https://github.com/gdellaire/bbii-decon,
7,beetlesafari,0.4.0,2022-06-13,2023-06-18,beetlesafari,Robert Haase,robert.haase@tu-dresden.de,,https://github.com/haesleinhuepf/beetlesafari,"A napari plugin for loading and working with light sheet imaging data of developing embryos acquired using ClearControl, e.g. _Tribolium castaneum_.",>=3.7,"['numpy', 'pyopencl', 'toolz', 'scikit-image', 'requests', 'pyclesperanto-prototype', 'napari', 'magicgui', 'dask', 'cachetools', 'napari-tools-menu']","A library for working with light sheet imaging data of developing embryos acquired using [ClearControl](https://github.com/ClearControl) at the [Center for Systems Biology Dresden](https://www.csbdresden.de/), e.g. _Tribolium castaneum_.

# Installation
```
conda install -c conda-forge pyopencl
pip install beetlesafari
```
","['Programming Language :: Python :: 3', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Framework :: napari', 'Intended Audience :: Science/Research', 'Development Status :: 3 - Alpha']",,,,,,,,,https://pypi.org/project/beetlesafari,https://github.com/haesleinhuepf/beetlesafari,
8,blik,0.6.13,2022-07-11,2023-11-16,blik,Lorenzo Gaifas,Lorenzo Gaifas <brisvag@gmail.com>,GPLv3,https://github.com/gutsche-lab/blik,Python tool for visualising and interacting with cryo-ET and subtomogram averaging data.,>=3.9,"['cryohub>=0.6.4', 'cryotypes>=0.2.0', 'dask', 'einops', 'magicgui>=0.4.0', 'morphosamplers>=0.0.10', 'numpy', 'packaging', 'pandas', 'pydantic<2', 'scipy', ""napari-label-interpolator>=0.1.1; extra == 'all'"", ""napari-properties-plotter; extra == 'all'"", ""napari-properties-viewer; extra == 'all'"", ""napari[all]>=0.4.19; extra == 'all'"", ""black; extra == 'dev'"", ""ipython; extra == 'dev'"", ""mypy; extra == 'dev'"", ""napari[all]>=0.4.19; extra == 'dev'"", ""pdbpp; extra == 'dev'"", ""pre-commit; extra == 'dev'"", ""pytest-cov; extra == 'dev'"", ""pytest-qt; extra == 'dev'"", ""pytest>=6.0; extra == 'dev'"", ""rich; extra == 'dev'"", ""ruff; extra == 'dev'"", ""napari[all]>=0.4.19; extra == 'test'"", ""pytest-cov; extra == 'test'"", ""pytest-qt; extra == 'test'"", ""pytest>=6.0; extra == 'test'""]","![logo](https://github.com/brisvag/blik/raw/main/docs/images/logo.png)

# blik

[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.10090438.svg)](https://zenodo.org/doi/10.5281/zenodo.10090438)
[![License](https://img.shields.io/pypi/l/blik.svg?color=green)](https://github.com/brisvag/blik/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/blik.svg?color=green)](https://pypi.org/project/blik)
[![Python Version](https://img.shields.io/pypi/pyversions/blik.svg?color=green)](https://python.org)
[![CI](https://github.com/brisvag/blik/actions/workflows/ci.yml/badge.svg)](https://github.com/brisvag/blik/actions/workflows/ci.yml)
[![codecov](https://codecov.io/gh/brisvag/blik/branch/main/graph/badge.svg)](https://codecov.io/gh/brisvag/blik)


![blik showcase](https://user-images.githubusercontent.com/23482191/161224963-ad746a06-c2e5-46fe-a13b-f356bc4ad72b.png)

**`blik`** is a tool for visualising and interacting with cryo-ET and subtomogram averaging data. It leverages the fast, multi-dimensional [napari viewer](https://napari.org) and the scientific python stack.

**DISCLAIMER**: this package is in development phase. Expect bugs and crashes. Please, report them on the issue tracker and ask if anything is unclear!

## Installation

You can either install `blik` through the [napari plugin system](https://napari.org/plugins/index.html), through pip, or get both napari and blik directly with:

```bash
pip install ""blik[all]""
```

The `[all]` qualifier also installs `pyqt5` as the napari GUI backend, and a few additional napari plugins that you might find useful in your workflow:
- [napari-properties-plotter](https://github.com/brisvag/napari-properties-plotter)
- [napari-properties-viewer](https://github.com/kevinyamauchi/napari-properties-viewer)
- [napari-label-interpolator](https://github.com/brisvag/napari-label-interpolator)

### Nightly build

If you'd like the most up to date `blik` possible, you can install directly from the `main` branch on github. This also uses napari `main`, so expect some instability!

```
pip install ""git+https://github.com/brisvag/blik.git@main#egg=blik[all]""
pip install ""git+https://github.com/napari/napari.git@main#egg=napari[all]""
```

## Basic Usage

From the command line:
```bash
napari -w blik -- /path/to.star /path/to/mrc/files/*
```

The `-w blik` is important for proper initialization of all the layers. Always open the main widget open to ensure nothing goes wrong!

*`blik` is just `napari`*. Particles and images are exposed as simple napari layers, which can be analysed and manipulated with simple python, and most importantly other [napari plugins](https://napari-hub.org/).

## Widgets

The main widget has a few functions:

- `experiment`: quickly switch to a different experiment id (typically, everything related to an individual tomogram such as volume, particles and segmentations)
- `new`: generate a new `segmentation`, a new manually-picked set of `particles`, or a new `surface picking` or `filament picking` for segmentation, particle generation or volume resampling.
- `add to exp`: add a layer to the currently selected `experiment` (just a shorthand for `layer.metadata['experiment_id'] = current_exp_id`)
- `slice_thickness`: changes the slicing thickness in all dimensions in napari. Images will be averaged over that thickness, and all particles in the slice will be displayed.

There are also widgets for picking of both surfaces and filaments.

- `surface`: process a previously picked `surface picking` layer to generate a surface mesh and distribute particles on it for subtomogram averaging, or resample a tomogram along the surface.
- `filament`: process a previously picked `filament picking` layer to generate a filament and distribute particles on it for subtomogram averaging, or resample a tomogram along the filament.

# References

A paper preprint about `blik` is available on the bioRxiv: [https://doi.org/10.1101/2023.12.05.570263](https://doi.org/10.1101/2023.12.05.570263).
","['Development Status :: 3 - Alpha', 'Framework :: napari', 'License :: OSI Approved :: GNU General Public License v3 (GPLv3)', 'Natural Language :: English', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Topic :: Scientific/Engineering :: Visualization', 'Typing :: Typed']","['homepage, https://github.com/brisvag/blik', 'repository, https://github.com/brisvag/blik']",blik.get_reader,blik.write_image,blik.main_widget,,"['*.mrc', '*.mrcs', '*.st', '*.map', '*.hdf', '*.em', '*.star', '*.tbl', '*.box', '*.cbox', '*.picks', '*.surf', '*.rec']","['.mrc', '.mrcs', '.st', '.rec']","['.mrc', '.mrcs', '.st']",https://pypi.org/project/blik,https://github.com/gutsche-lab/blik,
9,brainglobe-napari-io,0.3.4,2022-02-13,2024-04-23,brainglobe-napari-io,Adam Tyson,Adam Tyson <hello@brainglobe.info>,BSD-3-Clause,https://brainglobe.info,Read and write files from the BrainGlobe computational neuroanatomy suite into napari,>=3.9.0,"['brainglobe-atlasapi >=2.0.1', 'brainglobe-space >=1.0.0', 'brainglobe-utils', 'napari', 'tifffile >=2020.8.13', 'numpy', 'pandas', ""pytest ; extra == 'dev'"", ""pytest-cov ; extra == 'dev'"", ""coverage ; extra == 'dev'"", ""tox ; extra == 'dev'"", ""black ; extra == 'dev'"", ""mypy ; extra == 'dev'"", ""pre-commit ; extra == 'dev'"", ""ruff ; extra == 'dev'"", ""setuptools-scm ; extra == 'dev'""]","# napari-brainglobe-io

[![License](https://img.shields.io/pypi/l/brainglobe-napari-io.svg?color=green)](https://github.com/brainglobe/brainglobe-napari-io/blob/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/brainglobe-napari-io.svg?color=green)](https://pypi.org/project/brainglobe-napari-io)
[![Python Version](https://img.shields.io/pypi/pyversions/brainglobe-napari-io.svg?color=green)](https://python.org)
[![tests](https://github.com/brainglobe/brainglobe-napari-io/workflows/tests/badge.svg)](https://github.com/brainglobe/brainglobe-napari-io/actions)
[![codecov](https://codecov.io/gh/brainglobe/brainglobe-napari-io/branch/master/graph/badge.svg)](https://codecov.io/gh/brainglobe/brainglobe-napari-io)

Visualise cellfinder and brainreg results with napari


----------------------------------


## Installation
This package is likely already installed
(e.g. with cellfinder, brainreg or another napari plugin), but if you want to
install it again, either use the napari plugin install GUI or you can
install `brainglobe-napari-io` via [pip]:

    pip install brainglobe-napari-io

## Usage
* Open napari (however you normally do it, but typically just type `napari` into your terminal, or click on your desktop icon)

### brainreg
#### Sample space
Drag your [brainreg](https://github.com/brainglobe/brainreg) output directory (the one with the log file) onto the napari window.

Various images should then open, including:
* `Registered image` - the image used for registration, downsampled to atlas resolution
* `atlas_name` - e.g. `allen_mouse_25um` the atlas labels, warped to your sample brain
* `Boundaries` - the boundaries of the atlas regions

If you downsampled additional channels, these will also be loaded.

Most of these images will not be visible by default. Click the little eye icon to toggle visibility.

_N.B. If you use a high resolution atlas (such as `allen_mouse_10um`), then the files can take a little while to load._

![sample_space](https://raw.githubusercontent.com/brainglobe/brainglobe-napari-io/master/resources/sample_space.gif)


#### Atlas space
`napari-brainreg` also comes with an additional plugin, for visualising your data
in atlas space.

This is typically only used in other software, but you can enable it yourself:
* Open napari
* Navigate to `Plugins` -> `Plugin Call Order`
* In the `Plugin Sorter` window, select `napari_get_reader` from the `select hook...` dropdown box
* Drag `brainreg_read_dir_atlas_space` (the atlas space viewer plugin) above `brainreg_read_dir` (the normal plugin) to ensure that the atlas space plugin is used preferentially.


### cellfinder
#### Load cellfinder XML file
* Load your raw data (drag and drop the data directories into napari, one at a time)
* Drag and drop your cellfinder XML file (e.g. `cell_classification.xml`) into napari.

#### Load cellfinder directory
* Load your raw data (drag and drop the data directories into napari, one at a time)
* Drag and drop your cellfinder output directory into napari.

The plugin will then load your detected cells (in yellow) and the rejected cell
candidates (in blue). If you carried out registration, then these results will be
overlaid (similarly to the loading brainreg data, but transformed to the
coordinate space of your raw data).

![load_data](https://raw.githubusercontent.com/brainglobe/brainglobe-napari-io/master/resources/load_data.gif)
**Loading raw data**

![load_data](https://raw.githubusercontent.com/brainglobe/brainglobe-napari-io/master/resources/load_results.gif)
**Loading cellfinder results**



## Contributing
Please see the [developers guide](https://brainglobe.info/developers/index.html).

## License

Distributed under the terms of the [MIT] license,
""brainglobe-napari-io"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/brainglobe/brainglobe-napari-io/issues
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 4 - Beta', 'Framework :: napari', 'Intended Audience :: Science/Research', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Topic :: Scientific/Engineering :: Image Recognition']","['Homepage, https://brainglobe.info', 'Source Code, https://github.com/brainglobe/brainglobe-napari-io', 'Bug Tracker, https://github.com/brainglobe/brainglobe-napari-io/issues', 'Documentation, https://docs.brainglobe.info', 'User Support, https://forum.image.sc/tag/brainglobe', 'Twitter, https://twitter.com/brain_globe']",brainglobe-napari-io.brainreg_read_dir,brainglobe-napari-io.cellfinder_write_multiple_xml,,,['*.tiff'],['.xml'],,https://pypi.org/project/brainglobe-napari-io,,https://brainglobe.info
10,brainglobe-segmentation,1.2.3,2023-11-18,2024-03-20,brainglobe-segmentation,"Adam Tyson, Horst Obenhaus","""Adam Tyson, Horst Obenhaus"" <code@adamltyson.com>",BSD-3-Clause,https://pypi.org/project/brainglobe-segmentation,Segmentation of anatomical structures in a common coordinate space,>=3.9,"['brainglobe-atlasapi >=2.0.1', 'brainglobe-napari-io >=0.3.0', 'brainglobe-utils >=0.4.0', 'napari >=0.4.5', 'numpy', 'pandas[hdf5]', 'qtpy', 'scikit-image', 'scipy', 'tifffile', ""black ; extra == 'dev'"", ""gitpython ; extra == 'dev'"", ""pre-commit ; extra == 'dev'"", ""pytest ; extra == 'dev'"", ""coverage ; extra == 'dev'"", ""pytest-cov ; extra == 'dev'"", ""pytest-qt ; extra == 'dev'"", ""napari-time-slicer ; extra == 'dev'""]","[![Python Version](https://img.shields.io/pypi/pyversions/brainglobe-segmentation.svg)](https://pypi.org/project/brainglobe-segmentation)
[![PyPI](https://img.shields.io/pypi/v/brainglobe-segmentation.svg)](https://pypi.org/project/brainglobe-segmentation)
[![Wheel](https://img.shields.io/pypi/wheel/brainglobe-segmentation.svg)](https://pypi.org/project/brainglobe-segmentation)
[![Development Status](https://img.shields.io/pypi/status/brainglobe-segmentation.svg)](https://github.com/brainglobe/brainglobe-segmentation)
[![Tests](https://img.shields.io/github/actions/workflow/status/brainglobe/brainglobe-segmentation/test_and_deploy.yml?branch=main)](https://github.com/brainglobe/brainglobe-segmentation/actions)
[![codecov](https://codecov.io/gh/brainglobe/brainglobe-segmentation/graph/badge.svg?token=WP9KTPZE5R)](https://codecov.io/gh/brainglobe/brainglobe-segmentation)
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/python/black)
[![Twitter](https://img.shields.io/twitter/follow/brain_globe?style=social)](https://twitter.com/brain_globe)

# brainglobe-segmentation

Segmentation of anatomical structures in a common coordinate space

## Installation
**PyPI**
```
pip install brainglobe-segmentation
```

**conda**
```
conda install -c conda-forge brainglobe-segmentation
```

N.B. Your data will need to be registered to an anatomical atlas first.
## Usage

See [user guide](https://brainglobe.info/documentation/brainglobe-segmentation/index.html).

If you have any questions, head over to the [image.sc forum](https://forum.image.sc/tag/brainglobe).

## Contributing

Contributions are very welcome. Please see the [developers guide](https://brainglobe.info/community/developers/index.html).

### Citing brainglobe-segmentation

If you find brainglobe-segmentation useful, and use it in your research, please let us know and also cite the paper:

> Tyson, A. L., V&eacute;lez-Fort, M.,  Rousseau, C. V., Cossell, L., Tsitoura, C., Lenzi, S. C., Obenhaus, H. A., Claudi, F., Branco, T.,  Margrie, T. W. (2022). Accurate determination of marker location within whole-brain microscopy images. Scientific Reports, 12, 867 [doi.org/10.1038/s41598-021-04676-9](https://doi.org/10.1038/s41598-021-04676-9)
","['Development Status :: 4 - Beta', 'Framework :: napari', 'Intended Audience :: Developers', 'Intended Audience :: Science/Research', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11']","['Homepage, https://brainglobe.info/', 'Source Code, https://github.com/brainglobe/brainglobe-segmentation', 'Bug Tracker, https://github.com/brainglobe/brainglobe-segmentation/issues', 'Documentation, https://brainglobe.info/documentation/brainglobe-segmentation/index.html', 'User Support, https://forum.image.sc/tag/brainglobe']",,,brainglobe-segmentation.SegmentationWidget,,,,,https://pypi.org/project/brainglobe-segmentation,,
11,brainreg,1.0.8,2023-03-01,2024-04-09,brainreg,"Adam Tyson, Charly Rousseau, Stephen Lenzi","""Adam Tyson, Charly Rousseau, Stephen Lenzi"" <code@adamltyson.com>",BSD 3-Clause,https://docs.brainglobe.info/brainreg/introduction,Automated multi-atlas whole-brain microscopy registration,>=3.9,"['brainglobe-atlasapi >=2.0.1', 'brainglobe-space >=1.0.0', 'brainglobe-utils >=0.4.3', 'fancylog', 'numpy', 'scikit-image', ""black ; extra == 'dev'"", ""check-manifest ; extra == 'dev'"", ""gitpython ; extra == 'dev'"", ""napari[pyqt5] ; extra == 'dev'"", ""pre-commit ; extra == 'dev'"", ""pytest-cov ; extra == 'dev'"", ""pytest-qt ; extra == 'dev'"", ""pytest-mock ; extra == 'dev'"", ""pytest ; extra == 'dev'"", ""setuptools-scm ; extra == 'dev'"", ""tox ; extra == 'dev'"", ""brainglobe-napari-io >=0.3.2 ; extra == 'napari'"", ""brainglobe-segmentation >=1.0.0 ; extra == 'napari'"", ""magicgui ; extra == 'napari'"", ""napari-plugin-engine >=0.1.4 ; extra == 'napari'"", ""napari[pyqt5] ; extra == 'napari'"", ""pooch >1 ; extra == 'napari'"", ""qtpy ; extra == 'napari'""]","[![Python Version](https://img.shields.io/pypi/pyversions/brainreg.svg)](https://pypi.org/project/brainreg)
[![PyPI](https://img.shields.io/pypi/v/brainreg.svg)](https://pypi.org/project/brainreg)
[![Wheel](https://img.shields.io/pypi/wheel/brainreg.svg)](https://pypi.org/project/brainreg)
[![Development Status](https://img.shields.io/pypi/status/brainreg.svg)](https://github.com/brainglobe/brainreg)
[![Tests](https://img.shields.io/github/actions/workflow/status/brainglobe/brainreg/test_and_deploy.yml?branch=main)](https://github.com/brainglobe/brainreg/actions)
[![codecov](https://codecov.io/gh/brainglobe/brainreg/branch/master/graph/badge.svg?token=FbPgwBIGnd)](https://codecov.io/gh/brainglobe/brainreg)
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/python/black)

# brainreg

brainreg is an update to [amap](https://github.com/SainsburyWellcomeCentre/amap_python) (which is itself a port
of the [original Java software](https://www.nature.com/articles/ncomms11879)) to include multiple registration backends, and to support the many atlases provided by [brainglobe-atlasapi](https://github.com/brainglobe/brainglobe-atlasapi).
It also comes with an optional [napari plugin](https://github.com/brainglobe/brainreg-napari) if you'd rather use brainreg with through graphical interface.

Documentation for both the command-line tool and graphical interface can be found [here](https://brainglobe.info/documentation/brainreg/index.html).
If you have any issues, please get in touch [on the forum](https://forum.image.sc/tag/brainglobe), [on Zulip](https://brainglobe.zulipchat.com/), or by
[raising an issue](https://github.com/brainglobe/brainreg/issues).

For segmentation of bulk structures in 3D space (e.g. injection sites, Neuropixels probes), please see [brainglobe-segmentation](https://github.com/brainglobe/brainglobe-segmentation).

## Details

The aim of brainreg is to register the template brain (e.g. from the [Allen Reference Atlas](https://mouse.brain-map.org/static/atlas)) to the sample image.
Once this is complete, any other image in the template space can be aligned with the sample (such as region annotations, for segmentation of the sample image).
The template to sample transformation can also be inverted, allowing sample images to be aligned in a common coordinate space.

To do this, the template and sample images are filtered, and then registered in a three step process (reorientation, affine registration, and freeform registration).
The resulting transform from template to standard space is then applied to the atlas.

Full details of the process are in the [original aMAP paper](https://www.nature.com/articles/ncomms11879).

![An illustrated overview of the registration process](https://user-images.githubusercontent.com/13147259/143553945-a046e918-7614-4211-814c-fc840bb0159d.png)

## Installation

To install both the command line tool and the napari plugin, run

```bash
pip install brainreg[napari]
```

in your desired Python environment.
To only install the command line tool with no GUI (e.g. to run brainreg on an HPC cluster), just run:

```bash
pip install brainreg
```

### Installing on macOS

If you are using macOS, please run

```bash
conda install -c conda-forge niftyreg
```

in your environment before installing, to ensure all dependencies are installed.

## Command line usage

### Basic usage

```bash
brainreg /path/to/raw/data /path/to/output/directory -v 5 2 2 --orientation psl
```

Full command-line arguments are available with `brainreg -h`, but please
[get in touch](mailto:code@adamltyson.com?subject=brainreg) if you have any questions.

### Mandatory arguments

- Path to the directory of the images. This can also be a text file pointing to the files.
- Output directory for all intermediate and final results.
- You must also specify the voxel sizes with the `-v` flag, see [specifying voxel size](https://brainglobe.info/documentation/general/image-definition.html#voxel-sizes) for details.

### Atlas

By default, brainreg will use the 25um version of the [Allen Mouse Brain Atlas](https://mouse.brain-map.org/).
To use another atlas (e.g. for another species, or another resolution), you must use the `--atlas` flag, followed by the string describing the atlas, e.g.:

```bash
--atlas allen_mouse_50um
```

To find out which atlases are available, once brainreg is installed, please run `brainglobe list`.
The name of the resulting atlases is the string to pass with the `--atlas` flag.

### Input data orientation

If your data does not match the BrainGlobe default orientation (the origin voxel is the most anterior, superior, left-most voxel), then you must specify the orientation by using the `--orientation` flag.
What follows must be a string in the [brainglobe-space](https://github.com/brainglobe/brainglobe-space) ""initials"" form, to describe the origin voxel.

If the origin of your data (first, top left voxel) is the most anterior, superior, left part of the brain, then the orientation string would be ""asl"" (anterior, superior, left), and you would use:

```bash
--orientation asl
```

### Registration options

To change how the actual registration performs, see [registration parameters](https://brainglobe.info/documentation/brainreg/user-guide/parameters.html)

### Additional options

- `-a` or `--additional` Paths to N additional channels to downsample to the same coordinate space.
- `--sort-input-file` If set to true, the input text file will be sorted using natural sorting. This means that the file paths will be sorted as would be expected by a human and not purely alphabetically.
- `--brain_geometry` Can be one of `full` (default) for full brain registration, `hemisphere_l` for left hemisphere data-set and `hemisphere_r` for right hemisphere data-set.

### Misc options

- `--n-free-cpus` The number of CPU cores on the machine to leave unused by the program to spare resources.
- `--debug` Debug mode. Will increase verbosity of logging and save all intermediate files for diagnosis of software issues.
- `--save-original-orientation` Option to save the registered atlas with the same orientation as the input data.

## Visualising results

If you have installed the optional [napari](https://github.com/napari/napari) plugin, you can use napari to view your data.
The plugin automatically fetches the [brainglobe-napari-io](https://github.com/brainglobe/brainglobe-napari-io) which provides this functionality.
If you have installed only the command-line tool you can still manually install [brainglobe-napari-io](https://github.com/brainglobe/brainglobe-napari-io) and follow the steps below.

### Sample space

Open napari and drag your brainreg output directory (the one with the log file) onto the napari window.

Various images should then open, including:

- `Registered image` - the image used for registration, downsampled to atlas resolution
- `atlas_name` - e.g. `allen_mouse_25um` the atlas labels, warped to your sample brain
- `Boundaries` - the boundaries of the atlas regions

If you downsampled additional channels, these will also be loaded.
Most of these images will not be visible by default - click the little eye icon to toggle visibility.

**Note:** If you use a high resolution atlas (such as `allen_mouse_10um`), then the files can take a little while to load.

![GIF illustration of loading brainreg output into napari for visualisation](https://raw.githubusercontent.com/brainglobe/napari-brainreg/master/resources/sample_space.gif)

## Contributing

Contributions to brainreg are more than welcome.
Please see the [developers guide](https://brainglobe.info/developers/index.html).

## Citing brainreg

If you find brainreg useful, and use it in your research, please let us know and also cite the paper:

> Tyson, A. L., V&eacute;lez-Fort, M.,  Rousseau, C. V., Cossell, L., Tsitoura, C., Lenzi, S. C., Obenhaus, H. A., Claudi, F., Branco, T.,  Margrie, T. W. (2022). Accurate determination of marker location within whole-brain microscopy images. Scientific Reports, 12, 867 [doi.org/10.1038/s41598-021-04676-9](https://doi.org/10.1038/s41598-021-04676-9)

Please also cite aMAP (the original pipeline from which this software is based):

>Niedworok, C.J., Brown, A.P.Y., Jorge Cardoso, M., Osten, P., Ourselin, S., Modat, M. and Margrie, T.W., (2016). AMAP is a validated pipeline for registration and segmentation of high-resolution mouse brain data. Nature Communications. 7, 1–9. <https://doi.org/10.1038/ncomms11879>

Lastly, if you can, please cite the BrainGlobe Atlas API that provided the atlas:

>Claudi, F., Petrucco, L., Tyson, A. L., Branco, T., Margrie, T. W. and Portugues, R. (2020). BrainGlobe Atlas API: a common interface for neuroanatomical atlases. Journal of Open Source Software, 5(54), 2668, <https://doi.org/10.21105/joss.02668>

Finally, **don't forget to cite the developers of the atlas that you used (e.g. the Allen Brain Atlas)!**
","['Development Status :: 3 - Alpha', 'Intended Audience :: Developers', 'Intended Audience :: Science/Research', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Framework :: napari']","['Homepage, https://brainglobe.info', 'Bug Tracker, https://github.com/brainglobe/brainreg/issues', 'Documentation, https://docs.brainglobe.info/brainreg', 'Source Code, https://github.com/brainglobe/brainreg', 'User support, https://forum.image.sc/tag/brainglobe', 'Twitter, https://twitter.com/brain_globe']",,,brainreg.Register,brainreg.SampleData,,,,https://pypi.org/project/brainreg,,https://docs.brainglobe.info/brainreg/introduction
12,brainrender,0.0.3,2023-11-18,2023-11-18,brainrender-napari,Alessandro Felder,Alessandro Felder <a.felder@ucl.ac.uk>,BSD-3-Clause,https://pypi.org/project/brainrender-napari,A napari plugin to render BrainGlobe atlases and associated data as layers.,>=3.9.0,"['napari >=0.4.18', 'brainglobe-atlasapi >=2.0.1', 'numpy', 'qtpy', ""pytest ; extra == 'dev'"", ""pytest-cov ; extra == 'dev'"", ""pytest-mock ; extra == 'dev'"", ""pytest-qt ; extra == 'dev'"", ""coverage ; extra == 'dev'"", ""tox ; extra == 'dev'"", ""black ; extra == 'dev'"", ""mypy ; extra == 'dev'"", ""pre-commit ; extra == 'dev'"", ""ruff ; extra == 'dev'"", ""setuptools-scm ; extra == 'dev'"", ""pyqt5 ; extra == 'dev'""]","# brainrender-napari

[![License BSD-3](https://img.shields.io/pypi/l/brainrender-napari.svg?color=green)](https://github.com/brainglobe/brainrender-napari/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/brainrender-napari.svg?color=green)](https://pypi.org/project/brainrender-napari)
[![Python Version](https://img.shields.io/pypi/pyversions/brainrender-napari.svg?color=green)](https://python.org)
[![tests](https://github.com/brainglobe/brainrender-napari/workflows/tests/badge.svg)](https://github.com/brainglobe/brainrender-napari/actions)
[![codecov](https://codecov.io/gh/brainglobe/brainrender-napari/branch/main/graph/badge.svg)](https://codecov.io/gh/brainglobe/brainrender-napari)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/brainrender-napari)](https://napari-hub.org/plugins/brainrender-napari)

Visualisation and management of BrainGlobe atlases in napari.

----------------------------------

A napari plugin to visualise and manage BrainGlobe atlases. `brainrender-napari` aims to port the functionality of [`brainrender`](https://github.com/brainglobe/brainrender) to [`napari`](https://napari.org/stable/).
![add-region-brainrender-napari](https://github.com/brainglobe/brainrender-napari/assets/10500965/24fd3752-0ba7-4f47-aabf-5de22ff0f69b)

## Usage

Check out the [""Visualising an atlas in napari""](https://brainglobe.info/tutorials/visualise-atlas-napari.html) tutorial in the BrainGlobe documentation.

## Installation

We strongly recommend to use a virtual environment manager (like `conda` or `venv`). The installation instructions below will not specify the Qt backend for napari, and you will therefore need to install that separately. Please see [the `napari` installation instructions](https://napari.org/stable/tutorials/fundamentals/installation.html) for further advice on this.

You can install `brainrender-napari` via [pip]:

    pip install brainrender-napari



To install latest development version :

    pip install git+https://github.com/brainglobe/brainrender-napari.git


## Contributing

Contributions are very welcome. Have a look at our [developer conventions](https://brainglobe.info/developers/index.html) for more info. The core development team is happy to help and advise anyone wanting to contribute!

## License

Distributed under the terms of the [BSD-3] license,
""brainrender-napari"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

## Acknowledgements

This [@napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template and the [Neuroinformatics Unit's template](https://github.com/neuroinformatics-unit/python-cookiecutter).

[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[file an issue]: https://github.com/brainglobe/brainrender-napari/issues
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License', 'Topic :: Scientific/Engineering :: Image Processing']","['Homepage, https://github.com/brainglobe/brainrender-napari', 'Bug Tracker, https://github.com/brainglobe/brainrender-napari/issues', 'Documentation, https://brainglobe.github.io/brainrender-napari', 'Source Code, https://github.com/brainglobe/brainrender-napari', 'User Support, https://github.com/brainglobe/brainrender-napari/issues']",,,brainrender-napari.make_brainrender_widget,,,,,https://pypi.org/project/brainrender-napari,,
13,btrack,0.6.5,2022-04-01,2023-06-18,btrack,Alan R. Lowe,"""Alan R. Lowe"" <a.lowe@ucl.ac.uk>",MIT,https://github.com/quantumjot/BayesianTracker,A framework for Bayesian multi-object tracking,>=3.9,"['cvxopt >=1.3.1', 'h5py >=2.10.0', 'numpy >=1.17.3', 'pandas >=2.0.3', 'pooch >=1.0.0', 'pydantic <2', 'scikit-image >=0.16.2', 'scipy >=1.3.1', 'tqdm >=4.65.0', ""black ; extra == 'dev'"", ""pre-commit ; extra == 'dev'"", ""ruff ; extra == 'dev'"", ""numpydoc ; extra == 'docs'"", ""pytz ; extra == 'docs'"", ""sphinx ; extra == 'docs'"", ""sphinx-automodapi ; extra == 'docs'"", ""sphinx-panels ; extra == 'docs'"", ""sphinx-rtd-theme ; extra == 'docs'"", ""magicgui >=0.5.0 ; extra == 'napari'"", ""napari-plugin-engine >=0.1.4 ; extra == 'napari'"", ""napari >=0.4.16 ; extra == 'napari'"", ""qtpy ; extra == 'napari'""]","[![PyPI](https://img.shields.io/pypi/v/btrack)](https://pypi.org/project/btrack)
[![Downloads](https://static.pepy.tech/badge/btrack/month)](https://pepy.tech/project/btrack)
[![Black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)
[![Tests](https://github.com/quantumjot/btrack/actions/workflows/test.yml/badge.svg)](https://github.com/quantumjot/btrack/actions/workflows/test.yml)
[![pre-commit](https://img.shields.io/badge/pre--commit-enabled-brightgreen?logo=pre-commit&logoColor=white)](https://github.com/pre-commit/pre-commit)
[![Documentation](https://readthedocs.org/projects/btrack/badge/?version=latest)](https://btrack.readthedocs.io/en/latest/?badge=latest)
[![codecov](https://codecov.io/gh/quantumjot/btrack/branch/main/graph/badge.svg?token=QCFC9AWK0R)](https://codecov.io/gh/quantumjot/btrack)

![logo](https://btrack.readthedocs.io/en/latest/_images/btrack_logo.png)

# Bayesian Tracker (btrack) 🔬💻

`btrack` is a Python library for multi object tracking, used to reconstruct trajectories in crowded fields.
Here, we use a probabilistic network of information to perform the trajectory linking.
This method uses spatial information as well as appearance information for track linking.

The tracking algorithm assembles reliable sections of track that do not contain splitting events (tracklets).
Each new tracklet initiates a probabilistic model, and utilises this to predict future states (and error in states) of each of the objects in the field of view.
We assign new observations to the growing tracklets (linking) by evaluating the posterior probability of each potential linkage from a Bayesian belief matrix for all possible linkages.

The tracklets are then assembled into tracks by using multiple hypothesis testing and integer programming to identify a globally optimal solution.
The likelihood of each hypothesis is calculated for some or all of the tracklets based on heuristics.
The global solution identifies a sequence of high-likelihood hypotheses that accounts for all observations.

We developed `btrack` for cell tracking in time-lapse microscopy data.

## Installation

`btrack` has been tested with ![Python](https://img.shields.io/pypi/pyversions/btrack)
on `x86_64` `macos>=11`, `ubuntu>=20.04` and `windows>=10.0.17763`.
Note that `btrack<=0.5.0` was built against earlier version of
[Eigen](https://eigen.tuxfamily.org) which used `C++=11`, as of `btrack==0.5.1`
it is now built against `C++=17`.

### Installing the latest stable version

```sh
pip install btrack
```

## Usage examples

Visit [btrack documentation](https://btrack.readthedocs.io) to learn how to use it and see other examples.

### Cell tracking in time-lapse imaging data

 We provide integration with Napari, including a plugin for graph visualization, [arboretum](https://btrack.readthedocs.io/en/latest/user_guide/napari.html).


[![CellTracking](http://lowe.cs.ucl.ac.uk/images/youtube.png)](https://youtu.be/EjqluvrJGCg)  
*Video of tracking, showing automatic lineage determination*


<img src=""https://user-images.githubusercontent.com/8217795/225356392-6eb4b68c-eda5-4b96-af50-76930fa45e9d.png"" width=""700"" />


---

## Development

The tracker and hypothesis engine are mostly written in C++ with a Python wrapper.
If you would like to contribute to btrack, you will need to install the latest version from GitHub. Follow the [instructions on our developer guide](https://btrack.readthedocs.io/en/latest/dev_guide).


---
### Citation

More details of how this type of tracking approach can be applied to tracking cells in time-lapse microscopy data can be found in the following publications:

**Automated deep lineage tree analysis using a Bayesian single cell tracking approach**  
Ulicna K, Vallardi G, Charras G and Lowe AR.  
*Front in Comp Sci* (2021)  
[![doi:10.3389/fcomp.2021.734559](https://img.shields.io/badge/doi-10.3389%2Ffcomp.2021.734559-blue)](https://doi.org/10.3389/fcomp.2021.734559)


**Local cellular neighbourhood controls proliferation in cell competition**  
Bove A, Gradeci D, Fujita Y, Banerjee S, Charras G and Lowe AR.  
*Mol. Biol. Cell* (2017)  
[![doi:10.1091/mbc.E17-06-0368](https://img.shields.io/badge/doi-10.1091%2Fmbc.E17--06--0368-blue)](https://doi.org/10.1091/mbc.E17-06-0368)

```
@ARTICLE {10.3389/fcomp.2021.734559,
   AUTHOR = {Ulicna, Kristina and Vallardi, Giulia and Charras, Guillaume and Lowe, Alan R.},
   TITLE = {Automated Deep Lineage Tree Analysis Using a Bayesian Single Cell Tracking Approach},
   JOURNAL = {Frontiers in Computer Science},
   VOLUME = {3},
   PAGES = {92},
   YEAR = {2021},
   URL = {https://www.frontiersin.org/article/10.3389/fcomp.2021.734559},
   DOI = {10.3389/fcomp.2021.734559},
   ISSN = {2624-9898}
}
```

```
@ARTICLE {Bove07112017,
  author = {Bove, Anna and Gradeci, Daniel and Fujita, Yasuyuki and Banerjee,
    Shiladitya and Charras, Guillaume and Lowe, Alan R.},
  title = {Local cellular neighborhood controls proliferation in cell competition},
  volume = {28},
  number = {23},
  pages = {3215-3228},
  year = {2017},
  doi = {10.1091/mbc.E17-06-0368},
  URL = {http://www.molbiolcell.org/content/28/23/3215.abstract},
  eprint = {http://www.molbiolcell.org/content/28/23/3215.full.pdf+html},
  journal = {Molecular Biology of the Cell}
}
```
","['Framework :: napari', 'Intended Audience :: Science/Research', 'License :: OSI Approved :: MIT License', 'Operating System :: OS Independent', 'Programming Language :: C++', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Topic :: Scientific/Engineering :: Bio-Informatics', 'Topic :: Scientific/Engineering :: Image Recognition', 'Topic :: Scientific/Engineering :: Visualization']","['bugtracker, https://github.com/quantumjot/btrack/issues', 'documentation, https://btrack.readthedocs.io', 'homepage, https://github.com/quantumjot/btrack', 'usersupport, https://github.com/quantumjot/btrack/discussions']",btrack.read_btrack,btrack.write_hdf,btrack.track,,"['*.h5', '*.hdf', '*.hdf5']","['.h5', '.hdf', '.hdf5']",,https://pypi.org/project/btrack,https://github.com/quantumjot/BayesianTracker,
14,cellcanvas,0.0.1,,,cellcanvas,Kyle Harrington,czii@kyleharrington.com,MIT,,A tool for painting in cellular architecture,>=3.8,"['numpy <2.0.0', 'magicgui >=0.8.1', 'mrcfile', 'qtpy >=2.4.1', 'scikit-image >=0.22.0', 'toolz >=0.12.0', 'scikit-learn >=1.3.2', 'pyclesperanto-prototype', 'pymeshfix', 'psygnal >=0.9.5', 'superqt >=0.6.1', 'surforama', 'starfile', 'zarr >=2.16.1', 'xgboost >=2', 'matplotlib >=3.8.2', ""tox ; extra == 'dev'"", ""pytest ; extra == 'dev'"", ""pytest-cov ; extra == 'dev'"", ""pytest-qt ; extra == 'dev'"", ""napari ; extra == 'dev'"", ""pyqt5 ; extra == 'dev'"", ""pre-commit ; extra == 'dev'"", ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# cellcanvas
A tool to support painting in cellular architecture

![cellcanvas_screenshot](cover.png)
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: MIT License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/cellcanvas/cellcanvas/issues', 'Documentation, https://github.com/cellcanvas/cellcanvas#README.md', 'Source Code, https://github.com/cellcanvas/cellcanvas', 'User Support, https://github.com/cellcanvas/cellcanvas/issues']",,,cellcanvas.make_qwidget,,,,,https://pypi.org/project/cellcanvas,,
15,cellfinder,1.1.3,,,cellfinder,"Adam Tyson, Christian Niedworok, Charly Rousseau","""Adam Tyson, Christian Niedworok, Charly Rousseau"" <code@adamltyson.com>",BSD-3-Clause,,Automated 3D cell detection in large microscopy images,>=3.9,"['brainglobe-utils >=0.4.2', 'brainglobe-napari-io >=0.3.4', 'dask[array]', 'fancylog >=0.0.7', 'natsort', 'numba', 'numpy', 'scikit-image', 'scikit-learn', 'tifffile', 'tqdm', 'tensorflow <2.12.0,>=2.5.0 ; platform_system != ""Darwin"" or platform_machine != ""arm64""', 'tensorflow-macos <2.12.0,>=2.5.0 ; platform_system == ""Darwin"" and platform_machine == ""arm64""', ""black ; extra == 'dev'"", ""pre-commit ; extra == 'dev'"", ""pyinstrument ; extra == 'dev'"", ""pytest-cov ; extra == 'dev'"", ""pytest-mock ; extra == 'dev'"", ""pytest-qt ; extra == 'dev'"", ""pytest-timeout ; extra == 'dev'"", ""pytest ; extra == 'dev'"", ""tox ; extra == 'dev'"", ""brainglobe-napari-io ; extra == 'napari'"", ""magicgui ; extra == 'napari'"", ""napari-ndtiffs ; extra == 'napari'"", ""napari-plugin-engine >=0.1.4 ; extra == 'napari'"", ""napari[pyqt5] ; extra == 'napari'"", ""pooch >=1 ; extra == 'napari'"", ""qtpy ; extra == 'napari'""]","[![Python Version](https://img.shields.io/pypi/pyversions/cellfinder-core.svg)](https://pypi.org/project/cellfinder)
[![PyPI](https://img.shields.io/pypi/v/cellfinder-core.svg)](https://pypi.org/project/cellfinder)
[![Downloads](https://pepy.tech/badge/cellfinder-core)](https://pepy.tech/project/cellfinder)
[![Wheel](https://img.shields.io/pypi/wheel/cellfinder-core.svg)](https://pypi.org/project/cellfinder)
[![Development Status](https://img.shields.io/pypi/status/cellfinder-core.svg)](https://github.com/brainglobe/cellfinder)
[![Tests](https://img.shields.io/github/actions/workflow/status/brainglobe/cellfinder/test_and_deploy.yml?branch=main)](https://github.com/brainglobe/cellfinder/actions)
[![codecov](https://codecov.io/gh/brainglobe/cellfinder-core/branch/main/graph/badge.svg?token=nx1lhNI7ox)](https://codecov.io/gh/brainglobe/cellfinder)
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/python/black)
[![Imports: isort](https://img.shields.io/badge/%20imports-isort-%231674b1?style=flat&labelColor=ef8336)](https://pycqa.github.io/isort/)
[![pre-commit](https://img.shields.io/badge/pre--commit-enabled-brightgreen?logo=pre-commit&logoColor=white)](https://github.com/pre-commit/pre-commit)
[![Contributions](https://img.shields.io/badge/Contributions-Welcome-brightgreen.svg)](https://brainglobe.info/developers/index.html)
[![Twitter](https://img.shields.io/twitter/follow/brain_globe?style=social)](https://twitter.com/brain_globe)

# cellfinder

cellfinder is software for automated 3D cell detection in very large 3D images (e.g., serial two-photon or lightsheet volumes of whole mouse brains).
There are three different ways to interact and use it, each with different user interfaces and objectives in mind.
For more details, head over to [the documentation website](https://brainglobe.info/documentation/cellfinder/index.html).

At a glance:

- There is a command-line interface called [brainmapper](https://brainglobe.info/documentation/brainglobe-workflows/brainmapper/index.html) that integrates [with `brainreg`](https://github.com/brainglobe/brainreg) for automated cell detection and classification. You can install it through [`brainglobe-workflows`](https://brainglobe.info/documentation/brainglobe-workflows/index.html).
- There is a [napari plugin](https://brainglobe.info/documentation/cellfinder/user-guide/napari-plugin/index.html) for interacting graphically with the cellfinder tool.
- There is a [Python API](https://brainglobe.info/documentation/cellfinder/user-guide/cellfinder-core.html) to allow users to integrate BrainGlobe tools into their custom workflows.

## Installation

You can find [the installation instructions](https://brainglobe.info/documentation/cellfinder/installation.html#installation) on the BrainGlobe website, which will go into more detail about the installation process if you want to minimise your installation to suit your needs.
However, we recommend that users install `cellfinder` either through installing BrainGlobe version 1, or (if you also want the command-line interface) installing `brainglobe-workflows`.

```bash
# If you want to install all BrainGlobe tools, including cellfinder, in a consistent manner with one command:
pip install brainglobe>=1.0.0
# If you want to install the brainmapper CLI tool as well:
pip install brainglobe-workflows>=1.0.0
```

If you only want the `cellfinder` package by itself, you can `pip install` it alone:

```bash
pip install cellfinder>=1.0.0
```

Be sure to specify a version greater than version `v1.0.0` - prior to this version the `cellfinder` package had a very different structure that is incompatible with BrainGlobe version 1 and the other tools in the BrainGlobe suite.
See [our blog posts](https://brainglobe.info/blog/) for more information on the release of BrainGlobe version 1.

## Contributing

If you have encountered a bug whilst using cellfinder, please [open an issue on GitHub](https://github.com/brainglobe/cellfinder/issues).

If you are interested in contributing to cellfinder (thank you!) - please head over to our [developer documentation](https://brainglobe.info/community/developers/index.html).
","['Development Status :: 4 - Beta', 'Framework :: napari', 'Intended Audience :: Developers', 'Intended Audience :: Science/Research', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Recognition']","['Homepage, https://brainglobe.info/documentation/cellfinder/index.html', 'Source Code, https://github.com/brainglobe/cellfinder', 'Bug Tracker, https://github.com/brainglobe/cellfinder/issues', 'Documentation, https://brainglobe.info/documentation/cellfinder/index.html', 'User Support, https://forum.image.sc/tag/brainglobe']",,,cellfinder.napari.detect_widget,cellfinder.napari.SampleData,,,,https://pypi.org/project/cellfinder,,
16,cellpose-napari,0.1.5,2022-02-14,2023-06-18,cellpose-napari,Carsen Stringer,stringerc@janelia.hhmi.org,BSD-3,https://github.com/Mouseland/cellpose-napari,a generalist algorithm for anatomical segmentation,>=3.7,"['napari', 'napari-plugin-engine (>=0.1.4)', 'cellpose (>0.6.3)', 'imagecodecs', ""sphinx (>=3.0) ; extra == 'docs'"", ""sphinxcontrib-apidoc ; extra == 'docs'"", ""sphinx-rtd-theme ; extra == 'docs'"", ""sphinx-prompt ; extra == 'docs'"", ""sphinx-autodoc-typehints ; extra == 'docs'"", ""pytest ; extra == 'tests_require'"", ""pytest-qt ; extra == 'tests_require'""]","# cellpose-napari <img src=""docs/_static/favicon.ico"" width=""50"" title=""cellpose"" alt=""cellpose"" align=""right"" vspace = ""50"">

[![Documentation Status](https://readthedocs.org/projects/cellpose-napari/badge/?version=latest)](https://cellpose-napari.readthedocs.io/en/latest/?badge=latest)
[![tests](https://github.com/mouseland/cellpose-napari/workflows/tests/badge.svg)](https://github.com/mouseland/cellpose-napari/actions)
[![codecov](https://codecov.io/gh/Mouseland/cellpose-napari/branch/main/graph/badge.svg)](https://codecov.io/gh/MouseLand/cellpose-napari)
[![PyPI version](https://badge.fury.io/py/cellpose-napari.svg)](https://badge.fury.io/py/cellpose-napari)
[![PyPI - Downloads](https://img.shields.io/pypi/dm/cellpose-napari)](https://pypistats.org/packages/cellpose-napari)
[![Python version](https://img.shields.io/pypi/pyversions/cellpose-napari)](https://pypistats.org/packages/cellpose-napari)
[![License](https://img.shields.io/pypi/l/cellpose-napari.svg?color=green)](https://github.com/mouseland/cellpose-napari/raw/master/LICENSE)
[![Contributors](https://img.shields.io/github/contributors-anon/MouseLand/cellpose-napari)](https://github.com/MouseLand/cellpose-napari/graphs/contributors)
[![website](https://img.shields.io/website?url=https%3A%2F%2Fwww.cellpose.org)](https://www.cellpose.org)
[![GitHub stars](https://img.shields.io/github/stars/MouseLand/cellpose-napari?style=social)](https://github.com/MouseLand/cellpose-napari/)
[![GitHub forks](https://img.shields.io/github/forks/MouseLand/cellpose-napari?style=social)](https://github.com/MouseLand/cellpose-napari/)

a napari plugin for anatomical segmentation of general cellular images

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.

The plugin code was written by Carsen Stringer, and the cellpose code was written by Carsen Stringer and Marius Pachitariu. To learn about Cellpose, read the [**paper**](https://t.co/kBMXmPp3Yn?amp=1) or watch this [**talk**](https://t.co/JChCsTD0SK?amp=1). 

For support with the plugin, please open an [issue](https://github.com/MouseLand/cellpose-napari/issues). For support with cellpose, please open an [issue](https://github.com/MouseLand/cellpose/issues) on the cellpose repo. 


If you use this plugin please cite the [paper](https://www.nature.com/articles/s41592-020-01018-x):
::
    
      @article{stringer2021cellpose,
      title={Cellpose: a generalist algorithm for cellular segmentation},
      author={Stringer, Carsen and Wang, Tim and Michaelos, Michalis and Pachitariu, Marius},
      journal={Nature Methods},
      volume={18},
      number={1},
      pages={100--106},
      year={2021},
      publisher={Nature Publishing Group}
      }


![cellpose-napari_plugin](https://cellpose-napari.readthedocs.io/en/latest/_images/napari_main_demo_fast_small.gif?raw=true ""cellpose-napari"")

## Installation

Install an [Anaconda](https://www.anaconda.com/download/) distribution of Python -- Choose **Python 3** and your operating system. Note you might need to use an anaconda prompt if you did not add anaconda to the path.

Install `napari` with pip: `pip install napari[all]`. Then install `cellpose-napari` via [pip]:

    pip install cellpose-napari
    
 Or install the plugin inside napari in the plugin window.

If install fails in your base environment, create a new environment:
1. Download the [`environment.yml`](https://github.com/MouseLand/cellpose-napari/blob/master/environment.yml?raw=true) file from the repository. You can do this by cloning the repository, or copy-pasting the text from the file into a text document on your local computer.
2. Open an anaconda prompt / command prompt with `conda` for **python 3** in the path
3. Change directories to where the `environment.yml` is and run `conda env create -f environment.yml`
4. To activate this new environment, run `conda activate cellpose-napari`
5. You should see `(cellpose-napari)` on the left side of the terminal line. 

If you have **issues** with cellpose installation, see the [cellpose docs](https://cellpose.readthedocs.io/en/latest/installation.html) for more details, and then if the suggestions fail, open an issue.

### Upgrading software

You can upgrade the plugin with
~~~
pip install cellpose-napari --upgrade
~~~

and you can upgrade cellpose with
~~~
pip install cellpose --upgrade
~~~

### GPU version (CUDA) on Windows or Linux

If you plan on running many images, you may want to install a GPU version of *torch* (if it isn't already installed).

Before installing the GPU version, remove the CPU version:
~~~
pip uninstall torch
~~~

Follow the instructions [here](https://pytorch.org/get-started/locally/) to determine what version to install. The Anaconda install is recommended along with CUDA version 10.2. For instance this command will install the 10.2 version on Linux and Windows (note the `torchvision` and `torchaudio` commands are removed because cellpose doesn't require them):

~~~
conda install pytorch cudatoolkit=10.2 -c pytorch
~~~~

When upgrading GPU Cellpose in the future, you will want to ignore dependencies (to ensure that the pip version of torch does not install):
~~~
pip install --no-deps cellpose --upgrade
~~~

### Installation of github version

Follow steps from above to install the dependencies. In the github repository, run `pip install -e .` and the github version will be installed. If you want to go back to the pip version of cellpose-napari, then say `pip install cellpose-napari`.


## Running the software


Open napari with the cellpose-napari dock widget open
```
napari -w cellpose-napari
```

There is sample data in the File menu, or get started with your own images!

### Detailed usage [documentation](https://cellpose-napari.readthedocs.io/).

## Contributing

Contributions are very welcome. Tests are run with pytest.

## License

Distributed under the terms of the [BSD-3] license,
""cellpose-napari"" is free and open source software.

## Dependencies
cellpose-napari relies on the following excellent packages (which are automatically installed with conda/pip if missing):
- [napari](https://napari.org)
- [magicgui](https://napari.org/magicgui/)

cellpose relies on the following excellent packages (which are automatically installed with conda/pip if missing):
- [torch](https://pytorch.org/)
- [numpy](http://www.numpy.org/) (>=1.16.0)
- [numba](http://numba.pydata.org/numba-doc/latest/user/5minguide.html)
- [scipy](https://www.scipy.org/)
- [natsort](https://natsort.readthedocs.io/en/master/)
- [tifffile](https://pypi.org/project/tifffile/)
- [opencv](https://opencv.org/)


[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
","['Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License', 'Framework :: napari']",,,,cellpose-napari.widget_wrapper,cellpose-napari.data.rgb_3D,,,,https://pypi.org/project/cellpose-napari,https://github.com/Mouseland/cellpose-napari,
17,cryaleconcho,0.0.7,,,cryaleconcho,Ryan Conrad,conradrw@nih.gov,BSD-3-Clause,,Napari plugin of algorithms for Panoptic Segmentation of organelles in EM,>=3.7,"['napari >=0.4.16', 'numpy ==1.22', 'napari-plugin-engine >=0.1.4', 'scikit-image >=0.19', 'empanada-dl >=0.1.7', 'imagecodecs', 'openpyxl']","# empanada-napari

**The preprint describing this work is now available [on bioRxiv](https://www.biorxiv.org/content/10.1101/2022.03.17.484806v1).**

**Documentation for the plugin, including more detailed installation instructions, can be found [here](https://empanada.readthedocs.io/en/latest/empanada-napari.html).**

[empanada](https://github.com/volume-em/empanada) is a tool for deep learning-based panoptic segmentation of 2D and 3D electron microscopy images of cells.
This plugin allows the running of panoptic segmentation models trained in empanada within [napari](https://napari.org).
For help with this plugin please open an [issue](https://github.com/volume-em/empanada-napari/issues), for issues with napari specifically
raise an [issue here instead](https://github.com/napari/napari/issues).

## Implemented Models

  - *MitoNet*: A generalist mitochondrial instance segmentation model.

## Example Datasets

Volume EM datasets for benchmarking mitochondrial instance segmentation are available from
[EMPIAR-10982](https://www.ebi.ac.uk/empiar/EMPIAR-10982/).

## Installation

It's recommended to have installed napari through [conda](https://docs.conda.io/en/latest/miniconda.html).
Then to install this plugin:

```shell
pip install empanada-napari
```

Launch napari:

```shell
napari
```

Look for empanada-napari under the ""Plugins"" menu.

![empanada](images/demo.gif)

## GPU Support

**Note: Mac doesn't support NVIDIA GPUS. This section only applies to Windows and Linux systems.**

As for any deep learning models, having a GPU installed on your system will significantly
increase model throughput (although we ship CPU optimized versions of all models with the plugin).

This plugin relies on torch for running models. If a GPU was found on your system, then you will see that the
""Use GPU"" checkbox is checked by default in the ""2D Inference"" and ""3D Inference"" plugin widgets. Or if when running
inference you see a message that says ""Using CPU"" in the terminal that means a GPU is not being used.

Make sure that GPU drivers are correctly installed. In terminal or command prompt:

```shell
nvidia-smi
```

If this returns ""command not found"" then you need to [install the driver from NVIDIA](https://www.nvidia.com/download/index.aspx). Instead, if
if the driver is installed correctly, you may need to switch to the GPU enabled version of torch.

First, uninstall the current version of torch:

```shell
pip uninstall torch
```

Then [install torch >= 1.10 using conda for your system](https://pytorch.org/get-started/locally/).
This command should work:

```shell
conda install pytorch cudatoolkit=11.3 -c pytorch
```

## Citing this work

If you use results generated by this plugin in a publication, please cite:

```bibtex
@article {Conrad2022.03.17.484806,
	author = {Conrad, Ryan and Narayan, Kedar},
	title = {Instance segmentation of mitochondria in electron microscopy images with a generalist deep learning model},
	elocation-id = {2022.03.17.484806},
	year = {2022},
	doi = {10.1101/2022.03.17.484806},
	publisher = {Cold Spring Harbor Laboratory},
	URL = {https://www.biorxiv.org/content/early/2022/03/18/2022.03.17.484806},
	eprint = {https://www.biorxiv.org/content/early/2022/03/18/2022.03.17.484806.full.pdf},
	journal = {bioRxiv}
}
```
","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/volume-em/empanada-napari/issues', 'Documentation, https://github.com/volume-em/empanada-napari#README.md', 'Source Code, https://github.com/volume-em/empanada-napari', 'User Support, https://github.com/volume-em/empanada-napari/issues']",,,cryaleconcho.test_widget,,,,,https://pypi.org/project/cryaleconcho,,
18,cryocanvas,0.0.1,,,cryocanvas,Kyle Harrington,czii@kyleharrington.com,MIT,,A plugin for interactive segmentation of CryoET data using ML embeddings,>=3.8,"['numpy', 'magicgui', 'qtpy', 'scikit-image', 'toolz', 'scikit-learn', 'psygnal', 'superqt', 'zarr', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# cryocanvas
A tool to support interactive machine learning for cryoET data

![cryocanvas screenshot](cover.png)
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: MIT License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/kephale/cryocanvas/issues', 'Documentation, https://github.com/kephale/cryocanvas#README.md', 'Source Code, https://github.com/kephale/cryocanvas', 'User Support, https://github.com/kephale/cryocanvas/issues']",,,cryocanvas.make_qwidget,,,,,https://pypi.org/project/cryocanvas,,
19,Cut Detector,0.0.12,,,cut-detector,Thomas Bonte,thomas.bonte@mines-paristech.fr,BSD-3-Clause,,Automatic Cut Detector,>=3.9,"['cellpose >=2.2.3', 'pyimagej', 'scyjava', 'numpy <=1.24', 'cnn-framework ==0.0.15', 'magicgui', 'pydantic ==1.10.12', 'xmltodict', 'shapely', 'aicsimageio', 'scikit-learn ==1.2.2', 'charset-normalizer ==3.3.0', 'napari[all]', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# Cut Detector

[![License BSD-3](https://img.shields.io/pypi/l/cut-detector.svg?color=green)](https://github.com/15bonte/cut-detector/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/cut-detector.svg?color=green)](https://pypi.org/project/cut-detector)
[![Python Version](https://img.shields.io/pypi/pyversions/cut-detector.svg?color=green)](https://python.org)
[![tests](https://github.com/15bonte/cut-detector/workflows/tests/badge.svg)](https://github.com/15bonte/cut-detector/actions)
[![codecov](https://codecov.io/gh/15bonte/cut-detector/branch/main/graph/badge.svg)](https://codecov.io/gh/15bonte/cut-detector)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/cut-detector)](https://napari-hub.org/plugins/cut-detector)

Automatic micro-tubules cut detector.

---

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

### Conda environment

It is highly recommended to create a dedicated conda environment, by following these few steps:

1. Install an [Anaconda] distribution of Python. Note you might need to use an anaconda prompt if you did not add anaconda to the path.

2. Open an Anaconda prompt as admin to create a new environment using [conda]. We advice to use python 3.10 and conda 23.10.0, to get conda-libmamba-solver as default solver.

```
conda create --name cut_detector python=3.10 conda=23.10.0
conda activate cut_detector
```

### Package installation

Once in a dedicated environment, our package can be installed via [pip]:

```
pip install cut_detector
```

Alternatively, you can clone the github repo to access to playground scripts.

```
git clone https://github.com/15bonte/cut-detector.git
cd cut-detector
pip install -e .
```

### Fiji

This package relies on [Trackmate] to perform cell tracking. Trackmate is called through [Fiji], which has to be installed independently. Please follow the steps [here](https://imagej.net/software/fiji/downloads) to install it.

Next, install openjdk which is necessary to call Fiji from python.

```
conda install -c conda-forge openjdk=8
```

### GPU

We highly recommend to use GPU to speed up segmentation. To use your NVIDIA GPU, the first step is to download the dedicated driver from [NVIDIA].

Next we need to remove the CPU version of torch:

```
pip uninstall torch
```

The GPU version of torch to be installed can be found [here](https://pytorch.org/get-started/locally/). You may choose the CUDA version supported by your GPU, and install it with conda. This package has been developed with the version 11.6, installed with this command:

```
conda install numpy==1.25 pytorch==1.12.1 torchvision pytorch-cuda=11.6 -c pytorch -c nvidia
```

Note that we have added numpy here to prevent conda from installing a version higher than 1.25, which is not supported by numba.

## Update

To update cut-detector to the latest version, open an Anaconda prompt and use the following commands:

```
conda activate cut_detector
pip install cut-detector --upgrade
```

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""cut-detector"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/15bonte/cut-detector/issues
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
[Anaconda]: https://www.anaconda.com/products/distribution
[Trackmate]: https://imagej.net/plugins/trackmate/
[Fiji]: https://imagej.net/software/fiji/
[NVIDIA]: https://www.nvidia.com/Download/index.aspx?lang=en-us
[conda]: https://docs.conda.io/en/latest/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/15bonte/cut-detector/issues', 'Documentation, https://github.com/15bonte/cut-detector#README.md', 'Source Code, https://github.com/15bonte/cut-detector', 'User Support, https://github.com/15bonte/cut-detector/issues']",,,cut-detector.whole_process,,,,,https://pypi.org/project/cut-detector,,
20,darth-d,0.4.0,2023-12-04,2023-12-08,darth-d,Robert Haase,robert.haase@uni-leipzig.de,BSD-3-Clause,https://pypi.org/project/darth-d,A simple to use image generator based on OpenAIs DALL-E,>=3.8,"['openai >=1.2.0', 'Pillow', 'numpy', 'stackview >=0.7.1']","# Darth-D
[![License](https://img.shields.io/pypi/l/darth-d.svg?color=green)](https://github.com/haesleinhuepf/darth-d/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/darth-d.svg?color=green)](https://pypi.org/project/darth-d)
[![Python Version](https://img.shields.io/pypi/pyversions/darth-d.svg?color=green)](https://python.org)
[![tests](https://github.com/haesleinhuepf/darth-d/workflows/tests/badge.svg)](https://github.com/haesleinhuepf/darth-d/actions)
[![codecov](https://codecov.io/gh/haesleinhuepf/darth-d/branch/master/graph/badge.svg)](https://codecov.io/gh/haesleinhuepf/darth-d)
[![Development Status](https://img.shields.io/pypi/status/darth-d.svg)](https://en.wikipedia.org/wiki/Software_release_life_cycle#Alpha)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/darth-d)](https://napari-hub.org/plugins/darth-d)

A simple to use image generator based on [OpenAIs DALL-E 2/3](https://openai.com/dall-e-2).
It comes as [napari](https://napari.org/) plugin and has a Python interface. 
You need an [OpenAI API KEY](https://openai.com/blog/openai-api/) to use it.

Using some of the functions on scientific images could be seen as scientific misconduct. Handle these functions with care.

![](https://github.com/haesleinhuepf/darth-d/raw/main/docs/images/replace_screencast.gif)

## Usage

### From Python

You can generate images from text prompts in Python like this ([see this notebool](https://github.com/haesleinhuepf/darth-d/blob/main/demo/demo_darth-d.ipynb)).

```
from darth_d import create
```

```
image = create(""an image of a cat"")

image
```

![](https://github.com/haesleinhuepf/darth-d/raw/main/docs/images/jupyter_screenshot.png)

You can also vary images ([see this notebook](https://github.com/haesleinhuepf/darth-d/blob/main/demo/demo_vary.ipynb)):
```
from darth_d import vary

output_image = vary(input_image)
```

![](https://github.com/haesleinhuepf/darth-d/raw/main/docs/images/vary_screenshot.png)

Replacing regions in images is also possible. Note: Using this function on scientific images could be seen as scientific misconduct. Handle this function with care.

### In Napari

To generate images in Napari, click the `Tools > Generate > Image` menu. You can for example enter the prompt
""a professional comic with white background showing a cat having an idea. the idea is visualized using a light bulb.

![](https://github.com/haesleinhuepf/darth-d/raw/main/docs/images/napari_screenshot.png)


## Installation

```
pip install darth-d
```

If you want to use it from napari, please also install napari and the [tools menu](https://github.com/haesleinhuepf/napari-tools-menu):

```
mamba install napari pyqt napari-tools-menu -c conda-forge
```

## Similar tools and plugins

* https://github.com/kephale/napari-stable-diffusion
* https://github.com/seankmartin/napari-stable-diffusion

## Feedback welcome!

The `darth-d` is developed in the open because we believe in the open source community. Feel free to drop feedback as [github issue](https://github.com/haesleinhuepf/darth-d) or via [image.sc](https://image.sc)

## Contributing

Contributions are very welcome. 

## License

Distributed under the terms of the [BSD-3] license,
""darth-d"" is free and open source software

[BSD-3]: http://opensource.org/licenses/BSD-3-Clause

","['Framework :: napari', 'License :: OSI Approved :: BSD License', 'Topic :: Scientific/Engineering :: Image Processing', 'Topic :: Scientific/Engineering :: Information Analysis', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent']","['Bug Tracker, https://github.com/haesleinhuepf/darth-d/issues', 'Documentation, https://github.com/haesleinhuepf/darth-d/', 'Source Code, https://github.com/haesleinhuepf/darth-d', 'User Support, https://forum.image.sc/']",,,darth-d.napari_experimental_provide_function,,,,,https://pypi.org/project/darth-d,,
21,devbio-napari,0.10.1,2022-04-06,2023-06-11,devbio-napari,Robert Haase,robert.haase@tu-dresden.de,BSD-3,https://github.com/haesleinhuepf/devbio-napari,A bundle of napari plugins useful for 3D+t image processing and analysis for studying developmental biology.,>=3.8,"['napari-plugin-engine (>=0.1.4)', 'npe2 (<0.7.0)', 'numpy (>=1.21.4)', 'napari-pyclesperanto-assistant', 'napari-skimage-regionprops', 'napari-animation', 'PlatyMatch', 'napari-plot-profile', 'napari-accelerated-pixel-and-object-classification', 'napari-brightness-contrast', 'napari-plugin-search', 'napari-segment-blobs-and-things-with-membranes', 'napari-simpleitk-image-processing', 'napari-folder-browser', 'napari-crop', 'napari-clusters-plotter (>=0.7.1)', 'napari-tabu', 'napari-workflow-optimizer', 'napari-workflow-inspector', 'napari-curtain', 'napari-layer-details-display', 'napari', 'vispy', 'napari-mouse-controls', 'the-segmentation-game', 'napari-blob-detection', 'jupyterlab', 'napari-czifile2', 'napari-roi', 'pydantic (!=1.10.0)', 'napari-pystackreg', 'imageio (!=2.22.1)', 'redlionfish', 'jupyter-server (<2.0.0)', 'seaborn']","# devbio-napari

[![License](https://img.shields.io/pypi/l/devbio-napari.svg?color=green)](https://github.com/haesleinhuepf/devbio-napari/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/devbio-napari.svg?color=green)](https://pypi.org/project/devbio-napari)
[![Python Version](https://img.shields.io/pypi/pyversions/devbio-napari.svg?color=green)](https://python.org)
[![tests](https://github.com/haesleinhuepf/devbio-napari/workflows/tests/badge.svg)](https://github.com/haesleinhuepf/napari-plot-profile/actions)
[![codecov](https://codecov.io/gh/haesleinhuepf/devbio-napari/branch/master/graph/badge.svg)](https://codecov.io/gh/haesleinhuepf/devbio-napari)
[![Development Status](https://img.shields.io/pypi/status/devbio-napari.svg)](https://en.wikipedia.org/wiki/Software_release_life_cycle#Alpha)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/devbio-napari)](https://napari-hub.org/plugins/devbio-napari)

 
A bundle of napari plugins useful for 3D+t image processing and analysis for studying developmental biology.

* [accelerated-pixel-and-object-classification](https://www.napari-hub.org/plugins/napari-accelerated-pixel-and-object-classification)
  * Instance segmentation
  * Semantic segmentation
  * Object classification
  * Random Forest Classifier training
* [animation](https://www.napari-hub.org/plugins/napari-animation) 
  * Visualization
* [blob-detection](https://www.napari-hub.org/plugins/napari-blob-detection)
  * Detection
* [brightness-contrast](https://www.napari-hub.org/plugins/napari-brightness-contrast)
  * Visualization
* [clusters-plotter](https://www.napari-hub.org/plugins/napari-clusters-plotter)
  * Visualization
  * Plotting
  * Semantic object segmentation
  * Dimensionality reduction
  * Unsupervised machine learning
* [crop](https://www.napari-hub.org/plugins/napari-crop)
  * Transformation
* [curtain](https://www.napari-hub.org/plugins/napari-curtain)
  * Visualization 
* [czifile2](https://www.napari-hub.org/plugins/napari-czifile2)
  * File input/output
* [folder-browser](https://www.napari-hub.org/plugins/napari-folder-browser)
  * File input/output
* [layer-details-display](https://www.napari-hub.org/plugins/napari-layer-details-display)
  * Visualization
* [mouse-controls](https://www.napari-hub.org/plugins/napari-mouse-controls)
  * Interaction
* [PlatyMatch](https://www.napari-hub.org/plugins/PlatyMatch)
  * Image registration
* [plot-profile](https://www.napari-hub.org/plugins/napari-plot-profile)
  * Visualization
  * Quantification
* [plugin-search](https://www.napari-hub.org/plugins/napari-plugin-search)
  * Interaction
* [pyclesperanto-assistant](https://www.napari-hub.org/plugins/napari-pyclesperanto-assistant)
  * Filtering
  * Instance segmentation
  * Semantic segmentation
  * Quantification
* [pystackreg](https://www.napari-hub.org/plugins/napari-pystackreg)
  * Image registration
  * Motion correction
* [RedLionfish](https://www.napari-hub.org/plugins/RedLionfish)
  * Deconvolution
  * Processing
* [roi](https://www.napari-hub.org/plugins/napari-roi)
  * Manual segmentation
* [segment-blobs-and-things-with-membranes](https://www.napari-hub.org/plugins/napari-segment-blobs-and-things-with-membranes)
  * Filtering
  * Instance segmentation
  * Semantic segmentation
* [simpleitk-image-processing](https://www.napari-hub.org/plugins/napari-simpleitk-image-processing)
  * Filtering
  * Instance segmentation
  * Semantic segmentation
  * Quantification
* [skimage-regionprops](https://www.napari-hub.org/plugins/napari-skimage-regionprops)
  * Quantification
* [tabu](https://www.napari-hub.org/plugins/napari-tabu)
  * Interaction
* [the-segmentation-game](https://www.napari-hub.org/plugins/the-segmentation-game)
  * Quantification
  * Segmentation quality assurance
* [workflow-inspector](https://www.napari-hub.org/plugins/napari-workflow-inspector)
  * Visualization
* [workflow-optimizer](https://www.napari-hub.org/plugins/napari-workflow-optimizer)
  * Interaction
  * Optimization

----------------------------------

## Installation

You can install `devbio-napari` via conda/mamba. If you have never used conda before, please [read this guide first](https://biapol.github.io/blog/mara_lampert/getting_started_with_mambaforge_and_python/readme.html).  
Start by installing mamba in your base environment:

```
conda install mamba -c conda-forge
```

Afterwards, create an environment using mamba.

```
mamba create --name devbio-napari-env python=3.9 devbio-napari -c conda-forge -c pytorch
```

Afterwards, activate the environment like this:

```
mamba activate devbio-napari-env
```

Afterwards, run this command from the command line

```
naparia
```

This window should open. It shows the [Assistant](https://www.napari-hub.org/plugins/napari-assistant) graphical user interface. 
Read more about how to use it in its [documentation](https://www.napari-hub.org/plugins/napari-assistant).

![img.png](https://github.com/haesleinhuepf/devbio-napari/raw/master/docs/screenshot.png)

## Troubleshooting: Graphics cards drivers

In case error messages contains ""ImportError: DLL load failed while importing cl: The specified procedure could not be found"" [see also](https://github.com/clEsperanto/pyclesperanto_prototype/issues/55) or """"clGetPlatformIDs failed: PLATFORM_NOT_FOUND_KHR"", please install recent drivers for your graphics card and/or OpenCL device. Select the right driver source depending on your hardware from this list:

* [AMD drivers](https://www.amd.com/en/support)
* [NVidia drivers](https://www.nvidia.com/download/index.aspx)
* [Intel GPU drivers](https://www.intel.com/content/www/us/en/download/726609/intel-arc-graphics-windows-dch-driver.html)
* [Intel CPU OpenCL drivers](https://www.intel.com/content/www/us/en/developer/articles/tool/opencl-drivers.html#latest_CPU_runtime)
* [Microsoft Windows OpenCL support](https://www.microsoft.com/en-us/p/opencl-and-opengl-compatibility-pack/9nqpsl29bfff)

Sometimes, mac-users need to install this:

    conda install -c conda-forge ocl_icd_wrapper_apple

Sometimes, linux users need to install this:

    conda install -c conda-forge ocl-icd-system


In case installation didn't work in the first attempt, you may have to call this command line to reset the napari configuration:

```
napari --reset
```

## Troubleshooting: pytorch

In case pytorch-related plugins fail, install pytorch as explained on [its website](https://pytorch.org/get-started/locally/). Consider replacing `conda` with `mamba` in given instructions.

For example if you have an NVidia GPU at hand, install pytorch like this:
```
mamba install pytorch torchvision torchaudio pytorch-cuda=11.7 -c pytorch -c nvidia
```
Or if not:
```
mamba install pytorch torchvision torchaudio cpuonly -c pytorch
```

## Contributing

Contributions are very welcome. 
If you want to [suggest a new napari plugin](https://github.com/haesleinhuepf/devbio-napari/pulls) to become part of this distribution, please make sure it interoperates nicely with the other plugins. 
For example, if the plugin you suggest provided cell segmentation algorithms, please check if the resulting segmented cells can be analysed using napari-skimage-regionprops.
Furthermore, please make sure the README of the plugin you are proposing comes with user documentation, e.g. a step-by-step guide with screenshots explaining what users can do with the plugin and how to use it. 
It is recommended to provide example data as well so that end-users can try out the plugin under conditions it was developed for.

## License

Distributed under the terms of the [BSD-3] license,
""devbio-napari"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/haesleinhuepf/devbio/issues
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 3 - Alpha', 'Intended Audience :: Science/Research', 'Framework :: napari', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/haesleinhuepf/devbio-napari/issues', 'Documentation, https://github.com/haesleinhuepf/devbio-napari#README.md', 'Source Code, https://github.com/haesleinhuepf/devbio-napari', 'User Support, https://github.com/haesleinhuepf/devbio-napari/issues']",,,,,,,,https://pypi.org/project/devbio-napari,https://github.com/haesleinhuepf/devbio-napari,
22,Disease classifier,0.0.1,,,disease-classifier,Chenqi Zhang,cqzhang@g.ecc.u-tokyo.ac.jp,BSD-3-Clause,,A disease classifier based on iPAC images.,>=3.8,"['numpy', 'magicgui', 'qtpy', 'matplotlib', 'h5py (>=3.6.0)', 'napari (>=0.4.15)', 'numpy (>=1.22.4)', 'opencv-contrib-python-headless (>=4.5.5.64)', 'pytranskit (>=0.2.3)', 'statsmodels (>=0.13.2)', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# disease-classifier

[![License](https://img.shields.io/pypi/l/disease-classifier.svg?color=green)](https://github.com/zcqwh/disease-classifier/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/disease-classifier.svg?color=green)](https://pypi.org/project/disease-classifier)
[![Python Version](https://img.shields.io/pypi/pyversions/disease-classifier.svg?color=green)](https://python.org)
[![tests](https://github.com/zcqwh/disease-classifier/workflows/tests/badge.svg)](https://github.com/zcqwh/disease-classifier/actions)
[![codecov](https://codecov.io/gh/zcqwh/disease-classifier/branch/main/graph/badge.svg)](https://codecov.io/gh/zcqwh/disease-classifier)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/disease-classifier)](https://napari-hub.org/plugins/disease-classifier)

A napari plugin for disease classification based on iPAC images.



## Installation

You can install `disease-classifier` via [pip]:

    pip install disease-classifier



To install latest development version :

    pip install git+https://github.com/zcqwh/disease-classifier.git

## Introduction
#### Load data (.rtdc or .bin)
* Drag and drop the data in .rtdc or .bin into the files table.
* Click eye button to preview images.
![](https://github.com/zcqwh/disease-classifier/blob/main/Tutorial/Gif/01_Load_preview.gif?raw=true)


#### Choose model and classify

* Choose the model folder including CNN and RF/PLDA.
* Check the data.
* Click classify.
![](https://github.com/zcqwh/disease-classifier/blob/main/Tutorial/Gif/02_model_classify.gif?raw=true)

#### Preview classification results
* Click the eye button to preview the result.
* Click the header to show all.
![](https://github.com/zcqwh/disease-classifier/blob/main/Tutorial/Gif/03_preview_result.gif?raw=true)


#### Save results
* Click “Add classification to .rtdc file” button to save results.
![](https://github.com/zcqwh/disease-classifier/blob/main/Tutorial/Gif/04_save.gif?raw=true)


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""disease-classifier"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/stable/index.html
-->

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/zcqwh/disease-classifier/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/

","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/zcqwh/disease-classifier/issues', 'Documentation, https://github.com/zcqwh/disease-classifier#README.md', 'Source Code, https://github.com/zcqwh/disease-classifier', 'User Support, https://github.com/zcqwh/disease-classifier/issues']",,,disease-classifier.make_qwidget,,,,,https://pypi.org/project/disease-classifier,,
23,domb-napari,0.2.0,2023-12-08,2023-12-08,domb-napari,Borys Olifirov,omnia.fatum@gmail.com,MIT,https://pypi.org/project/domb-napari,napari plugin for analyzing fluorescence-labeled proteins redistribution,>=3.8,"['napari', 'domb', 'dipy']","domb-napari
===========

[![Stand With Ukraine](https://raw.githubusercontent.com/vshymanskyy/StandWithUkraine/main/banner-direct-single.svg)](https://stand-with-ukraine.pp.ua)

[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/domb-napari)](https://napari-hub.org/plugins/domb-napari)
![PyPI - Version](https://img.shields.io/pypi/v/domb-napari)
![PyPI - License](https://img.shields.io/pypi/l/domb-napari)
![Website](https://img.shields.io/website?up_message=domb.bio%2Fnapari&up_color=%2323038C93&url=https%3A%2F%2Fdomb.bio%2Fnapari%2F)

__napari Toolkit of Department of Molecular Biophysics <br /> Bogomoletz Institute of Physiology of NAS of Ukraine, Kyiv,  Ukraine__

This plugin offers widgets specifically designed to analyze the redistribution of fluorescence-labeled proteins in widefield epifluorescence time-lapse acquisitions. It is particularly useful for studying various phenomena, including:
- Calcium-dependent translocation of neuronal calcium sensors.
- Synaptic receptor traffic during long-term plasticity induction.
- Membrane protein tracking.

![](https://raw.githubusercontent.com/wisstock/domb-napari/master/images/translocation.gif)
__Hippocalcin (neuronal calcium sensor) redistributes in dendritic branches upon NMDA application__

---

## Detection of fluorescence redistributions
A set of widgets designed for preprocessing multispectral image stacks and detecting redistributions in fluorescence intensity. These widgets specifically analyze differential ""red-green"" image series to identify changes in fluorescence intensity.

Inspired by [Dovgan et al., 2010](https://pubmed.ncbi.nlm.nih.gov/20704590/) and [Osypenko et al., 2019](https://www.sciencedirect.com/science/article/pii/S0969996119301974?via%3Dihub).

### Dual-view stack registration
Registration of four-channel image stacks, including two excitation wavelengths and two emission pathbands, acquired with a dual-view beam splitter. This setup detects different spectral pathbands using distinct sides of the CCD matrix.

- `offset img` - input for a four-channel time-lapse image stack.
- `reference img` - an optional four-channel reference image (e.g., fluorescence beads image), used for offset estimation if `use reference img` is selected.
- `input crop` - number of pixels that will be deleted from each side of input stack frames to discard misalignment artifacts from the dual-view system.
- `output crop` - number of pixels that will be deleted from each side of output stack frames to discard registration artifacts.


### Multichannel stack preprocessing
- `stack order` - Represents the order of axes in the input data array (T - time, C - color, X and Y - image dimensions). If the input image stack has four dimensions (time, channel, x-axis, y-axis), channels will be split into individual three-dimensional images (time, x-axis, y-axis), each with the `_ch%index%` suffix.
- `median filter` - provides frame-by-frame image smoothing using a kernel of size specified in `median kernel`.
- `background subtraction` - compensates for background fluorescence intensity. Background intensity is estimated frame by frame as the mean intensity value outside of a simple Otsu mask.
- If the `photobleaching correction` option is selected, the image will undergo correction using either an exponential (method `exp`) or bi-exponential (method `bi_exp`) fitting.
- Image stacks can be cropped according to start and stop indexes specified in `frames range` if `drop frames` is selected.

![](https://raw.githubusercontent.com/wisstock/domb-napari/master/images/stack_preprocessing.png)


### Red-green series
Primary method for detecting fluorescence-labeled targets redistribution. This widget returns a series of differential images, each representing the intensity difference between the current frame and the previous one, output image labeled with the `_red-green` suffix.

Parameters:

- `left frames` - specifies the number of previous frames used for pixel-wise averaging.
- `space frames` - determines the number of frames between the last left frame and the first right frame.
- `right frames` - specifies the number of subsequent frames used for pixel-wise averaging.

`normalize by int`  function normalizes the differential images relative to the absolute intensity of the input image stack, which helps to reduce background noise amplitude.

If `save MIP` is selected, the maximal intensity projection (MIP) of the differential image stack will be saved with the `_red-green-MIP` suffix.

![](https://raw.githubusercontent.com/wisstock/domb-napari/master/images/rg_series.png)

### Up masking
Generates labels for insertion sites (regions with increasing intensity) based on `-red-green` images. Returns labels layer with `_up-labels` suffix.

Parameters:

- `detection img index` - index of the frame from `-red-green` image used for insertion sites detection.
- `insertion threshold` - threshold value for insertion site detection, intensity on selected `_red-green` frame normalized in -1 - 0 range.
- `opening footprint` - footprint size in pixels for mask filtering with morphology opening (disabled if 0).
- `save mask` - if selected, a total up mask (containing all ROIs) will be created with the `_up-mask` suffix.

![](https://raw.githubusercontent.com/wisstock/domb-napari/master/images/up_masking.png)

### Intensity masking
Extension of __Up Masking__ widget. Detects regions with increasing (`masking mode` - `up`) or decreasing (`masking mode` - `down`) intensity in `-red-green` images. Returns a labels layer with either `_up-labels` or `_down-labels` suffix, depending on the mode.

![](https://raw.githubusercontent.com/wisstock/domb-napari/master/images/int_masking.png)

---

## FRET detection
Widgets for detection and analysis of Förster resonance energy transfer multispectral image stacks.

Based on [Zal and Gascoigne, 2004](https://pubmed.ncbi.nlm.nih.gov/15189889/), [Chen et al., 2006](https://pubmed.ncbi.nlm.nih.gov/16815904/) and [Kamino et al., 2023](https://pubmed.ncbi.nlm.nih.gov/37014867/)

_Under development: calculation of crosstalk coefficients and G-factor, B-FRET estimation._

### E-FRET estimation
E-FRET estimation with 3-cube approach.

This method utilizes default values for `a` and `d` coefficients and the `G`-factor, optimized for the pair EYFP and ECFP in our experimental setup:
- Microscope Olympus IX71
- Cube Chroma 69008
- Dual-view system with Chroma 505DCXR beam splitter
- Donor excitation wavelength 435 nm
- Acceptor excitation wavelength 505 nm

Parameters:
- `DD img` - donor emission channel image acquired with the donor excitation wavelength.
- `AD img` - Acceptor emission channel image acquired with the donor excitation wavelength.
- `AA img` - Acceptor emission channel image acquired with the acceptor excitation wavelength.
- `output type` - Type of output image: sensitized emission (Fc), apparent FRET efficiency (Eapp), or FRET efficiency with photobleaching correction (Ecorr).

If the `save normalized` option is selected, an additional image will be saved. This image is normalized to the absolute intensity of the `AA img`, resulting in reduced background noise amplitude.

Raw Eapp| ![](https://raw.githubusercontent.com/wisstock/domb-napari/master/images/fret_raw.png)
:-:|:-:
__Normalized Eapp__|![](https://raw.githubusercontent.com/wisstock/domb-napari/master/images/fret_norm.png)

---

## Exo-/endo-cytosis monitoring with pH-sensitive tag
A set of widgets designed for the analysis of image series containing the pH-sensitive fluorescence protein Superecliptic pHluorin (SEP).

Insipred by [Fujii et al., 2017](https://pubmed.ncbi.nlm.nih.gov/28474392/) and [Sposini et al., 2020](https://www.nature.com/articles/s41596-020-0371-z).

### SEP image preprocessing
Processes image series obtained through repetitive pH exchange methods (such as U-tube or ppH approaches). `pH 1st frame` option indicates the 1st frame pH. By default frames with odd indexes, including index 0, are interpreted as images acquired at pH 7.0, representing total fluorescence intensity (saved with the suffix `_total`). Even frames are interpreted as images obtained at acidic pH (5.5-6.0), representing intracellular fluorescence only (saved with the suffix `_intra`).

If `calc surface img` is selected, an additional total fluorescence image with subtracted intracellular intensity will be saved as the cell surface fluorescence fraction (suffix `_surface`). The input image should be a 3-dimensional single-channel time-lapse.

The `calc projections` option allows obtaining individual pH series projections (pixel-wise series MIP - pixel-wise series average) for the detection of individual exo/endocytosis events.

---

## Intensty profiles building and data frame saving
### ROIs profiles
This widget builds a plot with mean intensity profiles for each Region of Interest (ROI) in labels. It uses either absolute intensity (if `absolute intensity` is selected) or relative intensities (ΔF/F0).

- `time scale` - sets the number of seconds between frames for x-axis scaling.
- `ΔF win` - the baseline intensity for ΔF/F0 profiles is estimated as the mean intensity of the specified number of initial profile points.
- `ΔF amplitude lim` - allows filtering of ROIs by minimum and maximum ΔF/F0 amplitudes. Note: Amplitude filtering works with ΔF/F0 profiles only.
- `profiles crop` - if selected, only a specified range of intensity profile indexes will be plotted, corresponding to the start and stop indexes from `profiles range`.

Additionally, you can save ROI intensity profiles as .csv files using the save data frame option and specifying the `saving path`. The output data frames named %img_name%_lab_prof.csv will include the following columns:

- `id` - Unique image ID, the name of the input napari.Image object.
- `roi` - ROI number, consecutively numbered starting from 1.
- `int` - ROI mean intensity, either raw or ΔF/F0, according to the selected intensity option.
- `index` - Frame index.
- `time` - Frame time point, adjusted according to the time scale.

_Note: The data frame will contain information for all ROIs; amplitude filtering and crop options pertain to plotting only._

Absolute intensity         | ![](https://raw.githubusercontent.com/wisstock/domb-napari/master/images/rois_abs.png)
:-------------------------:|:-------------------------:
__ΔF/F0__|![](https://raw.githubusercontent.com/wisstock/domb-napari/master/images/rois_df.png)


### Stat profiles
This widget builds a plot displaying the averaged intensity of all Regions of Interest (ROI) specified in labels. It can handle up to three images (img 0, img 1, and img 2) as inputs, depending on the selected profiles num.

`time scale`, `ΔF win`, and `absolute intensity` parameters are identical as described in the __ROIs profiles__ widget.

The `stat method` allows for the estimation of intensity and associated errors through the following methods:
- `se` - mean +/- standard error of the mean.
- `iqr` - median +/- interquartile range.
- `ci` - mean +/- 95% confidence interval based on the t-distribution.

Absolute intensity         | ![](https://raw.githubusercontent.com/wisstock/domb-napari/master/images/stat_abs.png)
:-------------------------:|:-------------------------:
__ΔF/F0__|![](https://raw.githubusercontent.com/wisstock/domb-napari/master/images/stat_df.png)
","['Framework :: napari', 'Development Status :: 3 - Alpha', 'License :: OSI Approved :: MIT License', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Operating System :: OS Independent', 'Topic :: Scientific/Engineering :: Bio-Informatics', 'Topic :: Scientific/Engineering :: Image Processing', 'Topic :: Scientific/Engineering :: Image Recognition', 'Topic :: Utilities']","['Documentation, https://domb.bio/', 'Source Code, https://github.com/wisstock/domb-napari', 'Bug Tracker, https://github.com/wisstock/domb-napari/issues', 'User Support, https://github.com/wisstock/domb-napari/issues']",,,domb-napari.dw_registration_widget,,,,,https://pypi.org/project/domb-napari,,
24,elastix-napari,0.2.1,,,elastix-napari,Viktor van der Valk,v.o.van_der_valk@lumc.nl,Apache Software License 2.0,,A toolbox for rigid and nonrigid registration of images.,>=3.8,"['itk-elastix (>=0.11.1)', 'numpy (>=1.19.0)', 'napari[all] (>=0.4.6)', 'napari-plugin-engine (>=0.1.4)', 'magicgui (>=0.4.0)', 'itk-napari-conversion (>=0.3.1)', 'napari-itk-io (>=0.1.0)']","# elastix-napari

[![License](https://img.shields.io/pypi/l/elastix-napari.svg?color=green)](https://github.com/SuperElastix/elastix-napari/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/elastix-napari.svg?color=green)](https://pypi.org/project/elastix-napari)
[![Python Version](https://img.shields.io/pypi/pyversions/elastix-napari.svg?color=green)](https://python.org)
[![tests](https://github.com/SuperElastix/elastix-napari/workflows/tests/badge.svg)](https://github.com/SuperElastix/elastix-napari/actions)
[![codecov](https://codecov.io/gh/SuperElastix/elastix-napari/branch/main/graph/badge.svg)](https://codecov.io/gh/SuperElastix/elastix-napari)
[![Youtube](https://img.shields.io/badge/YouTube-Demo-red)](https://www.youtube.com/watch?v=GzbP-qUR034)

The [napari] plugin for [elastix], a toolbox for rigid and nonrigid registration of images, based on [itk-elastix].

For a demo video see [youtube] channel.
For tutorials on how to use elastix, see our [Jupyter notebooks].

To find parameters that work well with specific datasets, see the [elastix Model Zoo].

<img width=""1438"" alt=""Screenshot 2021-05-12 at 15 07 24"" src=""https://user-images.githubusercontent.com/33719474/117980045-d6009b00-b333-11eb-9976-f64d34f4f7cc.png"">

## Installation

You can install `elastix-napari` via [pip]:

    pip install elastix-napari

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [Apache Software License 2.0] license,
""elastix-napari"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/SuperElastix/elastix-napari/issues
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
[elastix]: https://elastix.lumc.nl/
[itk-elastix]: https://github.com/InsightSoftwareConsortium/ITKElastix
[elastix Model Zoo]: https://elastix.lumc.nl/modelzoo/
[Jupyter notebooks]: https://mybinder.org/v2/gh/InsightSoftwareConsortium/ITKElastix/master?urlpath=lab/tree/examples%2FITK_Example01_SimpleRegistration.ipynb
[youtube]: https://www.youtube.com/watch?v=GzbP-qUR034
","['Development Status :: 4 - Beta', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Operating System :: OS Independent', 'License :: OSI Approved :: Apache Software License']","['Project Site, https://elastix.lumc.nl/', 'Bug Tracker, https://github.com/SuperElastix/elastix-napari/issues', 'Source Code, https://github.com/SuperElastix/elastix-napari', 'User Support, https://groups.google.com/g/elastix-imageregistration']",,,elastix-napari.elastix_registration,,,,,https://pypi.org/project/elastix-napari,,
25,empanada-napari,1.1.0,2023-04-17,2023-06-18,empanada-napari,"Madeline Barry, Abhishek Bhardwaj, Ryan Conrad",abhishek.bhardwaj@nih.gov,BSD-3-Clause,https://github.com/volume-em/empanada-napari,Napari plugin of algorithms for Panoptic Segmentation of organelles in EM,>=3.7,"['napari >=0.4.16', 'numpy ==1.22', 'napari-plugin-engine >=0.1.4', 'scikit-image >=0.19', 'empanada-dl >=0.1.7', 'imagecodecs', 'openpyxl', 'imagehash', 'mlflow', 'simpleitk', 'tqdm']","# empanada-napari

> [!IMPORTANT]
> **New Version Announcement!**
> * New modules 
>   * Morph labels - applies morphological operations to labels
>   * Count labels - counts and lists the label IDs within the dataset
>   * Filter labels - removes small pixel/voxel area labels or labels touching the image boundaries
>   * Export and import a model - export or import locally saved model files to use within empanada-napari
> * Updated modules 
>   * Export segmentations - now allows 3D segmentations to be exported as a single .tiff image
>   * Pick and save finetune/training patches - now allows paired grayscale and label mask images to create training patches 
>   * Split label - now allows users to specify new label IDs 
> * Updated documentation
>   * Check out the updated documentation [here](https://empanada.readthedocs.io/en/latest/empanada-napari.html)!

**The paper describing this work is now available [on Cell Systems](https://www.cell.com/cell-systems/fulltext/S2405-4712(22)00494-X).**

**Documentation for the plugin, including more detailed installation instructions, can be found [here](https://empanada.readthedocs.io/en/latest/empanada-napari.html).**

[empanada](https://github.com/volume-em/empanada) is a tool for deep learning-based panoptic segmentation of 2D and 3D electron microscopy images of cells.
This plugin allows the running of panoptic segmentation models trained in empanada within [napari](https://napari.org).
For help with this plugin please open an [issue](https://github.com/volume-em/empanada-napari/issues), for issues with napari specifically
raise an [issue here instead](https://github.com/napari/napari/issues).

## Implemented Models

  - *MitoNet*: A generalist mitochondrial instance segmentation model.

## Example Datasets

Volume EM datasets for benchmarking mitochondrial instance segmentation are available from
[EMPIAR-10982](https://www.ebi.ac.uk/empiar/EMPIAR-10982/).

## Installation

### New Users

If you've previously installed and used conda, it's recommended (but optional) to create a new virtual 
environment in order to avoid dependency conflicts. 

empanada-napari works with python=3.9 or lower

It's recommended to have installed napari through [conda](https://docs.conda.io/en/latest/miniconda.html). Then to install this plugin:

```shell
pip install empanada-napari==1.1.0
```

Launch napari:

```shell
napari
```

Look for empanada-napari under the ""Plugins"" menu.


### Returning Users

If you installed napari into a virtual environment as suggested in the original release documentation, 
be sure to activate it and uninstall the old empanada-napari.

```shell
pip uninstall empanada-napari
```

Then install the newest version:

```shell
pip install empanada-napari==1.1.0
```


![empanada](images/demo.gif)

## GPU Support

**Note: Mac doesn't support NVIDIA GPUS. This section only applies to Windows and Linux systems.**

As for any deep learning models, having a GPU installed on your system will significantly
increase model throughput (although we ship CPU optimized versions of all models with the plugin).

This plugin relies on torch for running models. If a GPU was found on your system, then you will see that the
""Use GPU"" checkbox is checked by default in the ""2D Inference"" and ""3D Inference"" plugin widgets. Or if when running
inference you see a message that says ""Using CPU"" in the terminal that means a GPU is not being used.

Make sure that GPU drivers are correctly installed. In terminal or command prompt:

```shell
nvidia-smi
```

If this returns ""command not found"" then you need to [install the driver from NVIDIA](https://www.nvidia.com/download/index.aspx). Instead, if
if the driver is installed correctly, you may need to switch to the GPU enabled version of torch.

First, uninstall the current version of torch:

```shell
pip uninstall torch
```

Then [install torch >= 1.10 using conda for your system](https://pytorch.org/get-started/locally/).
This command should work:

```shell
conda install pytorch cudatoolkit=11.3 -c pytorch
```

## Citing this work

If you use results generated by this plugin in a publication, please cite:

```bibtex
@article { Conrad2023,
    author = {Conrad, Ryan and Narayan, Kedar},
    title = {Instance segmentation of mitochondria in electron microscopy images with a generalist deep learning model trained on a diverse dataset},
    journal = {Cell Systems},
    year = {2023},
    month = {Jan},
    day = {18},
    publisher = {Elsevier},
    volume = {14},
    number = {1},
    pages = {58-71.e5},
    issn = {2405-4712},
    doi = {10.1016/j.cels.2022.12.006},
    url = {https://doi.org/10.1016/j.cels.2022.12.006}
}
```
","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/volume-em/empanada-napari/issues', 'Documentation, https://github.com/volume-em/empanada-napari#README.md', 'Source Code, https://github.com/volume-em/empanada-napari', 'User Support, https://github.com/volume-em/empanada-napari/issues']",,,empanada-napari.test_widget,,,,,https://pypi.org/project/empanada-napari,https://github.com/volume-em/empanada-napari,
26,EpiTools,0.0.12,2023-08-01,2023-09-07,epitools,Yanlan Mao,"""Daniel R. Matthews"" <d.matthews@ucl.ac.uk>, Giulia Paci <g.paci@ucl.ac.uk>, Pablo Vicente Munuera <p.munuera@ucl.ac.uk>, ""Patrick J. Roddy"" <patrick.roddy@ucl.ac.uk>, ""Paul J. Smith"" <paul.j.smith@ucl.ac.uk>, Yanlan Mao <y.mao@ucl.ac.uk>",BSD 3-Clause,https://github.com/epitools/epitools,Quantifying 2D cell shape and epithelial tissue dynamics,>=3.9,"['PartSeg', 'magicgui', 'matplotlib', 'napari', 'networkx', 'numpy', 'pandas', 'scikit-image >=0.20', 'scipy', ""black ; extra == 'dev'"", ""mypy ; extra == 'dev'"", ""pre-commit ; extra == 'dev'"", ""pyqt5 ; extra == 'dev'"", ""ruff ; extra == 'dev'"", ""tox ; extra == 'dev'"", ""myst-parser ; extra == 'docs'"", ""pydata-sphinx-theme ; extra == 'docs'"", ""pytz ; extra == 'docs'"", ""sphinx-autobuild ; extra == 'docs'"", ""sphinx <5 ; extra == 'docs'"", ""sphinx-autodoc-typehints ; extra == 'docs'"", ""sphinxcontrib-video ; extra == 'docs'"", ""types-pytz ; extra == 'docs'"", ""btrack[napari] >=0.6.1 ; extra == 'wf'"", ""napari-segment-blobs-and-things-with-membranes ; extra == 'wf'""]","[![Licence](https://img.shields.io/pypi/l/epitools.svg?color=green)](https://raw.githubusercontent.com/epitools/epitools/main/LICENCE.md)
[![PyPI](https://img.shields.io/pypi/v/epitools.svg?color=green)](https://pypi.org/project/epitools)
[![Python Version](https://img.shields.io/pypi/pyversions/epitools.svg?color=green)](https://python.org)
[![tests](https://github.com/epitools/epitools/actions/workflows/test.yml/badge.svg)](https://github.com/epitools/epitools/actions/workflows/test.yml)
[![Documentation](https://readthedocs.org/projects/epitools/badge/?version=latest)](https://epitools.readthedocs.io/en/latest/?badge=latest)
[![coverage](https://coveralls.io/repos/github/epitools/epitools/badge.svg?branch=main)](https://coveralls.io/github/epitools/epitools?branch=main)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/epitools)](https://napari-hub.org/plugins/epitools)

# Welcome to EpiTools!

EpiTools is a Python package and associated [napari](https://napari.org/stable/) plugin to extract the membrane signal from epithelial tissues and analyze it with the aid of computer vision.

The development of EpiTools was inspired by the challenges in analyzing time-lapses of growing Drosophila imaginal discs.

The folded morphology, the very small apical cell surfaces and the long time series required a new automated cell recognition to accurately study growth dynamics.

## Installation

First, install [napari](https://napari.org/index.html#installation).

The recommended way to install `EpiTools` is via
[pip](https://pypi.org/project/pip)

```sh
python -m pip install epitools
```

To install the latest development version of `EpiTools` clone this repository
and run

```sh
python -m pip install -e .
```

If working on Apple Silicon make sure to also install the following package from
[conda-forge](https://conda-forge.org).

```sh
conda install -c conda-forge pyqt
```

### Recommended Companion Napari Plugins

To also install the recommended plugins for the `EpiTools` workflow run

```sh
python -m pip install epitools[wf]
```

and

```sh
python -m pip install -e .[wf]
```

When installing with Apple Mac OS X terminal, you might need to add '""' to [wf] as in:

```sh
python -m pip install -e .""[wf]""
```

If working on Apple Silicon make sure to also install the following package from
[conda-forge](https://conda-forge.org)

```sh
conda install -c conda-forge cvxopt
```

which is required for [btrack](https://github.com/quantumjot/btrack).

## Issues

If you encounter any problems, please
[file an issue](https://github.com/epitools/epitools/issues) along with a
detailed description.

## Contributing

Contributions are very welcome. Tests can be run with [tox](https://tox.wiki),
please ensure the coverage at least stays the same before you submit a pull request.
","['Framework :: napari', 'Intended Audience :: Science/Research', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python', 'Topic :: Scientific/Engineering :: Image Processing', 'Topic :: Scientific/Engineering :: Medical Science Apps.', 'Topic :: Scientific/Engineering :: Bio-Informatics']","['Code, https://github.com/epitools/epitools', 'Download, https://pypi.org/project/epitools', 'Homepage, https://github.com/epitools/epitools', 'Issues, https://github.com/epitools/epitools/issues']",epitools.get_reader,epitools.write_single_image,epitools.projection_widget,epitools.load_sample_data,"['*.tif', '*.tiff']","['.tif', '.tiff']","['.tif', '.tiff']",https://pypi.org/project/epitools,https://github.com/epitools/epitools,
27,faser,0.2.9,,,faser,jhnnsrs,jhnnsrs@gmail.com,,,,">=3.8,<3.11","['magicgui (>=0.4.0,<0.5.0)', 'napari-plugin_engine (>=0.1.4,<0.2.0)', 'numpy (>=1.22.4,<2.0.0)', 'pydantic (>=1.9.1,<2.0.0)']",,"['Framework :: napari', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9']",,,,faser.napari.generate_psf,,,,,https://pypi.org/project/faser,,
28,Generate Dense Patches,0.0.2,2023-10-28,2023-10-28,generate-dense-patches,Aayush Bhatawadekar,asbhatawadekar@gmail.com,BSD-3-Clause,https://pypi.org/project/generate-dense-patches,A simple plugin to create a lot of training data from a 3D volume and mask,>=3.8,"['napari >=0.4.18', 'napari-plugin-engine >=0.2.0', 'numpy ==1.22', 'scikit-image >=0.19', 'magicgui', 'imagecodecs', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# generate-dense-patches

[![License BSD-3](https://img.shields.io/pypi/l/generate-dense-patches.svg?color=green)](https://github.com/volume-em/generate-dense-patches/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/generate-dense-patches.svg?color=green)](https://pypi.org/project/generate-dense-patches)
[![Python Version](https://img.shields.io/pypi/pyversions/generate-dense-patches.svg?color=green)](https://python.org)
[![tests](https://github.com/volume-em/generate-dense-patches/workflows/tests/badge.svg)](https://github.com/volume-em/generate-dense-patches/actions)
[![codecov](https://codecov.io/gh/volume-em/generate-dense-patches/branch/main/graph/badge.svg)](https://codecov.io/gh/volume-em/generate-dense-patches)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/generate-dense-patches)](https://napari-hub.org/plugins/generate-dense-patches)

A simple plugin to create a lot of training data from a 3D volume and mask. For help with this plugin please open an issue, for issues with napari specifically raise an issue here instead.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

## Installation

It's recommended to have installed napari and pyqt through conda. 

    conda install napari pyqt

Then to install this plugin via [pip]:

    pip install generate-dense-patches



To install latest development version :

    pip install git+https://github.com/volume-em/generate-dense-patches.git


## Usage
To use this plugin with napari:
1. Drag and drop an image and/or segmentation mask (tif) into the viewer.
2. Open ""Plugins"" Toolbar and select ""Generate dense patches"" and click ""Generate 2D Patches""

This plugin works to create a lot of 2D training data by generating an $n^3$ cube, rotating every $\theta$ slices and saving every (step size) slice of the generated volume.

3. Make sure the ""save directory box"", ""step size"", ""rotation theta"", and ""patch size"" is filled in

If no point is placed, then the center of the image will be used as the center of the cube. If a point is placed, then the center of the cube will be the point.

4. Press run and wait for the patches to be generated.

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""generate-dense-patches"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/volume-em/generate-dense-patches/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/volume-em/generate-dense-patches/issues', 'Documentation, https://github.com/volume-em/generate-dense-patches#README.md', 'Source Code, https://github.com/volume-em/generate-dense-patches', 'User Support, https://github.com/volume-em/generate-dense-patches/issues']",,,generate-dense-patches.make_patches_widget,,,,,https://pypi.org/project/generate-dense-patches,,
29,grabber-ift,0.2.2,2022-02-02,2023-06-18,grabber-ift,Jordão Bragantini,jordao.bragantini@gmail.com,MIT,https://github.com/LIDS-UNICAMP/grabber,A tool for contour-based segmentation correction (2D only).,>=3.7,"['napari-plugin-engine (>=0.1.4)', 'pyift (>=0.0.4)', 'opencv-python-headless (>=4.4.0)', 'scipy (>=1.7.2)']","# Grabber: A Tool to Improve Convergence in Interactive Image Segmentation

[![License](https://img.shields.io/pypi/l/grabber.svg?color=green)](https://github.com/LIDS-UNICAMP/grabber/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/grabber.svg?color=green)](https://pypi.org/project/grabber)
[![Python Version](https://img.shields.io/pypi/pyversions/grabber.svg?color=green)](https://python.org)
[![tests](https://github.com/LIDS-UNICAMP/grabber/workflows/tests/badge.svg)](https://github.com/LIDS-UNICAMP/grabber/actions)
[![codecov](https://codecov.io/gh/LIDS-UNICAMP/grabber/branch/master/graph/badge.svg)](https://codecov.io/gh/LIDS-UNICAMP/grabber)

A tool for contour-based segmentation correction (2D only).

This repository provides a demo code of the paper:
> **Grabber: A Tool to Improve Convergence in Interactive Image Segmentation**
> [Jordão Bragantini](https://jookuma.github.io/), Bruno Moura, [Alexandre X. Falcão](http://lids.ic.unicamp.br/), [Fábio A. M. Cappabianco](https://scholar.google.com/citations?user=qmH9VEEAAAAJ&hl=en&oi=ao)

https://user-images.githubusercontent.com/21022743/145699960-57da06a5-668f-4e81-82b5-7f3d3ddf8ee3.mp4

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/docs/plugins/index.html
-->

## Installation

You can install `grabber-ift` via [pip]:

    pip install grabber-ift


## Known Limitations

This implementation doesn't support the items below, feel free to open a PR to add them.

- It only support 2D image, supporting 3D images isn't trivial, but it could be applied per slice with minor changes.

## Citation

If this work was useful for your research, please cite our paper:

```
@article{bragantini2020grabber,
  title={Grabber: A Tool to Improve Convergence in Interactive Image Segmentation,
  author={Bragantini, Jord{\~a}o and Bruno Moura, Falc{\~a}o, Alexandre Xavier and Cappabianco, F{\'a}bio AM,
  journal={Pattern Recognition Letters},
  year={2020}
}
```

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [MIT] license,
""grabber"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/


","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: MIT License']",,,,grabber-ift.GrabberWidget,,,,,https://pypi.org/project/grabber-ift,https://github.com/LIDS-UNICAMP/grabber,
30,Guanine Crystal Analysis,0.0.2,2022-08-18,2023-06-05,guanine-crystal-analysis,Mara Lampert,mara_harriet.lampert@mailbox.tu-dresden.de,BSD-3-Clause,https://github.com/biapol/guanine-crystal-analysis,"A plugin for the guanine crystal segmentation, classification and characterization in the zebrafish eye",>=3.8,"['numpy', 'magicgui', 'qtpy', 'apoc', 'scikit-image', 'pandas', 'napari-simpleitk-image-processing', 'napari-skimage-regionprops', 'pyclesperanto-prototype', 'scikit-learn', 'napari-workflows', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# guanine-crystal-analysis

[![License BSD-3](https://img.shields.io/pypi/l/guanine-crystal-analysis.svg?color=green)](https://github.com/biopo/guanine-crystal-analysis/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/guanine-crystal-analysis.svg?color=green)](https://pypi.org/project/guanine-crystal-analysis)
[![Python Version](https://img.shields.io/pypi/pyversions/guanine-crystal-analysis.svg?color=green)](https://python.org)
[![tests](https://github.com/biopo/guanine-crystal-analysis/workflows/tests/badge.svg)](https://github.com/biopo/guanine-crystal-analysis/actions)
[![codecov](https://codecov.io/gh/biopo/guanine-crystal-analysis/branch/main/graph/badge.svg)](https://codecov.io/gh/biopo/guanine-crystal-analysis)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/guanine-crystal-analysis)](https://napari-hub.org/plugins/guanine-crystal-analysis)

A plugin for guanine crystal segmentation and classification in the zebrafish eye. More precisely, it provides a workflow that measures on guanine crystal labels and sorts out overlaying partially segmented crystals during classification.

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/index.html
-->

## Usage 

This plugin is suited for users who
- want to derive size-, shape and intensity-based parameters from individual guanine crystals
- struggle with partially segmented or overlapping crystals
- want to investigate further the size and shape of these guanine crystals

This plugin is not suited for users who 
- are interested in further investigations of intensity of guanine crystals

You can find the plugin in napari under `Plugins` → `guanine-crystal-analysis`

### Image Input

This plugin can be used on individual 2D slices of z-stacks as the workflow was developed on such input.
Therefore, the quality of the result might differ on differing input, like crops or maximum projections.

### 1. Normalization

You can normalize the image selecting `Normalization` where you only need to specify your input image and click on the `Run` button. 

![](img/plugin/normalization.png)

Normalizing the image helps to adjust the intensity values and needs to be applied here because the object segmenter is only trained on normalized images.

### 2. Segmentation

When selecting `Segmentation`, you need to select the normalized image and a minimum pixel count of label images and click on the `Run` button again.
![](img/plugin/segmentation.png)
This avoids having too small and unhelpful labels and is set by default to 50 pixels. 
For the training of the model, an [APOC](https://github.com/haesleinhuepf/apoc) pixel classifier was used.

### 3. Analyze Image

Under `Analyze Image`, you can extract features from your image and label image by selecting them and clicking on the `Run` button.  
![](img/plugin/analyzeimage.png)
The extracted features are a combination of the two libraries [napari-skimage-regionprops](https://github.com/haesleinhuepf/napari-skimage-regionprops) and [napari-simpleitk-image-processing](https://github.com/haesleinhuepf/napari-simpleitk-image-processing). They can be devided into size-, shape-, and intensity-based parameters: 

| **size** | **shape**                 | **intensity**  
|----------|---------------------------|-------------------|
|![](img/plugin/size.png)      	|![](img/plugin/shape.png)              	|![](img/plugin/intensity.png)  	|
| area     	| aspect ratio              	| maximum intensity 	|
|          	| perimeter                 	| mean intensity    	|
|          	| major-axis-length         	| minimum intensity 	|
|          	| minor-axis-length         	| median            	|
|          	| circularity               	| sum               	|
|          	| solidity                  	| variance          	|
|          	| eccentricity              	|                   	|
|          	| roundness                 	|                   	|
|          	| perimeter-on-border       	|                   	|
|          	| perimeter-on-border-ratio 	|                   	|

You can find a glossary with an explanation of these features [in this blog post](https://focalplane.biologists.com/2023/05/03/feature-extraction-in-napari/)
Some of the guanine crystals are not correctly segmented because of overlay or interference patterns. This problem is addressed with the help of a classification step demonstrated next

### 4. Classify Objects

You can divide the crystal labels into predicted (blue) and discarded (brown) crystal labels using `Classify Objects`. There you can choose classifiers trained on intensity-, shape- and/or size-based parameters with the help of the checkboxes.
![](img/plugin/classifyobjects.png)
For the training of the model, an [APOC](https://github.com/haesleinhuepf/apoc) object classifier was used.
It is recommended to later on not measure the parameters that the classifier was trained on, but other ones.

### 5. Bad Label Exclusion

Now, you can get rid of the discarded (brown) labels for further analysis using `Bad Label Exclusion`. Select the two label images of segmentation and classification result and press the `Run` button again. 
![](img/plugin/badlabelexclusion.png)
The result is a label image with only the predicted (blue) labels which are relabeled sequentially. If you want to derive measurements on these predicted labels, you can just use  `Analyze Image` again.

### ""Analyze Deluxe""

You can also do all the explained steps in one click using the `Analyze Deluxe` function.
![](img/plugin/analyzedeluxe.png)


## Installation

You can install `guanine-crystal-analysis` via [pip]:

    pip install guanine-crystal-analysis



To install latest development version :

    pip install git+https://github.com/biopo/guanine-crystal-analysis.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## Acknowledgements
This project was done in collaboration with the [Rita Mateus Laboratory](https://www.ritamateus.com/). The images shown in the documentation and in the demo jupyter notebooks were acquired there. 
This project was supported by the Deutsche Forschungsgemeinschaft under Germany’s Excellence Strategy – EXC2068 - Cluster of Excellence ""Physics of Life"" of TU Dresden. 
This project has been made possible in part by grant number [2021-240341 (Napari plugin accelerator grant)](https://chanzuckerberg.com/science/programs-resources/imaging/napari/improving-image-processing/) from the Chan Zuckerberg Initiative DAF, an advised fund of the Silicon Valley Community Foundation.


## License

Distributed under the terms of the [BSD-3] license,
""guanine-crystal-analysis"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/biopo/guanine-crystal-analysis/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/biapol/guanine-crystal-analysis/issues', 'Documentation, https://github.com/biapol/guanine-crystal-analysis#README.md', 'Source Code, https://github.com/biapol/guanine-crystal-analysis', 'User Support, https://github.com/biapol/guanine-crystal-analysis/issues']",,,guanine-crystal-analysis.normalization,guanine-crystal-analysis.make_sample_data,,,,https://pypi.org/project/guanine-crystal-analysis,https://github.com/biapol/guanine-crystal-analysis,
31,Hesperos application,0.2.1,2022-07-07,2023-07-25,hesperos,Charlotte Godard,charlotte.godard@pasteur.fr,BSD-3-Clause,https://github.com/chgodard/hesperos,A plugin to manually or semi-automatically segment medical data and correct previous segmentation data.,>=3.8,"['numpy', 'qtpy', 'tifffile', 'scikit-image', 'scikit-learn', 'SimpleITK', 'pandas', 'napari (<0.4.15)', 'napari-plugin-engine', 'imageio-ffmpeg', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","<div align=""justify"">
    
# HESPEROS PLUGIN FOR NAPARI

[![License](https://img.shields.io/pypi/l/hesperos.svg?color=green)](https://github.com/DBC/hesperos/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/hesperos.svg?color=green)](https://pypi.org/project/hesperos)
[![Python Version](https://img.shields.io/pypi/pyversions/hesperos.svg?color=green)](https://python.org)
[![tests](https://github.com/DBC/hesperos/workflows/tests/badge.svg)](https://github.com/DBC/hesperos/actions)
[![codecov](https://codecov.io/gh/DBC/hesperos/branch/main/graph/badge.svg)](https://codecov.io/gh/DBC/hesperos)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/hesperos)](https://napari-hub.org/plugins/hesperos)

A Napari plugin for pre-defined manual segmentation or semi-automatic segmentation with a one-shot learning procedure. The objective was to simplify the interface as much as possible so that the user can concentrate on annotation tasks using a pen on a tablet, or a mouse on a computer. 
    
This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

    
# Table of Contents
- [Installation and Usage](#installation-and-usage)
    * [Automatic installation](#automatic-installation)
    * [Manual installation](#manual-installation)
    * [Upgrade Hesperos version](#upgrade-hesperos-version)
- [Hesperos: *Manual Segmentation and Correction* mode](#hesperos-manual-segmentation-and-correction-mode)
    * [Import and adjust your image](#import-and-adjust-your-image-use-panel-1)
    * [Layer controls](#layer-controls)
    * [Annotate your image](#annotate-your-image-use-panel-2)
    * [Select slices of interest](#select-slices-of-interest-use-panel-3----only-displayed-for-the-shoulder-bones-category)
    * [Export annotations](#export-annotations-use-panel-3----or-4-if-the-shoulder-bones-category-is-selected)
- [Hesperos: *OneShot Segmentation* mode](#hesperos-oneshot-segmentation-mode)
    * [Import and adjust your image](#import-and-adjust-your-image-use-panel-1)
    * [Annotate your image](#annotate-your-image-use-panel-2)
    * [Run automatic segmentation](#run-automatic-segmentation-use-panel-3)
    * [Export annotations](#export-annotations-use-panel-4)

        
# Installation and Usage
The Hesperos plugin is designed to run on Windows (11 or less) and MacOS with Python 3.8 / 3.9 / 3.10.
     
    
## Automatic installation
1. Install [Anaconda] and unselect *Add to PATH*. Keep in mind the path where you choose to install anaconda.
2. Only download the *script_files* folder for [Windows](/script_files/for_Windows/) or [Macos](/script_files/for_Windows/). 
3. Add your Anaconda path in these script files:
    1. <ins>For Windows</ins>: 
    Right click on the .bat files (for [installation](/script_files/for_Windows/install_hesperos_env.bat) and [running](/script_files/for_Windows/run_hesperos.bat)) and select *Modify*. Change *PATH_TO_ADD* with your Anaconda path. Then save the changes.
        > for exemple:
        ```
        anaconda_dir=C:\Users\chgodard\anaconda3
        ```
    2. <ins>For Macos</ins>:
        1. Right click on the .command files (for [installation](/script_files/for_Macos/install_hesperos_env.command) and [running](/script_files/for_Macos/run_hesperos.command)) and select *Open with TextEdit*. Change *PATH_TO_ADD* with your Anaconda path. Then save the changes.
            > for exemple:
            ```
            source ~/opt/anaconda3/etc/profile.d/conda.sh
            ```
        2. In your terminal, change the permissions to allow the following .command files to be run (change *PATH* with the path of your .command files): 
            ``` 
            chmod u+x PATH/install_hesperos_env.command 
            chmod u+x PATH/run_hesperos.command 
            ```
4. Double click on the **install_hesperos_env file** to create a virtual environment in Anaconda with python 3.9 and Napari 0.4.14. 
    > /!\ The Hesperos plugin is not yet compatible with Napari versions superior to 0.4.14.
5. Double click on the **run_hesperos file** to run Napari from your virtual environment.
6. In Napari: 
    1. Go to *Plugins/Install Plugins...*
    2. Search for ""hesperos"" (it can take a while to load).
    3. Install the **hesperos** plugin.
    4. When the installation is done, close Napari. A restart of Napari is required to finish the plugin installation.
7. Double click on the **run_hesperos file** to run Napari.
8. In Napari, use the Hesperos plugin with *Plugins/hesperos*.

    
## Manual installation
1. Install [Anaconda] and unselect *Add to PATH*.
2. Open your Anaconda prompt command.
3. Create a virtual environment with Python 3.8 / 3.9 / 3.10:
    ```
    conda create -n hesperos_env python=3.9
    ```
4. Install the required Python packages in your virtual environment:
    ```
    conda activate hesperos_env
    conda install -c conda-forge napari=0.4.14 
    conda install -c anaconda pyqt
    pip install hesperos
    ```
    > /!\ Hesperos plugin is not yet compatible with napari version superior to 0.4.14.
5. Launch Napari:
    ```
    napari
    ```
    
## Upgrade Hesperos version
1. Double click on the **run_hesperos file** to run Napari. 
2. In Napari: 
    1. Go to *Plugins/Install Plugins...*
    2. Search for ""hesperos"" (it can take a while to load).
    3. Click on *Update* if a new version of Hesperos has been found. You can check the latest version of Hesperos in the [Napari Hub](https://www.napari-hub.org/plugins/hesperos).
    4. When the installation is done, close Napari. A restart of Napari is required to finish the plugin installation.
   
    
# Hesperos: *Manual Segmentation and Correction* mode
    
 The ***Manual Segmentation and Correction*** mode of the Hesperos plugin is a simplified and optimized interface to do basic 2D manual segmentation of several structures in a 3D image using a mouse or a stylet with a tablet.

    
 <img src=""https://user-images.githubusercontent.com/49953723/193262711-710673f2-5b53-4eb6-a7c7-6dada9d28d92.PNG"" width=""1000px""/>
    
## Import and adjust your image *(use Panel 1)*
The Hesperos plugin can be used with Digital Imaging and COmmunications in Medicine (DICOM), Neuroimaging Informatics Technology Initiative (NIfTI) or Tagged Image File Format (TIFF) images. To improve performances, use images that are located on your own disk.

1. To import data:
    - use the <img src=""https://user-images.githubusercontent.com/49953723/193262334-3c28e733-36ab-4504-9a6d-acd298c15994.PNG"" width=""100px""/> button for *(.tiff, .tif, .nii or .nii.gz)* image files.
    - use the <img src=""https://user-images.githubusercontent.com/49953723/193262624-149a4461-fbac-4498-a2b8-33bdd88e3a9f.PNG"" width=""100px""/> button for a DICOM serie. /!\ Folder with multiple DICOM series is not supported.  
2. After the image has loaded, a slider appears that allows to zoom in/out: <img src=""https://user-images.githubusercontent.com/49953723/193262738-7e6e68a9-0890-4e18-92a9-dbf2168a6bb5.PNG"" width=""100px""/>. Zooming is also possible with the <img src=""https://user-images.githubusercontent.com/49953723/193262725-7d4f7b09-d119-45cf-a9d4-c42c5f848c1a.PNG"" width=""25px""/> button in the layer controls panel. 
3. If your data is a DICOM serie, you have the possibility to directly change the contrast of the image (according to the Hounsfield Unit):
    - by choosing one of the two predefined contrasts: *CT bone* or *CT Soft* in <img src=""https://user-images.githubusercontent.com/49953723/193262708-17e1d301-0a9a-497f-9feb-613e69893c06.PNG"" width=""150px""/>.
    - by creating a custom default contrast with the <img src=""https://user-images.githubusercontent.com/49953723/193262707-466917b4-b885-429b-9924-6481fa6410bb.PNG"" width=""30px""/> button and selecting *Custom Contrast*. Settings can be exported as a .json file with the <img src=""https://user-images.githubusercontent.com/49953723/193262709-e1ad5321-1f60-4b60-a715-7c494670e1cd.PNG"" width=""30px""/> button.
    - by loading a saved default contrast with the <img src=""https://user-images.githubusercontent.com/49953723/193262710-c9f66354-f896-4e59-8718-70e5509875af.PNG"" width=""30px""/> button and selecting *Custom Contrast*.
4. In the bottom left corner of the application you also have the possibility to: 
    - <img src=""https://user-images.githubusercontent.com/49953723/193262716-d9947eb9-d87f-4251-af76-2d906cd36018.PNG"" width=""25px""/>: change the order of the visible axis (for example go to sagittal, axial or coronal planes).
    - <img src=""https://user-images.githubusercontent.com/49953723/193262717-12afbfb1-49ae-4a77-a83e-5bc99850734a.PNG"" width=""25px""/>: transpose the 3D image on the current axis being displayed.


## Layer controls

When data is loading, two layers are created: the *`image`* layer and the *`annotations`* layer. Order in the layer list correspond to the overlayed order. By clicking on these layers you will have acces to different layer controls (at the top left corner of the application). All actions can be undone/redone with the Ctrl-Z/Shift-Ctrl-Z keyboard shortcuts. You can also hide a layer by clicking on its eye icon on the layer list.
    
    
<ins>For the *image* layer:</ins>
- *`opacity`*: a slider to control the global opacity of the layer.
- *`contrast limits`*: a double slider to manually control the contrast of the image (same as the <img src=""https://user-images.githubusercontent.com/49953723/193262708-17e1d301-0a9a-497f-9feb-613e69893c06.PNG"" width=""150px""/> option for DICOM data).
    

<ins>For the *annotations* layer:</ins>
- <img src=""https://user-images.githubusercontent.com/49953723/193262718-30882770-59eb-4d2b-9cfe-8b88537560c4.PNG"" width=""25px""/>: erase brush to erase all labels at once (if *`preserve labels`* is not selected) or only erase the selected label (if *`preserve labels`* is selected).
- <img src=""https://user-images.githubusercontent.com/49953723/193262722-6bb6e6a4-ae7a-4ad1-b7f8-898e54ad62c3.PNG"" width=""25px""/>: paint brush with the same color than the *`label`* rectangle.
- <img src=""https://user-images.githubusercontent.com/49953723/193262719-f816b21e-78fd-4ba7-b415-30a461cbd652.PNG"" width=""25px""/>: fill bucket with the same color than the *`label`* rectangle.
- <img src=""https://user-images.githubusercontent.com/49953723/193262725-7d4f7b09-d119-45cf-a9d4-c42c5f848c1a.PNG"" width=""25px""/>: select to zoom in and out with the mouse wheel (same as the zoom slider at the top right corner in Panel 1).
- *`label`*: a colored rectangle to represent the selected label.  
- *`opacity`*: a slider to control the global opacity of the layer.  
- *`brush size limits`*: a slider to control size of the paint/erase brush.    
- *`preserve labels`*: if selected, all actions are applied only on the selected label (see the *`label`* rectangle); if not selected, actions are applied on all labels.
- *`show selected`*: if selected, only the selected label will be display on the layer; if not selected, all labels are displayed.
   
    
>*Remark*: a second option for filling has been added
>1. Drawn the egde of a closed shape with the paint brush mode.  
>2. Double click to activate the fill bucket.  
>3. Click inside the closed area to fill it.  
>4. Double click on the filled area to deactivate the fill bucket and reactivate the paint brush mode.
    

## Annotate your image *(use Panel 2)*
    
Manual annotation and correction on the segmented file is done using the layer controls of the *`annotations`* layer. Click on the layer to display them. /!\ You have to choose a structure to start annotating *(see 2.)*.
1. To modify an existing segmentation, you can directy open the segmented file with the <img src=""https://user-images.githubusercontent.com/49953723/193262702-df3b4fb8-63d0-4a1b-b1c9-8391cf8c3f22.PNG"" width=""130px""/> button. The file needs to have the same dimensions as the original image. 
    > /!\ Only .tiff, .tif, .nii and .nii.gz files are supported as segmented files.  
    
2. Choose a structure to annotate in the drop-down menu
    - *`Fetus`*: to annotate pregnancy image.
    - *`Shoulder`*: to annotate bones and muscles for shoulder surgery.
    - *`Shoulder Bones`*: to annotate only few bones for shoulder surgery.
    - *`Feta Challenge`*: to annotate fetal brain MRI with the same label than the FeTA Challenge (see ADD LIEN WEB).
    
> When selecting a structure, a new panel appears with a list of elements to annotate. Each element has its own label and color. Select one element in the list to automatically activate the paint brush mode with the corresponding color (color is updated in the *`label`* rectangle in the layer controls panel).
    
3. All actions can be undone with the <img src=""https://user-images.githubusercontent.com/49953723/193265848-8c458035-609a-433e-aa82-5d9588971425.PNG"" width=""30px""/> button or Ctrl-Z.
    
4. If you need to work on a specific slice of your 3D image, but also have to explore the volume to understand some complex structures, you can use the locking option to facilitate the annotation task.
    - <ins>To activate the functionality</ins>: 
        1. Go to the slice of interest.
        2. Click on the <img src=""https://user-images.githubusercontent.com/49953723/193262706-40f3dbca-5589-406d-81e8-e150ae8bfab6.PNG"" width=""30px""/> button => will change the button to <img src=""https://user-images.githubusercontent.com/49953723/193262703-2b2ea2dc-24fa-438b-a75c-3aa42b210f53.PNG"" width=""30px""/> and save the layer index.
        3. Scroll in the z-axis to explore the data (with the mouse wheel or the slider under the image).
        4. To go back to your slice of interest, click on the <img src=""https://user-images.githubusercontent.com/49953723/193262703-2b2ea2dc-24fa-438b-a75c-3aa42b210f53.PNG"" width=""30px""/> button.
    - <ins>To deactivate the functionality</ins> (or change the locked slice index): 
        1. Go to the locked slice.
        2. Click on the <img src=""https://user-images.githubusercontent.com/49953723/193262703-2b2ea2dc-24fa-438b-a75c-3aa42b210f53.PNG"" width=""30px""/> button  => change the button to <img src=""https://user-images.githubusercontent.com/49953723/193262706-40f3dbca-5589-406d-81e8-e150ae8bfab6.PNG"" width=""30px""/> and ""unlock"" the slice.


## Select slices of interest *(use Panel 3 -- only displayed for the Shoulder Bones category)*

This panel will only be displayed if the *`Shoulder Bones`* category is selected. A maxiumum of 10 slices can be selected in a 3D image and the corresponding z-indexes will be integrated in the metadata during the exportation of the segmentation file.
   
   > /!\ Metadata integration is available only for exported .tiff and .tif files and with the *`Unique`* save option. 

- <img src=""https://user-images.githubusercontent.com/49953723/201736039-4ed10553-4a4b-4d5e-9d61-826dc139e437.png"" width=""25px""/> : to add the currently displayed z-index in the drop-down menu.
- <img src=""https://user-images.githubusercontent.com/49953723/201736105-a9c45264-412a-453b-8475-5a9ab856b07d.png"" width=""25px""/> : to remove the currently displayed z-index from the drop-down menu.
- <img src=""https://user-images.githubusercontent.com/49953723/201736152-319d8559-dbfc-4e52-aeb3-e8e34445f67a.png"" width=""25px""/> : to go to the z-index selected in the drop-down menu. The icon will be checked when the currently displayed z-index matches the selected z-index in the drop-down menu.
- <img src=""https://user-images.githubusercontent.com/49953723/201733835-7bee453a-bc07-416f-8b95-aaf803683cac.png"" width=""100px""/> : a drop-down menu containing the list of selected z-indexes. Select a z-index from the list to work with it more easily.


## Export annotations *(use Panel 3 -- or 4 if the Shoulder Bones category is selected)*
    
1. Annotations can be exported as .tif, .tiff, .nii or .nii.gz file with the <img src=""https://user-images.githubusercontent.com/49953723/201735102-113f64b7-4da4-40ee-b058-9900268d270d.png"" width=""95px""/> button in one of the two following saving mode:
    - *`Unique`*: segmented data is exported as a unique 3D image with corresponding label ids (1-2-3-...). This file can be re-opened in the application.
    - *`Several`*: segmented data is exported as several binary 3D images (0 or 255), one for each label id.
2. <img src=""https://user-images.githubusercontent.com/49953723/193262699-95758bdb-ac40-439b-8959-d924781a2368.PNG"" width=""100px""/>: delete annotation data.
3. *`Automatic segmentation backup`*: if selected, the segmentation data will be automatically exported as a unique 3D image when the image slice is changed.
    > /!\ This process can slow down the display if the image is large.

# Hesperos: *OneShot Segmentation* mode
    
 The ***OneShot Segmentation*** mode of the Hesperos plugin is a 2D version of the VoxelLearning method implemented in DIVA (see [our Github](https://github.com/DecBayComp/VoxelLearning) and the latest article [Guérinot, C., Marcon, V., Godard, C., et al. (2022). New Approach to Accelerated Image Annotation by Leveraging Virtual Reality and Cloud Computing. _Frontiers in Bioinformatics_. doi:10.3389/fbinf.2021.777101](https://www.frontiersin.org/articles/10.3389/fbinf.2021.777101/full)).
    

The principle is to accelerate the segmentation without prior information. The procedure consists of:
1. A **rapid tagging** of few pixels in the image with two labels: one for the structure of interest (named positive tags), and one for the other structures (named negative tags).
2. A **training** of a simple random forest classifier with these tagged pixels and their features (mean, gaussian, ...).
3. An **inference** of all the pixels of the image to automatically segment the structure of interest. The output is a probability image (0-255) of belonging to a specific class.
4. Iterative corrections if needed.
    
<img src=""https://user-images.githubusercontent.com/49953723/193262714-8699cd59-3825-4d71-b27a-bbcad1e36d55.PNG"" width=""1000px""/>

    
## Import and adjust your image *(use Panel 1)*
    
Same panel as the *Manual Segmentation and Correction* mode *(see [panel 1 description](#import-and-adjust-your-image-use-panel-1))*.
   
    
## Annotate your image *(use Panel 2)*
    
Annotations and corrections on the segmented file is done using the layer controls of the *`annotations`* layer. Click on the layer to display them. Only two labels are available: *`Structure of interest`* and *`Other`*. 

The rapid manual tagging step of the one-shot learning method aims to learn and attribute different features to each label.
<img align=""right"" src=""https://user-images.githubusercontent.com/49953723/193262735-5dce56fb-8a2c-4aeb-9ee7-9727122d8089.PNG"" width=""220px""/> 
To achieve that, the user has to:
- with the label *`Structure of interest`*, tag few pixels of the structure of interest.
- with the label *`Other`*, tag the greatest diversity of uninteresting structures in the 3D image (avoid tagging too much pixels).

> see the exemple image with *`Structure of interest`* label in red and *`Other`* label in cyan.
    
1. To modify an existing segmentation, you can directy open the segmented file with the <img src=""https://user-images.githubusercontent.com/49953723/193266118-dfd241f6-8f0b-4cb9-94e7-5e74a3ce8b6e.PNG"" width=""130px""/> button. The file needs to have the same dimensions as the original image. 
    > /!\ Only .tiff, .tif, .nii and .nii.gz files are supported as segmented files. 
2. All actions can be undone with the <img src=""https://user-images.githubusercontent.com/49953723/193265848-8c458035-609a-433e-aa82-5d9588971425.PNG"" width=""30px""/> button or Ctrl-Z.

    
## Run automatic segmentation *(use Panel 3)*

From the previously tagged pixels, features are extracted and used to train a basic classifier : the Random Forest Classifier (RFC). When the training of the pixel classifier is done, it is applied to each pixel of the complete volume and outputs a probability to belong to the structure of interest.

To run training and inference, click on the <img src=""https://user-images.githubusercontent.com/49953723/193262731-719c226a-f7c5-4252-b2bb-fade4ab7f5b3.PNG"" width=""115px""/> button:
1. You will be asked to save a .pckl file which corresponds to the model.
2. A new status will appears under the *Panel 4* : *`Computing...`*. You must wait for the message to change to: *`Ready`* before doing anything in the application (otherwise the application may freeze or crash).
3. When the processing is done, two new layers will appear:
    - the *`probabilities`* layer which corresponds to the direct probability (between 0 and 1) of a pixel to belong to the structure of interest. This layer is disabled by default, to enable it click on its eye icon in the layer list.
    - the *`segmented probabilities`* layer which corresponds to a binary image obtained from the probability image normed and thresholded according to a value manually defined with the *`Probability threshold`* slider: <img src=""https://user-images.githubusercontent.com/49953723/193262730-6998c8a5-92f1-4ff1-bbf5-6972a373afd2.PNG"" width=""80px""/>.

>Remark: If the output is not perfect, you have two possibilities to improve the result:
>1. Add some tags with the paint brush to take in consideration unintersting structures or add information in critical areas of your structure of interest (such as in thin sections). Then, run the training and inference process again. /!\ This will overwrite all previous segmentation data.
>2. Export your segmentation data and re-open it with the *Manual Annotation and Correction* mode of Hesperos to manually erase or add annotations.
    
    
## Export annotations *(use Panel 4)*
    
1. Segmented probabilites can be exported as .tif, .tiff, .nii or .nii.gz file with the <img src=""https://user-images.githubusercontent.com/49953723/193262734-57159a97-2f46-4aba-b3bf-b55a35dfacbd.PNG"" width=""105px""/> button. The image is exported as a unique 3D binary image (value 0 and 255). This file can be re-opened in the application for correction.
2. Probabilities can be exported as .tif, .tiff, .nii or .nii.gz file with the <img src=""https://user-images.githubusercontent.com/49953723/193262733-26e37392-55b2-4c36-9287-b2f5d8d30e03.PNG"" width=""105px""/> button as a unique 3D image. The probabilities image is normed between 0 and 255.
3. <img src=""https://user-images.githubusercontent.com/49953723/193266056-9514b648-b3e0-43f5-901a-a45fa1390f00.PNG"" width=""100px""/>: delete annotation data.


# License

Distributed under the terms of the [BSD-3] license, **Hesperos** is a free and open source software.

    
[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
[Anaconda]: https://www.anaconda.com/products/distribution#Downloads
[VoxelLearning]: https://github.com/DecBayComp/VoxelLearning
","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Operating System :: MacOS :: MacOS X', 'Operating System :: Microsoft :: Windows', 'License :: OSI Approved :: BSD License']","['Documentation, https://github.com/chgodard/hesperos/blob/main/README.md', 'Source Code, https://github.com/chgodard/hesperos']",,,hesperos.make_manual_segmentation_widget,,,,,https://pypi.org/project/hesperos,https://github.com/chgodard/hesperos,
32,hipocount-napari,2024.2.5,,,hipocount-napari,Borys Olifirov,omnia.fatum@gmail.com,MIT,,Quantitative analysis of immunofluorescence images of hippocampal slices,>=3.8,['napari'],"hipocount-napari
================

Quantitative analysis of immunofluorescence images of hippocampal slices
","['Framework :: napari', 'Development Status :: 3 - Alpha', 'License :: OSI Approved :: MIT License', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Operating System :: OS Independent', 'Topic :: Scientific/Engineering :: Bio-Informatics', 'Topic :: Scientific/Engineering :: Image Processing', 'Topic :: Scientific/Engineering :: Image Recognition', 'Topic :: Utilities']","['Documentation, https://domb.bio/', 'Source Code, https://github.com/wisstock/domb-napari', 'Bug Tracker, https://github.com/wisstock/domb-napari/issues', 'User Support, https://github.com/wisstock/domb-napari/issues']",,,hipocount-napari.stack_process_widget,,,,,https://pypi.org/project/hipocount-napari,,
33,iacs-ipac-reader,0.0.13,2022-02-11,2023-06-18,iacs-ipac-reader,Chenqi Zhang,cqzhang@g.ecc.u-tokyo.ac.jp,BSD-3-Clause,https://github.com/zcqwh/iacs_ipac_reader,A reader plugin for read iacs/ipac images and export .rtdc files.,>=3.7,"['h5py (>=3.5.0)', 'napari (>=0.4.12)', 'napari-plugin-engine (>=0.2.0)', 'numpy (>=1.21.4)', 'opencv-contrib-python-headless (>=4.4.0.46)', 'openpyxl (>=3.0.9)', 'sklearn (>=0.0)', 'PyQt5 (==5.12.3)', 'pandas (>=1.4.0)']","# iacs_ipac_reader

[![License](https://img.shields.io/pypi/l/iacs_ipac_reader.svg?color=green)](https://github.com/zcqwh/iacs_ipac_reader/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/iacs_ipac_reader.svg?color=green)](https://pypi.org/project/iacs_ipac_reader)
[![Python Version](https://img.shields.io/pypi/pyversions/iacs_ipac_reader.svg?color=green)](https://python.org)
[![tests](https://github.com/zcqwh/iacs_ipac_reader/workflows/tests/badge.svg)](https://github.com/zcqwh/iacs_ipac_reader/actions)
[![codecov](https://codecov.io/gh/zcqwh/iacs_ipac_reader/branch/main/graph/badge.svg)](https://codecov.io/gh/zcqwh/iacs_ipac_reader)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/iacs_ipac_reader)](https://napari-hub.org/plugins/iacs_ipac_reader)

A plugin used a convolutional neural network (CNN) to distinguish single platelets, platelet clusters, and white blood cells and performed classical image analysis for each subpopulation individually. Based on the derived single-cell features for each population, a Random Forest (RF) model was trained and used to classify COVID-19 associated thrombosis and non-COVID-19 associated thrombosis.

More information about IACS/iPAC.  
__IACS__: DOI: [10.1016/j.cell.2018.08.028](https://www.sciencedirect.com/science/article/pii/S0092867418310444)   
__iPAC__: DOI: [10.7554/eLife.52938](https://elifesciences.org/articles/52938)

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/stable/index.html
-->

## Installation

You can install `iacs_ipac_reader` via [pip]:

    pip install iacs_ipac_reader



To install latest development version :

    pip install git+https://github.com/zcqwh/iacs_ipac_reader.git


## Introduction

The iacs-ipac-reader plugin mainly include 3 functional tabs:

* iPAC
* IACS
* AID classif.



### iPAC image contour tracker
<center>Interface of iPAC contour tracker</center>    

![ipac.](https://github.com/zcqwh/iacs_ipac_reader/blob/main/Tutorial/pictures/ipac.png?raw=true ""iPAC"")

### IACS image contour tracker
<center>Interface of IACS contour tracker</center>    

![iacs.](https://github.com/zcqwh/iacs_ipac_reader/blob/main/Tutorial/pictures/iacs.png?raw=true ""IACS"")

### AID classif.
<center>Interface of AID classif.</center>     
 
![AID_classif.](https://github.com/zcqwh/iacs_ipac_reader/blob/main/Tutorial/pictures/classifier.jpg?raw=true ""AID classif"")



## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""iacs_ipac_reader"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/zcqwh/iacs_ipac_reader/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/



","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/zcqwh/iacs_ipac_reader/issues', 'Documentation, https://github.com/zcqwh/iacs_ipac_reader#README.md', 'Source Code, https://github.com/zcqwh/iacs_ipac_reader', 'User Support, https://github.com/zcqwh/iacs_ipac_reader/issues']",,,iacs-ipac-reader.iacs_ipac_reader,,,,,https://pypi.org/project/iacs-ipac-reader,https://github.com/zcqwh/iacs_ipac_reader,
34,ilastik plugin for napari,0.2.4,2023-04-17,2023-07-25,ilastik-napari,Emil Melnikov,Emil Melnikov <emilmelnikov@gmail.com>,MIT,https://github.com/ilastik/ilastik-napari,ilastik plugin for napari,>=3.8,"['napari >=0.4.13', 'numpy >=1.20', 'qtpy', 'scikit-learn', 'sparse']","# ilastik-napari

[Napari][napari] plugin for interactive pixel classification.
Designed to be similar to the pixel classification workflow in [classic ilastik][ilastik].

## Installation

This plugin requires you to use a _conda_ environment. The environment manager conda comes in a few different forms.
If you haven't used conda before, you can find more information in the [conda user guide][conda-user-guide].
You can use whichever variant you prefer, as the resulting environment should be the same, but we recommend the [_mambaforge_][mambaforge] variant as it is usually the fastest.
When using mambaforge, the `mamba` command usually replaces the `conda` command one would otherwise use.

Once you have installed mambaforge, set up a conda environment with napari and the _fastfilters_ package, and then use pip to install _ilastik-napari_:
```shell
mamba create -y -c ilastik-forge -c conda-forge -n my-napari-env napari fastfilters
mamba activate my-napari-env
pip install ilastik-napari
```

Finally, run napari:
```shell
napari
```
That's it! You should be able to find the ilastik-napari plugin in the Plugins menu.

If you prefer to __install napari using pip__ instead of conda:
Make sure to install `napari[all]`.
Unless you want to [choose a PyQt implementation other than _PyQt5_][napari-pyqt], in which case you should leave out the `[all]` extra.

## Usage

As a prerequisite, make sure you understand the [napari basics][napari-quickstart].

1. Open your image, or use a sample in _File - Open Sample_.

   ![Use a sample image](https://ilastik.org/assets/ilastik-napari/image-sample.png ""Use a sample image"")

2. Activate the plugin in the _Plugins_ menu.

   ![Activate the plugin](https://ilastik.org/assets/ilastik-napari/activation.png ""Activate the plugin"")

3. In _layer list_, create a new _Labels_ layer.

   ![Labels layer](https://ilastik.org/assets/ilastik-napari/labels-layer.png ""Labels layer"")

4. In _layers control_, switch to the _paint_ action.

   ![Paint action](https://ilastik.org/assets/ilastik-napari/paint-action.png ""Paint action"")

5. Draw your background labels.

   ![Paint the background](https://ilastik.org/assets/ilastik-napari/draw-background.png ""Paint the background"")

6. Switch to a new label.

   ![Switch label](https://ilastik.org/assets/ilastik-napari/new-label.png ""Switch label"")

7. Draw your foreground labels.

   ![Paint cells](https://ilastik.org/assets/ilastik-napari/draw-cells.png ""Paint cells"")

8. Select output types you need, and click _Run_.

   ![Plugin interface](https://ilastik.org/assets/ilastik-napari/interface.png ""Plugin interface"")

9. The plugin will create one layer for each output type, which you save as normal napari layers.

   ![Example output](https://ilastik.org/assets/ilastik-napari/example.png ""Example output"")

## Development

Create a development environment:
```
mamba create -y -n ilastik-napari-dev -c ilastik-forge fastfilters setuptools-scm conda-build anaconda-client
conda activate napari-ilastik-dev
pip install -e .
```

Build conda package:
```
conda activate napari-ilastik-dev
mamba build -c ilastik-forge conda-recipe
anaconda upload /path/to/the/new/package.tar.bz2
```

Build wheel and sdist packages:
```
conda activate napari-ilastik-dev
pip install build twine
python -m build
python -m twine upload --repository testpypi dist/*
```

[napari]: https://napari.org/
[ilastik]: https://www.ilastik.org/
[conda-user-guide]: https://docs.conda.io/projects/conda/en/latest/user-guide/index.html
[miniconda]: https://docs.conda.io/en/latest/miniconda.html
[mambaforge]: https://github.com/conda-forge/miniforge#mambaforge
[napari-quickstart]: https://napari.org/tutorials/fundamentals/quick_start.html
[napari-pyqt]: https://napari.org/stable/plugins/best_practices.html#don-t-include-pyside2-or-pyqt5-in-your-plugin-s-dependencies
","['Development Status :: 2 - Pre-Alpha', 'Environment :: Plugins', 'Intended Audience :: End Users/Desktop', 'Intended Audience :: Science/Research', 'License :: OSI Approved :: MIT License', 'Framework :: napari', 'Operating System :: MacOS', 'Operating System :: MacOS :: MacOS X', 'Operating System :: Microsoft :: Windows', 'Operating System :: POSIX', 'Operating System :: POSIX :: Linux', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: Implementation :: CPython', 'Topic :: Scientific/Engineering', 'Topic :: Scientific/Engineering :: Image Processing']","['homepage, https://github.com/ilastik/ilastik-napari']",,,ilastik-napari.pixel_classification,,,,,https://pypi.org/project/ilastik-napari,https://github.com/ilastik/ilastik-napari,
35,Image-Composer,0.0.19,2022-02-10,2023-06-18,Image-Composer,"Marc Boucsein, Robin Koch",,BSD-3,https://github.com/MBPhys/Image-Composer,A napari plugin in order to compose a background image with a foreground image,>=3.7,"['napari-plugin-engine (>=0.1.4)', 'numpy']","# Image-Composer

[![License](https://img.shields.io/pypi/l/napari-medical-image-formats.svg?color=green)](https://github.com/MBPhys/Image-Composer/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/Image-Composer.svg?color=green)](https://pypi.org/project/Image-Composer)
[![Python Version](https://img.shields.io/pypi/pyversions/Image-Composer.svg?color=green)](https://python.org)


A napari plugin in order to compose a background image with a foreground image.

----------------------------------

## Installation

You can install `Image-Composer` via [pip]:

    pip install Image-Composer

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""Image-Composer"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/MBPhys/Image-Composer/issues
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/


","['Development Status :: 4 - Beta', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']",,,,Image-Composer.Composer,,,,,https://pypi.org/project/Image-Composer,https://github.com/MBPhys/Image-Composer,
36,Image-Part-Selecter,0.0.7,2022-02-11,2023-06-18,Image-Part-Selecter,"Marc Boucsein, Robin Koch",,BSD-3,https://github.com/MBPhys/Image-Part-Selecter,A napari plugin in order to select parts of images,>=3.7,"['napari-plugin-engine (>=0.1.4)', 'numpy']","# Image-Part-Selecter

[![License](https://img.shields.io/pypi/l/napari-medical-image-formats.svg?color=green)](https://github.com/MBPhys/Image-Part-Selecter/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/Image-Part-Selecter.svg?color=green)](https://pypi.org/project/Image-Part-Selecter)
[![Python Version](https://img.shields.io/pypi/pyversions/Image-Part-Selecter.svg?color=green)](https://python.org)


A napari plugin in order to select parts of images

----------------------------------

## Installation

You can install `Image-Part-Selecter` via [pip]:

    pip install Image-Part-Selecter

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""Image-Part-Selecter"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/MBPhys/Image-Part-Selecter/issues
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/


","['Development Status :: 4 - Beta', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']",,,,Image-Part-Selecter.Selecter,,,,,https://pypi.org/project/Image-Part-Selecter,https://github.com/MBPhys/Image-Part-Selecter,
37,IMAXT Multiscale Image Napari Plugin,0.3.1,2023-04-17,2023-07-25,imaxt-multiscale-plugin,Eduardo Gonzalez Solares,E.GonzalezSolares@ast.cam.ac.uk,LGPL-3.0-only,https://gitlab.developers.cam.ac.uk/astronomy/camcead/imaxt/imaxt-multiscale-plugin,A simple plugin to use with napari,>=3.8,"['numpy', 'magicgui', 'qtpy', 'xarray', 'dask', 'astropy', 'zarr', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# IMAXT multiscale napari plugin

[![License GNU LGPL v3.0](https://img.shields.io/pypi/l/imaxt-multiscale-plugin.svg?color=green)](https://github.com/eg266/imaxt-multiscale-plugin/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/imaxt-multiscale-plugin.svg?color=green)](https://pypi.org/project/imaxt-multiscale-plugin)
[![Python Version](https://img.shields.io/pypi/pyversions/imaxt-multiscale-plugin.svg?color=green)](https://python.org)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/imaxt-multiscale-plugin)](https://napari-hub.org/plugins/imaxt-multiscale-plugin)

A napari plugin to visualize multi-resolution images created with the IMAXT mosaic pipeline.

----------------------------------------------------

## Installation

You can install `imaxt-multiscale-plugin` via [pip]:

    pip install imaxt-multiscale-plugin


## Usage

Run [napari] with the name of the sample to visualize either a local path:

    napari /storage/imaxt/eglez/processed/stpt/20220606_PDX_AB559_GFP_005503_100x15um

or a sample in S3 storage:

    napari s3://imaxtgw/stpt/20220608_DI_PDX_SA535_Tum_5223_04280_100x15um
    
## Screenshots

![Alt text](https://gitlab.developers.cam.ac.uk/astronomy/camcead/imaxt/imaxt-multiscale-plugin/-/raw/main/assets/napari1.png ""a title"")
![Alt text](https://gitlab.developers.cam.ac.uk/astronomy/camcead/imaxt/imaxt-multiscale-plugin/-/raw/main/assets/napari2.png ""a title"")
![Alt text](https://gitlab.developers.cam.ac.uk/astronomy/camcead/imaxt/imaxt-multiscale-plugin/-/raw/main/assets/napari3.png ""a title"")
![Alt text](https://gitlab.developers.cam.ac.uk/astronomy/camcead/imaxt/imaxt-multiscale-plugin/-/raw/main/assets/napari4.png ""a title"")

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [GNU LGPL v3.0] license,
""imaxt-multiscale-plugin"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: GNU Lesser General Public License v3 (LGPLv3)', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Software Development :: Testing']",,imaxt-multiscale-plugin.get_reader,imaxt-multiscale-plugin.write_single_image,imaxt-multiscale-plugin.make_qwidget,,['*'],['.npy'],"['.tif', '.tiff']",https://pypi.org/project/imaxt-multiscale-plugin,,https://gitlab.developers.cam.ac.uk/astronomy/camcead/imaxt/imaxt-multiscale-plugin
38,In Silico Fate Mapping,0.1.2,2023-08-01,2024-04-10,in-silico-fate-mapping,Jordao Bragantini,jordao.bragantini@czbiohub.org,BSD-3-Clause,https://github.com/royerlab/in-silico-fate-mapping,TODO,>=3.8,"['numpy', 'pandas', 'scikit-learn', 'zarr', 'magicgui', 'qtpy', 'napari', 'click', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# in silico fate mapping

[![License BSD-3](https://img.shields.io/pypi/l/in-silico-fate-mapping.svg?color=green)](https://github.com/royerlab/in-silico-fate-mapping/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/in-silico-fate-mapping.svg?color=green)](https://pypi.org/project/in-silico-fate-mapping)
[![Python Version](https://img.shields.io/pypi/pyversions/in-silico-fate-mapping.svg?color=green)](https://python.org)
[![tests](https://github.com/royerlab/in-silico-fate-mapping/workflows/tests/badge.svg)](https://github.com/royerlab/in-silico-fate-mapping/actions)
[![codecov](https://codecov.io/gh/royerlab/in-silico-fate-mapping/branch/main/graph/badge.svg)](https://codecov.io/gh/royerlab/in-silico-fate-mapping)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/in-silico-fate-mapping)](https://napari-hub.org/plugins/in-silico-fate-mapping)


Interactive in silico fate mapping from tracking data.

This napari plugin estimates the cell fates from tracking data by building a radial regression model per time point. The user can select an area of interest using a `Points` layer; the algorithm will advent the probed coordinates forward (or backward) in time, showing the estimated fate.

Video example below:

https://user-images.githubusercontent.com/21022743/216478216-89c1c35f-2ce4-44e8-adb8-9aeea75b5833.mp4

## Installation

We suggest you create a fresh conda environment to avoid conflicts with your existing package.
To do this, you need to:

    conda create -n fatemap python=3.11
    conda activate fatemap

And then, you can install `in-silico-fate-mapping` via [pip] and other additional useful packages:

    pip install ultrack napari-ome-zarr napari[all] in-silicio-fate-mapping

To install the latest development version :

    pip install git+https://github.com/royerlab/in-silico-fate-mapping.git


## IO file format

This plugin does not depend on a specific file format, the only requirement is using a `Track` layer from napari.

Despite this, we ship a reader and writer interface. It supports `.csv` files with the following reader `TrackID, t, (z), y, x`, `z` is optional.
Such that each tracklet has a unique `TrackID` and it's composed of a sequence o time and spatial coordinates.

This is extremely similar to how napari store tracks, more information can be found [here](https://napari.org/stable/howtos/layers/tracks.html).

Divisions are not supported at the moment.

## Usage Example

### Minimal example

Minimal example using a track file following the convention described above.

```python3
import napari
import pandas as pd
from in_silico_fate_mapping.fate_mapping import FateMapping

tracks = pd.read_csv(""tracks.csv"")

fate_map = FateMapping(radius=5, n_samples=25, bind_to_existing=False, sigma=1)
fate_map.data = tracks[[""TrackID"", ""t"", ""z"", ""y"", ""x""]]

source = tracks[tracks[""t""] == 0].sample(n=1)

tracks = fate_map(source[[""t"", ""z"", ""y"", ""x""]])

napari.view_tracks(tracks)
napari.run()
```

### Zebrahub example

Zebrafish embryo tail example. This example requires the package `napari-ome-zarr`.

```python3
import napari
import pandas as pd
from in_silico_fate_mapping import FateMappingWidget

image_path = ""http://public.czbiohub.org/royerlab/zebrahub/imaging/single-objective/ZSNS001_tail.ome.zarr""
tracks_path = ""http://public.czbiohub.org/royerlab/zebrahub/imaging/single-objective/ZSNS001_tail_tracks.csv""

viewer = napari.Viewer()
viewer.window.add_dock_widget(FateMappingWidget(viewer))

viewer.open(image_path, plugin=""napari-ome-zarr"")

tracks = pd.read_csv(tracks_path)
viewer.add_tracks(tracks[[""TrackID"", ""t"", ""z"", ""y"", ""x""]])
viewer.add_points(name=""Markers"", ndim=4)

napari.run()
```

## Citing

If used please cite:

```
@article{lange2023zebrahub,
  title={Zebrahub-Multimodal Zebrafish Developmental Atlas Reveals the State Transition Dynamics of Late Vertebrate Pluripotent Axial Progenitors},
  author={Lange, Merlin and Granados, Alejandro and VijayKumar, Shruthi and Bragantini, Jordao and Ancheta, Sarah and Santhosh, Sreejith and Borja, Michael and Kobayashi, Hirofumi and McGeever, Erin and Solak, Ahmet Can and others},
  journal={bioRxiv},
  pages={2023--03},
  year={2023},
  publisher={Cold Spring Harbor Laboratory}
}
```

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/royerlab/in-silico-fate-mapping/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/royerlab/in-silico-fate-mapping/issues', 'Documentation, https://github.com/royerlab/in-silico-fate-mapping#README.md', 'Source Code, https://github.com/royerlab/in-silico-fate-mapping', 'User Support, https://github.com/royerlab/in-silico-fate-mapping/issues']",in-silico-fate-mapping.get_reader,in-silico-fate-mapping.write_tracks,in-silico-fate-mapping.make_fate_map,,['*.csv'],['.csv'],,https://pypi.org/project/in-silico-fate-mapping,https://github.com/royerlab/in-silico-fate-mapping,
39,iterseg,0.3.0,,,iterseg,Abigail S McGovern & Juan Nunez-Iglesias,Abigail.McGovern1@monash.edu,BSD-3-Clause,,napari plugin for iteratively improving unet-watershed segmentation,>=3.7,"['numpy', 'dask', 'torch', 'scikit-image', 'pandas', 'ome-zarr', 'zarr', 'matplotlib', 'napari', 'umetrix', 'numba', 'scipy', 'seaborn']","# iterseg

[![License](https://img.shields.io/pypi/l/iterseg.svg?color=green)](https://github.com/abigailmcgovern/iterseg/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/iterseg.svg?color=green)](https://pypi.org/project/iterseg)
[![Python Version](https://img.shields.io/pypi/pyversions/iterseg.svg?color=green)](https://python.org)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/iterseg)](https://napari-hub.org/plugins/iterseg)

napari plugin for iteratively improving a deep learning-based unet-watershed segmentation. 

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/docs/plugins/index.html
-->

## Installation
Install iterseg using pip. Assuming you have python and pip installed (e.g., via miniconda), you can install iterseg with only one line, typed into terminal (MacOS/Linux) or annaconda prompt (Windows). We recomend installing into a [new environment](https://conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html#) as some of our dependencies may not play well in the sandpit with certain versions of packages that may exist in a prexisting one. 

```bash
pip install iterseg napari
```


## Opening iterseg
Once `iterseg` is installed, you can access it through the napari viewer, which you can open from the command line (e.g., terminal (MacOS), anaconda prompt (Windows), git bash (Windows), etc.). To open napari simply type into the command line:
```bash
napari
```

## Loading data
Once you've opened napari, you can load image, labels, or shapes data through the `load_data` widget. to open the widget go to **plugins/iterseg/load_data** at the top left of your screen (MacOS) or viewer (Windows). 

 ![find the widgets](https://github.com/AbigailMcGovern/iterseg/blob/main/docs/images/load_data_find.png)

Once the widget appears at the right of the napari window, enter the name you want to give the data you are loading (this will appear in the layers pannel on the left of the window). Choose the type of layer you want to load (Image, Labels, or Shapes: segmentations are loaded as labels layer). You can load a folder of files or a zarr file using ""choose directory"" (zarrs are recognised as a folder of files) or you can load a tiff file using ""choose file"". You can tell the program what the scale of the 3D frames will be in (in the format (z, y, x)).

 ![load data](https://github.com/AbigailMcGovern/iterseg/blob/main/docs/images/load_data.png)

If you are using a single image file (3D, 4D, 5D - ctzyx) or a directory of 3D images (zyx), for ""data type"" choose ""individual frames"". If you are using a directory of 4D images (tzyx) choose ""image stacks"". If you are loading a file that is 4D or 5D and want to load time points (4D: tzyx, czyx) or channels (5D: ctzyx) as individual layers, select ""split channels"". 

## Segmenting images

You can segment data using the ""segment_data"" widget, which can be found at **plugins/iterseg/segment_data**. Once the widget appears, you can choose (1) the image layer you want to segment, (2) the folder into which to save the data, (3) the name you want to give the output file, (4) the type of segmentation to use, (5: optionally) the path to a neural network or configuration file, (6: optionally) a layer produced during training which contains metadata pointing to the trained neual network, (7) chunk size (the size of the neural network input), (8) margin (the margin of overlap between chunks). There is also an optional tickbox for debugging. If this is selected, errors will be easier to identify but you won't be able to interact with the viewer until the segmentation is done. 

 ![segmentation in progress](https://github.com/AbigailMcGovern/iterseg/blob/main/docs/images/segmenting_in_progress.png)

  ![segmented data](https://github.com/AbigailMcGovern/iterseg/blob/main/docs/images/segmented_data.png)

Segmented images can be used to more quickly generate ground truth for training, to assess segmentation quality, or for downstream analyses. 

### Segmentation algorithms
#### Affinity U-Net Watershed
The affinity U-net watershed is a feature based instance segmentation algorithm. A trained U-net predicts an edge affinity graph (basically boundaries in the x, y, and z axes), a map of centre points, and a mask that specifies which pixesl belong to objects. The feature map is fed to a modified watershed algorithm. The object centres are used to find seeds for the watershed and the affinity graph is used to find bounaries between objects. If you train a network using `iterseg`, you can select the outputted network file to segment. Otherwise, if one is not selected, a network we have trained to detect platelets will be used. This might be appropriate for small objects with high anisotropy. 

#### DoG Blob Segmentation
The DoG blob segmentation uses a difference of Gaussian (DoG) filter to find blob shaped objects. The DoG filter is used to find object seeds, a foreground mask, and is fed to a watershed to label objects. This algorithm cannot be trained but can be configured with a configuration file. An example configuration file can be seen in the example folder in this repository. Please see the Segmentation_config.md file for more details. 

## Generating ground truth
We include two tools that are useful for generating ground truth: ""save frames"" and ""ground truth from ROI"". 

### Save frames

The first tool is ""save frames"" can be found at **plugins/iterseg/save_frames**. It enables you to save frames of interest from a  series of segmented images or timeseries. 

 ![save frames](https://github.com/AbigailMcGovern/iterseg/blob/main/docs/images/save_frames.png)

### Ground truth from ROI

The ""ground truth from ROI"" tool can be found at **plugins/iterseg/ground_truth_from_ROI**. This tool enables you to take a small portion of corrected data and place it into a new frame, which can be used for training. The new data can be tiled in the new frame to overrepresent the data in the training data set. At present, the ROI must be selected by adding a shapes layer (added using the icon circled in orange), then adding a rectangle (blue circle).

 ![make an ROI](https://github.com/AbigailMcGovern/iterseg/blob/main/docs/images/generate_ROI.png)

 The rectangle will be used to select a region of the xy-plane. This can be seen in 3D below. 

 ![2D ROI in 3D](https://github.com/AbigailMcGovern/iterseg/blob/main/docs/images/roi_before_3D.png)

 At present, the entire z stack above and below the rectangle will be used to generate ground truth. We aim to incorporate 3D bounding boxes in the future. If multiple ROIs are selected, multiple new image frames will be made, each with a single ROI. When you generate ground truth from the shapes layer, you are able to select the desired shapes layer, image layer, and labels layer. Additionally, you can choose how many times you want to tile the ROI and how much padding to leave between. Tiling will start at the top right and progress right before moving to the next row. You will also be able to choose the save name and the folder into which to save the data. 

 ![ground truth from ROI](https://github.com/AbigailMcGovern/iterseg/blob/main/docs/images/gt_from_ROI.png)

## Training a network
`iterseg` includes a widget for training a u-net for the u-net affinity watershed. The training widget can be found at **plugins/iterseg/train_from_viewer**. Before training, you will need to load the images and ground truth you want to train from. The images and ground truth should each be a series of 3D frames that are stacked into a layer (we suggest loading from a series of frames in a directory). Once loaded, you are able to select a layer as the ground truth and a layer as the image data. You can tell the program what the scale of the output frames will be (in the format (z, y, x)). You can select what type of center prediction to use (we suggest centredness), what type of prediction to use for the mask, and what extent of affinities you want to train (if n = 1, the network will predict only the direct boundaries between objects in each axis, if greater than 1 the network will still predict the direct boundaires but will also predict where there is a new object n steps away - can be used as collateral learning to enhance training). Affinities extent is developmental. Please submit an issue for any problems. 

 ![train from viewer](https://github.com/AbigailMcGovern/iterseg/blob/main/docs/images/train_from_viewer.png)

For the U-net training, we allow you to choose the learning rate for the [ADAM optimiser](https://arxiv.org/abs/1412.6980) used to train the network. You can also choose between binary cross entropy loss ([BCELoss](https://pytorch.org/docs/stable/generated/torch.nn.BCELoss.html)) and Dice loss ([DICELoss](https://arxiv.org/abs/1707.03237v3)). We have found in our data that BCE loss works better. You can also choose how many chunks of data are produced from each frame (n each) and how many epochs you want to train for the training will be done in n_each * n_frames batches with a minibatch size of 1. 

In the future we hope to expand this training widget to enable training other types of networks. Please get involved if you feel you can help with this. 

## Assessing segmentations
`iterseg` includes widgets for assessing and comparing segmentations. If you want to assess segmentation quality, you will need to load a ground truth and a segmentation to assess. Once loaded, you can select the ground truth and segmentation (model segmentation) using the widget found in **plugins/iterseg/assess_segmentation**. You can select which metrics you want to assess. The metrics we enable are:
- **Variation of information (VI):** VI is a two part measure. It includes a measure of undersegmentation and oversegmentation. Undersegmentation is a measure of the amount of new information you get from looking at the ground truth if you have already seen the segmentation. It can be interpreted as the proportion of objects that are incorrectly merged. Oversegmentation is a measure of the amount of new information you get from looking at the segmentation if you have already seen the ground truth. It can be interpreted as the proportion of objects that are incorrectly split. For more info please see the [scikit-image documentation](https://scikit-image.org/docs/stable/api/skimage.metrics.html#skimage.metrics.variation_of_information). 
- **Object count difference (OD):** Object count difference is simply the difference in number of objects between a ground truth and the assessed segmentation (card(ground truth) - card(segmentation)). 
- **Average precision (AP):** Average precision  Average precision is a combined measure of how accurate the model is at finding true positive (real) objects (we call this precision) and how many of ground truth real objects it found (this is called recall). The assessment of whether an object is TP, FP, and FN depends on the threashold of overlap between objects. Here we use the intersection of union (IoU), which is the proportion of overlap between the bounding boxes of ground truth and model segemented objects. AP is assessed using different IoU thresholds (from 0.35-0.95). The resultant data will be plotted as IoU by AP. 

  - Precision = TP / (TP + FP)Recall = TP / (TP + FN). 
  - Abbreviations: FN, false negative; TP, true positive; FP, false 


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""iterseg"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/abigailmcgovern/iterseg/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/abigailmcgovern/iterseg/issues', 'Documentation, https://github.com/abigailmcgovern/iterseg#README.md', 'Source Code, https://github.com/abigailmcgovern/iterseg', 'User Support, https://github.com/abigailmcgovern/iterseg/issues']",iterseg.load_ome_zarr,,iterseg.train_from_viewer,,['*.ome.zarr'],,,https://pypi.org/project/iterseg,,
40,Koopa,0.0.5,2022-10-25,2023-06-18,koopa-viz,Bastian Eichenberger,bastian@eichenbergers.ch,MIT,https://github.com/bbquercus/koopa-viz,Vizualization plugin for koopa image analysis,>=3.8,"['numpy', 'pandas', 'pyarrow', 'qtpy', 'tifffile', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","[![License MIT](https://img.shields.io/pypi/l/koopa-viz.svg?color=green)](https://github.com/bbquercus/koopa/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/koopa-viz.svg?color=green)](https://pypi.org/project/koopa-viz)
[![Python Version](https://img.shields.io/pypi/pyversions/koopa-viz.svg?color=green)](https://python.org)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/koopa-viz)](https://napari-hub.org/plugins/koopa-viz)

# koopa-viz

Vizualization plugin for koopa image analysis

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

More information can be found on the official [GitHub repo].

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[GitHub repo]: https://github.com/bbquercus/koopa
[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[file an issue]: https://github.com/bbquercus/koopa/issues
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: MIT License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/bbquercus/koopa/issues', 'Documentation, https://github.com/bbquercus/koopa#README.md', 'Source Code, https://github.com/bbquercus/koopa', 'User Support, https://github.com/bbquercus/koopa/issues']",,,koopa-viz.make_qwidget,,,,,https://pypi.org/project/koopa-viz,https://github.com/bbquercus/koopa-viz,
41,Label-Creator,0.0.9,2022-02-11,2023-06-18,Label-Creator,"Marc Boucsein, Robin Koch",,BSD-3,https://github.com/MBPhys/Label-Creator,A napari plugin for generation of Label-Layers according to selected image data shapes,>=3.7,"['napari-plugin-engine (>=0.1.4)', 'numpy', 'dask']","# Label-Creator

[![License](https://img.shields.io/pypi/l/napari-medical-image-formats.svg?color=green)](https://github.com/MBPhys/Label-Creator/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/Label-Creator.svg?color=green)](https://pypi.org/project/Label-Creator)
[![Python Version](https://img.shields.io/pypi/pyversions/Label-Creator.svg?color=green)](https://python.org)


A napari plugin for generation of Label-Layers according to selected image data shapes.

----------------------------------

## Installation

You can install `Label-Creator` via [pip]:

    pip install Label-Creator

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""Label-Creator"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/MBPhys/Label-Creator/issues
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/


","['Development Status :: 4 - Beta', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']",,,,Label-Creator.Creator,,,,,https://pypi.org/project/Label-Creator,https://github.com/MBPhys/Label-Creator,
42,Large Image Viewer,1.1.0,2023-11-18,2023-11-18,Large-Image-Viewer,Nima Mojtahedi,nima.mojtahedi@wysscenter.ch,MIT,https://pypi.org/project/Large-Image-Viewer,A simple plugin to view large images,>=3.8,"['numpy', 'dask[array]', 'dask-image', 'scikit-image', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'""]","# Large-Image-Viewer

[![License MIT](https://img.shields.io/pypi/l/Large-Image-Viewer.svg?color=green)](https://github.com/WyssCenter/Large-Image-Viewer/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/Large-Image-Viewer.svg?color=green)](https://pypi.org/project/Large-Image-Viewer)
[![Python Version](https://img.shields.io/pypi/pyversions/Large-Image-Viewer.svg?color=green)](https://python.org)
[![tests](https://github.com/WyssCenter/Large-Image-Viewer/workflows/tests/badge.svg)](https://github.com/WyssCenter/Large-Image-Viewer/actions)
[![codecov](https://codecov.io/gh/WyssCenter/Large-Image-Viewer/branch/main/graph/badge.svg)](https://codecov.io/gh/WyssCenter/Large-Image-Viewer)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/Large-Image-Viewer)](https://napari-hub.org/plugins/Large-Image-Viewer)

A simple plugin to view large images

----------------------------------

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `Large-Image-Viewer` via [pip]:

    pip install Large-Image-Viewer



To install latest development version :

    pip install git+https://github.com/WyssCenter/Large-Image-Viewer.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [MIT] license,
""Large-Image-Viewer"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/WyssCenter/Large-Image-Viewer/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/




# Napari Large Image Viewer Plugin

The Napari Large Image Viewer Plugin is a powerful extension for the [napari](https://napari.org/) image visualization software. This plugin is designed to enable the visualization of large TIFF | TIF  files directly from disk, without the need to load the entire image into RAM. This is particularly useful when working with large datasets that exceed the available memory of your system.


## Features

- **Efficient Large Image Visualization**: The plugin allows you to open and visualize large files that are too big to fit into memory. It utilizes efficient memory-mapping techniques to display image data without fully loading it into RAM.

- **Interactive Exploration**: With the Napari Large Image Viewer Plugin, you can interactively explore large datasets using familiar zooming, panning, and slicing actions.

- **Quick Installation**: Installing the plugin is simple and straightforward, and it seamlessly integrates with the napari environment.

- **User-Friendly Interface**: The plugin provides an intuitive user interface that integrates seamlessly into the napari interface, making it easy to use for both beginners and experienced users.

## Installation

1. **Prerequisites**: Make sure you have [napari](https://napari.org/) installed on your system. If not, you can install it using:

   ```bash
   pip install napari
   ```

2. **Install the Plugin**: You can install the plugin directly from GitHub using pip:

   ```bash
   pip install git+https://github.com/WyssCenter/Large-Image-Viewer.git
   ```

3. **Launch napari**: Launch napari from your terminal:

   ```bash
   napari
   ```

4. **Activate the Plugin**: Once napari is launched, go to the `Plugins` menu and select `Large Image Viewer` to activate the plugin.

5. **Open Large TIFF | TIF  File**: With the plugin activated, you can now open a large file by dragging and dropping it to the napari viewer.

## Usage

1. Open a Large TIFF | TIF  File: Follow the installation instructions above to open a large TIFF | TIF  file using the plugin.

2. Explore the Image: Once the image is loaded, you can use the mouse to zoom in/out, pan, and interactively explore the data. You can also adjust the colormap, contrast, and other visualization settings from the napari interface.

3. Slicing and Navigation: Use the slicing and navigation tools in napari to navigate through different sections of the large file.

4. Save Visualizations: You can save snapshots or screenshots of the current visualization using the napari interface.

## Contributions

Contributions to the Napari Large Image Viewer Plugin are welcome! If you encounter issues or have suggestions for improvements, please open an issue on the [GitHub repository](https://github.com/WyssCenter/Large-Image-Viewer.git).

## License

This plugin is licensed under the [MIT License](LICENSE).

## Contact

For any inquiries or questions, you can reach out to the author at nima.mojtahedi@wysscenter.ch
","['Development Status :: 3 - Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: MIT License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/WyssCenter/Large-Image-Viewer/issues', 'Documentation, https://github.com/WyssCenter/Large-Image-Viewer#README.md', 'Source Code, https://github.com/WyssCenter/Large-Image-Viewer', 'User Support, https://github.com/WyssCenter/Large-Image-Viewer/issues']",Large-Image-Viewer.get_reader,,,,"['*.tiff', '*.tif']",,,https://pypi.org/project/Large-Image-Viewer,,
43,Layer-Data-Replace,0.0.5,2022-02-11,2023-06-18,Layer-Data-Replace,"Marc Boucsein, Robin Koch",,BSD-3,https://github.com/MBPhys/Layer-Data-Replace,A napari plugin in order to replace parts of the data of a layer by another one,>=3.7,"['napari-plugin-engine (>=0.1.4)', 'numpy', 'dask']","# Layer-Data-Replace

[![License](https://img.shields.io/pypi/l/napari-medical-image-formats.svg?color=green)](https://github.com/MBPhys/Layer-Data-Replace/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/Layer-Data-Replace.svg?color=green)](https://pypi.org/project/Layer-Data-Replace)
[![Python Version](https://img.shields.io/pypi/pyversions/Layer-Data-Replace.svg?color=green)](https://python.org)


A napari plugin in order to replace parts of the data of a layer by another one.

----------------------------------

## Installation

You can install `Layer-Data-Replace` via [pip]:

    pip install Layer-Data-Replace

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""Layer-Data-Replace"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/MBPhys/Layer-Data-Replace/issues
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/


","['Development Status :: 4 - Beta', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']",,,,Layer-Data-Replace.Replace,,,,,https://pypi.org/project/Layer-Data-Replace,https://github.com/MBPhys/Layer-Data-Replace,
44,Manini,0.0.10,,,manini,Herearii Metuarea,herearii.metuarea@gmail.com,BSD-3-Clause,,"An user-friendly plugin that enables to annotate images from a pre-trained model (segmentation, classification, detection) given by an user.",>=3.8,"['numpy', 'magicgui', 'qtpy', 'napari', 'scikit-image', 'pandas', 'opencv-python-headless', 'tensorflow', 'PyQt5', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'"", ""pytest-xvfb ; extra == 'testing'"", ""numpy ; extra == 'testing'"", ""magicgui ; extra == 'testing'"", ""qtpy ; extra == 'testing'"", ""scikit-image ; extra == 'testing'"", ""pandas ; extra == 'testing'"", ""opencv-python-headless ; extra == 'testing'"", ""tensorflow ; extra == 'testing'"", ""PyQt5 ; extra == 'testing'""]","# manini

[![License BSD-3](https://img.shields.io/pypi/l/manini.svg?color=green)](https://github.com/hereariim/manini/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/manini.svg?color=green)](https://pypi.org/project/manini)
[![Python Version](https://img.shields.io/pypi/pyversions/manini.svg?color=green)](https://python.org)
[![tests](https://github.com/hereariim/manini/workflows/tests/badge.svg)](https://github.com/hereariim/manini/actions)
[![codecov](https://codecov.io/gh/hereariim/manini/branch/main/graph/badge.svg)](https://codecov.io/gh/hereariim/manini)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/manini)](https://napari-hub.org/plugins/manini)

Manini (**MA**chi**N**e **IN**ference  & Correct**I**on) is thought as a tool to boost the collaborative contribution of end-users to the assessment of deep learning model during their testing phase.
It is a user-Friendly plugin that enables to manually correct the result of an inference of deep learning model by an end-user. The plugin covers the following informational tasks: segmentation, classification and object detection.

## White paper

Herearii Metuarea, David Rousseau. [Toward more collaborative deep learning project management in plant phenotyping. ](https://essopenarchive.org/doi/full/10.22541/essoar.169876925.51005273/v1)

ESS Open Archive . October 31, 2023.
DOI: 10.22541/essoar.169876925.51005273/v1

----------------------------------

This plugin was written by Herearii Metuarea, PHENET engineer at LARIS (French laboratory located in Angers, France) in Imhorphen team (bioimaging research group lead) under the supervision by David Rousseau (Full professor). This plugin was designed in the context of the european project INVITE and PHENET.

![Screenshot from 2023-11-13 00-13-13](https://github.com/hereariim/manini/assets/93375163/c602e802-71b9-48ec-a9f2-cec3e4fa8220)

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html!

-->

## Installation

You can install `manini` via [pip]:

    pip install manini

To install latest development version :

    pip install git+https://github.com/hereariim/manini.git


## Description

This plugin is a tool to perform image inference. The inference is open to the model for image segmentation (binary or multiclass), image classification and object detection. The dimension of image should be the same size with the input of model.
Currently compatible with tensorflow h5 models. In this format, the h5 file must contain all the elements of the model (architecture, weights, etc). Several ongoing developments, feel free to contact us if you have some request.

## Contact

Imhorphen team, bioimaging research group

42 rue George Morel, Angers, France

- Pr David Rousseau, david.rousseau@univ-angers.fr
- Herearii Metuarea, herearii.metuarea@univ-angers.fr 

### Scheme

![manini](https://github.com/hereariim/manini/assets/93375163/636a5e15-da0f-4387-8f37-b8ca89b4482b)

#### Input

The user must deposit two items (+1 optional item). 

- A compressed file (.zip) containing the images in RGB

```
.
└── input.zip
    ├── im_1.JPG
    ├── im_2.JPG 
    ├── im_3.JPG
    ...
    └── im_n.JPG
```

- A tensorflow h5 file (.h5) which is the segmentation model
- A text file (.txt) containing the names of the classes (optional)

The Ok button is used to validate the imported elements. The Run button is used to launch the segmentation.

#### Process

Correction is made by selecting some classes displayed in a widget :

- Paint panel for image segmentation

- Table for image classification

- Bounding box panel for object detection

#### Output

##### Segmentation + Detection

The plugin suggest 'Export' widget. When user select image and mask, the Save button allows you to obtain data in a compressed file. This file contains folders containing the images and their mask.

##### Classification

The Save button allows you to obtain a csv file. This file is the table on which the user had made his modifications.

#### Tutorial

Please, you can learn better if you watch a video tutorial below.

Presentation video of the context where the plugin was developped : [MANINI Napari Plugin Part 1](https://www.youtube.com/watch?v=ltbMIhApwRk)

Tutorial video to get started : [MANINI Napari Plugin Part 2](https://www.youtube.com/watch?v=HU21VQpvRAM)


## License

Distributed under the terms of the [BSD-3] license,
""manini"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/hereariim/manini/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/

","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/hereariim/manini/issues', 'Documentation, https://github.com/hereariim/manini#README.md', 'Source Code, https://github.com/hereariim/manini', 'User Support, https://github.com/hereariim/manini/issues']",,,manini.manini_widget,,,,,https://pypi.org/project/manini,,
45,Mikro Napari,0.1.63,,,mikro-napari,jhnnsrs,jhnnsrs@gmail.com,CC BY-NC 3.0,,A napari plugin to interact with and provide functionality for a connected arkitekt server,">=3.8,<=3.12","['arkitekt[fluss,mikro,reaktion,rekuest,unlok] (>=0.5.58)']","# mikro-napari

[![codecov](https://codecov.io/gh/jhnnsrs/mikro-napari/branch/master/graph/badge.svg?token=UGXEA2THBV)](https://codecov.io/gh/jhnnsrs/mikro-napari)
[![PyPI version](https://badge.fury.io/py/mikro-napari.svg)](https://pypi.org/project/mikro-napari/)
[![Maintenance](https://img.shields.io/badge/Maintained%3F-yes-green.svg)](https://pypi.org/project/mikro-napari/)
![Maintainer](https://img.shields.io/badge/maintainer-jhnnsrs-blue)
[![PyPI pyversions](https://img.shields.io/pypi/pyversions/mikro-napari.svg)](https://pypi.python.org/pypi/mikro-napari/)
[![PyPI status](https://img.shields.io/pypi/status/mikro-napari.svg)](https://pypi.python.org/pypi/mikro-napari/)

mikro napari enables napari on the mikro/arkitekt platform

# DEVELOPMENT

## Idea

This is a napari plugin, that provides a simple user interface to use napari with mikro you can view and annotate
data on the mikro platform (synchronised between all of your napari instances) and use napari within arkitekt workflows
(can be extended with other plugins)

## Install

Simple install this plugin via naparis plugin-manager and enable it. 
Login with your local mikro/arkitekt platform and start using it in workflows

You can also install mikro-napari directly in your enviroment 

```bash
pip install mikro-napari napari[pyqt5]
```


","['Framework :: napari', 'License :: Other/Proprietary License', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11']","['Repository, https://github.com/jhnnsrs/mikro-napari']",,,mikro-napari.arkitekt_widget,,,,,https://pypi.org/project/mikro-napari,,
46,misic-napari,0.2.3,2022-02-11,2023-06-18,misic-napari,"S. Panigrahi & L. Espinosa, IAM, LCB",spanigrahi@imm.cnrs.fr,MIT,https://github.com/pswapnesh/MiSiC,Segmentation of bacteria agnostic to imaging modality,>=3.6,"['tensorflow', 'termcolor']","# misic-napari

<!-- [![License](https://img.shields.io/pypi/l/misic-napari-plugin.svg?color=green)](https://github.com/pswap/misic-napari-plugin/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/misic-napari-plugin.svg?color=green)](https://pypi.org/project/misic-napari-plugin)
[![Python Version](https://img.shields.io/pypi/pyversions/misic-napari-plugin.svg?color=green)](https://python.org)
[![tests](https://github.com/pswap/misic-napari-plugin/workflows/tests/badge.svg)](https://github.com/pswap/misic-napari-plugin/actions)
[![codecov](https://codecov.io/gh/pswap/misic-napari-plugin/branch/master/graph/badge.svg)](https://codecov.io/gh/pswap/misic-napari-plugin) -->

----------------------------------

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/docs/plugins/index.html
-->

A napari plugin for [MiSiC](https://elifesciences.org/articles/65151). Segmentation of bacteria in dense colonies. 
The plugin provides acces to preprocessing of the image like scaling, gamma correction, sharpness and noise variance that can improve the segmentation of bacteria irrespective of the imaging modality.

## Install Napari
Install napari either the bundled app or through [pip/conda]
https://napari.org/#installation

## Installation

Install `misic-napari` through plugin manager in napari.

Or

You can install `misic-napari` via [pip] in the napari console:

    pip install misic-napari

## Tutorial
Note: 
The image should be in the format [n,row,col] or [row,col], i.e., a single image or a stack. Hyper-stacks are not supported yet. 

#### get_width


Creates a Shapes layer with name 'cell-width' where the cell width can be hand drawn using line drawing tools in the shapes layer. This need not be precise and can be adjusted later. Click `get_cell_width` to obtain the desired mean cell width. This will be used to scale the image accordingly before segmentation.
 
#### segment

This can be used to quickly set the parameters that can be later used to segment the whole stack.

```
use_roi
```
A square ROI of side 256 is created by default for quickly checking adjusting the segmentation parameters. The roi can be resized or moved in the `roi` shapes layer.

```
light_background
```
True; for phase-contrast images.

False; for bright-field and fluorescence images.

```
use_local_noise
```
If checked, this adds noise to image with local variance. In this case, a noise_var of around 0.1 works well. If unchecked, this adds noise with global variance of noise_var/100. Adding may help in removing false positives.

```
gaussian_laplace
```
Useful when segmenting fluorescence images. 

```
adjust_scale
```
Fine-tuning the scale around ([0.8,1.2]) the scale obtained from cell-width determined in `get_cell_width`.

```
noise_var
```
Amount of noise to be added to the image at the preprocessing step. This helps reduce the False Positives and, in many cases, to separate cells effectively. 
```
gamma
```
gamma correction 

```
sharpness_scale and sharpness_amount
```
Unsharp mask based sharpness with sigma = sharpness_scale and amount = sharpness_amount



### segment_stack
Segments the entire stack using the parameters that were obtained in ""segment"".


### save
The parameters can be saved in a json file. 

## License

Distributed under the terms of the [MIT] license,
""misic-napari"" is free and open source software

## Cite
```
@article {10.7554/eLife.65151,
article_type = {journal},
title = {Misic, a general deep learning-based method for the high-throughput cell segmentation of complex bacterial communities},
author = {Panigrahi, Swapnesh and Murat, Dorothée and Le Gall, Antoine and Martineau, Eugénie and Goldlust, Kelly and Fiche, Jean-Bernard and Rombouts, Sara and Nöllmann, Marcelo and Espinosa, Leon and Mignot, Tâm},
editor = {Xiao, Jie and Storz, Gisela and Hensel, Zach},
volume = 10,
year = 2021,
month = {sep},
pub_date = {2021-09-09},
pages = {e65151},
citation = {eLife 2021;10:e65151},
doi = {10.7554/eLife.65151},
url = {https://doi.org/10.7554/eLife.65151},
abstract = {Studies of bacterial communities, biofilms and microbiomes, are multiplying due to their impact on health and ecology. Live imaging of microbial communities requires new tools for the robust identification of bacterial cells in dense and often inter-species populations, sometimes over very large scales. Here, we developed MiSiC, a general deep-learning-based 2D segmentation method that automatically segments single bacteria in complex images of interacting bacterial communities with very little parameter adjustment, independent of the microscopy settings and imaging modality. Using a bacterial predator-prey interaction model, we demonstrate that MiSiC enables the analysis of interspecies interactions, resolving processes at subcellular scales and discriminating between species in millimeter size datasets. The simple implementation of MiSiC and the relatively low need in computing power make its use broadly accessible to fields interested in bacterial interactions and cell biology.},
keywords = {Deep learning, image analysis, microscopy, myxococcus xanthus, biofilms},
journal = {eLife},
issn = {2050-084X},
publisher = {eLife Sciences Publications, Ltd},
}
```
","['Development Status :: 4 - Beta', 'Intended Audience :: Developers', 'Framework :: napari', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Operating System :: OS Independent', 'License :: OSI Approved :: MIT License']",,,,misic-napari.get_width,,,,,https://pypi.org/project/misic-napari,https://github.com/pswapnesh/MiSiC,
47,mmv_h4tracks,1.1.1,,,mmv_h4tracks,lennart kowitz,,BSD-3-Clause,,Human in the loop 2d cell migration analysis,,,,,,,,,,,,,https://pypi.org/project/mmv_h4tracks,,
48,Human in the Loop Cell Tracking Tool,1.0.0,,,mmv_hitl4trk,lennart kowitz,,BSD-3-Clause,,A simple plugin to use with napari,,,,,,,,,,,,,https://pypi.org/project/mmv_hitl4trk,,
49,morphometrics,0.0.8,2022-07-05,2023-11-24,morphometrics,Kevin Yamauchi,kevin.yamauchi@gmail.com,BSD-3-Clause,https://pypi.org/project/morphometrics/,A plugin for quantifying shape and neighborhoods from images.,>=3.9,"['glasbey', 'imageio (!=2.11.0,!=2.22.1,>=2.5.0)', 'leidenalg', 'napari-skimage-regionprops', 'napari', 'numba', 'numpy', 'qtpy', 'pandas', 'pooch', 'pyclesperanto-prototype (>=0.8.0)', 'pymeshfix', 'pyqtgraph', 'scanpy', 'scikit-image (>0.19.0)', 'scikit-learn (>=0.24.2)', 'tqdm', 'trimesh[easy]', ""pre-commit ; extra == 'dev'"", ""pytest ; extra == 'dev'"", ""pytest-qt ; extra == 'dev'""]","# morphometrics

[![License](https://img.shields.io/pypi/l/morphometrics.svg?color=green)](https://github.com/morphometrics/morphometrics/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/morphometrics.svg?color=green)](https://pypi.org/project/morphometrics)
[![Python Version](https://img.shields.io/pypi/pyversions/morphometrics.svg?color=green)](https://python.org)
[![tests](https://github.com/morphometrics/morphometrics/workflows/tests/badge.svg)](https://github.com/morphometrics/morphometrics/actions)
[![codecov](https://codecov.io/gh/morphometrics/morphometrics/branch/main/graph/badge.svg)](https://codecov.io/gh/morphometrics/morphometrics)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/morphometrics)](https://napari-hub.org/plugins/morphometrics)

A plugin for quantifying shape and neighborhoods from images.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/stable/index.html
-->

## Installation

### conda environment file
You can install `morphometrics` via our conda environment file. To do so, first install anaconda or miniconda on
your computer. Then, download the [`environment.yml file`](https://raw.githubusercontent.com/kevinyamauchi/morphometrics/master/environment.yml) (right click the link and ""Save as...""). In your terminal,
navigate to the directory you downloaded the `environment.yml` file to:

```bash
cd <path/to/downloaded/environment.yml>
```

Then create the `morphometrics` environment using

```bash
conda env create -f environment.yml
```

Once the environment has been created, you can activate it and use `morphometrics` as described below.

```bash
conda activate morphometrics
```

If you are on Mac OS or Linux install the following:

Mac:

```bash
conda install -c conda-forge ocl_icd_wrapper_apple
```

Linux:

```bash
conda install -c conda-forge ocl-icd-system
```


### Development installation

To install latest development version :

    pip install git+https://github.com/kevinyamauchi/morphometrics.git

## Example applications
<table border=""0"">
<tr><td>


<img src=""https://github.com/kevinyamauchi/morphometrics/raw/main/resources/surface_distance_measurement.gif""
width=""300""/>

</td><td>

[measure the distance between surfaces](https://github.com/kevinyamauchi/morphometrics/blob/main/examples/surface_distance_measurement.ipynb)

</td></tr><tr><td>

<img src=""https://github.com/kevinyamauchi/morphometrics/raw/main/resources/region_props_plugin.png""
width=""300""/>

</td><td>

[napari plugin for measuring properties of segmented objects (regionprops)](https://github.com/kevinyamauchi/morphometrics/blob/main/examples/measure_with_widget.py)

</td></tr><tr><td>

<img src=""https://github.com/kevinyamauchi/morphometrics/raw/main/resources/object_classification.png""
width=""300""/>

</td><td>

[object classification](https://github.com/kevinyamauchi/morphometrics/blob/main/examples/object_classification.ipynb)

</td></tr><tr><td>

<img src=""https://github.com/kevinyamauchi/morphometrics/raw/main/resources/mesh_object.png""
width=""300""/>

</td><td>

[mesh binary mask](https://github.com/kevinyamauchi/morphometrics/blob/main/examples/mesh_binary_mask.ipynb)


</td></tr></table>


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""morphometrics"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/kevinyamauchi/morphometrics/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.9', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/kevinyamauchi/morphometrics/issues', 'Documentation, https://github.com/kevinyamauchi/morphometrics#README.md', 'Source Code, https://github.com/kevinyamauchi/morphometrics', 'User Support, https://github.com/kevinyamauchi/morphometrics/issues']",,,morphometrics.QtMeasurementWidget,morphometrics.make_simple_labeled_cube,,,,https://pypi.org/project/morphometrics/,,
50,morphometrics engine,0.0.1,2022-12-30,2023-06-18,morphometrics-engine,Kevin Yamauchi,kevin.yamauchi@gmail.com,BSD-3-Clause,https://github.com/morphometrics/morphometrics-engine,A morphometrics measurement engine.,>=3.8,"['napari', 'napari-skimage-regionprops', 'numpy', 'magicgui', 'pandas', 'qtpy', 'superqt', 'tqdm', 'toolz', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# morphometrics-engine

[![License BSD-3](https://img.shields.io/pypi/l/morphometrics-engine.svg?color=green)](https://github.com/morphometrics/morphometrics-engine/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/morphometrics-engine.svg?color=green)](https://pypi.org/project/morphometrics-engine)
[![Python Version](https://img.shields.io/pypi/pyversions/morphometrics-engine.svg?color=green)](https://python.org)
[![tests](https://github.com/morphometrics/morphometrics-engine/workflows/tests/badge.svg)](https://github.com/morphometrics/morphometrics-engine/actions)
[![codecov](https://codecov.io/gh/morphometrics/morphometrics-engine/branch/main/graph/badge.svg)](https://codecov.io/gh/morphometrics/morphometrics-engine)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/morphometrics-engine)](https://napari-hub.org/plugins/morphometrics-engine)

A morphometrics measurement engine.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `morphometrics-engine` via [pip]:

    pip install morphometrics-engine



To install latest development version :

    pip install git+https://github.com/morphometrics/morphometrics-engine.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""morphometrics-engine"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/morphometrics/morphometrics-engine/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/morphometrics/morphometrics-engine/issues', 'Documentation, https://github.com/morphometrics/morphometrics-engine#README.md', 'Source Code, https://github.com/morphometrics/morphometrics-engine', 'User Support, https://github.com/morphometrics/morphometrics-engine/issues']",,,morphometrics-engine.QtMeasurementWidget,,,,,https://pypi.org/project/morphometrics-engine,https://github.com/morphometrics/morphometrics-engine,
51,morphospace,0.0.3,,,morphospace,Kevin Yamauchi,,BSD-3-Clause,,a library for creating  and exploring morphospaces.,,,,,,,,,,,,,https://pypi.org/project/morphospace,,
52,MouseCHD,0.0.2a0,,,mousechd-napari,Hoa Nguyen,ntthoa.uphcm@gmail.com,MIT,,A tool for heart segmentation and congenital heart defect detection in mice.,>=3.9,"['setuptools', 'packaging', 'mousechd', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'""]","# Napari plugin for MouseCHD project

![](https://raw.githubusercontent.com/hnguyentt/mousechd-napari/master/assets/thumbnail.png)

*Tool for heart segmentation and congenital heart defect detection in mice.*

## Installation
### From Bundle
(1) Install Napari by following this instruction https://napari.org/stable/tutorials/fundamentals/installation.html#install-as-a-bundled-app

(2) Install `mousechd-napari` plugin:
    * Run Napari
    * `Plugins` --> `Install/Uninstall Plugins ...` --> Search for `mousechd_napari` --> Click on `install`.

(3) Restart Napari to run the plugin

### From code
```bash
conda create -n mousechd_napari python=3.9
conda activate mousechd_napari
pip install ""napari[all]""
pip install mousechd_napari
napari
```

## How to use

Please find details instruction in folder [docs](https://github.com/hnguyentt/mousechd-napari/tree/master/docs)
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: MIT License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/hnguyentt/mousechd-napari/issues', 'Documentation, https://github.com/hnguyentt/mousechd-napari#README.md', 'Source Code, https://github.com/hnguyentt/mousechd-napari', 'User Support, https://github.com/hnguyentt/mousechd-napari/issues']",mousechd-napari.get_reader,,mousechd-napari.widget,mousechd-napari.sample,"['*.nrrd', '*.nii.gz', '*.dcm']",,,https://pypi.org/project/mousechd-napari,,
53,MSI-Explorer,1.0.1,,,MSI-Explorer,lennart kowitz,lennart.kowitz@isas.de,BSD-3-Clause,,a napari plug-in for biochemical annotation of mass spectrometry imaging data,>=3.8,"['numpy', 'qtpy', 'pyimzml', 'matplotlib', 'vaex', 'opencv-python', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# MSI-Explorer

[![License BSD-3](https://img.shields.io/pypi/l/MSI-Explorer.svg?color=green)](https://github.com/MMV-Lab/MSI-Explorer/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/MSI-Explorer.svg?color=green)](https://pypi.org/project/MSI-Explorer)
[![Python Version](https://img.shields.io/pypi/pyversions/MSI-Explorer.svg?color=green)](https://python.org)
[![tests](https://github.com/MMV-Lab/MSI-Explorer/workflows/tests/badge.svg)](https://github.com/MMV-Lab/MSI-Explorer/actions)
[![codecov](https://codecov.io/gh/MMV-Lab/MSI-Explorer/branch/main/graph/badge.svg?token=LR8CU032ZD)](https://codecov.io/gh/MMV-Lab/MSI-Explorer)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/MSI-Explorer)](https://napari-hub.org/plugins/MSI-Explorer)

# User Manual

The MSI-Explorer napari plugin is a powerful tool designed for targeted biochemical annotations in MSI data. This user manual provides a comprehensive guide on how to install, use, and explore the functionalities of the plugin within the napari platform. It covers data import, visualization, mean intensity calculation, region of interest (ROI) analysis, annotation with selected databases and pre-processing such as noise reduction and normalization. 

[MSI-Explorer] 
 
## Installation

Install napari by using this command.
   
     pip install ""napari[all]""

You can install `MSI-Explorer` via [pip]:
   
     pip install MSI-Explorer

## Usage
Start napari from the console with:

    napari

Navigate to `Plugins -> MSI-Explorer (MSI-Explorer)`
![Plugin](https://github.com/nmmtsaw/MSI-Explorer_User-Manual/assets/127961719/104718fa-227e-4117-9b52-f674a265d218)

### 1. Uploading and visualization of mass spectrometry imaging data
- Select imzml file using `Load imzML`.
- Metadata can be checked by `View Metadata`.
![Uploading MSI data_v1](https://github.com/nmmtsaw/MSI-Explorer_User-Manual/assets/127961719/a4783643-cf8e-4c68-af8e-03f264a48573)

![Visualization of MSI data_v1](https://github.com/nmmtsaw/MSI-Explorer_User-Manual/assets/127961719/5e37c375-d430-419a-9038-9980e858c482)


####
Upon uploading profile mode data, a pop-up appears prompting you to convert it to centroid mode.
Selecting `Yes` converts the data, while `No` keeps it in its original profile format.

![profile_centroid](https://github.com/nmmtsaw/MSI-Explorer-Manual/assets/127961719/5eecf5c2-e9b5-45da-a620-6dfaad058faf)

### 2. Calculating mean (average) intensity
- To calculate the mean spectrum, click on `Show true mean spectrum`.
- Clicking `Show image` will create an image view of the currently plotted data
- To export the plotted data as .csv file, click `Export spectrum data`.
- To save the spectrum plot as image, click `Export spectrum plot`.

![Calculating mean spectrum](https://github.com/nmmtsaw/MSI-Explorer_User-Manual/assets/127961719/2e921e00-75cf-4925-a9de-01d093277a06)

![Calculating mean spectrum_v1](https://github.com/nmmtsaw/MSI-Explorer_User-Manual/assets/127961719/19a713e3-a9ff-4e0c-be6b-545fb29991c6)


#### 2.1. Calculating mean (average) intensity of selected m/z value
To focus on a specific m/z value, zoom in on the spectrum plot. The figure will be as
shown as below.
![Calculating mean spectrum specific mz_v1](https://github.com/nmmtsaw/MSI-Explorer_User-Manual/assets/127961719/ba47080a-f439-4dc2-96b9-1f82ee5acbc3)

It is recommended to use `Multi` panel view.
The image can be displayed by `Show image` and the data can be exported as `.csv` file by using `Export spectrum data`.

### 3. Pre-processing
The pre-processing capabilities of MSI-Explorer enhance data quality and prepare MSI data for downstream analysis. Pre-processing steps involve: 


#### (a) Noise reduction
Users can choose their desired level of noise reduction (shown as a percentage) for their experiment. 

![Noise reduction_v1](https://github.com/nmmtsaw/MSI-Explorer_User-Manual/assets/127961719/9ce5e428-fe46-4f5f-a53f-7186c9f5ca8c)

#### (b) Normalization
The normalization methods that the user can apply are 
- Total ion current (TIC)
- Root mean square (RMS)
- Medium
- Reference peak (or internal standard)

![normalization_v1](https://github.com/nmmtsaw/MSI-Explorer_User-Manual/assets/127961719/972b30af-8425-46e4-bb54-705df52c725a)

#### (c) Hotspot removal
Hotspot removal can also be applied using a default threshold of 99.99%.
![hotspot removal_v1](https://github.com/nmmtsaw/MSI-Explorer_User-Manual/assets/127961719/c9d279fa-d03b-499d-857d-6953ba7ea253)


After pre-processing steps are chosen, click `Execute` and `Show true mean spectrum` to calculate the mean intensity.

The figure shows the spectrum and image of the TIC normalization with 3% noise reduction and hotspot removal for the 99.9% quantile.
![pre-processed_v1](https://github.com/nmmtsaw/MSI-Explorer_User-Manual/assets/127961719/d1068382-f6e2-4af9-9c5b-949fb87ac90c)


### 4. Database
To use the database search, click on `Select` and a pop-up window will appear. There,
select `Metabolite_database_ver2`, which is a built-in database, and click `Confirm`.

![Database](https://github.com/nmmtsaw/MSI-Explorer_User-Manual/assets/127961719/928fa260-196e-4034-8ddd-0944c751c77e)

The features of the database function are
1. Charge (neutral, positive or negative)
2. Adduct (based on the charge chosen)
3. Range of the m/z value for the image display
4. custom search with molecule name or m/z value

![Database_search](https://github.com/nmmtsaw/MSI-Explorer_User-Manual/assets/127961719/ca7d943a-1b6b-4cba-bf4d-934ee574cc61)

Users can customize the database with exact mass, molecule name, or molecular formula. The format should be as shown in the table and the headers are not needed in the database.

Exact mass | Molecule name | Molecula formula
------- | -------- | --------
176.0950 | Cotinine | C10H12N2O
174.1117 | Arginine | C6H14N4O2
244.0881 | Biotin | C10H16N2O3S

### 5. Region of interest (ROI) selection
- To select the ROI, click on `Select ROI for mean spectrum`. Adjust the brush size and label color. You can fill the area by using paint icon. 
- Then click on the `Calculate ROI mean spectrum`.
- You can export as `.csv` file by using `Export spectrum data`.
- If one m/z is needed, just zoom-in the spectrum plot window and export.
- Before selecting the second ROI, remove the first selected area by using eraser or label 0.

![ROI selection_v1](https://github.com/nmmtsaw/MSI-Explorer_User-Manual/assets/127961719/e79ca007-a0b5-4ba7-8cea-ae5e8ad6dd7d)


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""MSI-Explorer"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/MMV-Lab/MSI-Explorerissues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/MMV-Lab/MSI-Explorer/issues', 'Documentation, https://github.com/MMV-Lab/MSI-Explorer#README.md', 'Source Code, https://github.com/MMV-Lab/MSI-Explorer', 'User Support, https://github.com/MMV-Lab/MSI-Explorer/issues']",msi_explorer.get_reader,MSI-Explorer.write_multiple,MSI-Explorer.make_qwidget,,['*.imzML'],,['.npy'],https://pypi.org/project/MSI-Explorer,,
54,Multiplex Registration,0.0.15,,,multireg,Gaëlle Letort,gaelle.letort@pasteur.fr,BSD-3-Clause,,Registration of 3D multiplex images with one common chanel,>=3.8,"['numpy', 'napari', 'magicgui', 'qtpy', 'tifffile', 'imaris-ims-file-reader', 'czifile', 'itk-registration', 'itk-elastix']","# multireg

[![License BSD-3](https://img.shields.io/pypi/l/multireg.svg?color=green)](https://gitlab.pasteur.fr/gletort/multireg/blob/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/multireg.svg?color=green)](https://pypi.org/project/multireg)
[![Python Version](https://img.shields.io/pypi/pyversions/multireg.svg?color=green)](https://python.org)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/multireg)](https://napari-hub.org/plugins/multireg)

Registration of 3D multiplex images with one common chanel, based on itk-elastix.

Napari plugin to align 3D stacks that have one common field of view in one chanel used to calculate the alignement. The plugin will apply the registration to all other chanels and output one final stack with all the aligned chanels.

The stacks **must have one common chanel** (typically cell junctions and nuclei) that is used to calculate the registration transformation. It can be rotated, translated, deformed, and with a wider field of view. 
Then the calculated transformation is applied to all the other chanels for each stack.

The final result is **one multi-chanel 3D stack**, with the first chanel being an average (or not) of the common chanel and each other chanel the registered chanels from the multiple stacks. The common chanel can be averaged between the different chanels, which improves its quality.

The plugin save and load files to a folder named `aligned` and created in the same directory as the source images.

Example of usage of this module is in the case of imaging the same cells with washing out or moving the sample in between. The corresponding cells will not be at the same position in the new stacks, and can even be deformed by the procedure. This plugin realign the images based on one common chanel on which the transformation is calculated. 

----------------------------------
## Installation

* You can install the plugin directly in `Napari` by going to `Plugins>Install/Uninstall plugins` and search for `multireg`

* Or you can install `multireg` via [pip]:

    pip install multireg


## Usage

You can launch `multireg` in napari by going to `Plugins>multireg: do multiplex registration`.

### Fixed image
It will open a prompt to ask you to select the reference (fixed) image, compared to which all other images will be aligned.
Then you have to choose the `reference chanel` that will be used in all the stacks to calculate the alignement. So this chanel should be common to all stacks.

![](https://gitlab.pasteur.fr/gletort/multireg/raw/main/imgs/plugin_step0.png)

#### Reference points
The first part of the registration relies on reference points manually selected, because the common field of view can be quite far from each other in the acquisition. So first a affine registration is applied to bring close the region of interest between the two stacks to match. 
<br> *Note that if your stacks did not move a lot then you could calculate the transformation without using the reference points. There's an option in the alignement calculation panel for this.*

![](https://gitlab.pasteur.fr/gletort/multireg/raw/main/imgs/plugin_fixedpoints.png)

You have to manually placed a few reference points (4-5 should be enough). Try to spread them in the image (in x,y and z) on landmarks to recognize them in other images. 

To add a new reference point, click on the ""plus"" sign in the left panel. To select one, click on the arrow icon (or press 3), then on the point. You can move the point in x and y. To move it in z, press `u` for up and `d` for down. 

When all points are placed, save them. The **points have to be saved** to be correctly loaded by the alignement calculation step.
Then click on `Fixed points done` to continue to the next step.


### Moving images
Then you can choose one of the images you want to align with the reference image. Its chanel that is common to the fixed image should be the same chanel, selected in the first step (the `reference chanel`). Select the file of the moving image to align by clicking on `select file`. This will open the new image and go to the step of placing the moving points in this image.

When you will have process all the moving images, you can click on `All done` to finish the plugin by creating the [resulting stack](#create-resulting-image).

![moving image step](https://gitlab.pasteur.fr/gletort/multireg/raw/main/imgs/plugin_movingimg.png)

#### Moving points
You now have to locate where the region of interest (the fixed image) is in your new image and find the landmarks referenced in the fixed image are in this new image. This allows the plugin to put together the region of interest in the two images in a first step, before to fine-tune the registration.

For each point placed in the fixed image, place the corresponding point in the moving image. By default, the moving points are placed close to the fixed points. 
* Each point must have the same label (number) as its corresponding fixed points to associate them correctly. You can change a point label by selecting it and putting the new value in `param` and clicking on `update`.


* When a point is selected, you can drag it to its desired location. To move it in the Z direction, you can press `u` to move it to the next Z (up direction) and `d` (down) to the previous Z. The viewed slice will also move, following the point new position, when you do so.

* You can click on `side_by_side_view` to see the two images (fixed and moving) with their placed points at the same time.

* You can click on `two_windows_view` to see the fixed image and points in a separate Napari window. This allows to have visualize separatly the fixed and moving images and points, and thus to see different z-slices or zoom for each image. The new window will be closed automatically by the plugin if you unselect this option or when you click on `Moving done`.

![two window](https://gitlab.pasteur.fr/gletort/multireg/raw/main/imgs/twowin.png)

When all the moving points have been correctly placed, click on `Save points` to save this positions and let it be usable by the alignement step. The points **have to be saved** in the point file to be correctly loaded in the alignement step.

### Alignement calculation
This step is the core of the plugin. The transformation necessary to change the moving image to match with the fixed image on the `reference chanel` is calculated based on [itk-elastix](https://pypi.org/project/itk-elastix/) python module. It is decomposed in two steps. 

1. First a global **affine registration** is performed, based on the correspondance between the reference and moving points (`do rigid` option). This allows to locate the fixed image postion within the moving image and apply a first **shearing, scaling, rotation and translation** to super-impose the region of interest. 

2. The second step fine-tunes the registration. It doesn't use the reference points (except if rigid transformation was not selected) anymore but calculate the matching based on the images local intensities. **Non-rigid transformation** based on B-spline is performed at this step, thus allowing to compensate for **local deformations** in the moving image (`do bspline` option).

The option `use reference points` determines if the previously placed reference points should be used or if the registration is only based on intensities matching. It's possible to use only the intensities if the two images are not so far away from each other. The reference points will be used only in the first pass (either rigid or bspline) when both are selected. If only one is selected, the points will be used on the selected transformation.

The option `strong_weight_points` allows to give more importance to reference points than to intensities matching when calculating the registration. The weights will be 0.2 for the intensity metric and 0.8 for points metric. Note that if both rigid and bspline transformations are selected, the second transformation (bspline) do not use the points.

![apply alignement step](https://gitlab.pasteur.fr/gletort/multireg/raw/main/imgs/interm.png)


You can click on `show advanced parameters` to tune the parameters of the non rigid transformation. After calculating the registration, the plugin will add a new layer, which is the moving image after alignement, so you can check the sucess of the regristration. `show intermediate_layer` will also add the moving image aligned after the first step only (the points matching with affine registration).

![calculate alignement step](https://gitlab.pasteur.fr/gletort/multireg/raw/main/imgs/align.png)


### Apply alignement
Once the calculated registration is satisfying, you can apply it to all the chanels of your moving image, or only to a few. By default, all chanels are selected in the `Apply alignement` panel, but you can unselect the chanels that you don't want to align in the parameter `align chanels`. 
When you click on `Align images`, the plugin will apply the transformation on the selected chanels of the moving image and save each of them in the `aligned` folder as individual `.tif` files. 

![apply alignement step](https://gitlab.pasteur.fr/gletort/multireg/raw/main/imgs/goalign.png)

### Create resulting image
This step allows to save a single 3D multi-chanels stack with all the aligned chanels. 

The common chanel present in all the images can be averaged together after alignement to obtain a much less noisy image. By default, the aligned `reference chanel` of all the images are averaged together to create the final image first chanel. However, it is possible to unselect some images in the first panel (`average chanels` parameter) if you do not wish to use all the images or do an average.

![create result image](https://gitlab.pasteur.fr/gletort/multireg/raw/main/imgs/create.png)

Then each aligned chanel of all the images that were not the reference chanel are stacked together in the final resulting image. Here also, if you don't want to keep all the other chanels in the resulting image, you can unselect the one that you don't want stacked, in the `add_chanels` parameter. 
All the aligned chanels have been previously saved in the `aligned` folder. If `delete_files` is checked (default) all these interemediate files will be deleted and only the final resulting stack will be saved in that folder.

You will end-up with a final 3D multi-chanels stack, saved as a `.tif` file in the `aligned` folder, with the same name as your fixed image. It can have a lot of chanels if you stacked together multiple images.
In napari, you can separate the chanels by right clicking on the layer and select `Split stack`. 
In Fiji, you can make the stack as a composite to see the chanels with different colors.

![final image](https://gitlab.pasteur.fr/gletort/multireg/raw/main/imgs/reslayer.png)

## License
Distributed under the terms of the [BSD-3] license,
""multireg"" is free and open source software

## Plugin initialization
This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.


## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://gitlab.pasteur.fr/gletort/multireg/issues', 'Documentation, https://gitlab.pasteur.fr/gletort/multireg#README.md', 'Source Code, https://gitlab.pasteur.fr/gletort/multireg']",,,multireg.registration,,,,,https://pypi.org/project/multireg,,
55,3D Counter,0.2.1,2023-10-29,2024-05-03,napari-3d-counter,Peter Newstein,peternewstein@gmail.com,GPL-3.0-or-later,https://pypi.org/project/napari-3d-counter,A simple plugin for counting objects in 3D images,>=3.8,"['numpy', 'qtpy', 'pandas', 'scikit-image', 'matplotlib', 'napari <=0.4.19', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-3d-counter

[![License GNU GPL v3.0](https://img.shields.io/pypi/l/napari-3d-counter.svg?color=green)](https://github.com/pnewstein/napari-3d-counter/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-3d-counter.svg?color=green)](https://pypi.org/project/napari-3d-counter)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-3d-counter.svg?color=green)](https://python.org)
[![tests](https://github.com/pnewstein/napari-3d-counter/workflows/tests/badge.svg)](https://github.com/pnewstein/napari-3d-counter/actions)
[![codecov](https://codecov.io/gh/pnewstein/napari-3d-counter/branch/main/graph/badge.svg)](https://codecov.io/gh/pnewstein/napari-3d-counter)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-3d-counter)](https://napari-hub.org/plugins/napari-3d-counter)

A simple plugin for counting objects in 3D images

![small](https://github.com/pnewstein/napari-3d-counter/assets/30813691/9d524c31-f23b-4b34-bcb6-ec3bb415cdae)

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-3d-counter` via [pip]:

    pip install napari-3d-counter


To install latest development version :

    pip install git+https://github.com/pnewstein/napari-3d-counter.git


##  Count3D Usage

Count3D can be launched from the plugin menu

### Adding a cell

You can add a cell of the currently selected cell type by clicking on the viewer.

- Ensure that `Point adder` layer is selected
- Ensure that `Add points` tool is selected
- Click on the viewer where you would like the point to be added

The counter on the current cell type's button will be incremented



https://github.com/pnewstein/napari-3d-counter/assets/30813691/745d495e-1d18-43dd-aa5e-e9ecd835cdae


### Changing cell type

You can change the currently selected cell type by clicking on that cell type's
button. This change will be reflected in the GUI. Additionally, the keyboard
shortcut for that cell type can be used. Keyboard shortcuts are listed on the
button, and are ""q"", ""w"", ""e"", ""r"", ""t"", ""y"" by default


https://github.com/pnewstein/napari-3d-counter/assets/30813691/844d04ce-2795-4226-a98b-d5fe5a0b131e


### Undo last added cell

The undo button (shortcut u) will remove last added cell, regardless of
cell type


https://github.com/pnewstein/napari-3d-counter/assets/30813691/c04ca5e3-9f48-4dd5-89e5-a9866b353e03


### Remove a particular cell

To remove a particular cell. Change to the layer containing the cell you would
like to remove. Then select the `select points` tool to select the points to
delete, then use `Delete selected points` to delete those points

This change will be reflected in the counts.


https://github.com/pnewstein/napari-3d-counter/assets/30813691/d0787cba-9b23-46d5-9cd3-21a4ad73460a



### Change appearance of a cell type

Changes to the name or edge color of a points layer will be reflected in the
previously added points, as well as the GUI. Features that are editable in this way include:
    - face color
    - edge color
    - symbol
    - size


https://github.com/pnewstein/napari-3d-counter/assets/30813691/6c495270-d4c4-473e-9091-8d2e0f8e2764


### Save configuration

Use the `Make launch_cell_count.py` button to create a python script that will
launch napari with 3DCounter added to the dock and current cell type appearances
already loaded


https://github.com/pnewstein/napari-3d-counter/assets/30813691/3448652d-3064-4900-8bbe-e88d75667108


### Save cells

Use the ""Save cells"" button to save the cell coordinates for all layers into a
csv file


https://github.com/pnewstein/napari-3d-counter/assets/30813691/38b30f2a-cc83-46c2-8b19-4d44715c07c5


### Load cells

Use the ""Load cells"" button to load the cells from a csv file into new layers


https://github.com/pnewstein/napari-3d-counter/assets/30813691/7df74688-85b1-4b61-aa51-dab179763832


### Launch with saved configuration

To run Count3D with custom configuration, paste the following code into your napari ipython console

```python
from napari_3d_counter import Count3D, CellTypeConfig

cell_type_config = [
    # The first celltype is called ""cq+eve+"" and should be green
    CellTypeConfig(
        name=""cq+eve+"",
        color=""g""
    ),
    # The first celltype is called ""cq+eve-"" and should be cyan
    CellTypeConfig(
        name=""cq+eve-"",
        color=""c""
    ),
    # The first celltype is called ""cq-eve+"" and should be red
    CellTypeConfig(
        name=""cq-eve+"",
        color=""r""
    ),
]
# Launch the plugin with configuration
viewer.window.add_dock_widget(Count3D(viewer, cell_type_config=cell_type_config))
```

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [GNU GPL v3.0] license,
""napari-3d-counter"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/pnewstein/napari-3d-counter/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 4 - Beta', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: GNU General Public License v3 (GPLv3)', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/pnewstein/napari-3d-counter/issues', 'Documentation, https://github.com/pnewstein/napari-3d-counter#README.md', 'Source Code, https://github.com/pnewstein/napari-3d-counter', 'User Support, https://github.com/pnewstein/napari-3d-counter/issues']",,,napari-3d-counter.make_count3d,,,,,https://pypi.org/project/napari-3d-counter,,
56,Ortho Viewer Widget,0.1.5,2022-02-04,2023-11-22,napari-3d-ortho-viewer,Niklas Netter,niknett@gmail.com,MIT,https://github.com/gatoniel/napari-3d-ortho-viewer,Napari 3D Ortho Viewer - an ortho viewer for napari for 3D images,>=3.8,"['numpy', 'magicgui', 'qtpy', 'scikit-image', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-3d-ortho-viewer

[![License](https://img.shields.io/pypi/l/napari-3d-ortho-viewer.svg?color=green)](https://github.com/gatoniel/napari-3d-ortho-viewer/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-3d-ortho-viewer.svg?color=green)](https://pypi.org/project/napari-3d-ortho-viewer)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-3d-ortho-viewer.svg?color=green)](https://python.org)
[![tests](https://github.com/gatoniel/napari-3d-ortho-viewer/workflows/tests/badge.svg)](https://github.com/gatoniel/napari-3d-ortho-viewer/actions)
[![codecov](https://codecov.io/gh/gatoniel/napari-3d-ortho-viewer/branch/main/graph/badge.svg)](https://codecov.io/gh/gatoniel/napari-3d-ortho-viewer)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-3d-ortho-viewer)](https://napari-hub.org/plugins/napari-3d-ortho-viewer)

Napari 3D Ortho Viewer - an ortho viewer for napari for 3D images

----------------------------------

https://github.com/gatoniel/napari-3d-ortho-viewer/assets/40384506/4296dc11-ea37-40a0-8b17-eeb77480672f

This plugin is heavily inspired by [ortho-view-napari].

Check out this post on image.sc (https://forum.image.sc/t/napari-visualization-in-3-planes/57768) for more infos about multiview support in [napari].

This viewer has some additional features:
- double click to jump to specific position in all slices
- additional 3d view of 3d stack with lines or planes indicating current position

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/docs/plugins/index.html
-->

## Installation

You can install `napari-3d-ortho-viewer` via [pip]:

    pip install napari-3d-ortho-viewer



To install latest development version :

    pip install git+https://github.com/gatoniel/napari-3d-ortho-viewer.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [MIT] license,
""napari-3d-ortho-viewer"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/gatoniel/napari-3d-ortho-viewer/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
[ortho-view-napari]: https://github.com/JoOkuma/ortho-view-napari
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: MIT License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/gatoniel/napari-3d-ortho-viewer/issues', 'Documentation, https://github.com/gatoniel/napari-3d-ortho-viewer#README.md', 'Source Code, https://github.com/gatoniel/napari-3d-ortho-viewer', 'User Support, https://github.com/gatoniel/napari-3d-ortho-viewer/issues']",,,napari-3d-ortho-viewer.make_ortho_viewer_widget,,,,,https://pypi.org/project/napari-3d-ortho-viewer,https://github.com/gatoniel/napari-3d-ortho-viewer,
57,3D Movies Registration,0.0.4,,,napari-3dtimereg,Gaëlle Letort,gaelle.letort@pasteur.fr,BSD-3-Clause,,Registration of 3D movies applied to all channels,>=3.8,"['numpy', 'napari', 'magicgui', 'qtpy', 'tifffile', 'imaris-ims-file-reader', 'czifile', 'itk ==5.3.0', 'itk-registration', 'itk-elastix']","# napari-3dtimereg

[![License BSD-3](https://img.shields.io/pypi/l/napari-3dtimereg.svg?color=green)](https://gitlab.pasteur.fr/gletort/napari-3dtimereg/-/blob/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-3dtimereg.svg?color=green)](https://pypi.org/project/napari-3dtimereg)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-3dtimereg.svg?color=green)](https://python.org)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-3dtimereg)](https://napari-hub.org/plugins/napari-3dtimereg)

Temporal registration of 2D/3D movies on one channel based on [itk-elastix](https://pypi.org/project/itk-elastix/), and transpose alignement to the other channels.

Adaptated from [multireg](https://gitlab.pasteur.fr/gletort/multireg) for temporal movies.

----------------------------------
## Installation

* You can install the plugin directly in `Napari` by going to `Plugins>Install/Uninstall plugins` and search for `napari-3dtimereg`

* Or you can install `napari-3dtimereg` via [pip]:

    pip install napari-3dtimereg


## Usage

You can launch `3dtimereg` in napari by going to `Plugins>Do 3D movie registration (napari-3dtimereg)`.

### Choose movie and reference chanel

First, choose select the movie that you want to register. The plugin will create a folder `aligned` in the folder of your selected movie where the results will be saved.

Choose the color chanel on which to calculate the registration (`reference chanel`). Color chanels are numbered from 0 to nchanels, and you can see their respective number in the layer list on the left panel of Napari. Click on `Update` when the correct chanel is selected to go to the registration calculation step.

### Calculate alignement

If the `reference frame` parameter is set to `previous`, the registration of each frame will be calculated by comparing it to its previous frame (previously aligned). You can also choose to calculate the alignement of all frames compared to the middle (temporally) frame or all frames compared to the first frame of the movie.

![parameters screenshot](./imgs/parameters.png ""Registration parameters"")

The other parameters are parameters to use [itk-elastix](https://elastix.lumc.nl/) to calculate the registration.
* `show log`: to see the log of Elastix calculation
* `do rigid`: performs a rigid (affine) transformation step, that allowed to correct for translations/rotations.
* `do bspline`: performs a b-spline based transformation step, that allowed for local deformations in the image.
* `show advanced parameters`: to control the parameters used in the rigid and/or bspline transformations. These parameters control the size of the local registrations calculated, the resolutions at which the transformations are calculated, and can thus greatly impact the results.

If both rigid and bspline transformations, the program first applies the rigid transformation to allow for a global registration of the images. Then it will performs the second step of b-spline transformation that can includes local deformations.

For each frame, after calculating the registration on the reference chanel, the plugin will apply the calculated transformation to all the other color chanels of the initial movie. All results are saved as separated images in the `aligned` folder during the computation.

### Create the final aligned movie

When all frames have been processed, each color chanel and each frame have been saved in the `aligned` folder as separated images. This is usefull to calculate the registration on large movies without having to keep all the intermediates and calculated images in memory. You can directly use these separated images, or reconstruct a single composite movie of the result.

If you click on `Concatenate aligned images` on the plugin interface, the plugin will create a single composite movie from the aligned images, save it and delete the separated images in the `aligned` folder. 

## License

Distributed under the terms of the [BSD-3] license, ""napari-3dtimereg"" is free and open source software


[napari]: https://github.com/napari/napari
[@napari]: https://github.com/napari
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://gitlab.pasteur.fr/gletort/napari-3dtimereg/issues', 'Documentation, https://gitlab.pasteur.fr/gletort/napari-3dtimereg#README.md', 'Source Code, https://gitlab.pasteur.fr/gletort/napari-3dtimereg']",,,napari-3dtimereg.registration,,,,,https://pypi.org/project/napari-3dtimereg,,
58,napari-accelerated-pixel-and-object-classification,0.14.1,2022-03-31,2023-11-05,napari-accelerated-pixel-and-object-classification,Robert Haase,robert.haase@tu-dresden.de,BSD-3,https://github.com/haesleinhuepf/napari-accelerated-pixel-and-object-classification,Pixel and label classification using OpenCL-based Random Forest Classifiers,>=3.7,"['napari-plugin-engine >=0.1.4', 'numpy', 'apoc >=0.12.0', 'napari-tools-menu >=0.1.17', 'napari-time-slicer', 'superqt', 'imageio !=2.22.1', 'napari >=0.4.11', 'napari-assistant >=0.4.7']","# napari-accelerated-pixel-and-object-classification (APOC)

[![License](https://img.shields.io/pypi/l/napari-accelerated-pixel-and-object-classification.svg?color=green)](https://github.com/haesleinhuepf/napari-accelerated-pixel-and-object-classification/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-accelerated-pixel-and-object-classification.svg?color=green)](https://pypi.org/project/napari-accelerated-pixel-and-object-classification)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-accelerated-pixel-and-object-classification.svg?color=green)](https://python.org)
[![tests](https://github.com/haesleinhuepf/napari-accelerated-pixel-and-object-classification/workflows/tests/badge.svg)](https://github.com/haesleinhuepf/napari-accelerated-pixel-and-object-classification/actions)
[![codecov](https://codecov.io/gh/haesleinhuepf/napari-accelerated-pixel-and-object-classification/branch/main/graph/badge.svg)](https://codecov.io/gh/haesleinhuepf/napari-accelerated-pixel-and-object-classification)
[![Development Status](https://img.shields.io/pypi/status/napari-accelerated-pixel-and-object-classification.svg)](https://en.wikipedia.org/wiki/Software_release_life_cycle#Alpha)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-accelerated-pixel-and-object-classification)](https://napari-hub.org/plugins/napari-accelerated-pixel-and-object-classification)
[![DOI](https://zenodo.org/badge/412525441.svg)](https://zenodo.org/badge/latestdoi/412525441)
 
[clesperanto](https://github.com/clEsperanto/pyclesperanto_prototype) meets [scikit-learn](https://scikit-learn.org/stable/) to classify pixels and objects in images, on a [GPU](https://en.wikipedia.org/wiki/Graphics_processing_unit) using [OpenCL](https://www.khronos.org/opencl/) in [napari].

![](https://github.com/haesleinhuepf/napari-accelerated-pixel-and-object-classification/raw/main/images/screencast.gif)
The processed example image was kindly acquired by Daniela Vorkel, Myers lab, MPI-CBG / CSBD ([Download full video](https://github.com/haesleinhuepf/napari-accelerated-pixel-and-object-classification/raw/main/images/demo_lund.mp4))

For using the accelerated pixel and object classifiers in python, check out [apoc](https://github.com/haesleinhuepf/apoc).
Training classifiers from pairs of image and label-mask folders is explained in 
[this notebook](https://github.com/haesleinhuepf/apoc/blob/main/demo/train_on_folders.ipynb).
For executing APOC's pixel and object classifiers in [Fiji](https://fiji.sc) using [clij2](https://clij.github.io) please read the documentation of the [corresponding Fiji plugin](https://github.com/clij/clijx-accelerated-pixel-and-object-classification). Table classifiers and object mergers are not compatible with Fiji yet.

![](https://github.com/clij/clijx-accelerated-pixel-and-object-classification/raw/main/docs/screenshot.png)



## Usage

### Object and Semantic Segmentation

Starting point is napari with at least one image layer and one labels layer (your annotation).

![img.png](https://github.com/haesleinhuepf/napari-accelerated-pixel-and-object-classification/raw/main/images/object_segmentation_starting_point.png)

You find Object and Semantic Segmentation in the `Tools > Segmentation / labeling`. When starting those, the following graphical user interface will show up.

![img.png](https://github.com/haesleinhuepf/napari-accelerated-pixel-and-object-classification/raw/main/images/object_and_semantic_segmentation.png)

1. Choose one or multiple images to train on. These images will be considered as multiple channels. Thus, they need to be spatially correlated. 
   Training from multiple images showing different scenes is not (yet) supported from the graphical user interface. Check out [this notebook](https://github.com/haesleinhuepf/apoc/blob/main/demo/demp_pixel_classifier_continue_training.ipynb) if you want to train from multiple image-annotation pairs.
2. Select a file where the classifier should be saved. If the file exists already, it will be overwritten.
3. Select the ground-truth annotation labels layer. 
4. Select which label corresponds to foreground (not available in Semantic Segmentation)
5. Select the feature images that should be considered for segmentation. If segmentation appears pixelated, try increasing the selected sigma values and untick `Consider original image`.
6. Tree depth and number of trees allow you to fine-tune how to deal with manifold regions of different characteristics. The higher these numbers, the longer segmentation will take. In case you use many images and many features, high depth and number of trees might be necessary. (See also `max_depth` and `n_estimators` in the [scikit-learn documentation of the Random Forest Classifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html).
7. The estimation of memory consumption allows you to tune the configuration to your GPU-hardware. Also consider the GPU-hardware of others who want to use your classifier.
8. Click on Run when you're done with configuring. If the segmentation doesn't fit after the first execution, consider fine-tuning the ground-truth annotation and try again.

A successful segmentation can for example look like this:

![img.png](https://github.com/haesleinhuepf/napari-accelerated-pixel-and-object-classification/raw/main/images/object_segmentation_result.png)

After your classifier has been trained successfully, click on the ""Application / Prediction"" tab. If you apply the classifier again, python code will be generated. 
You can use this code for example to apply the same classifier to a folder of images. If you're new to this, check out [this notebook](https://github.com/BiAPoL/Bio-image_Analysis_with_Python/blob/main/image_processing/12_process_folders.ipynb).

![img.png](https://github.com/haesleinhuepf/napari-accelerated-pixel-and-object-classification/raw/main/images/code_generation.png)

A pre-trained classifier can be [applied from scripts as shown in the example notebook](https://github.com/haesleinhuepf/apoc/blob/main/demo/demo_object_segmenter.ipynb) or from the `Tools > Segmentation / labeling > Object segmentation (apply pretrained, APOC)`.

### Integration with the napari-assistant

Pre-trained models can also be assembled to workflows using the [napari-assistant](https://www.napari-hub.org/plugins/napari-assistant). You find APOC-operations in the categories `Filter`, `Label` and `Label Filters`:

![img.png](https://github.com/haesleinhuepf/napari-accelerated-pixel-and-object-classification/raw/main/images/assistant.png)

### Semantic segmentation

Users can also generate semantic segmentation label images where the label identifier corresponds to a class the pixel has been allocated to. 
The tool can be found in the menu `Tools > Segmentation / labeling > Semantic segmentation (APOC)`.
It works analogously like the Object Segmenter, just without the need to specify the class identifier that objects correspond to.

![img.png](https://github.com/haesleinhuepf/napari-accelerated-pixel-and-object-classification/raw/main/images/semantic_segmentation.png)

### Probability maps

The tool for generating probability maps (`Tools > Filtering > Probability Mapper (APOC)` menu) works analogously to the Object Segmenter as well. 
The only difference is that the result image is not a label image but an intensity image where the intensity represents the probability (between 0 and 1)
that a pixel belongs to a given class. In this example: The raw image (grey) has been annotated with three classes: background (black, label 1), foreground (white, label 2) and edges (grey, label 3).
The probability mapper was configured to create probability image (shown in green) for edges (label 3):

![img.png](https://github.com/haesleinhuepf/napari-accelerated-pixel-and-object-classification/raw/main/images/probability_mapper.png)

### Classifier statistics

While training, you can also activate the `Show classifier statistics` checkbox. 
When doing so, it is recommended to increase the number of trees so that the measurements are more reliable, especially when selecting many features.
This will open a small table after training where you can see how large the share of decision trees are for each analysed feature image.

![img.png](https://github.com/haesleinhuepf/napari-accelerated-pixel-and-object-classification/raw/main/images/classifier_statistics.png)

It is recommended to turn on/off the features that hold a very large share (green) or a very small share (magenta) of trees in the random forest. 
Retrain the classifier to see how the features influence the decision making.

Note: Multiple of these parameters may be correlated. 
If you select 11 feature images, which all allow to make the pixel classification similarly, but 10 of those are correlated, these 10 may appear with a share of about 0.05 while the 11th parameter has a share of 0.5. 
Thus, study these values with care.

### Merging objects

After segmentation, you can merge labeled objects using the `Tools > Segmentation post-processing > Merge objects (APOC)` menu. 
Annotate label edges that should be merged with intensity 1 and those which should be kept with intensity 2 in a blank label image.
Select which features should be considered for merging:
* `touch_portion`: The relative amount an object touches another. E.g. in a symmetric, honey-comb like tissue, neighboring cells have a touch-portion of `1/6` to each other.
* `touch_count`: The number of pixels where object touch. When using this parameter, make sure that images used for training and prediction have the same voxel size.
* `mean_touch_intensity`: The mean average intensity between touching objects. When using this parameter, make sure images used for training and prediction are normalized the same way.
* `centroid_distance`: The distance (in pixels or voxels) between centroids of labeled objects. 
* `mean_intensity_difference`: The absolute difference between the mean intensity of the two objects. This measurement allows differentiating bright and dark object and [not] merging them.
* `standard_deviation_intensity_difference`: The absolute difference between the standard deviation of the two objects. This measurement allows to differentiate [in]homogeneous objects and [not] merge them.
* `area_difference`: The difference in area/volume/pixel-count allows differentiating small and large objects and [not] merging them.
* `mean_max_distance_to_centroid_ratio_difference`: This parameter is a shape descriptor, similar to elongation, allowing to differentiate roundish and elongate object and [not] merging them.

Note: most features are recommended to be used in isotropic images only.

![img.png](https://github.com/haesleinhuepf/napari-accelerated-pixel-and-object-classification/raw/main/images/merge_objects.gif)

For training, use an image with equivalized intensity (1), an over-segmented label image (2) and annotations (3). When drawing annotations in a new labels layer, make sure to misguide the algorithm draw on edges of touching objects a 1 if those should be merged and a 2 if they should be kept. Make sure there are no 1/2 annotation circles on both: labels which should be merged and kept.

![img.png](https://github.com/haesleinhuepf/napari-accelerated-pixel-and-object-classification/raw/main/images/merge_objects2.png)

### Object classification

Click the menu `Tools > Segmentation post-processing > Object classification (APOC)`. 

![img.png](https://github.com/haesleinhuepf/napari-accelerated-pixel-and-object-classification/raw/main/images/menu.png)

This user interface will be shown:

![img.png](https://github.com/haesleinhuepf/napari-accelerated-pixel-and-object-classification/raw/main/images/object_classifier_gui.png)

1. The image layer will be used for intensity based feature extraction (see below).
2. The labels layer should be contain the segmentation of objects that should be classified. 
   You can use the Object Segmenter explained above to create this layer.
3. The annotation layer should contain manual annotations of object classes. 
   You can draw lines crossing single and multiple objects of the same kind. 
   For example draw a line through some elongated objects with label ""1"" and another line through some rather roundish objects with label ""2"".
   If these lines touch the background, that will be ignored.
4. Tree depth and number of trees allow you to fine-tune how to deal with manifold objects of different characteristics. The higher these numbers, the longer classification will take. In case you use many features, high depth and number of trees might be necessary. (See also `max_depth` and `n_estimators` in the [scikit-learn documentation of the Random Forest Classifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html).
5. Select the right features for training. For example, for differentiating objects according to their shape as suggested above, select ""shape"".
   The features are extracted using clEsperanto and are shown by example in [this notebook](https://github.com/clEsperanto/pyclesperanto_prototype/blob/master/demo/tissues/parametric_maps.ipynb).
6. Click on the `Run` button. If classification doesn't perform well in the first attempt, try changing selected features.  

If classification worked well, it may for example look like this. Note the two thick lines which were drawn to annotate elongated and roundish objects with brown and cyan:

![img.png](https://github.com/haesleinhuepf/napari-accelerated-pixel-and-object-classification/raw/main/images/object_classification_result.png)

A pre-trained model can later be applied [from scripts as shown in the example notebook](https://github.com/haesleinhuepf/apoc/blob/main/demo/cell_classification.ipynb) or using the menu `Tools > Segmentation post-processing > Object classification (apply pretrained, APOC)`.

### Object selection

Analogously to object classification, the object selector removes all objects from a label image that do not belong to a specified class.
It can be found in the menu `Tools > Segmentation post-processing > Object selection (APOC)`. 

![img.png](https://github.com/haesleinhuepf/napari-accelerated-pixel-and-object-classification/raw/main/images/select_objects.gif)


### Feature correlation matrix

When training object classifiers it is crucial to investigate to which degree features are correlated and select the right, ideally uncorrelated features to classify objects robustly.
After measuring features with any compatible napari plugin listed below, you can visualize the feature correlation matrix using the menu `Tools > Measurement tables > Show feature correlation matrix (pandas, APOC)` and by selecting the labels layer which has been analyzed.
Before computing the correlation matrix, all rows containing [NaN](https://en.wikipedia.org/wiki/NaN) values are removed.
For further details, please refer to the [documentation of the underlying function in pandas](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.corr.html).

![img.png](https://github.com/haesleinhuepf/napari-accelerated-pixel-and-object-classification/raw/main/images/feature_correlation_matrix.png)

### Surface Vertex Classification (SVeC)

When using napari-APOC in combination with [napari-process-points-and-surfaces>=0.3.3](https://github.com/haesleinhuepf/napari-process-points-and-surfaces), 
one can also classify vertices. Therefore, use for example the menu `Measurement > Surface quality table (vedo, nppas)` to determine quantitative measurements
and the menu `Surfaces > Annotate surface manually (nppas)` for manual annotations. It is recommended to annotate the entire surface with value 1 as background, and specific regions of interest with integer numbers > 1.
After measurements have been extracted and annotations were made, start SVeC from the `Surfaces > Surface vertex classification (custom properties, APOC)` menu. It can be used like the Object Classifier explained above.

![img.png](https://github.com/haesleinhuepf/napari-accelerated-pixel-and-object-classification/raw/main/images/demo_vertex_classification.gif)

[Download full video](https://github.com/haesleinhuepf/napari-accelerated-pixel-and-object-classification/raw/main/images/demo_vertex_classification.mp4)

### Classifier statistics
After classifier training, you can study the share of the individual features/measurements and how they are correlated by activating the checkboxes `Show classifier statistics` and `Show feature correlation matrix`.

![img.png](https://github.com/haesleinhuepf/napari-accelerated-pixel-and-object-classification/raw/main/images/correlation_matrix2.png)

This can help understanding how the classifier works. Furthermore, you can accelerate the classifier by reducing the number of correlated features.

### Object classification from custom measurements

You can also classify labeled objects according to custom measurements. For deriving those measurements, you can use these napari plugins:

* [morphometrics](https://www.napari-hub.org/plugins/morphometrics)
* [PartSeg](https://www.napari-hub.org/plugins/PartSeg)
* [napari-simpleitk-image-processing](https://www.napari-hub.org/plugins/napari-simpleitk-image-processing)
* [napari-cupy-image-processing](https://www.napari-hub.org/plugins/napari-cupy-image-processing)
* [napari-pyclesperanto-assistant](https://www.napari-hub.org/plugins/napari-pyclesperanto-assistant)
* [napari-skimage-regionprops](https://www.napari-hub.org/plugins/napari-skimage-regionprops)

Furthermore, if you use napari from Python, you can also create a dictionary or pandas DataFrame with measurements and store it in the `labels_layer.features` to make them available in the object classifier.

After labels have been measured, you can start the `Object Classifier (custom properties, APOC)` from the `Tools > Segmentation post-processing` menu:

![img.png](https://github.com/haesleinhuepf/napari-accelerated-pixel-and-object-classification/raw/main/images/table_row_classifier_gui.png)

1. Select the labels layers that has been measured.
2. The annotation layer should contain manual annotations of object classes. 
   You can draw lines crossing single and multiple objects of the same kind. 
   For example draw a line through some elongated objects with label ""1"" and another line through some rather roundish objects with label ""2"".
   If these lines touch the background, that will be ignored.
3. Select the measurements / features that should be used for object classification.
4. Use the `Update Measurements` button in case you did new measurements after Object classifier dialog was opened.
5. Enter the filename of the classifier to be trained here. This file will be overwritten in case it existed already.
6. Tree depth and number of trees allow you to fine-tune how to deal with manifold objects of different characteristics. The higher these numbers, the longer classification will take. In case you use many features, high depth and number of trees might be necessary. (See also `max_depth` and `n_estimators` in the [scikit-learn documentation of the Random Forest Classifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html).
7. The classification result will be stored under this name in the labels-layer's properties.
8. Choose if the results table should be shown. Choose if classifier statistics should be shown. [Read more about classifier statistics](https://haesleinhuepf.github.io/BioImageAnalysisNotebooks/27_cell_classification/forest_statistics.html).
9. Click on `Run` to start training and prediction.

You can also train those classifiers from Python and reuse them: [Read more about using the TableRowClassifier from python](https://haesleinhuepf.github.io/BioImageAnalysisNotebooks/27_cell_classification/apoc_simpleitk_object_classification.html)

### Classifier statistics and correlation matrix
After classifier training, you can study the share of the individual features/measurements and how they are correlated by activating the checkboxes `Show classifier statistics` and `Show correlation matrix`.
![img.png](https://github.com/haesleinhuepf/napari-accelerated-pixel-and-object-classification/raw/main/images/correlation_matrix.png)

This can help understanding how the classifier works. Furthermore, you can accelerate the classifier by reducing the number of correlated features.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.

## Installation

It is recommended to install the plugin in a conda environment. Therefore install conda first, e.g. [mini-conda](https://docs.conda.io/en/latest/miniconda.html).
If you never worked with conda before, reading this [short introduction](https://github.com/BiAPoL/Bio-image_Analysis_with_Python/blob/main/conda_basics/01_conda_environments.md) might be helpful.

Optional: Setup a fresh conda environment, activate it and install napari:

```
conda create --name napari_apoc python=3.9
conda activate napari_apoc
conda install napari
```

If your conda environment is set up, you can install `napari-accelerated-pixel-and-object-classification` using [pip]. Note: you need [pyopencl](https://documen.tician.de/pyopencl/) first.

```
conda install -c conda-forge pyopencl
pip install napari-accelerated-pixel-and-object-classification
```

Mac-users please also install this:

    conda install -c conda-forge ocl_icd_wrapper_apple
    
Linux users please also install this:
    
    conda install -c conda-forge ocl-icd-system


## Contributing
 
Contributions, feedback and suggestions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## Similar software
There are other napari plugins and other software with similar functionality for interactive classification of pixels and objects.

* [napari-feature-classifier](https://github.com/fractal-napari-plugins-collection/napari-feature-classifier)
* [napari-buds](https://www.napari-hub.org/plugins/napari-buds)
* [ilastik](https://www.ilastik.org/)
* [Fiji's Trainable Weka Segmentation](https://imagej.net/plugins/tws/)
* [scikit-learn](https://scikit-learn.org/stable/)

## License

Distributed under the terms of the [BSD-3] license,
""napari-accelerated-pixel-and-object-classification"" is free and open source software

## Issues

If you encounter any problems, please [open a thread on image.sc](https://image.sc) along with a detailed description and tag [@haesleinhuepf](https://github.com/haesleinhuepf).

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/haesleinhuepf/napari-accelerated-pixel-and-object-classification/issues
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 3 - Alpha', 'Intended Audience :: Science/Research', 'Framework :: napari', 'Topic :: Scientific/Engineering :: Image Processing', 'Topic :: Scientific/Engineering :: Information Analysis', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/haesleinhuepf/napari-accelerated-pixel-and-object-classification/issues', 'Documentation, https://github.com/haesleinhuepf/napari-accelerated-pixel-and-object-classification', 'Source Code, https://github.com/haesleinhuepf/napari-accelerated-pixel-and-object-classification', 'User Support, https://forum.image.sc/tag/clij']",,,napari-accelerated-pixel-and-object-classification.ObjectSegmentation,,,,,https://pypi.org/project/napari-accelerated-pixel-and-object-classification,https://github.com/haesleinhuepf/napari-accelerated-pixel-and-object-classification,
59,napari Affinities,0.1.3,2022-11-30,2023-06-18,napari-affinities,William Patton,will.hunter.patton@gmail.com,MIT,https://github.com/pattonw/napari-affinities,"A plugin for creating, visualizing, and processing affinities",>=3.7,"['numpy', 'zarr', 'magicgui', 'bioimageio.core', 'gunpowder', 'matplotlib', 'torch', 'lsds']","# napari-affinities

[![License](https://img.shields.io/pypi/l/napari-affinities.svg?color=green)](https://github.com/pattonw/napari-affinities/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-affinities.svg?color=green)](https://pypi.org/project/napari-affinities)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-affinities.svg?color=green)](https://python.org)
[![tests](https://github.com/pattonw/napari-affinities/workflows/tests/badge.svg)](https://github.com/pattonw/napari-affinities/actions)
[![codecov](https://codecov.io/gh/pattonw/napari-affinities/branch/main/graph/badge.svg)](https://codecov.io/gh/pattonw/napari-affinities)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-affinities)](https://napari-hub.org/plugins/napari-affinities)

A plugin for creating, visualizing, and processing affinities

---

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/stable/index.html
-->

## Installation

You will need a conda environment for everything to run
smoothly. Supported python versions are 3.7, 3.8, 3.9.

### pip
You can install `napari-affinities` via [pip]:

    `pip install napari-affinities`

To install latest development version :

    `pip install git+https://github.com/pattonw/napari-affinities.git`

Install torch according to your system [(follow the instructions here)](https://pytorch.org/get-started/locally/). For example with cuda 10.2 available, run:

    conda install pytorch torchvision cudatoolkit=10.2 -c pytorch

Install conda requirements:

    conda install -c conda-forge affogato

### conda

If you install via conda, there are fewer steps since
affogato and pytorch will be installed for you.

You can install `napari-affinities` via [conda]:

    `conda install -c conda-forge napari-affinities`

### Download example model:

#### 2D:

[epithelial example model](https://oc.embl.de/index.php/s/zfWMKu7HoQnSJLs)
Place the model zip file wherever you want. You can open it in the plugin with the ""load from file"" button.

#### 3D

[lightsheet example model](https://owncloud.gwdg.de/index.php/s/LsShICsOcilqPRs)
Unpack the tar file into test data (`lightsheet_nuclei_test_data` (an hdf5 file)) and model (`LightsheetNucleusSegmentation.zip` (a bioimageio model)).
Move the data into sample_data which will enable you to load the ""Lightsheet Sample"" data in napari.
Place the model zip file anywhere you want. You can open it in the plugin with the ""load from file"" button.

##### Workarounds to be fixed:

1. you need to update the `rdf.yaml` in the `LightsheetNucleusSegmentation.zip` with the following:
   - ""shape"" for ""input0"" should be updated with a larger minimum input size and ""output0"" should be updated with a larger halo. If not fixed, there will be significant tiling artifacts.
   - (Optional) ""output0"" should be renamed to affinities. The plugin supports multiple outputs and relies on names for figuring out which one is which. If unrecognized names are provided we assume the outputs are ordered (affinities, fgbg, lsds) but this is less reliable than explicit names.
2. This model also generates foreground in the same array as affinities, i.e. a 10 channel output `(fgbg, [-1, 0, 0], [0, -1, 0], [0, 0, -1], [-2, 0, 0], ...)`. Although predictions will work, post processing such as mutex watershed will break unless you manually separate the first channel.

## Use

Requirements for the model:

1. Bioimageio packaged pytorch model
2. Outputs with names ""affinities"", ""fgbg""(optional) or ""lsds""(optional)
   - if these names are not used, it will be assumed that the outputs are affinities, fgbg, then lsds in that order

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [MIT] license,
""napari-affinities"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[mit]: http://opensource.org/licenses/MIT
[bsd-3]: http://opensource.org/licenses/BSD-3-Clause
[gnu gpl v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[gnu lgpl v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[apache software license 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[mozilla public license 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/pattonw/napari-affinities/issues
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[pypi]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: MIT License']","['Bug Tracker, https://github.com/pattonw/napari-affinities/issues', 'Documentation, https://github.com/pattonw/napari-affinities#README.md', 'Source Code, https://github.com/pattonw/napari-affinities', 'User Support, https://github.com/pattonw/napari-affinities/issues']",,,napari-affinities.make_mutex_watershed_widget,napari-affinities.sample_epithelial,,,,https://pypi.org/project/napari-affinities,https://github.com/pattonw/napari-affinities,
60,napari-aicsimageio,0.7.2,2022-02-04,2023-08-04,napari-aicsimageio,"Eva Maxfield Brown, Talley Lambert","Eva Maxfield Brown <evamaxfieldbrown@gmail.com>, Talley Lambert <talley.lambert@gmail.com>",GPLv3,https://pypi.org/project/napari-aicsimageio/,AICSImageIO bindings for napari,>=3.8,"['aicsimageio[all] (>=4.6.3)', 'fsspec[http] (>=2022.7.1)', 'napari (>=0.4.11)', 'psutil (>=5.7.0)', 'aicspylibczi (>=3.0.5)', 'bioformats-jar', 'readlif (>=0.6.4)', ""black (>=19.10b0) ; extra == 'dev'"", ""coverage (>=5.1) ; extra == 'dev'"", ""docutils (<0.16,>=0.10) ; extra == 'dev'"", ""flake8-debugger (>=3.2.1) ; extra == 'dev'"", ""flake8-pyprojecttoml ; extra == 'dev'"", ""flake8 (>=3.8.3) ; extra == 'dev'"", ""ipython (>=7.15.0) ; extra == 'dev'"", ""isort (>=5.7.0) ; extra == 'dev'"", ""mypy (>=0.800) ; extra == 'dev'"", ""pytest-runner (>=5.2) ; extra == 'dev'"", ""twine (>=3.1.1) ; extra == 'dev'"", ""wheel (>=0.34.2) ; extra == 'dev'"", ""PyQt5 ; extra == 'test'"", ""pytest (>=5.4.3) ; extra == 'test'"", ""pytest-qt (~=4.0) ; extra == 'test'"", ""pytest-cov (>=2.9.0) ; extra == 'test'"", ""pytest-raises (>=0.11) ; extra == 'test'"", ""pytest-xvfb (~=2.0) ; extra == 'test'"", ""quilt3 (~=3.4.0) ; extra == 'test'""]","# napari-aicsimageio

[![License](https://img.shields.io/pypi/l/napari-aicsimageio.svg?color=green)](https://github.com/AllenCellModeling/napari-aicsimageio/raw/main/LICENSE)
[![Build Status](https://github.com/AllenCellModeling/napari-aicsimageio/workflows/Build%20Main/badge.svg)](https://github.com/AllenCellModeling/napari-aicsimageio/actions)
[![Code Coverage](https://codecov.io/gh/AllenCellModeling/napari-aicsimageio/branch/main/graph/badge.svg)](https://codecov.io/gh/AllenCellModeling/napari-aicsimageio)

AICSImageIO bindings for napari

---

## Features

-   Supports reading metadata and imaging data for:
    -   `OME-TIFF`
    -   `TIFF`
    -   `CZI` (Zeiss)
    -   `LIF` (Leica)
    -   `ND2` (Nikon)
    -   `DV` (DeltaVision)
    -   Any formats supported by [aicsimageio](https://github.com/AllenCellModeling/aicsimageio)
    -   Any formats supported by [bioformats](https://github.com/tlambert03/bioformats_jar)
        -   `SLD` (Slidebook)
        -   `SVS` (Aperio)
        -   [Full List](https://docs.openmicroscopy.org/bio-formats/6.5.1/supported-formats.html)
    -   Any additional format supported by [imageio](https://github.com/imageio/imageio)
        -   `PNG`
        -   `JPG`
        -   `GIF`
        -   `AVI`
        -   [Full List](https://imageio.readthedocs.io/en/v2.4.1/formats.html)

_While upstream `aicsimageio` is released under BSD-3 license, this plugin is released under GPLv3 license because it installs all format reader dependencies._

## Installation

**Stable Release:** `pip install napari-aicsimageio` or `conda install napari-aicsimageio -c conda-forge`<br>
**Development Head:** `pip install git+https://github.com/AllenCellModeling/napari-aicsimageio.git`

### Reading Mode Threshold

This image reading plugin will load the provided image directly into memory if it meets
the following two conditions:

1. The filesize is less than 4GB.
2. The filesize is less than 30% of machine memory available.

If either of these conditions isn't met, the image is loaded in chunks only as needed.

### Use napari-aicsimageio as the Reader for All File Formats

If you want to force napari to always use this plugin as the reader for all file formats,
try running this snippet:

```python
from napari.settings import get_settings

get_settings().plugins.extension2reader = {'*': 'napari-aicsimageio', **get_settings().plugins.extension2reader}
```

For more details, see [#37](https://github.com/AllenCellModeling/napari-aicsimageio/issues/37).

## Examples of Features

#### General Image Reading

All image file formats supported by
[aicsimageio](https://github.com/AllenCellModeling/aicsimageio) will be read and all
raw data will be available in the napari viewer.

In addition, when reading an OME-TIFF, you can view all OME metadata directly in the
napari viewer thanks to `ome-types`.

![screenshot of an OME-TIFF image view, multi-channel, z-stack, with metadata viewer](https://raw.githubusercontent.com/AllenCellModeling/napari-aicsimageio/main/images/ome-tiff-with-metadata-viewer.png)

#### Multi-Scene Selection

When reading a multi-scene file, a widget will be added to the napari viewer to manage
scene selection (clearing the viewer each time you change scene or adding the
scene content to the viewer) and a list of all scenes in the file.

![gif of drag and drop file to scene selection and management](https://raw.githubusercontent.com/AllenCellModeling/napari-aicsimageio/main/images/scene-selection.gif)

#### Access to the AICSImage Object and Metadata

![napari viewer with console open showing `viewer.layers[0].metadata`](https://raw.githubusercontent.com/AllenCellModeling/napari-aicsimageio/main/images/console-access.png)

You can access the `AICSImage` object used to load the image pixel data and
image metadata using the built-in napari console:

```python
img = viewer.layers[0].metadata[""aicsimage""]
img.dims.order  # TCZYX
img.channel_names  # [""Bright"", ""Struct"", ""Nuc"", ""Memb""]
img.get_image_dask_data(""ZYX"")  # dask.array.Array
```

The napari layer metadata dictionary also stores a shorthand
for the raw image metadata:

```python
viewer.layers[0].metadata[""raw_image_metadata""]
```

The metadata is returned in whichever format is used by the underlying
file format reader, i.e. for CZI the raw metadata is returned as
an `xml.etree.ElementTree.Element`, for OME-TIFF the raw metadata is returned
as an `OME` object from `ome-types`.

Lastly, if the underlying file format reader has an OME metadata conversion function,
you may additionally see a key in the napari layer metadata dictionary
called `""ome_types""`. For example, because the AICSImageIO
`CZIReader` and `BioformatsReader` both support converting raw image metadata
to OME metadata, you will see an `""ome_types""` key that stores the metadata transformed
into the OME metadata model.

```python
viewer.layers[0].metadata[""ome_types""]  # OME object from ome-types
```

#### Mosaic Reading

When reading CZI or LIF images, if the image is a mosaic tiled image, `napari-aicsimageio`
will return the reconstructed image:

![screenshot of a reconstructed / restitched mosaic tile LIF](https://raw.githubusercontent.com/AllenCellModeling/napari-aicsimageio/main/images/tiled-lif.png)

## Development

See [CONTRIBUTING.md](CONTRIBUTING.md) for information related to developing the code.

For additional file format support, contributed directly to
[AICSImageIO](https://github.com/AllenCellModeling/aicsimageio).
New file format support will become directly available in this
plugin on new `aicsimageio` releases.

## Citation

If you find `aicsimageio` _(or `napari-aicsimageio`)_ useful, please cite as:

> AICSImageIO Contributors (2021). AICSImageIO: Image Reading, Metadata Conversion, and Image Writing for Microscopy Images in Pure Python [Computer software]. GitHub. https://github.com/AllenCellModeling/aicsimageio

_Free software: GPLv3_
","['Development Status :: 5 - Production/Stable', 'Intended Audience :: Science/Research', 'Framework :: napari', 'License :: OSI Approved :: GNU General Public License v3 (GPLv3)', 'Operating System :: OS Independent', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Bio-Informatics', 'Topic :: Scientific/Engineering :: Image Processing', 'Topic :: Scientific/Engineering :: Information Analysis', 'Topic :: Scientific/Engineering :: Visualization', 'Topic :: Scientific/Engineering']","['Homepage, https://github.com/AllenCellModeling/napari-aicsimageio', 'Bug Tracker, https://github.com/AllenCellModeling/napari-aicsimageio/issues', 'Documentation, https://github.com/AllenCellModeling/napari-aicsimageio#README.md', 'User Support, https://github.com/AllenCellModeling/napari-aicsimageio/issues']",napari-aicsimageio.get_reader,,,,"['*.1sc', '*.2fl', '*.3fr', '*.acff', '*.acqp', '*.afi', '*.afm', '*.aim', '*.al3d', '*.ali', '*.am', '*.amiramesh', '*.ano', '*.apl', '*.arf', '*.array-like', '*.arw', '*.avi', '*.bay', '*.bif', '*.bin', '*.bip', '*.bmp', '*.bmq', '*.bsdf', '*.bufr', '*.bw', '*.c01', '*.cap', '*.cat', '*.cfg', '*.ch5', '*.cif', '*.cine', '*.cr2', '*.crw', '*.cs1', '*.csv', '*.ct', '*.ct.img', '*.cur', '*.cut', '*.cxd', '*.czi', '*.dat', '*.db', '*.dc2', '*.dcm', '*.dcr', '*.dcx', '*.dds', '*.df3', '*.dicom', '*.dm2', '*.dm3', '*.dng', '*.drf', '*.dsc', '*.dti', '*.dv', '*.ecw', '*.emf', '*.eps', '*.epsi', '*.erf', '*.exp', '*.exr', '*.fake', '*.fdf', '*.fff', '*.ffr', '*.fid', '*.fit', '*.fits', '*.flc', '*.flex', '*.fli', '*.fpx', '*.frm', '*.ftc', '*.fts', '*.ftu', '*.fz', '*.g3', '*.gbr', '*.gdcm', '*.gel', '*.gif', '*.gipl', '*.grey', '*.grib', '*.h5', '*.hdf', '*.hdf5', '*.hdp', '*.hdr', '*.hed', '*.his', '*.htd', '*.htm', '*.html', '*.hx', '*.i2i', '*.ia', '*.icns', '*.ico', '*.ics', '*.ids', '*.iff', '*.iim', '*.iiq', '*.im', '*.im3', '*.img', '*.imggz', '*.ims', '*.inf', '*.inr', '*.ipl', '*.ipm', '*.ipw', '*.j2c', '*.j2k', '*.jfif', '*.jif', '*.jng', '*.jp2', '*.jpc', '*.jpe', '*.jpeg', '*.jpf', '*.jpg', '*.jpk', '*.jpx', '*.jxr', '*.k25', '*.kc2', '*.kdc', '*.klb', '*.koa', '*.l2d', '*.labels', '*.lbm', '*.lei', '*.lfp', '*.lfr', '*.lif', '*.liff', '*.lim', '*.lms', '*.lsm', '*.mdb', '*.mdc', '*.mef', '*.mgh', '*.mha', '*.mhd', '*.mic', '*.mkv', '*.mnc', '*.mnc2', '*.mng', '*.mod', '*.mos', '*.mov', '*.mp4', '*.mpeg', '*.mpg', '*.mpo', '*.mrc', '*.mri', '*.mrw', '*.msp', '*.msr', '*.mtb', '*.mvd2', '*.naf', '*.nd', '*.nd2', '*.ndpi', '*.ndpis', '*.nef', '*.nhdr', '*.nia', '*.nii', '*.nii.gz', '*.niigz', '*.npz', '*.nrrd', '*.nrw', '*.obf', '*.oib', '*.oif', '*.oir', '*.ome', '*.ome.tif', '*.ome.tiff', '*.orf', '*.par', '*.pbm', '*.pcd', '*.pcoraw', '*.pct', '*.pcx', '*.pef', '*.pfm', '*.pgm', '*.pic', '*.pict', '*.png', '*.pnl', '*.ppm', '*.pr3', '*.ps', '*.psd', '*.ptx', '*.pxn', '*.pxr', '*.qptiff', '*.qtk', '*.r3d', '*.raf', '*.ras', '*.raw', '*.rcpnl', '*.rdc', '*.rec', '*.rgb', '*.rgba', '*.rw2', '*.rwl', '*.rwz', '*.scan', '*.scn', '*.sdt', '*.seq', '*.sif', '*.sld', '*.sm2', '*.sm3', '*.spc', '*.spe', '*.spi', '*.sr2', '*.srf', '*.srw', '*.st', '*.sti', '*.stk', '*.stp', '*.svs', '*.swf', '*.sxm', '*.targa', '*.tfr', '*.tga', '*.thm', '*.tif', '*.tiff', '*.tim', '*.tnb', '*.top', '*.txt', '*.v', '*.vff', '*.vms', '*.vsi', '*.vtk', '*.vws', '*.wap', '*.wat', '*.wav', '*.wbm', '*.wbmp', '*.wdp', '*.webp', '*.wlz', '*.wmf', '*.wmv', '*.wpi', '*.xbm', '*.xdce', '*.xml', '*.xpm', '*.xqd', '*.xqf', '*.xv', '*.xys', '*.zfp', '*.zfr', '*.zip', '*.zpo', '*.zvi']",,,https://pypi.org/project/napari-aicsimageio/,,
61,napari AIDeveloper,0.0.4,2023-11-18,2023-11-18,napari-aideveloper,Chenqi Zhang,cqzhang@g.ecc.u-tokyo.ac.jp,BSD-3-Clause,https://pypi.org/project/napari-aideveloper,"napari_aideveloper is a napari-plugin deived from AIDeveloper that allows you to train, evaluate and apply deep neural nets for image classification within a graphical user-interface (GUI).",>=3.8,"['numpy', 'magicgui', 'qtpy', 'dclab (>=0.39.9)', 'h5py (>=3.6.0)', 'Keras-Applications (>=1.0.8)', 'keras (>=2.8.0)', 'keras-metrics (>=1.1.0)', 'napari-plugin-engine (>=0.2.0)', 'napari (>=0.4.14)', 'onnx (>=1.11.0)', 'opencv-contrib-python-headless (>=4.5.5.62)', 'openpyxl (>=3.0.9)', 'pandas (>=1.4.1)', 'Pillow (>=9.1.1)', 'psutil (>=5.9.0)', 'pyqtgraph (>=0.12.3)', 'pytest (>=7.1.2)', 'scikit-learn (>=1.1.1)', 'scipy (>=1.8.0)', 'setuptools (>=58.0.4)', 'six (>=1.16.0)', 'tensorboard (>=2.8.0)', 'tensorflow (>=2.8.0)', 'tf2onnx (>=1.9.3)', 'xlrd (>=2.0.1)', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-aideveloper

[![License](https://img.shields.io/pypi/l/napari-aideveloper.svg?color=green)](https://github.com/zcqwh/napari-aideveloper/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-aideveloper.svg?color=green)](https://pypi.org/project/napari-aideveloper)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-aideveloper.svg?color=green)](https://python.org)
[![tests](https://github.com/zcqwh/napari-aideveloper/workflows/tests/badge.svg)](https://github.com/zcqwh/napari-aideveloper/actions)
[![codecov](https://codecov.io/gh/zcqwh/napari-aideveloper/branch/main/graph/badge.svg)](https://codecov.io/gh/zcqwh/napari-aideveloper)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-aideveloper)](https://napari-hub.org/plugins/napari-aideveloper)

[napari_aideveloper](https://www.napari-hub.org/plugins/napari-aideveloper) is a napari-plugin derived from [AIDeveloper](https://github.com/maikherbig/AIDeveloper) that allows you to train, evaluate, and apply deep neural nets for image classification within a graphical user-interface (GUI).


<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/index.html
-->

## Installation

You can install `napari-aideveloper` via [pip]:

    pip install napari-aideveloper

## Introduction
### Main functions
* [Build](#build)
* [History](#history)

****

### Build 
#### 1. Load data
Drag and drop your data in .rtdc (HDF5) format into the file table and set the class and training/validation.
![alt Load_data](https://github.com/zcqwh/napari-aideveloper/blob/main/Tutorial/00_Load_data.gif?raw=true)

#### 2. Choose Neural Networks
![alt Load_data](https://github.com/zcqwh/napari-aideveloper/blob/main/Tutorial/01_choose%20NN.gif?raw=true)

#### 3. Set model storage path
![alt Load_data](https://github.com/zcqwh/napari-aideveloper/blob/main/Tutorial/02_save_model.gif?raw=true)

#### 4. Start fitting
![alt Load_data](https://github.com/zcqwh/napari-aideveloper/blob/main/Tutorial/03_start_fitting.gif?raw=true)
![alt Load_data](https://github.com/zcqwh/napari-aideveloper/blob/main/Tutorial/04_fitting.gif?raw=true)

#### Preview image
![alt Load_data](https://github.com/zcqwh/napari-aideveloper/blob/main/Tutorial/05_preview.gif?raw=true)

#### Image augmentation
![alt Load_data](https://github.com/zcqwh/napari-aideveloper/blob/main/Tutorial/06_augmentation.gif?raw=true)

****

### History
#### 1. Load meta data
![alt Load_data](https://github.com/zcqwh/napari-aideveloper/blob/development/Tutorial/GIF/History/01_Load_metadata.gif?raw=true)

#### 2. Check model details
![alt Load_data](https://github.com/zcqwh/napari-aideveloper/blob/development/Tutorial/GIF/History/02_model_detail.gif?raw=true)

#### 3. Rolling median & Linear fit
![alt Load_data](https://github.com/zcqwh/napari-aideveloper/blob/development/Tutorial/GIF/History/03_rolling_linear.gif?raw=true)






## Contributing

Contributions are very welcome. You can submit your pull request on [GitHub](https://github.com/zcqwh/napari-aideveloper/pulls). Tests can be run with [tox], please ensure the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-aideveloper"" is free and open source software

## Issues

If you encounter any problems, please [file an issue](https://github.com/zcqwh/napari-aideveloper/issues) along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/


----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.
","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/zcqwh/napari-aideveloper/issues', 'Documentation, https://github.com/zcqwh/napari-aideveloper#README.md', 'Source Code, https://github.com/zcqwh/napari-aideveloper', 'User Support, https://github.com/zcqwh/napari-aideveloper/issues']",,,napari-aideveloper.make_qwidget,,,,,https://pypi.org/project/napari-aideveloper,,
62,napari-allencell-annotator,1.0.7,2022-08-19,2023-06-18,napari-allencell-annotator,Allen Institute for Cell Science,,UNKNOWN,https://github.com/aics-int/napari-allencell-annotator/,A plugin that enables annotations provided by Allen Institute for Cell Science,>=3.9,"['napari (>=0.4.9)', 'napari-plugin-engine (>=0.1.4)', 'numpy', 'aicsimageio (>=4.9.1)', 'xarray (>=2022.6.0)', 'magicgui (>=0.3.7)', 'aicspylibczi (>=3.0.5)', 'fsspec (>=2022.8.2)', 'bioformats-jar', 'bfio', 'qtpy', ""napari (>=0.4.9) ; extra == 'all'"", ""napari-plugin-engine (>=0.1.4) ; extra == 'all'"", ""numpy ; extra == 'all'"", ""aicsimageio (>=4.9.1) ; extra == 'all'"", ""xarray (>=2022.6.0) ; extra == 'all'"", ""magicgui (>=0.3.7) ; extra == 'all'"", ""aicspylibczi (>=3.0.5) ; extra == 'all'"", ""fsspec (>=2022.8.2) ; extra == 'all'"", ""bioformats-jar ; extra == 'all'"", ""bfio ; extra == 'all'"", ""qtpy ; extra == 'all'"", ""black (>=19.10b0) ; extra == 'all'"", ""codecov (>=2.0.22) ; extra == 'all'"", ""docutils (<0.16,>=0.10) ; extra == 'all'"", ""flake8 (>=3.7.7) ; extra == 'all'"", ""psutil (>=5.7.0) ; extra == 'all'"", ""pytest (>=4.3.0) ; extra == 'all'"", ""pytest-cov (==2.6.1) ; extra == 'all'"", ""pytest-raises (>=0.10) ; extra == 'all'"", ""pytest-qt (>=3.3.0) ; extra == 'all'"", ""quilt3 (>=3.1.12) ; extra == 'all'"", ""pytest-runner ; extra == 'all'"", ""bumpversion (>=0.5.3) ; extra == 'all'"", ""gitchangelog (>=3.0.4) ; extra == 'all'"", ""ipython (>=7.5.0) ; extra == 'all'"", ""m2r (>=0.2.1) ; extra == 'all'"", ""pytest-runner (>=4.4) ; extra == 'all'"", ""Sphinx (<3,>=2.0.0b1) ; extra == 'all'"", ""sphinx-rtd-theme (>=0.1.2) ; extra == 'all'"", ""tox (>=3.5.2) ; extra == 'all'"", ""twine (>=1.13.0) ; extra == 'all'"", ""wheel (>=0.33.1) ; extra == 'all'"", ""black (>=19.10b0) ; extra == 'dev'"", ""bumpversion (>=0.5.3) ; extra == 'dev'"", ""docutils (<0.16,>=0.10) ; extra == 'dev'"", ""flake8 (>=3.7.7) ; extra == 'dev'"", ""gitchangelog (>=3.0.4) ; extra == 'dev'"", ""ipython (>=7.5.0) ; extra == 'dev'"", ""m2r (>=0.2.1) ; extra == 'dev'"", ""pytest (>=4.3.0) ; extra == 'dev'"", ""pytest-cov (==2.6.1) ; extra == 'dev'"", ""pytest-raises (>=0.10) ; extra == 'dev'"", ""pytest-runner (>=4.4) ; extra == 'dev'"", ""pytest-qt (>=3.3.0) ; extra == 'dev'"", ""quilt3 (>=3.1.12) ; extra == 'dev'"", ""Sphinx (<3,>=2.0.0b1) ; extra == 'dev'"", ""sphinx-rtd-theme (>=0.1.2) ; extra == 'dev'"", ""tox (>=3.5.2) ; extra == 'dev'"", ""twine (>=1.13.0) ; extra == 'dev'"", ""wheel (>=0.33.1) ; extra == 'dev'"", ""pytest-runner ; extra == 'setup'"", ""black (>=19.10b0) ; extra == 'test'"", ""codecov (>=2.0.22) ; extra == 'test'"", ""docutils (<0.16,>=0.10) ; extra == 'test'"", ""flake8 (>=3.7.7) ; extra == 'test'"", ""psutil (>=5.7.0) ; extra == 'test'"", ""pytest (>=4.3.0) ; extra == 'test'"", ""pytest-cov (==2.6.1) ; extra == 'test'"", ""pytest-raises (>=0.10) ; extra == 'test'"", ""pytest-qt (>=3.3.0) ; extra == 'test'"", ""quilt3 (>=3.1.12) ; extra == 'test'""]","# napari-allencell-annotator

[![License BSD-3](https://img.shields.io/pypi/l/napari-allencell-annotator.svg?color=green)](https://github.com/bbridge0200/napari-allencell-annotator/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-allencell-annotator.svg?color=green)](https://pypi.org/project/napari-allencell-annotator)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-allencell-annotator.svg?color=green)](https://python.org)
[![tests](https://github.com/bbridge0200/napari-allencell-annotator/workflows/tests/badge.svg)](https://github.com/bbridge0200/napari-allencell-annotator/actions)
[![codecov](https://codecov.io/gh/bbridge0200/napari-allencell-annotator/branch/main/graph/badge.svg)](https://codecov.io/gh/bbridge0200/napari-allencell-annotator)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-allencell-annotator)](https://napari-hub.org/plugins/napari-allencell-annotator)

A plugin that enables image annotation/scoring and writes annotations to a .csv file. 
Plugin provided by the Allen Institute for Cell Science.

The Allen Cell Image Annotator plugin for napari provides an intuitive
graphical user interface to create annotation templates, annotate large 
image sets using these templates, and save image annotations to a csv file. 
The Allen Cell Image Annotator is a Python-based open source toolkit 
developed at the Allen Institute for Cell Science for both blind, unbiased and un-blind 
microscope image annotating. This toolkit supports easy image set selection
from a file finder and creation of annotation templates (text, checkbox, drop-down, and spinbox).
With napari's multi-dimensional image viewing capabilities, the plugin seamlessly allows users to
view each image and write annotations into the custom template.
Annotation templates can be written to a json file for sharing or re-using. After annotating,
the annotation template, image file list, and the annotation values 
are conveniently saved to csv file, which can be re-opened for further annotating. 

-   Supports the following image types:
    - `OME-TIFF`
    - `TIFF`
    - `CZI` 
    - `PNG` 
    -   `JPEG` 


----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to files up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/index.html
-->

## Installation
### 1. Prerequisites

The plugin requires [Conda](https://docs.anaconda.com/anaconda/install/).
- [Installing on Windows ](https://docs.anaconda.com/anaconda/install/windows/) 
  - Follow the steps linked above except
  - On step 8, check top the box to add to PATH
  - ![Alt text](napari_allencell_annotator/assets/windowsstep8.png)
- [Installing on Mac ](https://docs.anaconda.com/anaconda/install/mac-os/) 

### 2. Install the plugin
Click the link corresponding to your OS.
#### [Windows](https://alleninstitute-my.sharepoint.com/:u:/g/personal/beatrice_bridge_alleninstitute_org/EVOKZ8-PZB5AvO6z6OAjZ_YB2EHbaU9XRc_Z281oM0ctOg?e=skbKzh)
- From the link above, click the three dots on the top menu bar and select download. 
- Open a file explorer and go to the Downloads folder. Use **Option 1** below. A prompt window should open and start installing. If this fails use **Option 2**. 
  - **Option 1**: Double-click the file _install_napari.sh_
  - **Option 2**: Search the file finder for Anaconda Prompt. Open version 3. Run the following commands one line at a time. 
    - conda create -n napari_annotator python=3.9 anaconda
    - conda activate napari_annotator
    - python -m pip install --upgrade pip
    - python -m pip install ""napari[all]""
    - python -m pip install napari-allencell-annotator
    - napari
  - **Still not working?** Try using conda forge instead of pip. 
    - Ex: conda install -c conda-forge napari instead of python -m pip install ""napari[all]""
#### [MacOS/Unix](https://alleninstitute-my.sharepoint.com/:u:/g/personal/beatrice_bridge_alleninstitute_org/EaeV_RPXZz9DijxYy7qfoeMB3Hbq4vMpmJERqDyhL97KAg?e=HuKY2k)
- From the link above, download the file. 
- Open terminal. 
- Run _chmod +x ./Downloads/install_napari.command_ 
  - If you get a file not found error try adjusting the path to match where install_napari.command was downloaded.
- Open finder, navigate to the file, double-click _install_napari.command_ . 
  - A terminal window should open and start installing. 
  

### 3. Launch the Plugin

Once the napari window opens, go to **Plugins**.
- If **napari-allencell-annotator: Annotator** is listed click it to launch. 
- If it is not listed 
- **Install/Uninstall Plugins** ⇨ check the box next to **napari-allencell-annotator** ⇨ **close** ⇨ **Plugins** ⇨ **napari-allencell-annotator: Annotator** .

### 4. Re-opening the Plugin After Installing
- Windows
  - Search for anaconda navigator in file finder
  - Click on navigator version 3
  - Once the navigator opens, click **Environments** on the left side
  - Click on the annotator environment and wait for it to load
  - Press the play button
  - Type _napari_ in the prompt that opens
  - Click **Plugins** ⇨ **napari-allencell-annotator: Annotator**
- MacOS
  - Open terminal
  - Run these commands one line at a time
    - conda activate napari_annotator
    - napari
  - Click **Plugins** ⇨ **napari-allencell-annotator: Annotator**

## Quick Start

1. Open napari
2. Start the plugin 
   - Open napari, go to ""Plugins"" ⇨ ""napari-allencell-annotator"".
3. Create or import annotations and add images to annotate.

For more detailed usage instructions, check out this [document](napari_allencell_annotator/assets/AnnotatorInstructions.pdf) 
## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-allencell-annotator"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/bbridge0200/napari-allencell-annotator/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/


","['Intended Audience :: Science/Research', 'Framework :: napari', 'Topic :: Scientific/Engineering', 'Topic :: Scientific/Engineering :: Visualization', 'Topic :: Scientific/Engineering :: Information Analysis', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']",,,,napari-allencell-annotator.MainController,,,,,https://pypi.org/project/napari-allencell-annotator,https://github.com/aics-int/napari-allencell-annotator/,
63,napari-allencell-segmenter,2.1.12,2022-02-13,2023-07-31,napari-allencell-segmenter,Allen Institute for Cell Science,,BSD-3,https://github.com/AllenCell/napari-allencell-segmenter,A plugin that enables 3D image segmentation provided by Allen Institute for Cell Science,>=3.7,"['napari (>=0.4.9)', 'napari-plugin-engine (>=0.1.4)', 'numpy', 'aicssegmentation (>=0.5.3)', 'magicgui (>=0.2.9)', 'aicsimageio (~=4.0.5)', 'opencv-python-headless (>=4.5.1)', 'importlib-metadata (==4.11.4)', 'npe2', ""napari (>=0.4.9) ; extra == 'all'"", ""napari-plugin-engine (>=0.1.4) ; extra == 'all'"", ""numpy ; extra == 'all'"", ""aicssegmentation (>=0.5.3) ; extra == 'all'"", ""magicgui (>=0.2.9) ; extra == 'all'"", ""aicsimageio (~=4.0.5) ; extra == 'all'"", ""opencv-python-headless (>=4.5.1) ; extra == 'all'"", ""importlib-metadata (==4.11.4) ; extra == 'all'"", ""npe2 ; extra == 'all'"", ""black (>=19.10b0) ; extra == 'all'"", ""codecov (>=2.0.22) ; extra == 'all'"", ""docutils (<0.16,>=0.10) ; extra == 'all'"", ""flake8 (>=3.7.7) ; extra == 'all'"", ""psutil (>=5.7.0) ; extra == 'all'"", ""pytest (>=4.3.0) ; extra == 'all'"", ""pytest-cov (==2.6.1) ; extra == 'all'"", ""pytest-raises (>=0.10) ; extra == 'all'"", ""pytest-qt (>=3.3.0) ; extra == 'all'"", ""quilt3 (>=3.1.12) ; extra == 'all'"", ""pytest-runner ; extra == 'all'"", ""bumpversion (>=0.5.3) ; extra == 'all'"", ""coverage (>=5.0a4) ; extra == 'all'"", ""gitchangelog (>=3.0.4) ; extra == 'all'"", ""ipython (>=7.5.0) ; extra == 'all'"", ""m2r (>=0.2.1) ; extra == 'all'"", ""pytest-runner (>=4.4) ; extra == 'all'"", ""Sphinx (<3,>=2.0.0b1) ; extra == 'all'"", ""sphinx-rtd-theme (>=0.1.2) ; extra == 'all'"", ""tox (==3.25.0) ; extra == 'all'"", ""twine (>=1.13.0) ; extra == 'all'"", ""wheel (>=0.33.1) ; extra == 'all'"", ""black (>=19.10b0) ; extra == 'dev'"", ""bumpversion (>=0.5.3) ; extra == 'dev'"", ""coverage (>=5.0a4) ; extra == 'dev'"", ""docutils (<0.16,>=0.10) ; extra == 'dev'"", ""flake8 (>=3.7.7) ; extra == 'dev'"", ""gitchangelog (>=3.0.4) ; extra == 'dev'"", ""ipython (>=7.5.0) ; extra == 'dev'"", ""m2r (>=0.2.1) ; extra == 'dev'"", ""pytest (>=4.3.0) ; extra == 'dev'"", ""pytest-cov (==2.6.1) ; extra == 'dev'"", ""pytest-raises (>=0.10) ; extra == 'dev'"", ""pytest-runner (>=4.4) ; extra == 'dev'"", ""pytest-qt (>=3.3.0) ; extra == 'dev'"", ""quilt3 (>=3.1.12) ; extra == 'dev'"", ""Sphinx (<3,>=2.0.0b1) ; extra == 'dev'"", ""sphinx-rtd-theme (>=0.1.2) ; extra == 'dev'"", ""tox (==3.25.0) ; extra == 'dev'"", ""twine (>=1.13.0) ; extra == 'dev'"", ""wheel (>=0.33.1) ; extra == 'dev'"", ""pytest-runner ; extra == 'setup'"", ""black (>=19.10b0) ; extra == 'test'"", ""codecov (>=2.0.22) ; extra == 'test'"", ""docutils (<0.16,>=0.10) ; extra == 'test'"", ""flake8 (>=3.7.7) ; extra == 'test'"", ""psutil (>=5.7.0) ; extra == 'test'"", ""pytest (>=4.3.0) ; extra == 'test'"", ""pytest-cov (==2.6.1) ; extra == 'test'"", ""pytest-raises (>=0.10) ; extra == 'test'"", ""pytest-qt (>=3.3.0) ; extra == 'test'"", ""quilt3 (>=3.1.12) ; extra == 'test'""]","# napari-allencell-segmenter

[![License](https://img.shields.io/pypi/l/napari-allencell-segmenter.svg?color=green)](https://github.com/AllenCell/napari-allencell-segmenter/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-allencell-segmenter.svg?color=green)](https://pypi.org/project/napari-allencell-segmenter)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-allencell-segmenter.svg?color=green)](https://python.org)
[![Anaconda](https://anaconda.org/conda-forge/napari-allencell-segmenter/badges/version.svg)](https://anaconda.org/conda-forge/napari-allencell-segmenter)
[![tests](https://github.com/AllenCell/napari-allencell-segmenter/workflows/tests/badge.svg)](https://github.com/AllenCell/napari-allencell-segmenter/actions)
[![codecov](https://codecov.io/gh/AllenCell/napari-allencell-segmenter/branch/main/graph/badge.svg)](https://codecov.io/gh/AllenCell/napari-allencell-segmenter)


A plugin that enables 3D image segmentation provided by Allen Institute for Cell Science

The Allen Cell & Structure Segmenter plugin for napari provides an intuitive graphical user interface to access the powerful segmentation capabilities of an open source 3D segmentation software package developed and maintained by the Allen Institute for Cell Science (classic workflows only with v1.0). ​[The Allen Cell & Structure Segmenter](https://allencell.org/segmenter) is a Python-based open source toolkit developed at the Allen Institute for Cell Science for 3D segmentation of intracellular structures in fluorescence microscope images. This toolkit brings together classic image segmentation and iterative deep learning workflows first to generate initial high-quality 3D intracellular structure segmentations and then to easily curate these results to generate the ground truths for building robust and accurate deep learning models. The toolkit takes advantage of the high replicate 3D live cell image data collected at the Allen Institute for Cell Science of over 30 endogenous fluorescently tagged human induced pluripotent stem cell (hiPSC) lines. Each cell line represents a different intracellular structure with one or more distinct localization patterns within undifferentiated hiPS cells and hiPSC-derived cardiomyocytes.

More details about Segmenter can be found at https://allencell.org/segmenter

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/docs/plugins/index.html
-->

## Installation

### Option 1 (recommended):

After you installed the lastest version of napari, you can go to ""Plugins"" --> ""Install/Uninstall Package(s)"". Then, you will be able to see all available napari plugins and you can find us by name `napari-allencell-segmenter`. Just click the ""install"" button to install the Segmenter plugin.

### Option 2:

You can also install `napari-allencell-segmenter` via [pip]:

    pip install napari-allencell-segmenter

## Quick Start

In the current version, there are two parts in the plugin: **workflow editor** and **batch processing**. The **workflow editor** allows users adjusting parameters in all the existing workflows in the lookup table, so that the workflow can be optimized on users' data. The adjusted workflow can be saved and then applied to a large batch of files using the **batch processing** part of the plugin. 

1. Open a file in napari (the plugin is able to support multi-dimensional data in .tiff, .tif. ome.tif, .ome.tiff, .czi)
2. Start the plugin (open napari, go to ""Plugins"" --> ""napari-allencell-segmenter"" --> ""workflow editor"")
3. Select the image and channel to work on
4. Select a workflow based on the example image and target segmentation based on user's data. Ideally, it is recommend to start with the example with very similar morphology as user's data.
5. Click ""Run All"" to execute the whole workflow on the sample data.
6. Adjust the parameters of steps, based on the intermediate results. For instruction on the details on each function and the effect of each parameter, click the tooltip button. A complete list of all functions can be found [here](https://github.com/AllenCell/aics-segmentation/blob/main/aicssegmentation/structure_wrapper_config/function_params.md)
7. Click ""Run All"" again after adjusting the parameters and repeat step 6 and 7 until the result is satisfactory.
8. Save the workflow
9. Close the plugin and open the **batch processing** part by (go to ""Plugins"" --> ""napari-allencell-segmenter"" --> ""batch processing"")
10. Load the customized workflow (or an off-the-shelf workflow) json file
11. Load the folder with all the images to process
12. Click ""Run""

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-allencell-segmenter"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/AllenCell/napari-allencell-segmenter/issues
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/


","['Development Status :: 5 - Production/Stable', 'Intended Audience :: Science/Research', 'Framework :: napari', 'Topic :: Scientific/Engineering', 'Topic :: Scientific/Engineering :: Visualization', 'Topic :: Scientific/Engineering :: Information Analysis', 'Topic :: Scientific/Engineering :: Bio-Informatics', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/AllenCell/napari-allencell-segmenter/issues', 'Documentation, https://github.com/AllenCell/napari-allencell-segmenter#README.md', 'Source Code, https://github.com/AllenCell/napari-allencell-segmenter', 'User Support, https://github.com/AllenCell/napari-allencell-segmenter/issues']",,,napari-allencell-segmenter.WorkflowEditorWidget,,,,,https://pypi.org/project/napari-allencell-segmenter,https://github.com/AllenCell/napari-allencell-segmenter,
64,Amend segmentation and track,1.1.0,2023-04-18,2023-07-26,napari-amdtrk,Yifan Gui,jeffgui9912@gmail.com,MIT,https://github.com/Jeff-Gui/napari-amdtrk-plugin,Manually amend segmentation and track within napari,>=3.8,"['numpy (<1.24)', 'magicgui', 'qtpy', 'trackpy', 'pandas', 'scikit-image', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-amdtrk

[![License MIT](https://img.shields.io/pypi/l/napari-amdtrk.svg?color=green)](https://github.com/Jeff-Gui/napari-amdtrk/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-amdtrk.svg?color=green)](https://pypi.org/project/napari-amdtrk)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-amdtrk.svg?color=green)](https://python.org)
[![tests](https://github.com/Jeff-Gui/napari-amdtrk/workflows/tests/badge.svg)](https://github.com/Jeff-Gui/napari-amdtrk/actions)
[![codecov](https://codecov.io/gh/Jeff-Gui/napari-amdtrk/branch/main/graph/badge.svg)](https://codecov.io/gh/Jeff-Gui/napari-amdtrk)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-amdtrk)](https://napari-hub.org/plugins/napari-amdtrk)

Amend segmentation and track within napari manually.

<img src=""preview.png"" alt=""overview"" width=""900"" />


### [:eyes: watch a demo video](https://drive.google.com/file/d/1oHPdYcKv-QgOWylm21DnOF1NlVNsRIcL/view)

----------------------------------

### Input data structure

Napari-amdtrk reads an input directory which includes:
- An intensity image (`tif`) in txyc (or txy) format
- An object mask (`tif`) in txy format
- An object table (`csv`) with following essential columns:
    - frame: time frame
    - trackId: ID of the track, starting from 1
    - Center_of_the_object_0: x coordinate
    - Center_of_the_object_1: y coordinate
    - continuous_label: the corresponding label (intensity value) of the object in the object mask (You may use `skimage.measure.label` to get it from a binary mask).

- A config file named `config.yaml` (_other names are not allowed_)

    Within the config file, there should be:
    - intensity_suffix: suffix of the intensity image (e.g., for `foo_GFP.tif`, use `GFP` in the config). For multiple intensity images, separate them with commas (e.g., `GFP, mCherry`)
    - mask_suffix: suffix of the mask image
    - track_suffix: suffix of the tracked object table
    - frame_base: index of the first frame (either `0` or `1`)
    - stateCol: __optional__ column name for the cell state (e.g., cell cycle phase) in the object table. Leave blank if the object table does not contain it

__Napari-amdtrk will modify mask and track files in place.__ Other files are not affected.

---
### Quick start

1. Open `napari` GUI.
2. `File` > `Open folder` > choose `Amend segmentation and track`
3. `Plugins` > `napari-amdtrk: Amend track widget` > `Run`
4. In `layer list`, select the `segm` layer to start editing.

Please check out the demo video [here](https://drive.google.com/file/d/1oHPdYcKv-QgOWylm21DnOF1NlVNsRIcL/view) and the sample data (see below).

----------------------------------

### Sample data

To load sample data, `File` > `Open Sample` > `napari-amdtrk` > `basic tracks` or `complete cell cycle tracks`.

- basic tracks: simple cell tracks as essential input data.
- complete cell cycle tracks: cell tracks with additional cell cycle features.

The above operations will download data to `~/.amd_trk/_sample_data/` (__~230MB__). After downloading is finished, sample data will be loaded.

_Notes_
- Please cite this repository if using the plugin in your work (try `About` > `Cite this repository` upper right of this homepage).
  
- Sample data (cell track videos) have been published with [_pcnaDeep: a fast and robust single-cell tracking method using deep-learning mediated cell cycle profiling_](10.1093/bioinformatics/btac602). We acknowledge Dr Kuan Yoow Chan and members of his lab for generating the data. 

----------------------------------

### Keyboard shortcuts

- <kbd>&uarr;</kbd> and <kbd>&darr;</kbd>: toggle different operations
- <kbd>enter</kbd>: run the operation

- Available to a selected object:
  - <kbd>control</kbd> + <kbd>9</kbd>: shrink the object mask
  - <kbd>control</kbd> + <kbd>0</kbd>: expand the object mask


----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

Please install `napari` GUI first:

    python -m pip install ""napari[all]""

You can install `napari-amdtrk` via [pip]:

    pip install napari-amdtrk


## License

Distributed under the terms of the [MIT] license,
""napari-amdtrk"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 3 - Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: MIT License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/Jeff-Gui/napari-amdtrk-plugin/issues', 'Documentation, https://github.com/Jeff-Gui/napari-amdtrk-plugin/blob/master/README.md', 'Source Code, https://github.com/Jeff-Gui/napari-amdtrk-plugin']",napari-amdtrk.get_reader,,napari-amdtrk.make_amdtrkwidget,,['*'],,,https://pypi.org/project/napari-amdtrk,https://github.com/Jeff-Gui/napari-amdtrk-plugin,
65,napari-animated-gif-io,0.1.2,2022-02-04,2023-06-18,napari-animated-gif-io,Robert Haase,robert.haase@tu-dresden.de,BSD-3-Clause,https://github.com/haesleinhuepf/napari-animated-gif-io,Save 3D image stacks as animated gifs,>=3.7,"['napari-plugin-engine (>=0.1.4)', 'numpy', 'imageio', 'napari-tools-menu', 'napari', 'microfilm']","# napari-animated-gif-io

[![License](https://img.shields.io/pypi/l/napari-animated-gif-io.svg?color=green)](https://github.com/haesleinhuepf/napari-animated-gif-io/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-animated-gif-io.svg?color=green)](https://pypi.org/project/napari-animated-gif-io)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-animated-gif-io.svg?color=green)](https://python.org)
[![tests](https://github.com/haesleinhuepf/napari-animated-gif-io/workflows/tests/badge.svg)](https://github.com/haesleinhuepf/napari-animated-gif-io/actions)
[![codecov](https://codecov.io/gh/haesleinhuepf/napari-animated-gif-io/branch/main/graph/badge.svg)](https://codecov.io/gh/haesleinhuepf/napari-animated-gif-io)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-animated-gif-io)](https://napari-hub.org/plugins/napari-animated-gif-io)

Open and save 3D image stacks as animated gifs

You find the menus for opening and saving animated gifs in the `Tools > File Import/Export` menu:

![img.png](https://github.com/haesleinhuepf/napari-animated-gif-io/raw/main/docs/screenshot.png)

Furthermore, if in 3D view, you can save the current view with a little tilt animation as animated gif.
Under the hood this uses the [microfilm](https://github.com/guiwitz/microfilm) library.

![img.png](https://github.com/haesleinhuepf/napari-animated-gif-io/raw/main/docs/video.gif)

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

## Installation

You can install `napari-animated-gif-io` via [pip]:

    pip install napari-animated-gif-io



To install latest development version :

    pip install git+https://github.com/haesleinhuepf/napari-animated-gif-io.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-animated-gif-io"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/haesleinhuepf/napari-animated-gif-io/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/


","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/haesleinhuepf/napari-animated-gif-io/issues', 'Documentation, https://github.com/haesleinhuepf/napari-animated-gif-io#README.md', 'Source Code, https://github.com/haesleinhuepf/napari-animated-gif-io', 'User Support, https://github.com/haesleinhuepf/napari-animated-gif-io/issues']",,napari-animated-gif-io.napari_write_image,napari-animated-gif-io.napari_experimental_provide_function,,,,,https://pypi.org/project/napari-animated-gif-io,https://github.com/haesleinhuepf/napari-animated-gif-io,
66,napari-animation,0.0.8,2021-09-21,2024-04-16,napari-animation,"Nicholas Sofroniew, Alister Burt, Guillaume Witz, Faris Abouakil, Talley Lambert",,BSD 3-Clause,https://github.com/napari/napari-animation,A plugin for making animations in napari,>=3.8,"['imageio', 'imageio-ffmpeg', 'napari >=0.4.19rc5', 'npe2', 'numpy', 'qtpy', 'scipy', 'tqdm >=4.56.0', 'superqt', ""pre-commit ; extra == 'dev'"", ""black ; extra == 'dev'"", ""ruff ; extra == 'dev'"", ""check-manifest ; extra == 'dev'"", ""pytest ; extra == 'dev'"", ""pytest-cov ; extra == 'dev'"", ""pytest-qt ; extra == 'dev'"", ""lxml-html-clean ; extra == 'dev'"", ""sphinx >6 ; extra == 'dev'"", ""sphinx-autobuild ; extra == 'dev'"", ""sphinx-external-toc ; extra == 'dev'"", ""sphinx-copybutton ; extra == 'dev'"", ""sphinx-gallery ; extra == 'dev'"", ""sphinx-favicon ; extra == 'dev'"", ""sphinxcontrib-video ; extra == 'dev'"", ""matplotlib ; extra == 'dev'"", ""myst-nb ; extra == 'dev'"", ""napari-sphinx-theme >=0.3.0 ; extra == 'dev'"", ""sphinx >6 ; extra == 'doc'"", ""sphinx-autobuild ; extra == 'doc'"", ""sphinx-external-toc ; extra == 'doc'"", ""sphinx-copybutton ; extra == 'doc'"", ""sphinx-gallery ; extra == 'doc'"", ""sphinx-favicon ; extra == 'doc'"", ""sphinxcontrib-video ; extra == 'doc'"", ""matplotlib ; extra == 'doc'"", ""myst-nb ; extra == 'doc'"", ""napari-sphinx-theme >=0.3.0 ; extra == 'doc'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""lxml-html-clean ; extra == 'testing'""]","# napari-animation

[![License](https://img.shields.io/pypi/l/napari-animation.svg?color=green)](https://github.com/napari/napari-animation/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-animation.svg?color=green)](https://pypi.org/project/napari-animation)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-animation.svg?color=green)](https://python.org)
[![tests](https://github.com/napari/napari-animation/actions/workflows/test_and_deploy.yml/badge.svg)](https://github.com/napari/napari-animation/actions)
[![codecov](https://codecov.io/gh/napari/napari-animation/branch/main/graph/badge.svg)](https://codecov.io/gh/napari/napari-animation)

**napari-animation** is a plugin for making animations in [napari](https://napari.org).

<p align=""center"">
  <img width=""500"" src=""https://user-images.githubusercontent.com/7307488/196110138-6c4663b1-67b2-4c79-97b7-57b706d1d49c.gif"">
</p>

----------------------------------

[Merlin Lange](https://twitter.com/Merlin_Lange) used *napari-animation* to create one of [Nature's best science images for September 2022](https://www.nature.com/immersive/d41586-022-03051-6/index.html)

----------------------------------

This plugin is built on [`naparimovie`](https://github.com/guiwitz/naparimovie) from [@guiwitz](https://github.com/guiwitz). `naparimovie` was submitted to napari in [PR#851](https://github.com/napari/napari/pull/780) before napari plugin infrastructure existed.

----------------------------------

## Overview

**napari-animation** provides a framework for the creation of animations in napari. The plugin contains:

- an easy to use GUI for creating animations interactively;
- a Python package for the programmatic creation of animations.

This plugin remains under development and contributions are very welcome, please open an issue to discuss potential improvements.

You can read the documentation at [https://napari.org/napari-animation](https://napari.org/napari-animation)

## Installation

### PyPI
`napari-animation` is available through the Python package index and can be installed using `pip`.

```sh
pip install napari-animation
```

```{warning}
`napari-animation` uses `ffmpeg` to export animations. If you are using a macOS arm64 computer (Apple Silicon e.g. M1, M2 processor)
the PyPI package does not include the needed binary for your platform. You will need to install `ffmpeg` using
`conda` from the [conda-forge channel](https://conda-forge.org/docs/#what-is-conda-forge) (`conda install -c conda-forge ffmpeg`)
or using [`homebrew`](https://brew.sh) (`brew install ffmpeg`).
```

### Conda
`napari-animation` is also available for install using `conda` through the [conda-forge channel](https://conda-forge.org/docs/#what-is-conda-forge).

```sh
conda install -c conda-forge napari-animation
```

### Local
You can clone this repository and install locally with

    pip install -e .

### Interactive use
**napari-animation** can be used interactively.

An animation is created by capturing [keyframes](https://en.wikipedia.org/wiki/Key_frame) containing the current viewer state.

<p align=""center"">
  <img width=""600"" src=""https://user-images.githubusercontent.com/7307488/196113682-96ce0da3-fa5c-411e-8fb1-52dc3a8f96b6.png"">
</p>

To activate the GUI, select **napari-animation: wizard** from the *plugins menu*

<p align=""center"">
  <img width=""200"" src=""https://user-images.githubusercontent.com/7307488/196114466-56cb5985-0d79-4cfa-96f1-38cf3ccfbc48.png"">
</p>

### Scripting

**napari-animation** can also be run programatically, allowing for reproducible, scripted creation of animations.

```python
from napari_animation import Animation

animation = Animation(viewer)

viewer.dims.ndisplay = 3
viewer.camera.angles = (0.0, 0.0, 90.0)
animation.capture_keyframe()
viewer.camera.zoom = 2.4
animation.capture_keyframe()
viewer.camera.angles = (-7.0, 15.7, 62.4)
animation.capture_keyframe(steps=60)
viewer.camera.angles = (2.0, -24.4, -36.7)
animation.capture_keyframe(steps=60)
viewer.reset_view()
viewer.camera.angles = (0.0, 0.0, 90.0)
animation.capture_keyframe()
animation.animate('demo.mov', canvas_only=False)
```

## Examples

Examples can be found in our [Examples gallery](https://napari.org/napari-animation/gallery), generated from [our example scripts](https://github.com/napari/napari-animation/tree/main/examples). Simple examples for both interactive and headless
use of the plugin follow.

## Contributing

Contributions are very welcome and a detailed contributing guide is coming soon.
In the meantime, clone this repository and install it in editable mode using `pip`:

```
pip install -e .
```
We recommend using a virtual environment, for example `conda`.


```{important}
Ensure you have a suitable Qt backend for napari! We recommend `PyQt5`.
For more information, see the napari [Qt backend installation guide](https://napari.org/stable/tutorials/fundamentals/installation.html#choosing-a-different-qt-backend)
```

To set up your development installation, clone this repository, navigate to the clone folder, and install napari-animation in editable mode using `pip`.

```sh
conda create -n nap-anim python=3.10
conda activate nap-anim
pip install -e "".[dev]"" PyQt5

```

Tests are run with `pytest`.
You can make sure your `[dev]` installation is working properly by running
`pytest .` from within the repository.

```{note}
We use [`pre-commit`](https://pre-commit.com) to sort imports and lint with
[`ruff`](https://github.com/astral-sh/ruff) and format code with
[`black`](https://github.com/psf/black) automatically prior to each commit.
To minmize test errors when submitting pull requests, please install `pre-commit`
in your environment as follows:

`pre-commit install`
```

## Documentation

The documentation is available at [https://napari.org/napari-animation](https://napari.org/napari-animation)

The documentation for napari-animation is built with [Sphinx](https://www.spinx-doc.org) and the [napari Sphinx Theme](https://github.com/napari/napari-sphinx-theme).

### Building docs locally

After installing the documentation dependencies with

```sh
pip install "".[doc]""
```

you can see a local version of the documentation by running

```sh
make docs
```

Open up the `docs/_build/index.html` file in your browser, and you'll see the home page of the docs being displayed.

### Deploying docs

The napari-animation documentation is automatically built and deployed to the website
whenever the main branch is updated, or a new release is tagged.
This is controlled by the [deploy_docs.yml](https://github.com/napari/napari-animation/blob/main/.github/workflows/deploy_docs.yml) github actions script.

You can also manually trigger a documenation re-build and deployment [from the github actions tab](https://github.com/napari/napari-animation/actions/workflows/deploy_docs.yml).

## License

Distributed under the terms of the [BSD-3 license](http://opensource.org/licenses/BSD-3-Clause),
`napari-animation` is free and open source software.

## Issues

If you encounter any problems, please [file an issue](https://github.com/napari/napari-animation/issues) along with a detailed description.

[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/sofroniewn/napari-animation/issues
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 3 - Alpha', 'Intended Audience :: Science/Research', 'Topic :: Scientific/Engineering', 'Topic :: Scientific/Engineering :: Visualization', 'Framework :: napari', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']",,,,napari-animation.make_animation_widget,,,,,https://pypi.org/project/napari-animation,https://github.com/napari/napari-animation,
67,napari-annotate,0.0.2,2023-04-11,2023-07-26,napari-annotate,Jules Scholler,jules.scholler@wysscenter.ch,MPL-2.0,https://github.com/WyssCenter,Annotate large 2D slides,>=3.8,"['numpy', 'napari[all]', 'napari-tools-menu', 'magic-class', 'napari-plugin-engine (>=0.1.4)']","Plugin for annotating TissueScope data.

The plugin will be automatically deployed on Pypi and Napari hub upon release on GitHub (assign a new tag for it to be pushed correctly.)
","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: Mozilla Public License 2.0 (MPL 2.0)']",,,,napari-annotate.next_slide_huron,,,,,https://pypi.org/project/napari-annotate,https://github.com/WyssCenter,
68,napari-annotation-project,0.1.1,2023-11-18,2023-11-18,napari-annotation-project,Guillaume Witz,guillaume.witz@unibe.ch,BSD-3-Clause,https://pypi.org/project/napari-annotation-project,A napari plugin to keep images and annotations as a re-loadable project,>=3.8,"['numpy', 'PyYAML', 'scikit-image', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-annotation-project

[![License](https://img.shields.io/pypi/l/napari-annotation-project.svg?color=green)](https://github.com/guiwitz/napari-annotation-project/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-annotation-project.svg?color=green)](https://pypi.org/project/napari-annotation-project)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-annotation-project.svg?color=green)](https://python.org)
[![tests](https://github.com/guiwitz/napari-annotation-project/workflows/tests/badge.svg)](https://github.com/guiwitz/napari-annotation-project/actions)
[![codecov](https://codecov.io/gh/guiwitz/napari-annotation-project/branch/main/graph/badge.svg)](https://codecov.io/gh/guiwitz/napari-annotation-project)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-annotation-project)](https://napari-hub.org/plugins/napari-annotation-project)

This napari plugin allows to define projects consisting of multiple images that can be annotated with labels and rectangular regions of interest (rois). Those rois can then be exported as series of cropped images and labels, typically to train Machine Learning models. Projects can be easily reopened in order to browse through images and their annotations. This package is a meant to be a *light-weight plugin which does not introduce any specific dependencies* and that should be easily installable in any environment already containing napari and other plugins.

## Usage
To start a project, you can just drag and drop files in the file list area. This prompts for the selection of a project folder. After that, more files (also from different folders) can be dragged and dropped to be included in the project. Files can optionally be copied to the project folder but this option has to be set **before adding files**. When selecting a file in the list, it is opened (using the default image reader or a reader plugin if installed) and two layers, one for rois, and one for annotations are added.

https://user-images.githubusercontent.com/4622767/147265874-57dcd956-4d54-4c76-9129-c1fc2837e6a4.mp4

### Adding rois
After selecting the ```rois``` layer, you can add rectangular rois to the image. If you need square rois of a specific size (as often needed in DL training) you can select the ```Fixed roi size``` option and then use the ```Add roi``` button. **Note that currently only 2D rois are supported**. If you work with nD images, the roi is therefore added to the **current selected 2D plane**.

### Adding annotations
After selecting the ```annotations``` layer, you can add annotations to your image. There are no restrictions here and you can e.g. add as many labels as you need.

### Info storage
All relevant information on project location, project files and rois is stored in a yaml file ```Parameters.yml```. Annotations are stored as 2D tiff files in the ```annotations``` as files named after the original files. **Note that at the moment if multiple files have the same name, this will cause trouble**. This parameter file is used when re-loading an existing project.

https://user-images.githubusercontent.com/4622767/147265984-adb6ee1f-9319-45c9-a9a4-735ade2a3905.mp4

## Exporting rois
Once you are satisfied with your annotations and rois, you can use the rois to export only the corresponing cropped rois of both the image and annotation layers. For this you can head to the ```Export``` tab. Here you can set the location of the export folder, set the names of the folders that will contain cropped images and cropped annotations, and finally set the prefix names for these two types of files. Files are exported as tif files. 

https://user-images.githubusercontent.com/4622767/147266002-9c4485c9-5bcc-4c64-9c92-6c06775e2711.mp4

## Installation


You can install `napari-annotation-project` via [pip] (**note yet functional**):

    pip install napari-annotation-project

To install latest development version :

    pip install git+https://github.com/guiwitz/napari-annotation-project.git

## Contributing

Contributions are very welcome. Tests can be run with [tox].

## License

Distributed under the terms of the [BSD-3] license,
""napari-annotation-project"" is free and open source software.

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/guiwitz/napari-annotation-project/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/guiwitz/napari-annotation-project/issues', 'Documentation, https://github.com/guiwitz/napari-annotation-project#README.md', 'Source Code, https://github.com/guiwitz/napari-annotation-project', 'User Support, https://github.com/guiwitz/napari-annotation-project/issues']",,,napari-annotation-project.make_qwidget,,,,,https://pypi.org/project/napari-annotation-project,,
69,Annotator,0.0.4,2022-07-11,2023-06-18,napari-annotator,Loïc Sauteur,loic.sauteur@unibas.ch,BSD-3-Clause,https://github.com/loicsauteur/napari-annotator,A lightweight plugin extending label layer control,>=3.8,"['numpy', 'scikit-image', 'qtpy', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-annotator

[![License](https://img.shields.io/pypi/l/napari-annotator.svg?color=green)](https://github.com/loicsauteur/napari-annotator/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-annotator.svg?color=green)](https://pypi.org/project/napari-annotator)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-annotator.svg?color=green)](https://python.org)
[![tests](https://github.com/loicsauteur/napari-annotator/workflows/tests/badge.svg)](https://github.com/loicsauteur/napari-annotator/actions)
[![codecov](https://codecov.io/gh/loicsauteur/napari-annotator/branch/main/graph/badge.svg)](https://codecov.io/gh/loicsauteur/napari-annotator)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-annotator)](https://napari-hub.org/plugins/napari-annotator)

A lightweight plugin extending label layer control.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/stable/index.html
-->
## Description
This lightweight plugin helps you navigate your labels layer. It is intended to ease your manual annotation work.
![Overview image](resources/image1.png)
- Select a label from the list.
- Toggle the visibility of individual label entries.
- Move to the centroid of a label at the current zoom.
- Change the color of individual labels.
- Erase all drawn pixels of a given label.
- Restore an erased label.



## Usage
Start the plugin `Plugins > napari-annotator: Annotator`.

The plugin will list available labels once a labels layer is selected and labels drawn.

Color shuffling for labels will not work, since the plugin sets the color mode of the layer to `direct`.
But you can always change the color of individual labels, using the color picker.

## Known limitations
1. Lag when drawing (probably related to [this issue](https://github.com/napari/napari/issues/2380#issue-825308887)).
2. Locating / moving to the center of a label only works on 2D/3D label layers, i.e.:
   1. single- / multi-channel 2D label layers.
   2. single-channel 3D label layers (the third dimension being either Z or T).
3. Maximum 255 labels supported. Increasing number of supported label is possible, but when increasing it, colors in the canvas will mismatch the layer control and plugin entries (probably related to [this issue](https://github.com/napari/napari/issues/3174))
4. Restoring an erased labels is lost after switching between layers.
<!--#3: This mismatch will also prevent the hide button to work on those mismatched labels...-->




## Installation

You can install `napari-annotator` via [pip]:

    pip install napari-annotator


To install latest development version :

    pip install git+https://github.com/loicsauteur/napari-annotator.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-annotator"" is free and open source software.

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.
Or open a thread on [forum.image.sc](https://forum.image.sc) with a detailed description
and a [@loicsauteur](https://github.com/loicsauteur) tag.


[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/loicsauteur/napari-annotator/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/loicsauteur/napari-annotator/issues', 'Documentation, https://github.com/loicsauteur/napari-annotator#README.md', 'Source Code, https://github.com/loicsauteur/napari-annotator', 'User Support, https://github.com/loicsauteur/napari-annotator/issues']",,,napari-annotator.annotator,,,,,https://pypi.org/project/napari-annotator,https://github.com/loicsauteur/napari-annotator,
70,napari-annotatorj,0.0.8,2022-06-08,2023-06-18,napari-annotatorj,Reka Hollandi,reka.hollandi@gmail.com,BSD-3-Clause,https://github.com/spreka/napari-annotatorj,The napari adaptation of the ImageJ/Fiji plugin AnnotatorJ for easy image annotation.,>=3.7,"['napari', 'napari-plugin-engine >=0.1.4', 'numpy', 'roifile', 'scikit-image', 'opencv-python >=4.5.5', 'keras', 'tensorflow >=2.5.0', 'tifffile', 'imagecodecs', 'tqdm', 'pyqtgraph']","# napari-annotatorj

[![License](https://img.shields.io/pypi/l/napari-annotatorj.svg?color=green)](https://github.com/spreka/napari-annotatorj/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-annotatorj.svg?color=green)](https://pypi.org/project/napari-annotatorj)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-annotatorj.svg?color=green)](https://python.org)
[![tests](https://github.com/spreka/napari-annotatorj/workflows/tests/badge.svg)](https://github.com/spreka/napari-annotatorj/actions)
[![codecov](https://codecov.io/gh/spreka/napari-annotatorj/branch/main/graph/badge.svg)](https://codecov.io/gh/spreka/napari-annotatorj)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-annotatorj)](https://napari-hub.org/plugins/napari-annotatorj)

The napari adaptation of the ImageJ/Fiji plugin [AnnotatorJ](https://github.com/spreka/annotatorj) for easy image annotation.

![image](https://drive.google.com/uc?export=view&id=1fVfvanffTdrXvLE0m1Yo6FV5TAjh6sb2)

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/docs/plugins/index.html
-->

## Installation

Installation is possible with [pip](#pip), [napari](#bundled-napari-app) or [scripts](#script).
### Pip
You can install `napari-annotatorj` via [pip]:

    pip install napari[all]
	pip install napari-annotatorj



To install latest development version :

    pip install git+https://github.com/spreka/napari-annotatorj.git


On Linux distributions, the following error may arise upon napari startup after the installation of the plugin: `Could not load the Qt platform plugin “xcb” in “” even though it was found`. In this case, the manual install of `libxcb-xinerama0` for Qt is required:

	sudo apt install libxcb-xinerama0

### Bundled napari app
The bundled application version of [napari](https://github.com/napari/napari/releases) allows the pip install of plugins in the .zip distribution. After installation of this release, napari-annotatorj can be installed from the `Plugins --> Install/Uninstall plugins...` menu by searching for its name and clicking on the `Install` button next to it.

### Script
Single-file install is supported on [**Windows**](#windows) and [Linux](#linux) (currently). It will create a virtual environment named `napariAnnotatorjEnv` in the parent folder of the cloned repository, install the package via pip and start napari. It requires a valid Python install.

#### Windows
To start it, run in the Command prompt

	git clone https://github.com/spreka/napari-annotatorj.git
	cd napari-annotatorj
	install.bat

Or download [install.bat](https://github.com/spreka/napari-annotatorj/blob/main/install.bat) and run it from the Command prompt.

After install, you can use [startup_napari.bat](https://github.com/spreka/napari-annotatorj/blob/main/startup_napari.bat) to activate your installed virtual environment and run napari. Run it from the Command prompt with:

	startup_napari.bat


#### Linux
To start it, run in the Terminal

	git clone https://github.com/spreka/napari-annotatorj.git
	cd napari-annotatorj
	install.sh

Or download [install.sh](https://github.com/spreka/napari-annotatorj/blob/main/install.sh) and run it from the Terminal.

After install, you can use [startup_napari.sh](https://github.com/spreka/napari-annotatorj/blob/main/startup_napari.sh) to activate your installed virtual environment and run napari. Run it from the Terminal with:

	startup_napari.sh

***
## Intro

napari-annotatorj has several convenient functions to speed up the annotation process, make it easier and more fun. These *modes* can be activated by their corresponding checkboxes on the left side of the main AnnotatorJ widget.

- [Contour assist mode](#contour-assist-mode)
- [Edit mode](#edit-mode)
- [Class mode](#class-mode)
- [Overlay](#overlay)

Freehand drawing is enabled in the plugin. The ""Add polygon"" tool is selected by default upon startup. To draw a freehand object (shape) simply hold the mouse and drag it around the object. The contour is visualized when the mouse button is released.

See the [guide](#how-to-annotate) below for a quick start or a [demo](#demo). See [shortcuts](#shortcuts) for easy operation.

***
## How to annotate

1. Open --> opens an image
2. (Optionally) 
	- ... --> Select annotation type --> Ok --> a default tool is selected from the toolbar that fits the selected annotation type
	- The default annotation type is instance
	- Selected annotation type is saved to a config file
3. Start annotating objects
	- [instance](#instance-annotation): draw contours around objects
	- [semantic](#semantic-annotation): paint the objects' area
	- [bounding box](#bounding-box-annotation): draw rectangles around the objects
4. Save --> Select class --> saves the annotation to a file in a sub-folder of the original image folder with the name of the selected class

5. (Optionally)
	- Load --> continue a previous annotation
	- Overlay --> display a different annotation as overlay (semi-transparent) on the currently opened image
	- Colours --> select annotation and overlay colours
	- ... (coming soon) --> set options for semantic segmentation and *Contour assist* mode
	- checkboxes --> Various options
		- (default) Add automatically --> adds the most recent annotation to the ROI list automatically when releasing the left mouse button
		- Smooth (coming soon) --> smooths the contour (in instance annotation type only)
		- Show contours --> displays all the contours in the ROI list
		- Contours assist --> suggests a contour in the region of an initial, lazily drawn contour using the deep learning method U-Net
		- Show overlay --> displays the overlayed annotation if loaded with the Overlay button
		- Edit mode --> edits a selected, already saved contour in the ROI list by clicking on it on the image
		- Class mode --> assigns the selected class to the selected contour in the ROI list by clicking on it on the image and displays its contour in the class's colour (can be set in the Class window); clicking on the object a second time unclassifies it
	- [^] --> quick export in 16-bit multi-labelled .tiff format; if classified, also exports by classes

***
## Instance annotation
Allows freehand drawing of object contours (shapes) with the mouse as in ImageJ.

Shape contour points are tracked automatically when the left mouse button is held and dragged to draw a shape. The shape is closed when the mouse button is released, automatically, and added to the default shapes layer (named ""ROI""). In direct selection mode (from the layer controls panel), you can see the saved contour points. The slower you drag the mouse, the more contour points saved, i.e. the more refined your contour will be.

Click to watch demo video below.

[![instance-annot-demo](https://drive.google.com/uc?export=view&id=1sBg19d_hqGH-UI8irkrwame7ZjrldwHr)](https://drive.google.com/uc?export=view&id=1wELreE9MdCZq4Kf4oCWdxIw4e5o05XzK ""Click to watch instance annotation demo"")

***
## Semantic annotation
Allows painting with the brush tool (labels).

Useful for semantic (e.g. scene) annotation. Currently saves all labels to binary mask only (foreground-background).

***
## Bounding box annotation
Allows drawing bounding boxes (shapes, rectangles) around objects with the mouse.

Useful for object detection annotation.

***
## Contour assist mode
Assisted annotation via a pre-trained deep learning model's suggested contour.

1. initialize a contour with mouse drag around an object
2. the suggested contour is displayed automatically
3. modify the contour:
    - edit with mouse drag or 
    - erase holding ""Alt"" or
	- invert with pressing ""u""
4. finalize it
    - accept with pressing ""q"" or
    - reject with pressing ""Ctrl"" + ""Del""

- if the suggested contour is a merge of multiple objects, you can erase the dividing line around the object you wish to keep, and keep erasing (or splitting with the eraser) until the object you wish to keep is the largest, then press ""q"" to accept it
- this mode requires a Keras model to be present in the [model folder](#configure-model-folder)

Click to watch demo video below

[![contour-assist-demo](https://drive.google.com/uc?export=view&id=1Mw2fCPdm5WHBVRgNnp8fGNmqxI84F_9I)](https://drive.google.com/uc?export=view&id=1VTd6RScjNfAwi3vMk-bU87U4ucPmOO_M ""Click to watch contour assist demo"")

***
## Edit mode
Allows to modify created objects with a brush tool.

1. select an object (shape) to modify by clicking on it
2. an editing layer (labels layer) is created for painting automatically
3. modify the contour:
    - edit with mouse drag or 
    - erase holding ""Alt""
4. finalize it
    - accept with pressing ""q"" or
    - delete with pressing ""Ctrl"" + ""Del"" or
    - revert changes with pressing ""Esc"" (to the state before editing)

- if the edited contour is a merge of multiple objects, you can erase the dividing line around the object you wish to keep, and keep erasing (or splitting with the eraser) until the object you wish to keep is the largest, then press ""q"" to accept it

Click to watch demo video below

[![edit-mode-demo](https://drive.google.com/uc?export=view&id=1M-XdEWPXMsIOtO0ncyUtvGACS0SRX-3K)](https://drive.google.com/uc?export=view&id=10MQm53hblLKQlfBNrfUsi1vxvIdTbzCZ ""Click to watch edit mode demo"")

***
## Class mode
Allows to assign class labels to objects by clicking on shapes.

1. select a class from the class list to assign
2. click on an object (shape) to assign the selected class label to it
3. the contour colour of the clicked object will be updated to the selected class colour, plus the class label is updated in the text properties of object (turn on ""display text"" on the layer control panel to see the text properties as `objectID:(classLabel)` e.g. 1:(0) for the first object)

- optionally, you can set a default class for all currently unlabelled objects on the ROI (shapes) layer by selecting a class from the drop-down menu on the right to the text label ""Default class""
- class colours can be changed with the drop-down menu right to the class list; upon selection, all objects whose class label is the currently selected class will have their contour colour updated to the selected colour
- clicking on an object that has already been assigned a class label will unclassify it: assign the label *0* to it

Click to watch demo video below

[![class-mode-demo](https://drive.google.com/uc?export=view&id=1EV1cn_mySO11S_ZDFv6Dl1laAk30jGJk)](https://drive.google.com/uc?export=view&id=1uOmznUvfHEFvviWTtOnUHty8rkKyWR7Q ""Click to watch class mode demo"")

***
## Export
See also: [Quick export](#quick-export)

The exporter plugin AnnotatorJExport can be invoked from the Plugins menu under the plugin name `napari-annotatorj`. It is used for batch export of annotations to various formats directly suitable to train different types of deep learning models. See a [demonstrative figure](https://raw.githubusercontent.com/spreka/annotatorj/master/demos/annotation_and_export_types.png) in the [AnnotatorJ repository](https://github.com/spreka/annotatorj) and further description in its [README](https://github.com/spreka/annotatorj#export) or [documentation](https://github.com/spreka/annotatorj/blob/master/AnnotatorJ_documentation.pdf).

1. browse original image folder with either the
    - ""Browse original..."" button or
    - text input field next to it
2. browse annotation folder with either the
    - ""Browse annot..."" button or
    - text input field next to it
3. select the export options you wish to export the annotations to (see tooltips on hover for help)
    - at least one export option must be selected to start export
    - (optional) right click on the checkbox ""Coordinates"" to switch between the default COCO format and YOLO format; see [explanation](#coordinate-formats)
4. click on ""Export masks"" to start the export
    - this will open a progress bar in the napari window and close it upon finish

The folder structure required by the exporter is as follows:

```
image_folder
	|--- image1.png
	|--- another_image.png
	|--- something.png
	|--- ...

annotation_folder
	|--- image1_ROIs.zip
	|--- another_image_ROIs.zip
	|--- something_ROIs.zip
	|--- ...
```

Multiple export options can be selected at once, any selected will create a subfolder in the folder where the annotations are saved.


Click to watch demo video below

[![exporter-demo](https://drive.google.com/uc?export=view&id=1QoaJrI9pKziUzYwiZNdWlfRD7PcvJB9U)](https://drive.google.com/uc?export=view&id=1uJz-x_ypEOjc7SYPUTqrEt0ieyNLFy6u ""Click to watch exporter demo"")

***
## Quick export
Click on the ""[^]"" button to quickly save annotations and export to mask image. It saves the current annotations (shapes) to an ImageJ-compatible roi.zip file and a generated a 16-bit multi-labelled mask image to the subfolder ""masks"" under the current original image's folder.


***
## Coordinate formats
In the AnnotatorJExport plugin 2 coordinates formats can be selecting by right clicking on the Coordinates checkbox: COCO or YOLO. The default is COCO.

*COCO format*:
- `[x, y, width, height]` based on the top-left corner of the bounding box around the object
- coordinates are not normalized
- annotations are saved with header to 
    - .csv file
    - tab delimeted

*YOLO format*:
- `[class, x, y, width, height]` based on the center point of the bounding box around the object
- coordinates are normalized to the image size as floating point values between 0 and 1
- annotations are saved with header to
    - .txt file
    - whitespace delimeted
    - class is saved as the 1st column

***
## Overlay
A separate annotation file can be loaded as overlay for convenience, e.g. to compare annotations.

1. load another annotation file with the ""Overlay"" button

- (optional) switch its visibility with the ""Show overlay"" checkbox
- (optional) change the contour colour of the overlay shapes with the [""Colours"" button](#change-colours)

***
## Change colours
Clicking on the ""Colours"" button opens the Colours widget where you can set the annotation and overlay colours.

1. select a colour from the drop-down list either next to the text label ""overlay"" or ""annotation""
2. click the ""Ok"" button to apply changes

- contour colour of shapes on the annotation shapes layer (named ""ROI"") that already have a class label assigned to them will **not** be updated to the new annotation colour, only those not having a class label (the class label can be displayed with the ""display text"" checkbox on the layer controls panel as `objectID:(classLabel)` e.g. 1:(0) for the first object)
- contour colour of shapes on the overlay shapes layer (named ""overlay"") will all have the overlay colour set, regardless of any existing class information saved to the annotation file loaded as overlay

***
## Configure model folder
The Contour assist mode imports a pre-trained Keras model from a folder named *models* under exactly the path *napari_annotatorj*. This is automatically created on the first startup in your user folder:
- `C:\Users\Username\.napari_annotatorj` on Windows
- `\home\username\.napari_annotatorj` on Linux

A pre-trained model for nucleus segmentation is automatically downloaded from the GitHub repository of the [ImageJ version of AnnotatorJ](https://github.com/spreka/annotatorj/releases/tag/v0.0.2-model). The model will be saved to `[your user folder]\.napari_annotatorj\models\model_real.h5`. This location is printed to the console (command prompt or powershell on Windows, terminal on Linux).

(deprecated) When bulding from source the model folder is located at *path\to\napari-annotatorj\src\napari_annotatorj\models* whereas installing from pypi it is located at *path\to\virtualenv\Lib\site-packages\napari_annotatorj\models*.

The model must be in either of these file formats:
- config .json file + weights file: *model_real.json* and *model_real_weights.h5*
- combined weights file: *model_real.hdf5*

You can also train a new model on your own data in e.g. Python and save it with this code block:

```python
	# save model as json
	model_json=model.to_json()
	with open(‘model_real.json’, ‘w’) as f:
		f.write(model_json)
	
	# save weights too
	model.save_weights(‘model_real_weights.h5’)

```
You can also train in the [train widget](#Training).

This configuration will change in the next release to allow model browse and custom model name in an [options widget](#options).

***
## Training
To start training a new model or refine an existing one click the **Train** button on the right of the napari-annotatorj widget. This will open the training widget where you can set input paths and training options. During training a progress bar will show the epochs passed and plot the loss on a graph. See a [guide](#how-to-train) below.

The trained model will be saved to the `model` folder under the located training data folder which is named `training` by default when preparing data. Each new training will be saved to a new training folder with increased numbering e.g. `training_1`, `training_2` etc.

When an existing training data folder is browsed with the ""Browse train ..."" button, the `model` folder will be created under it without an additiona `training` folder.

After training is finished, a message is shown to indicate the newly trained model can be tested by drawing bounding boxes (rectangles) to initiate [contour assist](#contour-assist-mode) prediction. The presented region on the editing layer (Label layer) can be modified with the paint brush tool (automatically selected) as in [contour assist](#contour-assist-mode).

The trained model can be further refined by selecting the ""Retrain latest"" checkbox from the [training parameters](#training-parameters) (⚙ button on the right).

To use this new model for annotation in [contour assist mode](#contour-assist-mode), you mush set the model path in the [Options widget](#options) or in the configuration file (see how to [here](#configure-model-folder)), then restart napari.

### How to train
1. On current annotation
	1. ""Use current annotation"" checkbox --> use this image and its current annotation for training
	2. Prep data --> prepare data to [suitable format](#training-data-format)
	3. (optional) ⚙ --> [set parameters](#training-parameters)
	4. Start --> start training
2. Additional data
	1. Select images and annotations to use for training
		- Browse original ... --> locate folder of original images
		- Browse annot ... --> locate folder of annotations
		- Prep data --> prepare data to [suitable format](#training-data-format)
	2. Browse train ... --> select already prepared training data
	3. (optional) ⚙ --> [set parameters](#training-parameters)
	4. Start --> start training

### Training data format
The data format expected by the training widget is as follows.

```
images
	|--- image1.png
	|--- another_image.png
	|--- something.png
	|--- ...

unet_masks
	|--- image1.tiff
	|--- another_image.tiff
	|--- something.tiff
	|--- ...
```

Masks are 8-bit binary (black and white) .tiff images that can be exported from the [Exporter widget](#export) selecting the Semantic (binary) export option. When the ""Prep data"" button is clicked in the Training widget, these folders are automatically created from the located annotation files and original images.

### Training parameters
The following configurable parameters can be set after clicking on the ⚙ icon:
| Parameter | Description | Default value |
| --------- | ----------- | ------------- |
| Epochs | number of epochs to train | 5 |
| Steps | number of steps in each epoch | 1 |
| Batch size | number of samples in an iteration| 1 |
| Image size | size of training images | 256 |
| Start from scratch | train a new model from scratch| `False` |
| Retrain latest | re-fine latest training | `False` |
| Write pred | write test image prediction to file| `False` |
| Test image | path to test image | `None`|

Note: by default CPU will be used for training. This can be changed to GPU in the [Options widget](#options) if your computer has a capable CUDA-device.

***
## Options
Settings found in the configuration file can be set in the Options widget opened with the ""..."" button on the right of the main plugin. For changes to take effect you must save your changes with the ""Ok"" button at the bottom of the Options widget.

The following options can be configured:
|Group|Option|Description|Default|Valid values|
|-----|------|-----------|-------|------------|
|General|Annotation type | see [instance](#instance-annotation), [bbox](#bounding-box-annotation), [semantic](#semantic-annotation) | instance |instance, bbox, semantic |
| |Remember annotation type|use the same annotation type on next startup|`True`|`True`, `False`|
| |Colours|select annotation and overlay colours; see [here](#change-colours)|white|white, red, green, blue, cyan, magenta, yellow, orange, black|
| |Classes|names of folders to save annotations when not classified*|normal|(any string)**|
|Semantic segmentation|Brush size|size of the brush|50|`int`|
|*Advanced settings*|
|Contour assist|Max distance|number of pixels to extend the initial contour with|17|`int`|
||Threshold|intensity threshold after prediction|||
||- gray||0.1|`float` in [0,1]|
||- R (red)||0.2|`float` in [0,1]|
||- G (green)||0.4|`float` in [0,1]|
||- B (blue)||0.2|`float` in [0,1]|
||Brush size|correction brush size|5|`int`|
||Method|contour assist prediction method|U-Net|U-Net, Classic***|
||Model|U-Net model to use for Contour assist prediction|||
||folder|path to the model folder|`user/.napari_annotatorj/models`|existing `models` folder path|
||.json file|name of the model .json file **without** extension|model_real|any string**|
||weights file|name of the model weights file|model_real_weights.h5|any string**|
||full file|name of the combined config+weights file|model_real.hdf5|any string**|
||Device|computation device to perform prediction|cpu|cpu,`int`****|
|Mask/text import|
||Auto mask load|load annotation files automatically when a new image is opened|`False`|`True`, `False`|
||Enable mask load|load instance annotation mask image|`False`|`True`, `False`|
||Enable text load|load object detection bounding box coordinate text file|`False`|`True`, `False`|
||Method|load as editable or overlay|load|load, overlay|
|Others|
||Save outlines|save image with annotations outlined|`False`|`True`, `False`|
||Show help on startup|show the help window upon every startup|`False`|`True`, `False`|
||Save annot times|save annotation times to text file*****|`False`|`True`, `False`|

*: right click the last element (other...) to add a new item to the list. When annotations are assigned class labels in [class mode](#class-mode), they will be saved to the folder `masks` by default.

**: do not use whitespace (' ') if possible

***: region growing classical algorithm

****: valid id of a GPU device e.g. `0` or `3`; if your computer has only one GPU the id is `0`

*****: currently disabled, used for development

***
## Demo
Run a demo of napari-annotatorj with sample data: a small 3-channel RGB image as original image and an ImageJ roi.zip file as annotations loaded.

```shell
    # from the napari-annotatorj folder
	python src/napari_annotatorj/load_imagej_roi.py
```
Alternatively, you can startup the napari-annotatorj plugin by running

```shell
    # from the napari-annotatorj folder
	python src/napari_annotatorj/startup_annotatorj.py
```

***
## Shortcuts

| Function | Shortcut |
| -------- | -------- |
| Contour assist | `a` |
| Class mode | `c` |
| Edit mode | `Shift` + `e` |
| Show contours | `Shift` + `v` |
| Accept Contour assist | `q` |
| Reject Contour assist | `Ctrl` + `del` |
| Invert Contour assist | `u` |
| Erase in Edit/Contour assist mode | `Alt` (hold) |
| Revert changes in Edit mode | `Esc` |


***
## Setting device for deep learning model prediction
The [Contour assist](#contour-assist-mode) mode uses a pre-trained U-Net model for suggesting contours based on a lazily initialized contour drawn by the user. The default configuration loads and runs the model on the CPU so all users can run it. It is possible to switch to GPU if you have:
- a CUDA-capable GPU in your computer
- nVidia's CUDA toolkit + cuDNN installed

See installation guide on [nVidia's website](https://developer.nvidia.com/cuda-downloads) according to your system.

To switch to GPU utilization, edit [_dock_widget.py](https://github.com/spreka/napari-annotatorj/blob/main/src/napari_annotatorj/_dock_widget.py#L112) and set to the device you would like to use. Valid values are `'cpu','0','1','2',...`. The default value is `cpu`. The default GPU device is `0` if your system has any CUDA-capable GPU. If the device you set cannot be found or utilized by the code, it will fall back to `cpu`. An informative message is printed to the console upon plugin startup.

***
## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-annotatorj"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/spreka/napari-annotatorj/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 3 - Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/spreka/napari-annotatorj/issues', 'Documentation, https://github.com/spreka/napari-annotatorj#README.md', 'Source Code, https://github.com/spreka/napari-annotatorj', 'User Support, https://github.com/spreka/napari-annotatorj/issues']",napari-annotatorj.get_reader,napari-annotatorj.write_labels,napari-annotatorj.AnnotatorJ,,['<EDIT_ME>'],['.tiff'],,https://pypi.org/project/napari-annotatorj,https://github.com/spreka/napari-annotatorj,
71,Aphid,1.1.7,2023-04-11,2023-11-07,napari-aphid,Herearii Metuarea,herearii.metuarea@gmail.com,BSD-3-Clause,https://github.com/hereariim/napari-aphid,A plugin to classify aphids by stage of development.,>=3.8,"['napari', 'numpy', 'magicgui', 'qtpy', 'opencv-python-headless', 'scikit-learn', 'scikit-image', 'h5py', 'matplotlib', 'pandas', 'scipy', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-aphid

[![License BSD-3](https://img.shields.io/pypi/l/napari-aphid.svg?color=green)](https://github.com/hereariim/napari-aphid/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-aphid.svg?color=green)](https://pypi.org/project/napari-aphid)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-aphid.svg?color=green)](https://python.org)
[![tests](https://github.com/hereariim/napari-aphid/workflows/tests/badge.svg)](https://github.com/hereariim/napari-aphid/actions)
[![codecov](https://codecov.io/gh/hereariim/napari-aphid/branch/main/graph/badge.svg)](https://codecov.io/gh/hereariim/napari-aphid)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-aphid)](https://napari-hub.org/plugins/napari-aphid)

A plugin to classify aphids by stage of development.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started
and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-aphid` via [pip]:

    pip install napari-aphid

To install latest development version :

    pip install git+https://github.com/hereariim/napari-aphid.git

## Description

This plugin is a tool to count the number of aphids from two models developed on ilastik. Implemented in napari, this tool allows the correction of pixels and labels that are not well 
predicted. 

In this plugin we find our two main parts of the aphid counting model presented in two widgets. A third widget allows to save the updates applied on the segmentation mask.

This plugin is an use cas, dedicated to private use of french laboratory.

## Plugin input

### Segmentation

The user must give two objects as input:

- Compressed file in .zip format
- Ilastik pixel classification model in .ilp format

In particular, compressed file must be organized as follows:

```
.
└── Country.zip
    └── Country
        ├── Area1
        │   ├── Area1.im_1.tif
        │   ├── Area1.im_1.h5
        │   ├── Area1.im_2.tif 
        │   ├── Area1.im_2.h5  
        │   ├── Area1.im_3.tif
        │   ├── Area1.im_3.h5
        │   ...
        │   ├── Area1.im_n.tif
        │   └── Area1.im_n.h5
        │
        ├── Area2
        │   ├── Area2.im_1.tif
        │   ├── Area2.im_1.h5
        │   ├── Area2.im_2.tif
        │   ├── Area2.im_2.h5
        │   ├── Area2.im_3.tif
        │   ├── Area2.im_3.h5
        │   ...
        │   ├── Area2.im_n.tif
        │   └── Area2.im_n.h5
        │
        ...
        │
        └── Arean
            ├── Arean.im_1.tif
            ├── Arean.im_1.h5
            ├── Arean.im_2.tif
            ├── Arean.im_2.h5
            ├── Arean.im_3.tif
            ├── Arean.im_3.h5
            ...
            ├── Arean.im_n.tif
            └── Arean.im_n.h5
```

In each folder Area1, Area2, ..., Arean, we notice that **each tif image is accompanied by its h5 version**. The images in h5 format were generated by the Export h5 widget of the Ilastik plugin in the ImageJ software.

### Classification

The user must give the Ilastik object classification model in .ilp format.

## Widget: Image segmentation

This widget is a tool to segment a set of images. It takes as input a compressed file of images and an ilastik segmentation model. A Run button is used to start the image segmentation process. In the background, the console presents the progress status. This widget returns a menu which is a list of processed images. This list allows an RGB image and its segmentation mask to be displayed in the napari window.

![segmentation_cpe](https://user-images.githubusercontent.com/93375163/212323051-bc84d597-a9ff-46ca-b897-cb18a0e77b4c.png)

**User conduct :** In this widget, the user corrects the image with the annotation tools (brush and eraser only). With the brush, he/she has to add the same colour presented in the image. To obtain this colour, the user can take the color with the color picker tool. With the eraser, he/she erase colour not well predicted. Tous les annotations appliquées dans l'image doit être sauvegarder avec le bouton *Save* du widget **Save modification**

## Widget: Save modification

This is the backup of the segmentation mask. It saves updates applied to the mask.

## Widget: Object classification

This widget is a tool to classify segmented images. It takes as input an ilastik object classification model. A Run button is used to start the classification process. In the background, the console shows the progress of the image processing. This widget returns a menu that lists the processed images. This list provides two elements. The first is the display of the selected image in the window. The second is the display of a table that shows the predicted classes for each object.

![classification_cpe](https://user-images.githubusercontent.com/93375163/212323369-32423622-4f41-4dcb-800b-39ff66be67f9.png)

**User conduct :** In this widget, the user corrects labels not well predicted in the table at the bottom right. He must not forget to save his correction with the Save button.
When the user has finished with all his images, he uses the Export button to import a quantitative table. This table contains for each image, the name of the aphid type and its size in pixels.

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-aphid"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/hereariim/napari-aphid/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/hereariim/napari-aphid/issues', 'Documentation, https://github.com/hereariim/napari-aphid#README.md', 'Source Code, https://github.com/hereariim/napari-aphid', 'User Support, https://github.com/hereariim/napari-aphid/issues']",,,napari-aphid.process_segmentation,,,,,https://pypi.org/project/napari-aphid,https://github.com/hereariim/napari-aphid,
72,Apple,0.0.8,,,napari-apple,Herearii Metuarea,herearii.metuarea@gmail.com,BSD-3-Clause,,Detection of apple based on YOLOv4 model,>=3.8,"['numpy', 'magicgui', 'qtpy', 'opencv-python-headless', 'scikit-image', 'napari', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-apple

[![License BSD-3](https://img.shields.io/pypi/l/napari-apple.svg?color=green)](https://github.com/hereariim/napari-apple/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-apple.svg?color=green)](https://pypi.org/project/napari-apple)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-apple.svg?color=green)](https://python.org)
[![tests](https://github.com/hereariim/napari-apple/workflows/tests/badge.svg)](https://github.com/hereariim/napari-apple/actions)
[![codecov](https://codecov.io/gh/hereariim/napari-apple/branch/main/graph/badge.svg)](https://codecov.io/gh/hereariim/napari-apple)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-apple)](https://napari-hub.org/plugins/napari-apple)

Detection of apple based on YOLOv4-tiny model

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/index.html
-->

## Installation

Before you can operate the module, you must install the `napari-apple` module.

### Instruction for napari-module

You can install `napari-apple` via [pip]:

    pip install napari-apple

To install latest development version :

    pip install git+https://github.com/hereariim/napari-apple.git

## How does it works

Here, user drop its images in the napari windows. The plugin shows two widgets : 
- Image detection
- Export data

In Image detection, user select the interesting layer to detect apple. The ""Run"" button run the inference detection based on Yolov4-tiny model. At the end, the result is displayed on screen. User can correct freely the detection by removing or adding box in image.

In Export data, user export select the interesting shape layer and RGB image. A button ""Save to csv"" save bounding box coordinate in Yolo way into a text file.

![Capture d'écran 2024-04-24 114340](https://github.com/hereariim/napari-apple/assets/93375163/d8873a6a-8ebb-4686-bfe9-e7e7729378b1)


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-apple"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/hereariim/napari-apple/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Software Development :: Testing']","['Bug Tracker, https://github.com/hereariim/napari-apple/issues', 'Documentation, https://github.com/hereariim/napari-apple#README.md', 'Source Code, https://github.com/hereariim/napari-apple', 'User Support, https://github.com/hereariim/napari-apple/issues']",napari-apple.get_reader,napari-apple.write_multiple,napari-apple.image_detection,napari-apple.make_sample_data,['*.npy'],,['.npy'],https://pypi.org/project/napari-apple,,
73,napari-apr-viewer,1.0.1,,,napari-apr-viewer,Joel Jonsson,jonsson@mpi-cbg.de,Apache-2.0,,A simple plugin to view APR images in napari,>=3.8,"['numpy', 'pyapr >=1.0.0rc1', 'napari', 'napari-plugin-engine >=0.1.4', 'qtpy', 'magicgui']","# napari-apr-viewer

[![License](https://img.shields.io/pypi/l/napari-apr-viewer.svg?color=green)](https://github.com/AdaptiveParticles/napari-apr-viewer/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-apr-viewer.svg?color=green)](https://pypi.org/project/napari-apr-viewer)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-apr-viewer.svg?color=green)](https://python.org)
[![tests](https://github.com/AdaptiveParticles/napari-apr-viewer/workflows/tests/badge.svg)](https://github.com/AdaptiveParticles/napari-apr-viewer/actions)
[![codecov](https://codecov.io/gh/AdaptiveParticles/napari-apr-viewer/branch/main/graph/badge.svg)](https://codecov.io/gh/AdaptiveParticles/napari-apr-viewer)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-apr-viewer)](https://napari-hub.org/plugins/napari-apr-viewer)

A simple plugin to create and view APR images in napari

## Usage

To get started, open an image of your choice (2D or 3D grayscale) in napari and open the `convert_image_to_apr` panel. Select the image layer to convert, an appropriate data type, and hit `Run`. 

**Note:** choosing a data type smaller than the input type may lead to overflow and thus erroneous results.

Conversion parameters can often be left to their default values, thanks to the automatic parameter tuning. For very noisy images, it is sometimes useful to increase the `smoothing` parameter. In order to get a more (or less) aggressive adaptation, change the `relative error` parameter.

![conversion.png](https://github.com/AdaptiveParticles/napari-apr-viewer/raw/main/docs/conversion.png)

To save the result to file, simply save the newly created layer using the `File` menu. We use the extension `.apr`, although the file is actually written in `hdf5` format (and can be opened/explored as such). In this example, the APR is roughly 80 times smaller than the original image on disk. APR files can be opened directly in napari, e.g. by drag and drop.

![apr_file.png](https://github.com/AdaptiveParticles/napari-apr-viewer/raw/main/docs/apr_file.png)

To better understand the workings of the APR on your data, you can use the `APR Viewer` panel to change the `View mode` for a selected APR layer to `level`. This shows you a visualization of the adaptive resolution. Particles in the brightest regions correspond exactly to pixels (lossless), while each shade darker corresponds to downsampling by a factor of 2 in each dimension.

![view_level.png](https://github.com/AdaptiveParticles/napari-apr-viewer/raw/main/docs/view_level.png)

The `Downsample` slider can be used to reduce the resolution of the displayed data for the selected layer. This can be used to explore large volumes in 3D, where rendering the full data requires too much memory. 

**Note:** We do not offer APR-native rendering at this time, so this step will reconstruct the entire pixel volume (at the selected resolution). Thus, for large volumes, be sure to increase the downsampling before toggling the 3D viewer. 

![view_3D.png](https://github.com/AdaptiveParticles/napari-apr-viewer/raw/main/docs/view_3D.png)

![view_3D_ds.png](https://github.com/AdaptiveParticles/napari-apr-viewer/raw/main/docs/view_3D_downsampled.png)

_The data shown in these examples was taken from the Platynereis-ISH-Nuclei-CBG dataset available [here](https://github.com/juglab/EmbedSeg/releases)._

&nbsp;

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

## Installation

You can install `napari-apr-viewer` via [pip]:

    pip install napari-apr-viewer

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [Apache Software License 2.0] license,
""napari-apr-viewer"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/

[file an issue]: https://github.com/AdaptiveParticles/napari-apr-viewer/issues
","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Operating System :: OS Independent', 'License :: OSI Approved :: Apache Software License']",,napari-apr-viewer.napari_get_reader,napari-apr-viewer.napari_write_image,napari-apr-viewer.APRViewer,,['*'],,,https://pypi.org/project/napari-apr-viewer,,
74,napari-arboretum,0.1.2,2022-02-10,2023-07-28,napari-arboretum,Alan R. Lowe,"""Alan R. Lowe"" <a.lowe@ucl.ac.uk>",,https://github.com/quantumjot/arboretum,Track graph and lineage tree visualization with napari,>=3.8,"['matplotlib', 'napari-matplotlib (>=0.2.1)', 'napari (>=0.4.0)', 'numpy (>=1.17.3)', 'pandas', 'pooch (>=1)', 'qtpy', 'scikit-image', 'vispy']"," <!--[![Downloads](https://pepy.tech/badge/napari-arboretum)](https://pepy.tech/project/napari-arboretum)-->

[![License](https://img.shields.io/pypi/l/napari-arboretum.svg?color=green)](https://github.com/lowe-lab-ucl/arboretum/blob/main/LICENSE.md)
[![PyPI](https://img.shields.io/pypi/v/napari-arboretum.svg?color=green)](https://pypi.org/project/napari-arboretum)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-arboretum.svg?color=green)](https://python.org)
[![tests](https://github.com/lowe-lab-ucl/arboretum/workflows/tests/badge.svg)](https://github.com/lowe-lab-ucl/arboretum/actions)
[![codecov](https://codecov.io/gh/lowe-lab-ucl/arboretum/branch/main/graph/badge.svg?token=2M2HhM60op)](https://app.codecov.io/gh/lowe-lab-ucl/arboretum/tree/main)

# Arboretum



https://github.com/lowe-lab-ucl/arboretum/assets/8217795/d98c22c4-73bb-493a-9f8f-c224d615209d


_Automated cell tracking and lineage tree reconstruction_.

### Overview

A dockable widget for [Napari](https://github.com/napari/napari) for visualizing cell lineage trees.

Features:

- Lineage tree plot widget
- Integration with [btrack](https://github.com/quantumjot/btrack)

---

### Usage

Once installed, Arboretum will be visible in the `Plugins > Add Dock Widget > napari-arboretum` menu in napari. To visualize a lineage tree, (double) click on one of the tracks in a napari `Tracks` layer.

### Examples

You can use the example script to display some sample tracking data in napari and load the arboretum tree viewer:

```sh
python ./examples/show_sample_data.py
```

Alternatively, you can use _btrack_ to generate tracks from your image data. See the example notebook here:
https://github.com/quantumjot/btrack/blob/main/examples

---

### History

This project has changed considerably. The `Tracks` layer, originally developed for this plugin, is now an official layer type in napari. Read the napari documentation here:
https://napari.org/stable/api/napari.layers.Tracks.html

To view the legacy version of this plugin, visit the legacy branch:
https://github.com/quantumjot/arboretum/tree/v1-legacy
","['Development Status :: 4 - Beta', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python', 'Topic :: Scientific/Engineering :: Visualization']","['homepage, https://github.com/lowe-lab-ucl/arboretum']",,,napari-arboretum.Arboretum,,,,,https://pypi.org/project/napari-arboretum,https://github.com/quantumjot/arboretum,
75,Dioptic ARGOS Archive Reader,0.0.7,,,napari-argos-archive-reader,Volker Hilsenstein,hilsenstein@dioptic.de,MIT,,A plugin to read Dioptic ARGOS archive files,>=3.9,"['napari', 'numpy', 'scikit-image', 'pydantic', 'ruamel.yaml', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'""]","# napari-argos-archive-reader

[![License MIT](https://img.shields.io/pypi/l/napari-argos-archive-reader.svg?color=green)](https://github.com/dioptic/napari-argos-archive-reader/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-argos-archive-reader.svg?color=green)](https://pypi.org/project/napari-argos-archive-reader)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-argos-archive-reader.svg?color=green)](https://python.org)
[![tests](https://github.com/dioptic/napari-argos-archive-reader/workflows/tests/badge.svg)](https://github.com/dioptic/napari-argos-archive-reader/actions)
[![codecov](https://codecov.io/gh/dioptic/napari-argos-archive-reader/branch/main/graph/badge.svg)](https://codecov.io/gh/dioptic/napari-argos-archive-reader)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-argos-archive-reader)](https://napari-hub.org/plugins/napari-argos-archive-reader)

A plugin to read Dioptic ARGOS archive files

----------------------------------

This repo contains a reader plugin for [DIOPTIC ARGOS](https://www.dioptic.de/en/argos-en/) Archive files, which
have `.zip` file extension.
Individual ARGOS layers are grouped into napari layer with stacks according to
their illumination, stage XY position and Z-stack information.

The plugin implements delayed reading using `dask.delayed` so that one can quickly
see the contents even for large archives with many layers. Note!: switching to
volume rendering or swapping axes can trigger the loading of all ARGOS layers, which
can take a long time for large archives.

[ARGOS](https://www.dioptic.de/en/argos-en/) is an automated system
for surface inspection according to ISO 10110-7.

This plugin is still experimental and does not support all features of ARGOS archives.

Currently, the plugin

* can read Argos matrix archives containing regular image layers including:
  * ✅ segmentation masks
  * ✅ Z-stack metadata
  * ✅ Illumination metadata
  * ✅ proper scaling and affine transformation of layers
* can read ❔✅ Argos line scan (polar) archives with minimal support (no metadata parsing)
This has not been tested on many archives.

Not supported are:

* ❌ annotated archives
* ❌ pyramid image structures
* ❌ Line segmentation metadata
* ❌ color metadata
* ❌ ...

## Usage

### Opening files

Simply drag and drop an ARGOS Archive `.zip` file onto the napari canvas or use `File->Open` to open it.

### Synchronizing contrast limits

By default, after reading an archive, each napari layer will have their own contrast limits, so you can
adjust these contrast limits individually.

The reader plugin registers a custom key binding after reading an ARGOS archive. Pressing the `s` key will allow
you to synchronize the contrast limits for a set of layers:

* If you select _a single_ napari layer corresponding to an image/stack from an ARGOS archive, all napari image
layers that were loaded from this archive now have their contrast limits synchronized, i.e. changing the
contrast limits of _any_ of them will adjust the contrast limits of _all_ of the layers belonging to the same
archive.
* If you select _multiple_ napari layers and press `s` all of these and only these napari layers will have
their contrast limits synchronized, regardless of whether they belong to the same ARGOS archive or not.

## Installation

If you have napari installed you can install the plugin from the napari hub through the `Plugins -> Plugin Manger` menu
entry. After waiting a short while for napari to retrieve the plugins available from the hub, simply enter ""argos"" in
the filter line entry field at the top to narrow down the plugin list and click install.

You can install `napari-argos-archive-reader` via [pip]:

    pip install napari-argos-archive-reader

To install latest development version :

    pip install git+https://github.com/dioptic/napari-argos-archive-reader.git

## License

Distributed under the terms of the [MIT] license,
""napari-argos-archive-reader"" is free and open source software

[MIT]: http://opensource.org/licenses/MIT
[pip]: https://pypi.org/project/pip/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: MIT License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/dioptic/napari-argos-archive-reader/issues', 'Documentation, https://github.com/dioptic/napari-argos-archive-reader#README.md', 'Source Code, https://github.com/dioptic/napari-argos-archive-reader', 'User Support, https://github.com/dioptic/napari-argos-archive-reader/issues']",napari-argos-archive-reader.get_reader,,,,['*.zip'],,,https://pypi.org/project/napari-argos-archive-reader,,
76,napari-assistant,0.4.7,2022-03-09,2023-11-04,napari-assistant,"Robert Haase, Ryan Savill",robert.haase@tu-dresden.de,BSD-3-Clause,https://github.com/haesleinhuepf/napari-assistant,A pocket calculator like interface to image processing in napari,>=3.8,"['napari-plugin-engine >=0.1.4', 'toolz', 'napari >=0.4.14', 'magicgui', 'numpy !=1.19.4', 'pyperclip', 'loguru', 'jupytext', 'jupyter', 'pandas', 'napari-time-slicer >=0.4.8', 'napari-workflows >=0.2.10']","# napari-assistant
[![License](https://img.shields.io/pypi/l/napari-assistant.svg?color=green)](https://github.com/haesleinhuepf/napari-assistant/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-assistant.svg?color=green)](https://pypi.org/project/napari-assistant)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-assistant.svg?color=green)](https://python.org)
[![tests](https://github.com/haesleinhuepf/napari-assistant/workflows/tests/badge.svg)](https://github.com/haesleinhuepf/napari-assistant/actions)
[![codecov](https://codecov.io/gh/haesleinhuepf/napari-assistant/branch/master/graph/badge.svg)](https://codecov.io/gh/haesleinhuepf/napari-assistant)
[![Development Status](https://img.shields.io/pypi/status/napari-assistant.svg)](https://en.wikipedia.org/wiki/Software_release_life_cycle#Alpha)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-assistant)](https://napari-hub.org/plugins/napari-assistant)
[![DOI](https://zenodo.org/badge/463875112.svg)](https://zenodo.org/badge/latestdoi/463875112)


The napari-assistant is a [napari](https://github.com/napari/napari) meta-plugin for building image processing workflows. 

## Usage

After installing one or more napari plugins that use the napari-assistant as user interface, you can start it from the 
menu `Tools > Utilities > Assistant (na)` or run `naparia` from the command line. 

By clicking on the buttons in the assistant, you can setup a workflow for processing the images.

![img.png](https://github.com/haesleinhuepf/napari-assistant/raw/main/docs/napari-assistant-screenshot.png)

While setting up your workflow, you can at any point select a layer from the layer list (1) and change the parameters of
the corresponding operation (2). The layer will update when you change parameters and also all subsequent operations. 
You can also vary which operation is applied to the image (3). Also make sure the right input image layer is selected (4).

![img.png](https://github.com/haesleinhuepf/napari-assistant/raw/main/docs/design_workflows.png)

### Saving and loading workflows

You can also save and load workflows to disk. 

![img.png](https://github.com/haesleinhuepf/napari-assistant/raw/main/docs/save_and_load.png)

After loading a workflow, make sure that the right input images are selected.

### Code generation

The napari-assistant allows exporting the given workflow as Python script and Jupyter Notebook. 

![img.png](https://github.com/haesleinhuepf/napari-assistant/raw/main/docs/code_generator.png)

Furthermore, if you have the [napari-script-editor](https://www.napari-hub.org/plugins/napari-script-editor) installed,
you can also send the current workflow as code to the script editor from the same menu.

![img.png](https://github.com/haesleinhuepf/napari-assistant/raw/main/docs/napari_script_editor.png)

### Plugin generation

There is also a Napari plugin generator available. Check out [its documentation](https://github.com/haesleinhuepf/napari-assistant-plugin-generator) to learn how napari-assistant compatible plugins can be generated directly from within the assistant.

## Installation

It is recommended to install the napari-assistant via one of the plugins that use it as graphical user interface.
You find a complete list of plugins that use the assistant [on the napari-hub](https://www.napari-hub.org/?search=napari-assistant&sort=relevance).
Multiple of these plugins come bundled when installing [devbio-napari](https://www.napari-hub.org/plugins/devbio-napari).

## For developers

If you want to make your napari-plugin accessible from the napari-assistant, consider programming functions with a simple 
interface that consume images, labels, integers, floats and strings. Annotate input and return types, e.g. like this:
```python
def example_function_widget(image: ""napari.types.ImageData"") -> ""napari.types.LabelsData"":
    from skimage.filters import threshold_otsu
    binary_image = image > threshold_otsu(image)

    from skimage.measure import label
    return label(binary_image)
```

Furthermore, please add your function to the napari.yaml which uses [npe2](https://github.com/napari/npe2):
```
name: napari-npe2-test
display_name: napari-npe2-test
contributions:
  commands: 
    - id: napari-npe2-test.make_magic_widget
      python_name: napari_npe2_test._widget:example_magic_widget
      title: Make example magic widget
  widgets:
    - command: napari-npe2-test.make_magic_widget
      display_name: Segmentation / labeling > Otsu Labeling (nnpe2t)
```

To put it in the right button within the napari-assistant, please use one of the following prefixes for the `display_name`:
* `Filtering / noise removal > `
* `Filtering / background removal > `
* `Filtering > `
* `Image math > `
* `Transform > `
* `Projection > `
* `Segmentation / binarization > `
* `Segmentation / labeling > `
* `Segmentation post-processing > `
* `Measurement > `
* `Label neighbor filters > `
* `Label filters > `
* `Visualization > `

You find a fully functional example [here](https://github.com/haesleinhuepf/napari-npe2-test).

Last but not least, to make your napari-plugin is listed in the napari-hub when searching for ""napari-assistant"", make sure
you mention it in your `readme`.

## Feedback welcome!

The napari-assistant is developed in the open because we believe in the open source community. Feel free to drop feedback as [github issue](https://github.com/haesleinhuepf/napari-assistant/issues) or via [image.sc](https://image.sc)

## Contributing

Contributions are very welcome. Please ensure
the test coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-assistant"" is free and open source software

## Acknowledgements
This project was supported by the Deutsche Forschungsgemeinschaft under Germany’s Excellence Strategy – EXC2068 - Cluster of Excellence ""Physics of Life"" of TU Dresden. 
This project has been made possible in part by grant number [2021-240341 (Napari plugin accelerator grant)](https://chanzuckerberg.com/science/programs-resources/imaging/napari/improving-image-processing/) from the Chan Zuckerberg Initiative DAF, an advised fund of the Silicon Valley Community Foundation.

[BSD-3]: http://opensource.org/licenses/BSD-3-Clause

","['Framework :: napari', 'License :: OSI Approved :: BSD License', 'Topic :: Scientific/Engineering :: Image Processing', 'Topic :: Scientific/Engineering :: Information Analysis', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent']","['Bug Tracker, https://github.com/haesleinhuepf/napari-assistant/issues', 'Documentation, https://github.com/haesleinhuepf/napari-assistant/', 'Source Code, https://github.com/haesleinhuepf/napari-assistant', 'User Support, https://forum.image.sc/']",,,napari-assistant.Assistant,,,,,https://pypi.org/project/napari-assistant,https://github.com/haesleinhuepf/napari-assistant,
77,BacSeg,1.0.17,,,napari-bacseg,Piers Turner,Piers Turner <piers.turner@physics.ox.ac.uk>,,,"Bacterial segmentation and analysis platform than can inport/export files in multiple formats. Integrating many tools such as Cellpose, ColiCoords, Oufti/MicrobeTracker.",>=3.9,"['napari[all] >=0.4.19', 'torch', 'cellpose >=3.0.1', 'opencv-python', 'picassosr ==0.6.5', 'numpy', 'pyqt5', 'pyqt6', 'qtpy', 'scipy', 'natsort', 'tqdm', 'imagecodecs', 'tifffile', 'pandas', 'mat4py', 'glob2', 'matplotlib', 'scikit-image', 'roifile', 'openpyxl', 'shapely', 'colicoords', 'psutil', 'xmltodict', 'astropy', 'tiler', 'imageio-ffmpeg', 'aicspylibczi', 'czifile', 'omnipose', 'h5py', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-BacSeg

[![License BSD-3](https://img.shields.io/pypi/l/napari-bacseg.svg?color=green)](https://github.com/piedrro/napari-bacseg/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-bacseg.svg?color=green)](https://pypi.org/project/napari-bacseg)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-bacseg.svg?color=green)](https://python.org)
[![tests](https://github.com/piedrro/napari-bacseg/workflows/tests/badge.svg)](https://github.com/piedrro/napari-bacseg/actions)
[![codecov](https://codecov.io/gh/piedrro/napari-bacseg/branch/main/graph/badge.svg)](https://codecov.io/gh/piedrro/napari-bacseg)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-bacseg)](https://napari-hub.org/plugins/napari-bacseg)

Bacterial segmentation and analysis platform than can inport/export files in multiple formats. Integrating many tools such as Cellpose, ColiCoords, Oufti/MicrobeTracker.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installing BacSeg

Create a virtual environment and then activate it:

    conda create –-name napari-bacseg python==3.9
    conda activate napari-bacseg

Install `napari-bacseg` via [pip]:

    pip install napari-bacseg

Launch Napari:

    Napari

Select **napari-bacseg** from the **Plugins** dropdown menu


## Installing BacSeg From GitHub

    conda create –-name napari-bacseg python==3.9
    conda activate napari-bacseg
    conda install -c anaconda git
    conda update --all

    pip install napari[all]

    pip install git+https://github.com/piedrro/napari-bacseg.git

## Updating BacSeg From Github
Once you have installed the plugin, you can update the plugin by running the following commands:

    pip install git+https://github.com/piedrro/napari-bacseg.git

## GPU Installation
 Once you have installed the plugin, you can install the GPU version of the plugin by running the following commands:

    pip uninstall torch torchvision torchaudio -y
    pip3 install torch torchvision --index-url https://download.pytorch.org/whl/cu118

If the latest CUDA versions don't work, try an older version like cuda 11.3:

    pip uninstall torch torchvision torchaudio -y
    pip3 install torch torchvision --index-url https://download.pytorch.org/whl/cu113




## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-bacseg"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/piedrro/napari-bacseg/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Framework :: napari', 'Environment :: Plugins', 'License :: OSI Approved :: BSD License', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent']","['Homepage, https://github.com/piedrro/napari-bacseg', 'Bug Tracker, https://github.com/piedrro/napari-bacseg/issues']",,,napari-bacseg.make_qwidget,,,,,https://pypi.org/project/napari-bacseg,,
78,Bounding Box,0.0.7,2023-04-12,2023-07-28,napari-bbox,David Bauer,dbauer@brc.hu,BSD-3-Clause,https://github.com/bauerdavid/napari-bbox,A new layer for bounding boxes in 2+ dimensions,>=3.9,"['numpy', 'magicgui', 'qtpy', 'napari >=0.4.15', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-bbox

[![License BSD-3](https://img.shields.io/pypi/l/napari-bbox.svg?color=green)](https://github.com/bauerdavid/napari-bbox/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-bbox.svg?color=green)](https://pypi.org/project/napari-bbox)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-bbox.svg?color=green)](https://python.org)
[![tests](https://github.com/bauerdavid/napari-bbox/workflows/tests/badge.svg)](https://github.com/bauerdavid/napari-bbox/actions)
[![codecov](https://codecov.io/gh/bauerdavid/napari-bbox/branch/main/graph/badge.svg)](https://codecov.io/gh/bauerdavid/napari-bbox)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-bbox)](https://napari-hub.org/plugins/napari-bbox)

A new layer for bounding boxes in 2+ dimensions

> **Note**: This plugin was originally part of [Annotation Toolbox](https://www.napari-hub.org/plugins/napari-nD-annotator), and was separated to allow other plugins to utilize it.

----------------------------------

## Demo


https://user-images.githubusercontent.com/36735863/227506511-d672ce5c-eab5-436f-a7fd-6080e118a9a8.mp4


This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-bbox` via [pip]:

    pip install napari-bbox



To install latest development version :

    pip install git+https://github.com/bauerdavid/napari-bbox.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-bbox"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.


[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/bauerdavid/napari-bbox/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/bauerdavid/napari-bbox/issues', 'Documentation, https://github.com/bauerdavid/napari-bbox#README.md', 'Source Code, https://github.com/bauerdavid/napari-bbox', 'User Support, https://github.com/bauerdavid/napari-bbox/issues']",napari-bbox.get_reader,,napari-bbox.create_bounding_box_layer_widget,,['*.csv'],,,https://pypi.org/project/napari-bbox,https://github.com/bauerdavid/napari-bbox,
79,Bee annotator,0.0.1,,,napari-bee-annotator,Florian Aymanns,florian.aymanns@epfl.ch,BSD-3-Clause,,Napari plugin for the annotation of bee entering and leaving the hive.,>=3.8,"['numpy', 'magicgui', 'qtpy', 'scikit-image', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","<img style=""float: right;"" src=""https://imaging.epfl.ch/resources/logo-for-gitlab.svg"">


# napari-bee-annotator
Developed by the [EPFL Center for Imaging](https://imaging.epfl.ch/) for the [Mobile Robotic Systems Group](https://www.epfl.ch/labs/mobots/) in Dec 2023.
This napari plugin provides an easy way for the researches to annotate honey bees leaving/entering the hive. The annotations will serve as ground truth for the validation of various automated animal tracking approaches.

[![License BSD-3](https://img.shields.io/pypi/l/napari-bee-annotator.svg?color=green)](https://github.com/EPFL-Center-for-Imaging/napari-bee-annotator/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-bee-annotator.svg?color=green)](https://pypi.org/project/napari-bee-annotator)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-bee-annotator.svg?color=green)](https://python.org)
[![tests](https://github.com/EPFL-Center-for-Imaging/napari-bee-annotator/workflows/tests/badge.svg)](https://github.com/EPFL-Center-for-Imaging/napari-bee-annotator/actions)
[![codecov](https://codecov.io/gh/EPFL-Center-for-Imaging/napari-bee-annotator/branch/main/graph/badge.svg)](https://codecov.io/gh/EPFL-Center-for-Imaging/napari-bee-annotator)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-bee-annotator)](https://napari-hub.org/plugins/napari-bee-annotator)

## Installation

You can install `napari-bee-annotator` via [pip]:

    pip install napari-bee-annotator



To install latest development version :

    pip install git+https://github.com/EPFL-Center-for-Imaging/napari-bee-annotator.git

## Getting started

1. Open napari with the plugin and your video using the following command `napari -w napari-bee-annotator --plugin video path/to/video.mp4`. Note that you need to have [napari_video](https://www.napari-hub.org/plugins/napari_video) installed to read `mp4` files.

2. Select the orientation of your video: horizontal/vertical refers to the direction of the bee's leaving/entering the hive.

3. Start annotating: A simple left click indicates a bee moving up or to the left depending on the orientation selected. You can hold down the shift key to annotate a bee moving down or to the right. Annotations can be deleted with a right click on the annotation you want to delete. To move to the next frame, you can either hold down `ctrl` and scroll with the mouse wheel or click on the play button. Playback parameters, such as the playback speed, can be changed by right clicking on the play button.

4. Saving and loading tracks: To save a tracks layer selected from the list of layers and click on `File > Save selected layers`. Choose a name and the csv extension. If you want to continue to work on the annotations for a specific video, you first have to load the corresponding csv file by clicking on `Open with Plugin > Open file(s)...`. Select the file you want to load and click on open. A dialog should pop up that asks you to select the reader to use for loading the csv file. Select `Bee annotator`. Lastly, you have to tell the plugin to interact with the layer you just loaded by selecting it in the `Tracks layer` drop down menu.

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-bee-annotator"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/EPFL-Center-for-Imaging/napari-bee-annotator/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/EPFL-Center-for-Imaging/napari-bee-annotator/issues', 'Documentation, https://github.com/EPFL-Center-for-Imaging/napari-bee-annotator#README.md', 'Source Code, https://github.com/EPFL-Center-for-Imaging/napari-bee-annotator', 'User Support, https://github.com/EPFL-Center-for-Imaging/napari-bee-annotator/issues']",napari-bee-annotator.get_reader,napari-bee-annotator.write_single_tracks_layer,napari-bee-annotator.make_container_widget,,['*.csv'],['.csv'],,https://pypi.org/project/napari-bee-annotator,,
80,Bfio,0.0.4,2023-10-28,2023-10-28,napari-bfio,Sameeul B Samee,sameeul.samee@nih.gov,MIT,https://pypi.org/project/napari-bfio,A plugin to read and write images using bfio within napari,>=3.8,"['numpy', 'bfio >=2.3.1', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'""]","# napari-bfio

[![License MIT](https://img.shields.io/pypi/l/napari-bfio.svg?color=green)](https://github.com/PolusAI/napari-bfio/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-bfio.svg?color=green)](https://pypi.org/project/napari-bfio)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-bfio.svg?color=green)](https://python.org)
[![tests](https://github.com/PolusAI/napari-bfio/workflows/tests/badge.svg)](https://github.com/PolusAI/napari-bfio/actions)
[![codecov](https://codecov.io/gh/PolusAI/napari-bfio/branch/main/graph/badge.svg)](https://codecov.io/gh/PolusAI/napari-bfio)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-bfio)](https://napari-hub.org/plugins/napari-bfio)

A plugin to read and write images using bfio within napari

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-bfio` via [pip]:

    pip install napari-bfio

`napari-bfio` depends on `bfio` package to read/write the data. By default, `bfio` package and the core dependencies (numpy, tifffile, imagecodecs, scyjava) are installed during the installation process of `napari-bfio`.

To install latest development version :

    pip install git+https://github.com/PolusAI/napari-bfio.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [MIT] license,
""napari-bfio"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/PolusAI/napari-bfio/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: MIT License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/PolusAI/napari-bfio/issues', 'Documentation, https://github.com/PolusAI/napari-bfio#README.md', 'Source Code, https://github.com/PolusAI/napari-bfio', 'User Support, https://github.com/PolusAI/napari-bfio/issues']",napari-bfio.get_reader,napari-bfio.write_single_image,,,"['*.ome.tiff', '*.ome.tif', '*.ome.zarr', '*.tiff', '*.1sc', '*.2fl', '*.acff', '*.afi', '*.afm', '*.aim', '*.al3d', '*.ali', '*.am', '*.amiramesh', '*.apl', '*.arf', '*.avi', '*.bif', '*.bin', '*.bip', '*.bmp', '*.btf', '*.c01', '*.cfg', '*.ch5', '*.cif', '*.cr2', '*.crw', '*.cxd', '*.dat', '*.db', '*.dcm', '*.dib', '*.dicom', '*.dm2', '*.dm3', '*.dm4', '*.dti', '*.dv', '*.eps', '*.epsi', '*.exp', '*.fdf', '*.fff', '*.ffr', '*.fits', '*.flex', '*.fli', '*.frm', '*.gel', '*.gif', '*.grey', '*.h5', '*.hdf', '*.hdr', '*.hed', '*.his', '*.htd', '*.hx', '*.i2i', '*.ics', '*.ids', '*.im3', '*.img', '*.img', '*.ims', '*.inr', '*.ipl', '*.ipm', '*.ipw', '*.j2k', '*.jp2', '*.jpeg', '*.jpf', '*.jpg', '*.jpk', '*.jpx', '*.klb', '*.l2d', '*.labels', '*.lei', '*.lif', '*.liff', '*.lim', '*.lms', '*.lof', '*.lsm', '*.map', '*.mdb', '*.mea', '*.mnc', '*.mng', '*.mod', '*.mov', '*.mrc', '*.mrcs', '*.mrw', '*.msr', '*.mtb', '*.mvd2', '*.naf', '*.nd', '*.nd2', '*.ndpi', '*.ndpis', '*.nef', '*.nhdr', '*.nii', '*.nii.gz', '*.nrrd', '*.obf', '*.obsep', '*.oib', '*.oif', '*.oir', '*.omp2info', '*.par', '*.pbm', '*.pcoraw', '*.pcx', '*.pds', '*.pgm', '*.pic', '*.pict', '*.png', '*.pnl', '*.ppm', '*.pr3', '*.ps', '*.psd', '*.qptiff', '*.r3d', '*.raw', '*.rcpnl', '*.rec', '*.res', '*.scn', '*.sdt', '*.seq', '*.sif', '*.sld', '*.sldy', '*.sm2', '*.sm3', '*.spc', '*.spe', '*.spi', '*.st', '*.stk', '*.stp', '*.svs', '*.sxm', '*.tf2', '*.tf8', '*.tfr', '*.tga', '*.tif', '*.tif', '*.tiff', '*.tnb', '*.top', '*.txt', '*.v', '*.vff', '*.vms', '*.vsi', '*.vws', '*.wat', '*.wpi', '*.xdce', '*.xlef', '*.xqd', '*.xqf', '*.xv', '*.xys', '*.zfp', '*.zfr', '*.zvi']","['.ome.tiff', '.ome.tif', '.ome.zarr']","['.ome.tiff', '.ome.tif', '.ome.zarr']",https://pypi.org/project/napari-bfio,,
81,BigFISH smFISH Analysis,0.4,2023-04-17,2023-06-18,napari-bigfish,Volker Baecker,volker.baecker@mri.cnrs.fr,MIT,https://github.com/MontpellierRessourcesImagerie/napari-bigfish,A napari-plugin providing an alternative GUI for Big-FISH. Big-FISH is a python package for the analysis of smFISH images.,>=3.8,"['numpy', 'magicgui', 'qtpy', 'pyperclip', 'big-fish', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]"," # napari-bigfish

[![License MIT](https://img.shields.io/pypi/l/napari-bigfish.svg?color=green)](https://github.com/MontpellierRessourcesImagerie/napari-bigfish/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-bigfish.svg?color=green)](https://pypi.org/project/napari-bigfish)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-bigfish.svg?color=green)](https://python.org)
[![tests](https://github.com/MontpellierRessourcesImagerie/napari-bigfish/workflows/tests/badge.svg)](https://github.com/MontpellierRessourcesImagerie/napari-bigfish/actions)
[![codecov](https://codecov.io/gh/MontpellierRessourcesImagerie/napari-bigfish/branch/main/graph/badge.svg)](https://codecov.io/gh/MontpellierRessourcesImagerie/napari-bigfish)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-bigfish)](https://napari-hub.org/plugins/napari-bigfish)

A napari-plugin providing an alternative GUI for [Big-FISH](https://github.com/fish-quant/big-fish). Big-FISH is a python package for the analysis of smFISH images.

The plugin provides a graphical user interface for some of the functionality in Big-FISH. Currently implemented are:

 * Gaussian-background subtraction
 * FISH-spot detection with 
	* Elimination of duplicates
	* Auto-detection of threshold
* Dense-region decomposition

The plugin further implements by itself:

* Counting of spots per cell, inside and outside of the nucleus
* Batch processing on a list of images


You can find the user and the api-documentation of napari-bigfish [here](https://montpellierressourcesimagerie.github.io/napari-bigfish/).
 

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

## Installation

You can install `napari-bigfish` via [pip]:

    pip install napari-bigfish


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.


## License

Distributed under the terms of the [MIT] license,
""napari-bigfish"" is free and open source software


## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 4 - Beta', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: MIT License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/MontpellierRessourcesImagerie/napari-bigfish/issues', 'Documentation, https://montpellierressourcesimagerie.github.io/napari-bigfish/', 'Source Code, https://github.com/MontpellierRessourcesImagerie/napari-bigfish', 'User Support, https://github.com/MontpellierRessourcesImagerie/napari-bigfish/issues']",,,napari-bigfish.make_qwidget,napari-bigfish.make_sample_data,,,,https://pypi.org/project/napari-bigfish,https://github.com/MontpellierRessourcesImagerie/napari-bigfish,
82,napari-bigwarp,0.0.1,2022-07-06,2023-06-18,napari-bigwarp,Ben Kantor,benkantor@gmail.com,BSD-3-Clause,https://github.com/bkntr/napari-bigwarp,BigWarp-like interface for napari,>=3.7,"['napari-plugin-engine (>=0.1.4)', 'numpy', 'opencv-contrib-python', 'opencv-python']","# napari-bigwarp

[![License](https://img.shields.io/pypi/l/napari-bigwarp.svg?color=green)](https://github.com/bkntr/napari-bigwarp/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-bigwarp.svg?color=green)](https://pypi.org/project/napari-bigwarp)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-bigwarp.svg?color=green)](https://python.org)
[![tests](https://github.com/bkntr/napari-bigwarp/workflows/tests/badge.svg)](https://github.com/bkntr/napari-bigwarp/actions)
[![codecov](https://codecov.io/gh/bkntr/napari-bigwarp/branch/main/graph/badge.svg)](https://codecov.io/gh/bkntr/napari-bigwarp)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-bigwarp)](https://napari-hub.org/plugins/napari-bigwarp)

BigWarp-like interface for napari

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/stable/index.html
-->

## Installation

You can install `napari-bigwarp` via [pip]:

    pip install napari-bigwarp



To install latest development version :

    pip install git+https://github.com/bkntr/napari-bigwarp.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-bigwarp"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/bkntr/napari-bigwarp/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/


","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Software Development :: Testing']","['Bug Tracker, https://github.com/bkntr/napari-bigwarp/issues', 'Documentation, https://github.com/bkntr/napari-bigwarp#README.md', 'Source Code, https://github.com/bkntr/napari-bigwarp', 'User Support, https://github.com/bkntr/napari-bigwarp/issues']",,,napari-bigwarp.BigWarpQWidget,,,,,https://pypi.org/project/napari-bigwarp,https://github.com/bkntr/napari-bigwarp,
83,napari-bil-data-viewer,0.6.0,2022-02-10,2023-06-18,napari-bil-data-viewer,Alan M Watson,alan.watson@pitt.edu,BSD-3-Clause,https://github.com/brain-image-library/napari-bil-data-viewer,Napari plugin for viewing Brain Image Library datasets,>=3.8,"['napari[all]', 'napari-plugin-engine >=0.1.4', 'scikit-image', 'fsspec', 'requests', 'aiohttp', 'imagecodecs', 'beautifulsoup4', 'dask', 'neurom ==3.2.2', 'napari-ome-zarr ==0.5.2']","<p href=""https://www.brainimagelibrary.org/"">
    <align=""center"" width=""100%"">
    <img width=""100%"" src=""https://i.imgur.com/ljZKq8h.png"">
</p>


# Description

View datasets archived at the **[Brain Image Library](https://www.brainimagelibrary.org/)**.

**NOTE: This plugin is under early development.  Currently, only a subset of single-channel, fMOST datasets which include projections are available to view.  An example can be found [here]( https://download.brainimagelibrary.org/2b/da/2bdaf9e66a246844/mouseID_405429-182725/).



![Plugin Demo GIF](https://imgur.com/gkDCsMd.gif ""Plugin Demo GIF"")



### Features

* Multiscale Rendering
  * In datasets that include multiple resolution representations of the data, each resolution can be combined to improve the speed of browsing and user experience.  An example of a dataset with multiple resolution projections can be found [here](https://download.brainimagelibrary.org/2b/da/2bdaf9e66a246844/mouseID_405429-182725/).
  * All datasets included in the current release of napari-bil-data-viewer use multi-resolution datasets.
* 3D rendering of whole datasets.  The lowest resolution is used for rendering.  Currently, this is a limitation imposed by napari.
* The plugin does NOT require a BIL account as datasets are already accessible via https.

### Known Issues / limitations
* Currently the only datasets that are available are those which have been manually selected by the developers.  If you would like a specific dataset to be included please consider adding the dataset(s) to the [dataset_info.py](https://github.com/brain-image-library/napari-bil-data-viewer/blob/main/napari_bil_data_viewer/dataset_info.py) file and submitting a pull request.
* To inquire about this plugin please contact Brain Image Library support:  bil-support@psc.edu
* The plugin is still under development.  We appreciate all [reports of issues / errors](https://github.com/brain-image-library/napari-bil-data-viewer/issues) which occur during use.


----------------------------------

This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/docs/plugins/index.html
-->

## Installation

Option #1: Install plugin via the napari plugin menu

1. Menu: Plugins >> Install/Uninstall Plugins
2. Search: napari-bil-data-viewer
3. Select install

Option #2:  Install a fresh python virtual environment

```bash
# Example of venv creation using conda
conda create -y -n bil-viewer python=3.8
conda activate bil-viewer

# Install napari-bil-data-viewer
pip install napari-bil-data-viewer

# Run Napari
napari
```

## Contributing

Please consider contributing to this project!  Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-bil-data-viewer"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/brain-image-library/napari-bil-data-viewer/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/

## Change Log:

##### <u>v0.1.0:</u>

Initial release.

<u>**v0.1.1 & v0.1.2:**</u>

Changes to documentation

<u>**v0.1.3:**</u>

Added all available summary fMOST datasets

<u>**v0.2.0:**</u>

Added support for SWC neuron tracings

<u>**v0.3.0:**</u>

Added support for multiscale OME zarr data

<u>**v0.4.0:**</u>

Add scale controls for layers

<u>**v0.4.2:**</u>

Add URL input to visualize image stacks (tif, tiff, jp2)

<u>**v0.5.0:**</u>

Split the plugin into 5 widgets:<br/>
- Load Curated Datasets
- Load Image Stack From URL
- Load Multiscale Data From URL
- Load Neuron Morphology From URL
- Layer Scale Controls

<u>**v0.5.1:**</u>

Add metadata link to curated datasets

<u>**v0.6.0:**</u>

Add widget to visualize histology RGB tiffs
","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/brain-image-library/napari-bil-data-viewer/issues', 'Documentation, https://github.com/brain-image-library/napari-bil-data-viewer#README.md', 'Source Code, https://github.com/brain-image-library/napari-bil-data-viewer', 'User Support, https://github.com/brain-image-library/napari-bil-data-viewer']",napari-bil-data-viewer.napari_get_reader,,napari-bil-data-viewer.LoadCuratedDatasets,,['*'],,,https://pypi.org/project/napari-bil-data-viewer,https://github.com/brain-image-library/napari-bil-data-viewer,
84,napari bio sample data,0.0.4,2022-08-18,2023-06-18,napari-bio-sample-data,Chi-Li Chiu,cchiu@chanzuckerberg.com,BSD-3-Clause,https://github.com/chili-chiu/napari-bio-sample-data,a sample data plugin for bio-related demos,>=3.8,"['numpy', 'fsspec', 'zarr (>=2.12.0)', 'dask', 's3fs', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'""]","# napari-bio-sample-data

[![License](https://img.shields.io/pypi/l/napari-bio-sample-data.svg?color=green)](https://github.com/chili-chiu/napari-bio-sample-data/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-bio-sample-data.svg?color=green)](https://pypi.org/project/napari-bio-sample-data)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-bio-sample-data.svg?color=green)](https://python.org)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-bio-sample-data)](https://napari-hub.org/plugins/napari-bio-sample-data)

a sample data plugin for bio-related demos

----------------------------------
This plugin contains 5 sample datasets with additional napari layer types:

(1) 3D EM dataset (image + points + vectors)  
Image credit: Alister Burt  
The [original data](https://github.com/alisterburt/napari-cryo-et-demo) is down-sampled to have smaller file size.  
<img width=""300"" alt=""image"" src=""https://user-images.githubusercontent.com/89602983/178569428-7daa2eb8-a3ff-4c0e-8e5f-4f615a55684f.png"">

(2) 2D skin RGB dataset (image + shape)  
Image credit: skimage.data.skin  
<img width=""300"" alt=""image"" src=""https://user-images.githubusercontent.com/89602983/178569580-bf77e55c-71cc-4883-9fe5-ed94e05f2a29.png"">
  
(3) 3D nuclei dataset (image + label + surface)  
Image credit: skimage.data.cells3d  
<img width=""300"" alt=""image"" src=""https://user-images.githubusercontent.com/89602983/178569701-7c9b1cc3-c1c3-4e54-8ca0-fb2b530f858e.png"">

(4) 2D timelapse dataset (image + points + tracks)  
Image credit: [Cell Tracking Challenge](http://celltrackingchallenge.net/2d-datasets/)  
The original data is cropped to have smaller file size.  
<img width=""300"" alt=""image"" src=""https://user-images.githubusercontent.com/89602983/178569846-b995d1cb-c1ec-4363-ba1a-71243ffea4e0.png"">

(5) large multi-resolution 3D EM dataset  
Image credit: [Janelia Open Organelle](https://openorganelle.janelia.org/datasets/jrc_hela-1)   
This plugin only accesses 2 lower resolution levels.  
<img width=""300"" alt=""image"" src=""https://user-images.githubusercontent.com/89602983/178570136-6f59ba3c-d687-446c-9f5e-1df567a62948.png"">

Datasets (1)-(4) are stored locally.   
Dataset (5) is downloaded and temporarily stored on RAM when accessed.    

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/index.html
-->

## Installation

You can install `napari-bio-sample-data` via [pip]:

    pip install napari-bio-sample-data

To install latest development version :

    pip install git+https://github.com/chili-chiu/napari-bio-sample-data.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-bio-sample-data"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/chili-chiu/napari-bio-sample-data/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/chili-chiu/napari-bio-sample-data/issues', 'Documentation, https://github.com/chili-chiu/napari-bio-sample-data#README.md', 'Source Code, https://github.com/chili-chiu/napari-bio-sample-data', 'User Support, https://github.com/chili-chiu/napari-bio-sample-data/issues']",,,,napari-bio-sample-data.tomo_data,,,,https://pypi.org/project/napari-bio-sample-data,https://github.com/chili-chiu/napari-bio-sample-data,
85,napari-bioformats,0.2.1,2021-07-09,2023-06-16,napari-bioformats,Talley Lambert,talley.lambert@gmail.com,GPL-3.0,https://github.com/tlambert03/napari-bioformats,"Bioformats for napari, using pims",>=3.7,"['jpype1', 'napari-plugin-engine (>=0.1.4)', 'numpy', 'ome-types', 'pims', 'requests', ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'""]","# napari-bioformats

[![License](https://img.shields.io/pypi/l/napari-bioformats.svg?color=green)](https://github.com/napari/napari-bioformats/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-bioformats.svg?color=green)](https://pypi.org/project/napari-bioformats)
[![Conda](https://img.shields.io/conda/v/conda-forge/napari-bioformats)](https://anaconda.org/conda-forge/napari-bioformats)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-bioformats.svg?color=green)](https://python.org)
[![tests](https://github.com/tlambert03/napari-bioformats/workflows/tests/badge.svg)](https://github.com/tlambert03/napari-bioformats/actions)
[![codecov](https://codecov.io/gh/tlambert03/napari-bioformats/branch/master/graph/badge.svg)](https://codecov.io/gh/tlambert03/napari-bioformats)

Bioformats plugin for napari using
[pims-bioformats](http://soft-matter.github.io/pims/v0.5/bioformats.html)

----------------------------------

## Use this plugin as a fallback!

Anyone coming to napari from the Fiji/ImageJ world will likely be aware of the
_incredible_ [Bio-Formats](https://docs.openmicroscopy.org/bio-formats/6.6.1/index.html)
library.  A heroic effort, built over years, to read
[more than a 100 file formats](https://docs.openmicroscopy.org/bio-formats/6.6.1/supported-formats.html).  Naturally, we want some of that goodness for `napari` ... hence this plugin.

**However:** it's important to note that this plugin _still_
requires having a java runtime engine installed.  This is easy enough to do
(the plugin will ask to install it for you if you're in a `conda` environment), but
it definitely makes for a more complicated environment setup, it's not very
""pythonic"", and the performance will likely not feel as snappy as a native ""pure""
python module.

So, before you reflexively install this plugin to fill that bio-formats
sized hole in your python heart, consider trying some of the other pure-python
plugins designed to read your format of interest:

- **Zeiss (.czi)**: [napari-aicsimageio](https://github.com/AllenCellModeling/napari-aicsimageio), [napari-czifile2](https://github.com/BodenmillerGroup/napari-czifile2)
- **Nikon (.nd2)**: [napari-nikon-nd2](https://github.com/cwood1967/napari-nikon-nd2), [nd2-dask](https://github.com/DragaDoncila/nd2-dask)
- **Leica (.lif)**: [napari-aicsimageio](https://github.com/AllenCellModeling/napari-aicsimageio)
- **Olympus (.oif)**: no plugin?  (but see [oiffile](https://pypi.org/project/oiffile/) )
- **DeltaVision (.dv, .mrc)**: [napari-dv](https://github.com/tlambert03/napari-dv)

> *if you have a pure-python reader for a bio-formats-supported file format that
you'd like to see added to this list, please open an issue*

## Installation

The easiest way to install `napari-bioformats` is via [conda], from the
[conda-forge] channel:

    conda install -c conda-forge napari-bioformats

It is also possible to install via [pip], but you will need to have a working
JVM installed, and may need to set the `JAVA_HOME` environment variable

    pip install napari-bioformats

### First Usage

The first time you attempt to open a file with napari-bioformats, you will
likely notice a long delay as pims downloads the `loci_tools.jar` (speed will
depend on your internet connection). Subsequent files should open more quickly.

## License

Distributed under the terms of the [GPLv3] license,
""napari-bioformats"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

_This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template._

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[GPLv3]: https://opensource.org/licenses/GPL-3.0
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/tlambert03/napari-bioformats/issues
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[conda]: https://docs.conda.io/en/latest/
[conda-forge]: https://conda-forge.org
[PyPI]: https://pypi.org/


","['Development Status :: 4 - Beta', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: GNU General Public License v3 (GPLv3)', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Topic :: Software Development :: Testing']","['Bug Tracker, https://github.com/tlambert03/napari-bioformats/issues', 'Documentation, https://github.com/tlambert03/napari-bioformats#README.md', 'Source Code, https://github.com/tlambert03/napari-bioformats', 'User Support, https://github.com/tlambert03/napari-bioformats/issues']",napari-bioformats.napari_get_reader,,,,['*'],,,https://pypi.org/project/napari-bioformats,https://github.com/tlambert03/napari-bioformats,
86,BioImage.IO Model Manager,0.1.3,2022-07-11,2023-06-18,napari-bioimageio,,,,https://github.com/bioimage-io/napari-bioimageio,,>=3.7,"['napari', 'bioimageio.core (>=0.5.1)', 'PyYAML (>=6.0)']","# napari-bioimageio

napari plugin for managing AI models in the [BioImage Model Zoo](https://bioimage.io).

> **WARNING**: This is an alpha release. The API may change in future versions, and please feel free to create issues to report bugs or provide feedbacks.

![](assets/screenshot-model-manager-1.png)

## Installation

```
pip install napari-bioimageio
```

(If you don't have napari installed, run `pip install napari[pyqt5]`)

## Usage

This library is meant for helping developers to ease the handling of models in napari.

We provide a set of API functions for managing and selecting models.
### `show_model_manager()`
Show the model manager with a model list pulled from the BioImage Model Zoo, the user can explore all the available models, download or remove models.

### `show_model_selector(filter=None)`
Display a dialog for selecting models from the BioImage Model Zoo, the user can either select an existing model or download from the BioImage Model Zoo.

The selecte model information (a dictionary) will be returned if the user selected a model, otherwise it returns `None`.

Once the user selected the model, you can access the name, and also the file path to the model resource description file (via the `rdf_source` key). With the `bioimageio.core` library (installed via `pip install bioimageio.core` or `conda install -c conda-forge bioimageio.core`), you can run inference directly, the following examples shows how to implement it:

```python
# Popup a model selection dialog for choosing the model
model_info = show_model_selector(filter=nuclear_segmentation_model_filter)

if model_info:
  self.nucseg_model_source = model_info[""rdf_source""]
  # Load model 
  model_description = bioimageio.core.load_resource_description(model_info[""rdf_source""])
  input_image = imageio.imread(""./my-image.tif"")

  with bioimageio.core.create_prediction_pipeline(
      bioimageio_model=model_description
  ) as pipeline:
    output_image = bioimageio.core.prediction.predict_with_padding(
        pipeline, input_image, padding=padding
    )
```
Note: To run the models, you need to setup the conda environment properly according to the [installation guide of bioimageio.core](https://github.com/bioimage-io/core-bioimage-io-python#installation).

For more examples, see [this example notebook](https://github.com/bioimage-io/core-bioimage-io-python/blob/main/example/bioimageio-core-usage.ipynb) for `bioimageio.core`.

You can also access the weight files directly by searching the model folder (e.g. extract the model folder path via `os.path.dirname(model_description[""rdf_source""])`), this will be useful if you prefer to use your own model inference logic.
### `show_model_uploader()`
Display a dialog to instruct the user to upload a model package to the BioImage Model Zoo.
Currently, it only shows a message, in the future, we will try to support direct uploading with user's credentials obtained from Zenodo (a public data repository used by the BioImage Model Zoo to store models).

To create a BioImageIO-compatible model package, you can use the `build_model` function as demonstrated in [this notebook]((https://github.com/bioimage-io/core-bioimage-io-python/blob/main/example/bioimageio-core-usage.ipynb)).

## Development

- Install and set up development environment.

  ```sh
  pip install -r requirements_dev.txt
  ```

  This will install all requirements.
It will also install this package in development mode, so that code changes are applied immediately without reinstall necessary.

- Here's a list of development tools we use.
  - [black](https://pypi.org/project/black/)
  - [flake8](https://pypi.org/project/flake8/)
  - [mypy](https://pypi.org/project/mypy/)
  - [pydocstyle](https://pypi.org/project/pydocstyle/)
  - [pylint](https://pypi.org/project/pylint/)
  - [pytest](https://pypi.org/project/pytest/)
  - [tox](https://pypi.org/project/tox/)
- It's recommended to use the corresponding code formatter and linters also in your code editor to get instant feedback. A popular editor that can do this is [`vscode`](https://code.visualstudio.com/).
- Run all tests, check formatting and linting.

  ```sh
  tox
  ```

- Run a single tox environment.

  ```sh
  tox -e lint
  ```

- Reinstall all tox environments.

  ```sh
  tox -r
  ```

- Run pytest and all tests.

  ```sh
  pytest
  ```

- Run pytest and calculate coverage for the package.

  ```sh
  pytest --cov-report term-missing --cov=napari-bioimageio
  ```

- Continuous integration is by default supported via [GitHub actions](https://help.github.com/en/actions). GitHub actions is free for public repositories and comes with 2000 free Ubuntu build minutes per month for private repositories.
","['Framework :: napari', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.7']",,,,napari-bioimageio.QtBioImageIOModelManager,,,,,https://pypi.org/project/napari-bioimageio,https://github.com/bioimage-io/napari-bioimageio,
87,BIOMAG Annotator,0.0.3,,,napari-biomag-annotator,"Reka Hollandi, David Bauer",hunreka93@hotmail.com,BSD-3-Clause,,An annotator tool collection by the BIOMAG group.,>=3.8,"['napari', 'napari-plugin-engine >=0.1.4', 'napari-annotatorj', 'napari-nD-annotator', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-biomag-annotator

[![License BSD-3](https://img.shields.io/pypi/l/napari-biomag-annotator.svg?color=green)](https://github.com/biomag-lab/napari-biomag-annotator/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-biomag-annotator.svg?color=green)](https://pypi.org/project/napari-biomag-annotator)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-biomag-annotator.svg?color=green)](https://python.org)
[![tests](https://github.com/biomag-lab/napari-biomag-annotator/workflows/tests/badge.svg)](https://github.com/biomag-lab/napari-biomag-annotator/actions)
[![codecov](https://codecov.io/gh/biomag-lab/napari-biomag-annotator/branch/main/graph/badge.svg)](https://codecov.io/gh/biomag-lab/napari-biomag-annotator)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-biomag-annotator)](https://napari-hub.org/plugins/napari-biomag-annotator)

An annotator tool collection by the BIOMAG group.

This plugin allows object annotation on 2/3D images using 4 assisted annotation methods arising from two napari plugins:

- [napari-annotatorj](https://github.com/spreka/napari-annotatorj)
- [napari-nD-annotator](https://github.com/bauerdavid/napari-nD-annotator)

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-biomag-annotator` via [pip]:

    pip install napari[all]
    pip install napari-biomag-annotator



To install latest development version :

    pip install git+https://github.com/biomag-lab/napari-biomag-annotator.git


On Linux distributions, the following error may arise upon napari startup after the installation of the plugin: `Could not load the Qt platform plugin “xcb” in “” even though it was found`. In this case, the manual install of `libxcb-xinerama0` for Qt is required:

    sudo apt install libxcb-xinerama0

### Bundled napari app
The bundled application version of [napari](https://github.com/napari/napari/releases) allows the pip install of plugins in the .zip distribution. After installation of this release, napari-annotatorj can be installed from the `Plugins --> Install/Uninstall plugins...` menu by searching for its name and clicking on the `Install` button next to it.

### Script
Single-file install is supported on [**Windows**](#windows) and [Linux](#linux) (currently). It will create a virtual environment named `napariAnnotatorEnv` in the parent folder of the cloned repository, install the package via pip and start napari. It requires a valid Python install.

#### Windows
To start it, run in the Command prompt

    git clone https://github.com/biomag-lab/napari-biomag-annotator.git
    cd napari-biomag-annotator
    install.bat

Or download [install.bat](https://github.com/biomag-lab/napari-biomag-annotator/blob/main/install.bat) and run it from the Command prompt.

After install, you can use [startup_napari.bat](https://github.com/biomag-lab/napari-biomag-annotator/blob/main/startup_napari.bat) to activate your installed virtual environment and run napari. Run it from the Command prompt with:

    startup_napari.bat


#### Linux
To start it, run in the Terminal

    git clone https://github.com/biomag-lab/napari-biomag-annotator.git
    cd napari-annotatorj
    install.sh

Or download [install.sh](https://github.com/biomag-lab/napari-biomag-annotator/blob/main/install.sh) and run it from the Terminal.

After install, you can use [startup_napari.sh](https://github.com/biomag-lab/napari-biomag-annotator/blob/main/startup_napari.sh) to activate your installed virtual environment and run napari. Run it from the Terminal with:

    startup_napari.sh

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-biomag-annotator"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/biomag-lab/napari-biomag-annotator/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/biomag-lab/napari-biomag-annotator/issues', 'Documentation, https://github.com/biomag-lab/napari-biomag-annotator#README.md', 'Source Code, https://github.com/biomag-lab/napari-biomag-annotator', 'User Support, https://github.com/biomag-lab/napari-biomag-annotator/issues']",napari-biomag-annotator.get_reader,napari-biomag-annotator.write_multiple,napari-biomag-annotator.BIOMAGAnnotator,,['*.npy'],,['.npy'],https://pypi.org/project/napari-biomag-annotator,,
88,Bleaching Correction,0.0.1,2023-03-30,2023-06-18,napari-bleach-correct,Alexander Marx,a.marx95@gmx.de,MIT,https://github.com/marx-alex/napari-bleach-correct,A napari plugin to correct time-lapse images for photobleaching.,>=3.8,"['numpy', 'magicgui', 'qtpy', 'scikit-image', 'scipy', 'pyqtgraph', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-bleach-correct

[![License](https://img.shields.io/github/license/marx-alex/napari-bleach-correct)](https://github.com/marx-alex/napari-bleach-correct)
[![PyPI](https://img.shields.io/pypi/v/napari-bleach-correct.svg?color=green)](https://pypi.org/project/napari-bleach-correct)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-bleach-correct.svg?color=green)](https://python.org)
[![tests](https://github.com/marx-alex/napari-bleach-correct/workflows/tests/badge.svg)](https://github.com/marx-alex/napari-bleach-correct/actions)
[![codecov](https://codecov.io/gh/marx-alex/napari-bleach-correct/branch/main/graph/badge.svg)](https://codecov.io/gh/marx-alex/napari-bleach-correct)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-bleach-correct)](https://napari-hub.org/plugins/napari-bleach-correct)

## Bleach correction for napari

This plugin is a python implementation of three different algorithms for bleach correction and can be used 
to correct time-lapse images that lose intensity due to photobleaching. The implementation is based on the ImageJ 
plugin Bleach Corrector by Miura et al. All methods work with 2D and 3D time series.

Napari Bleach correction is easy to use:

![Demo](./data/demo.gif)

### Ratio Method

This is the simplest method. Every pixel in a frame is multiplied by the ratio from the mean intensity of the 
first frame to that of the *i-th* frame.

Assumptions:
* the mean intensity is constant through the time-lapse
* the background fluorescence is the same for every pixel and frame

Parameters:
* Background Intensity: Must be estimated

### Exponential Curve Fitting

Drift estimation of fluorescence signal by fitting the mean intensity to an exponential curve.
The image is corrected by the decay in the normalized exponential function.

Assumptions:
* time intervals between frames are equal

Parameters:
* Exponential Curve: Bleaching can be modelled as a mono- or bi-exponential curve

### Histogram Matching

Bleaching correction by matching histograms to a reference image.
The correct pixel values can be calculated by the cumulative distribution function
of a frame and its reference frame. This method introduced by Miura et al.

Parameters:
* Reference Frame: Match the frame's histogram with the first our neighbor frame 

**The Histogram Matching method using the neighbor frame as reference is a good start to correct bleaching.**
All methods are described in detail in Miura et al.

## References

* Miura K. [Bleach correction ImageJ plugin for compensating the photobleaching of time-lapse sequences.](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7871415/) F1000Res. 2020 Dec 21;9:1494. doi: 10.12688/f1000research.27171.1
* [Documentation of the ImageJ plugin](https://wiki.cmci.info/downloads/bleach_corrector)
----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/stable/index.html
-->

## Installation

You can install `napari-bleach-correct` via [pip]:

    pip install napari-bleach-correct



To install latest development version :

    pip install git+https://github.com/marx-alex/napari-bleach-correct.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [MIT] license,
""napari-bleach-correct"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/marx-alex/napari-bleach-correct/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Operating System :: OS Independent', 'License :: OSI Approved :: MIT License']","['Bug Tracker, https://github.com/marx-alex/napari-bleach-correct/issues', 'Documentation, https://github.com/marx-alex/napari-bleach-correct#README.md', 'Source Code, https://github.com/marx-alex/napari-bleach-correct', 'User Support, https://github.com/marx-alex/napari-bleach-correct/issues']",,,napari-bleach-correct.main_widget,napari-bleach-correct.make_sample_data,,,,https://pypi.org/project/napari-bleach-correct,https://github.com/marx-alex/napari-bleach-correct,
89,napari-blender-bridge,0.2.0,2023-04-17,2023-06-18,napari-blender-bridge,Robert Haase,robert.haase@tu-dresden.de,GNU GPL v3.0,https://github.com/haesleinhuepf/napari-blender-bridge,Transfer surface layers between Napari and Blender,>=3.8,"['napari-plugin-engine (>=0.1.4)', 'numpy', 'napari-tools-menu', 'napari-process-points-and-surfaces (>=0.4.2)', 'vedo']","# napari-blender-bridge



[![License](https://img.shields.io/pypi/l/napari-blender-bridge.svg?color=green)](https://github.com/haesleinhuepf/napari-blender-bridge/raw/master/LICENSE)

[![PyPI](https://img.shields.io/pypi/v/napari-blender-bridge.svg?color=green)](https://pypi.org/project/napari-blender-bridge)

[![Python Version](https://img.shields.io/pypi/pyversions/napari-blender-bridge.svg?color=green)](https://python.org)

[![tests](https://github.com/haesleinhuepf/napari-blender-bridge/workflows/tests/badge.svg)](https://github.com/haesleinhuepf/napari-blender-bridge/actions)

[![codecov](https://codecov.io/gh/haesleinhuepf/napari-blender-bridge/branch/master/graph/badge.svg)](https://codecov.io/gh/haesleinhuepf/napari-blender-bridge)

[![Development Status](https://img.shields.io/pypi/status/napari-blender-bridge.svg)](https://en.wikipedia.org/wiki/Software_release_life_cycle#Alpha)

[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-blender-bridge)](https://napari-hub.org/plugins/napari-blender-bridge)



Transfer surface layers between Napari and Blender. This plugin is young and has just limited functionality. Contributions are welcome.





![img.png](https://github.com/haesleinhuepf/napari-blender-bridge/raw/main/docs/easter.gif)



## Usage



This plugin has its own submenu with all functionality under `Tools > Blender`. You can start up Blender, send a surface layer to Blender, retrieve all meshes back as one surface layer and shut down Blender.



## Installation instructions



* Download and install [Blender 3.5](https://www.blender.org/download/). 

* Start Blender and click the menu `Edit > Preferences`. Activate `Developer extras`.



![img.png](https://github.com/haesleinhuepf/napari-blender-bridge/raw/main/docs/blender_preferences.png)



* It is recommended to run this plugin in a conda environment together with [devbio-napari](https://github.com/haesleinhuepf/devbio-napari), 

[vedo](https://vedo.embl.es/) and [napari-process-points-and-surfaces](https://github.com/haesleinhuepf/napari-process-points-and-surfaces).

To install these, please run these commands line-by-line:

```

mamba create --name napari-blender-env python=3.9 devbio-napari vedo -c conda-forge

mamba activate napari-blender-env

pip install napari-process-points-and-surfaces napari-blender-bridge

```



## Similar and related plugins



There are other plugins for working with surface meshes:

* [napari-stress](https://github.com/campaslab/napari-stress)

* [napari-pymeshlab](https://github.com/zacsimile/napari-pymeshlab)

* [napari-process-points-and-surfaces](https://github.com/haesleinhuepf/napari-process-points-and-surfaces)



## Contributing



Contributions are very welcome. Tests can be run with [tox], please ensure

the coverage at least stays the same before you submit a pull request.



## License



Distributed under the terms of the [GNU GPL v3.0] license,

""napari-blender-bridge"" is free and open source software



## Issues



If you encounter any problems, please [file an issue] along with a detailed description.



[napari]: https://github.com/napari/napari

[Cookiecutter]: https://github.com/audreyr/cookiecutter

[@napari]: https://github.com/napari

[MIT]: http://opensource.org/licenses/MIT

[BSD-3]: http://opensource.org/licenses/BSD-3-Clause

[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt

[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt

[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0

[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt

[cookiecutter-napari-plugin]: https://github.com/haesleinhuepf/cookiecutter-napari-assistant-plugin

[file an issue]: https://github.com/haesleinhuepf/napari-blender-bridge/issues

[napari]: https://github.com/napari/napari

[tox]: https://tox.readthedocs.io/en/latest/

[pip]: https://pypi.org/project/pip/

[PyPI]: https://pypi.org/

","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Science/Research', 'Framework :: napari', 'Topic :: Scientific/Engineering :: Image Processing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: GNU General Public License v3 (GPLv3)']",,,,,,,,,https://pypi.org/project/napari-blender-bridge,https://github.com/haesleinhuepf/napari-blender-bridge,
90,napari blob detection,0.0.2,2022-06-13,2023-06-18,napari-blob-detection,"Andy Sweet, Chi-Li Chiu","andrewdsweet@gmail.com, cchiu@chanzuckerberg.com",BSD-3-Clause,https://github.com/andy-sweet/napari-blob-detection,Detects blobs in images,>=3.8,"['napari (>=0.4.13)', 'numpy', 'scikit-image', 'magicgui', ""pytest ; extra == 'test'""]","# napari-blob-detection

[![License](https://img.shields.io/pypi/l/napari-blob-detection.svg?color=green)](https://github.com/andy-sweet/napari-blob-detection/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-blob-detection.svg?color=green)](https://pypi.org/project/napari-blob-detection)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-blob-detection.svg?color=green)](https://python.org)
[![tests](https://github.com/andy-sweet/napari-blob-detection/workflows/tests/badge.svg)](https://github.com/andy-sweet/napari-blob-detection/actions)
[![codecov](https://codecov.io/gh/andy-sweet/napari-blob-detection/branch/main/graph/badge.svg)](https://codecov.io/gh/andy-sweet/napari-blob-detection)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-blob-detection)](https://napari-hub.org/plugins/napari-blob-detection)

Detects blobs in images

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/stable/index.html
-->

This plugin consists of two widgets:

1. Detects blobs on images
2. Convert points layer to labels layer

----------------------------------

### Detects blobs on images

This widget uses [scikit-image's blob detection algorithms](https://scikit-image.org/docs/stable/auto_examples/features_detection/plot_blob.html) to detect bright blobs on dark backgrounds.

Parameters

- method: Laplacian of Gaussian (most accurate) or Difference of Gaussian (faster approximation) 
- image: Image layer for blob detection. Can be a 2D, 3D, or higher dimensionality image.
- dimensionality: users can specify if the image is 2D(+t) or 3D(+t).
- min sigma: the smallest blob size to detect
- max sigma: the largest blob size to detect
- threshold: the lower the threshold, the more low intensity blobs are detected. 

Output

Blobs are represented by the Points layer.
The size of each blob is proportional to `Points.feature['sigma']`,
which signifies the scale at which the feature point was found.

### Convert points layer to labels layer

This widget takes a points layer and converts it into a labels layer, with the image dimension matching the selected image layer.
By converting points to labels, users can leverage feature extraction functions that are available to labels to the detected points.

----------------------------------

## Installation

You can install `napari-blob-detection` via [pip]:

    pip install napari-blob-detection



To install latest development version :

    pip install git+https://github.com/andy-sweet/napari-blob-detection.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-blob-detection"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/andy-sweet/napari-blob-detection/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/


","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/andy-sweet/napari-blob-detection/issues', 'Documentation, https://github.com/andy-sweet/napari-blob-detection#README.md', 'Source Code, https://github.com/andy-sweet/napari-blob-detection', 'User Support, https://github.com/andy-sweet/napari-blob-detection/issues']",,,napari-blob-detection.detect_blobs_widget,,,,,https://pypi.org/project/napari-blob-detection,https://github.com/andy-sweet/napari-blob-detection,
91,Blossom,0.1.6,2022-07-07,2023-11-07,napari-blossom,Herearii Metuarea,herearii.metuarea@gmail.com,BSD-3-Clause,https://github.com/hereariim/napari-blossom,Segmentation of blossom apple tree images,>=3.8,"['numpy >=1.23.0', 'magicgui >=0.6.1', 'qtpy', 'opencv-python-headless >=4.7.0.68', 'tensorflow >=2.11.0', 'scikit-image >=0.19.3', 'napari', 'focal-loss >=0.0.7', 'pillow >=9.3.0', 'tqdm >=4.64.1', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-blossom

[![License BSD-3](https://img.shields.io/pypi/l/napari-blossom.svg?color=green)](https://github.com/hereariim/napari-blossom/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-blossom.svg?color=green)](https://pypi.org/project/napari-blossom)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-blossom.svg?color=green)](https://python.org)
[![tests](https://github.com/hereariim/napari-blossom/workflows/tests/badge.svg)](https://github.com/hereariim/napari-blossom/actions)
[![codecov](https://codecov.io/gh/hereariim/napari-blossom/branch/main/graph/badge.svg)](https://codecov.io/gh/hereariim/napari-blossom)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-blossom)](https://napari-hub.org/plugins/napari-blossom)

Segmentation of blossom apple tree images

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/index.html
-->

This plugin was written by Herearii Metuarea, student intern at LARIS (French laboratory located in Angers, France) in Imhorphen, french scientific team lead by David Rousseau (Full professor). This plugin was designed as part of the european project INVITE.

<img width=""86"" alt=""Logo-IRHS-h_2022_png_large"" src=""https://github.com/hereariim/napari-blossom/assets/93375163/750bbd60-ef3e-4148-9cbd-8a32e11252a4""> ![Logo-INRAE](https://github.com/hereariim/napari-blossom/assets/93375163/d7cc95a1-f09c-4430-8ac8-8962c1046767) ![logo2](https://github.com/hereariim/napari-blossom/assets/93375163/3b41c838-acc8-49a3-81f8-46d1305f43d3) ![logolaris1](https://github.com/hereariim/napari-blossom/assets/93375163/bf92a903-5810-4c43-aa28-573f96f64ff9) ![logo1](https://github.com/hereariim/napari-blossom/assets/93375163/f9361560-dd4f-49f4-955d-ffe41b5c014d)

## Installation

You can install `napari-blossom` via [pip]:

    pip install napari-blossom

To install latest development version :

    pip install git+https://github.com/hereariim/napari-blossom.git

## How does it works

This module offers a plugin that allows you to segment the images of the apple tree flowers. As input, you can enter a **single image** with the image selection widget. Once the image is entered in the napari window, you can segment the apple blossoms with the image segmentation widget by running the run button. The segmented image will appear in the napari window.

![Capture d'écran 2024-04-24 120758](https://github.com/hereariim/napari-blossom/assets/93375163/4f0c6ac7-b3a8-4849-9c5c-0ff5f35c8362)

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-blossom"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/hereariim/napari-blossom/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Software Development :: Testing']","['Bug Tracker, https://github.com/hereariim/napari-blossom/issues', 'Documentation, https://github.com/hereariim/napari-blossom#README.md', 'Source Code, https://github.com/hereariim/napari-blossom', 'User Support, https://github.com/hereariim/napari-blossom/issues']",napari-blossom.get_reader,napari-blossom.write_multiple,napari-blossom.model_segmentation,napari-blossom.make_sample_data,['*.npy'],,['.npy'],https://pypi.org/project/napari-blossom,https://github.com/hereariim/napari-blossom,
92,FooBar Segmentation,0.0.2,2023-10-27,2023-10-27,napari-boardgame-maker,Johannes Soltwedel,johannes_richard.soltwedel@tu-dresden.de,BSD-3-Clause,https://pypi.org/project/napari-boardgame-maker,Make boardgame tiles,>=3.8,"['numpy', 'magicgui', 'qtpy', 'napari-stl-exporter', 'vedo', 'napari-tools-menu', 'imagecodecs', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-boardgame-maker

[![License BSD-3](https://img.shields.io/pypi/l/napari-boardgame-maker.svg?color=green)](https://github.com/jo-mueller/napari-boardgame-maker/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-boardgame-maker.svg?color=green)](https://pypi.org/project/napari-boardgame-maker)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-boardgame-maker.svg?color=green)](https://python.org)
[![tests](https://github.com/jo-mueller/napari-boardgame-maker/workflows/tests/badge.svg)](https://github.com/jo-mueller/napari-boardgame-maker/actions)
[![codecov](https://codecov.io/gh/jo-mueller/napari-boardgame-maker/branch/main/graph/badge.svg)](https://codecov.io/gh/jo-mueller/napari-boardgame-maker)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-boardgame-maker)](https://napari-hub.org/plugins/napari-boardgame-maker)

This plugin turns 2D grayscale images into 3D-printable landscape tiles for a certain all-time tabletop boardgame which revolves around building settlements, obtaining ressources expanding and collecting more points than your opponents.

In short, images (for instance, [digital elevation models](https://en.wikipedia.org/wiki/Digital_elevation_model)) can be turned into surfaces like this:

| Image | Created tile|
| --- | --- |
| <img src=""https://github.com/jo-mueller/napari-boardgame-maker/raw/main/docs/imgs/sample.png""> | <img src=""https://github.com/jo-mueller/napari-boardgame-maker/raw/main/docs/imgs/sample_as_tile.png""> |

## Data

In principle, all 2D grayscale image data can be used to create a tile. However, using digital elevation models is particularly cool. Such data is publicly available at [OpenTopography.org](https://portal.opentopography.org/raster?opentopoID=OTSDEM.032021.4326.2). Acknowledgement:

```text
 NASA JPL. NASADEM Merged DEM Global 1 arc second V001. 2020, distributed by NASA EOSDIS Land Processes DAAC, https://doi.org/10.5067/MEaSUREs/NASADEM/NASADEM_HGT.001.
```
## Usage

To use the boardgame tile maker, open it from the plugins menu (`Plugins > napari-boardgame-maker: Boardgame Tile Maker`) or from the tools menu (`Tools > Boardgame tile maker (npbgm)`). There are a few steps and parameters to set before the tile can be created.

[](https://github.com/jo-mueller/napari-boardgame-maker/raw/main/docs/imgs/GUI_screenshot.jpg)

Clicking on `Make hexagon` and `Make number field` will create a hexagonal shape in the viewer (which will be the outline of the tile) and a circular field (which can later be used to put some markers, figures, chips, etc. On the center of the board).

![](https://github.com/jo-mueller/napari-boardgame-maker/raw/main/docs/imgs/sample_with_shapes.png)

The next step is to set the parameters for the tile. The following parameters can be set:

### Radii and sizes

The following sketch shows the different radii and sizes that can be set:

![](https://github.com/jo-mueller/napari-boardgame-maker/raw/main/docs/imgs/stride_and_town.png)

- `hexagon radius`: The radius of the hexagon (in pixels). Upon export, this will be rescaled to a desired physical size in mm.
- `number field radius`: The radius of the number field (in pixels). Can also be set in mm units. The pixels are changed accordingly if the size of the whole hexagon is changed.
- `stride`: The region next to the edge of the tile that should remain flat.
- `town radius`: A circular region around the edges of the hexagonal tiles that should remain flat.

### Topography

The following parameters can be set to create the topography of the tile:

![](https://github.com/jo-mueller/napari-boardgame-maker/raw/main/docs/imgs/slope_and_heights.png)

- `slope`: Adds a smooth transition of a given width between the edge of the cropped topography and the level of the base platte. Setting this to zero will result in a sharp edge.
- `z-multiplier`: The height of the topography is multiplied by this factor. This can be used to scale the topography to the desired height.
- `Plate thickness`: The thickness of the base plate (in mm).

### Export

- CLicking on `produce tile` will run the workflow to create the tile
- Clicking `Export` will open a dialog to save the tile as an `.stl` file. *Note*: The tile will be exported in the size of the hexagon radius. If the hexagon radius is set to 100 mm, the tile will be exported as a 100 mm hexagon.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-boardgame-maker` via [pip]:

    pip install napari-boardgame-maker


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-boardgame-maker"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']",,,napari-boardgame-maker.write_single_image,napari-boardgame-maker.boardgame_maker,napari-boardgame-maker.rhone_glacier,,['.npy'],,https://pypi.org/project/napari-boardgame-maker,,
93,Boids,0.0.1,2023-04-11,2023-06-18,napari-boids,Léo Guignard,leo.guignard@univ-amu.fr,BSD-3-Clause,https://github.com/leoguignard/napari-boids,A plugin to look at boids,>=3.8,"['numpy', 'scipy', 'magicgui', 'qtpy', 'napari', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-boids

[![License BSD-3](https://img.shields.io/pypi/l/napari-boids.svg?color=green)](https://github.com/leoguignard/napari-boids/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-boids.svg?color=green)](https://pypi.org/project/napari-boids)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-boids.svg?color=green)](https://python.org)
[![tests](https://github.com/leoguignard/napari-boids/workflows/tests/badge.svg)](https://github.com/leoguignard/napari-boids/actions)
[![codecov](https://codecov.io/gh/leoguignard/napari-boids/branch/main/graph/badge.svg)](https://codecov.io/gh/leoguignard/napari-boids)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-boids)](https://napari-hub.org/plugins/napari-boids)

A plugin to look at boids

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/index.html
-->

## Installation

You can install `napari-boids` via [pip]:

    pip install napari-boids



To install latest development version :

    pip install git+https://github.com/leoguignard/napari-boids.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-boids"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/leoguignard/napari-boids/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/leoguignard/napari-boids/issues', 'Documentation, https://github.com/leoguignard/napari-boids#README.md', 'Source Code, https://github.com/leoguignard/napari-boids', 'User Support, https://github.com/leoguignard/napari-boids/issues']",,,napari-boids.boid_viewer,,,,,https://pypi.org/project/napari-boids,https://github.com/leoguignard/napari-boids,
94,Box Manager,0.4.11,2023-04-11,2023-12-09,napari-boxmanager,Markus Stabrin,markus.stabrin@mpi-dortmund.mpg.de,MPL-2.0,https://github.com/MPI-Dortmund/napari-boxmanager,Particle selection tool for cryo-em,>=3.10,"['matplotlib', 'mrcfile', 'numpy <=1.23.5', 'pystardb >=0.4.2', 'napari >=0.4.17', 'pandas', 'scipy', 'tifffile', 'tqdm', ""mrcfile ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""tox ; extra == 'testing'""]","# napari-boxmanager

[![License Mozilla Public License 2.0](https://img.shields.io/pypi/l/napari-boxmanager.svg?color=green)](https://github.com/mstabrin/napari-boxmanager/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-boxmanager.svg?color=green)](https://pypi.org/project/napari-boxmanager)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-boxmanager.svg?color=green)](https://python.org)
[![tests](https://github.com/mstabrin/napari-boxmanager/workflows/tests/badge.svg)](https://github.com/mstabrin/napari-boxmanager/actions)
[![codecov](https://codecov.io/gh/mstabrin/napari-boxmanager/branch/main/graph/badge.svg)](https://codecov.io/gh/mstabrin/napari-boxmanager)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-boxmanager)](https://napari-hub.org/plugins/napari-boxmanager)

Particle selection tool for cryo-em

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/index.html
-->

## Installation

Here is how to install napari together with the boxmanager plugin:

    mamba env create -n napari -f https://raw.githubusercontent.com/MPI-Dortmund/napari-boxmanager/main/conda_env.yml
    conda activate napari

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [Mozilla Public License 2.0] license,
""napari-boxmanager"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: Mozilla Public License 2.0 (MPL 2.0)', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.10', 'Topic :: Software Development :: Testing']",,napari-boxmanager.get_reader,napari-boxmanager.get_writer,napari-boxmanager.select_metric,,"['*.tloc', '*.temb', '*.tmap', '*.cbox', '*.box', '*.star', '*.mrc', '*.mrcs', '*.st', '*.coords', '*.rec', '*.cs', '*.tif', '*.tiff', '*.mrci']","['.tloc', '.temb', '.tmap', '.cbox', '.box', '.star', '.mrc', '.mrcs', '.st', '.coords', '.rec', '.mrci']",,https://pypi.org/project/napari-boxmanager,https://github.com/MPI-Dortmund/napari-boxmanager,
95,Napari Brainbow Diagnose,0.1.3,2023-04-18,2023-06-18,napari-brainbow-diagnose,Clement Caporal,clement.caporal@polytechnique.edu,BSD-3-Clause,https://github.com/LaboratoryOpticsBiosciences/napari-brainbow-diagnose,Visualize and Diagnose brainbow dataset in color space.,>=3.8,"['numpy', 'magicgui', 'qtpy', 'pooch', 'matplotlib', 'scikit-image', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""pre-commit ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-brainbow-diagnose

[![License BSD-3](https://img.shields.io/pypi/l/napari-brainbow-diagnose.svg?color=green)](https://github.com/LaboratoryOpticsBiosciences/napari-brainbow-diagnose/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-brainbow-diagnose.svg?color=green)](https://pypi.org/project/napari-brainbow-diagnose)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-brainbow-diagnose.svg?color=green)](https://python.org)
[![tests](https://github.com/LaboratoryOpticsBiosciences/napari-brainbow-diagnose/workflows/tests/badge.svg)](https://github.com/LaboratoryOpticsBiosciences/napari-brainbow-diagnose/actions)
[![codecov](https://codecov.io/gh/LaboratoryOpticsBiosciences/napari-brainbow-diagnose/branch/main/graph/badge.svg)](https://codecov.io/gh/LaboratoryOpticsBiosciences/napari-brainbow-diagnose)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-brainbow-diagnose)](https://napari-hub.org/plugins/napari-brainbow-diagnose)

Explore image in channel coordinate space.
Brainbow dataset have unique features that need to be addressed by specialized tools. This plugin aims at visualize and diagnose brainbow dataset.
In particular we want to interact with the distribution of the dataset in the channel space.

![demo_gif](https://raw.githubusercontent.com/LaboratoryOpticsBiosciences/napari-brainbow-diagnose/main/docs/demo_napari-brainbow-diagnose.gif)

## Usage

You can also look at the [demo notebook](docs/demo.ipynb)
Find all menus under `Plugins > napari-brainbow-diagnose > Diagnose Brainbow Image`

### Choose your dataset

If you want to use your dataset, you have to format it such as each channel is in one distinct `napari.Layers`
You can open test dataset to try this plugin in `File > Open Sample > napari-brainbow-diagnose`.

- The RGB Cube is an array with shape (3x256x256x256) cube : Great to check how the plugin work when all color are represented
- Chrom Cortex Sample is an array with shape (3x256x256x256) #Hugo : Real life brainbow image (Cortex E18 Emx1Cre) !

Once you have your layers you can use the dropdown and select the corresponding layer. It is advised to match the `red, green, blue` order so the ratio you see on the napari viewer corresponds to the Hue-Saturation Wheel of the plugin.

### Get Channel Ratio Density of the image

When you click on `Compute brainbow image density` you will populate the Hue-Saturation density Wheel.
This should allow you to quickly see which ratio is more present in your image. You can see the corresponding ratio according to the ""HS Color wheel"" on the right.
For example here on this screenshot we can see that:

- there is a high number of non saturated red-only ratio. (2)
- there is not a high number of non saturated magenta ratio. (3)

![ratio](https://raw.githubusercontent.com/LaboratoryOpticsBiosciences/napari-brainbow-diagnose/main/docs/ratio_view.png)

### Create a selection of ratio on the channel coordinate system and apply it on the original image


![ratio](https://raw.githubusercontent.com/LaboratoryOpticsBiosciences/napari-brainbow-diagnose/main/docs/wheel_to_image_selection.gif)

### Create a selection of pixel in the image and show where they are in the channel coordinate system

![ratio](https://raw.githubusercontent.com/LaboratoryOpticsBiosciences/napari-brainbow-diagnose/main/docs/image_to_wheel_selection.gif)
## Installation

You can install `napari-brainbow-diagnose` via [pip]:

    pip install napari-brainbow-diagnose



To install latest development version :

    pip install git+https://github.com/LaboratoryOpticsBiosciences/napari-brainbow-diagnose.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-brainbow-diagnose"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/LaboratoryOpticsBiosciences/napari-brainbow-diagnose/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/LaboratoryOpticsBiosciences/napari-brainbow-diagnose/issues', 'Documentation, https://github.com/LaboratoryOpticsBiosciences/napari-brainbow-diagnose#README.md', 'Source Code, https://github.com/LaboratoryOpticsBiosciences/napari-brainbow-diagnose', 'User Support, https://github.com/LaboratoryOpticsBiosciences/napari-brainbow-diagnose/issues']",,,napari-brainbow-diagnose.DiagnoseWidget,napari-brainbow-diagnose.make_rgb_cube_data,,,,https://pypi.org/project/napari-brainbow-diagnose,https://github.com/LaboratoryOpticsBiosciences/napari-brainbow-diagnose,
96,Brainways,0.1.11.1,,,napari-brainways,Ben Kantor,benkantor@mail.tau.ac.il,GPL-3.0,,Brainways UI,>=3.9,"['brainways[all] ==0.1.11', 'datasets ==2.15.0', 'importlib-resources', 'napari[all] ==0.4.18', 'qtpy ==2.3.1', ""brainways-reg-model ; extra == 'all'"", ""py ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt <4.1.0 ; extra == 'testing'"", ""tox ; extra == 'testing'""]","# Overview

[![DOI](https://img.shields.io/badge/DOI-10.1101/2023.05.25.542252-green.svg)](https://doi.org/10.1101/2023.05.25.542252)
[![License GNU GPL v3.0](https://img.shields.io/pypi/l/napari-brainways.svg?color=green)](https://github.com/bkntr/napari-brainways/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-brainways.svg?color=green)](https://pypi.org/project/napari-brainways)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-brainways.svg?color=green)](https://python.org)
[![tests](https://github.com/bkntr/napari-brainways/workflows/tests/badge.svg)](https://github.com/bkntr/napari-brainways/actions)
[![codecov](https://codecov.io/gh/bkntr/napari-brainways/branch/main/graph/badge.svg)](https://codecov.io/gh/bkntr/napari-brainways)
[![Documentation Status](https://readthedocs.org/projects/napari-brainways/badge/?version=latest)](https://napari-brainways.readthedocs.io/en/latest/?badge=latest)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-brainways)](https://napari-hub.org/plugins/napari-brainways)

<!-- markdownlint-disable MD026 -->
## What Is Brainways?
<!-- markdownlint-enable MD026 -->

Brainways is an AI-based tool for automated registration, quantification and generation of brain-wide activity networks based on fluorescence in coronal slices.

![Brainways UI](docs/assets/brainways-ui.gif)

<!-- markdownlint-disable MD026 -->
## Why Brainways?
<!-- markdownlint-enable MD026 -->

Coronal slice registration, cell quantification and whole-brain contrast analysis between experimental conditions should be made easily accessible from a single software, without requiring programming experience.
Customization should be made easy by having a highly flexible pythonic backend.

## Getting Started

To install and run brainways, run the following in your python environment:

```bash
pip install napari-brainways
brainways ui
```

Follow our [getting started guide](https://napari-brainways.readthedocs.io/en/latest/getting_started/) for more details.

## How it works

Brainways allows users to register, quantify and provide statistical contrast analysis by following several simple steps:

1. Rigid registration of coronal slices to a 3D atlas.
1. Non-rigid registration of coronal slices to a 3D atlas, to account for individual difference and imperfections in acquisition procedure.
1. Cell detection (using [StarDist](https://github.com/stardist/stardist)).
1. Quantification of cell counts per brain region.
1. Statistical analysis:
    * ANOVA contrast analysis.
    * PLS (Partial Least Square) analysis.
    * Network graph creation.

<!-- For a quick 10 minute overview of brainways, check out the demo presented to The Social Club community
meeting:

[![Brainways Overview Demo](https://img.youtube.com/vi/aWDIQMbp1cc/0.jpg)](https://youtu.be/aWDIQMbp1cc?t=1m4s) -->

## Architecture

Brainways is implemented as three python packages. [*napari-brainways*](https://github.com/bkntr/napari-brainways) contains the GUI implementation as a [napari](https://napari.org/stable/) plugin. napari-brainways is using [*brainways*](https://github.com/bkntr/brainways) as its backend. All of the functionality is implemented in the brainways package. This separation was done to guarantee that brainways is a GUI-agnostic software, and can be fully accessed and manipulated through python code to allow custom complex usage scenarios. The code that was used to train, evaluate and run the automatic registration model resides in [*brainways-reg-model*](https://github.com/bkntr/brainways-reg-model).

## Development Status

Brainways is being actively developed by Ben Kantor of Bartal lab, Tel Aviv University, Israel. Our releases can be found [here](https://github.com/bkntr/napari-brainways/releases).

## Citation

If you use brainways, please cite [Kantor and Bartal (2023)](https://doi.org/10.1101/2023.05.25.542252):

    @article{kantor2023brainways,
      title={Brainways: An Open-Source AI-based Software For Registration and Analysis of Fluorescent   Markers on Coronal Brain Slices},
      author={Kantor, Ben and Ben-Ami Bartal, Inbal},
      journal={bioRxiv},
      pages={2023--05},
      year={2023},
      publisher={Cold Spring Harbor Laboratory}
    }

## License

Distributed under the terms of the [GNU GPL v3.0] license,
""napari-brainways"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/bkntr/napari-brainways/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: GNU General Public License v3 (GPLv3)', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.9', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/bkntr/napari-brainways/issues', 'Documentation, https://github.com/bkntr/napari-brainways#README.md', 'Source Code, https://github.com/bkntr/napari-brainways', 'User Support, https://github.com/bkntr/napari-brainways/issues']",napari-brainways.read_bwp,,napari-brainways.make_qwidget,napari-brainways.load_sample_project,['*.bwp'],,,https://pypi.org/project/napari-brainways,,
97,napari-brightness-contrast,0.1.8,2022-02-04,2023-06-18,napari-brightness-contrast,Robert Haase,robert.haase@tu-dresden.de,BSD-3-Clause,https://github.com/haesleinhuepf/napari-brightness-contrast,Advanced layer visualization options,>=3.7,"['napari-plugin-engine (>=0.1.4)', 'napari', 'numpy', 'pyqtgraph', 'superqt', 'napari-tools-menu', ""pytest ; extra == 'tests'"", ""pytest-qt ; extra == 'tests'""]","# napari-brightness-contrast

[![License](https://img.shields.io/pypi/l/napari-brightness-contrast.svg?color=green)](https://github.com/haesleinhuepf/napari-brightness-contrast/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-brightness-contrast.svg?color=green)](https://pypi.org/project/napari-brightness-contrast)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-brightness-contrast.svg?color=green)](https://python.org)
[![tests](https://github.com/haesleinhuepf/napari-brightness-contrast/workflows/tests/badge.svg)](https://github.com/haesleinhuepf/napari-brightness-contrast/actions)
[![codecov](https://codecov.io/gh/haesleinhuepf/napari-brightness-contrast/branch/master/graph/badge.svg)](https://codecov.io/gh/haesleinhuepf/napari-brightness-contrast)
[![Development Status](https://img.shields.io/pypi/status/napari-brightness-contrast.svg)](https://en.wikipedia.org/wiki/Software_release_life_cycle#Alpha)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-brightness-contrast)](https://napari-hub.org/plugins/napari-brightness-contrast)

Advanced layer histogram visualization options, e.g. for brightness / contrast
![](https://github.com/haesleinhuepf/napari-brightness-contrast/blob/main/docs/images/napari-brightness-contrast3.gif?raw=true)

Note: This will not work for big image data at the moment. 
If the user interface feels slow, consider installing [pyclesperanto](https://github.com/clEsperanto/pyclesperanto_prototype) to speed it up.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/docs/plugins/index.html
-->

## Installation

You can install `napari-brightness-contrast` via [pip]:

    pip install napari-brightness-contrast

## Contributing

Contributions are very welcome.  
After cloning the repo, install using `pip install -e .[tests]` to enable testing via `pytest`.

## License

Distributed under the terms of the [BSD-3] license,
""napari-brightness-contrast"" is free and open source software

## Issues

If you encounter any problems, please [open a thread on image.sc](https://image.sc) along with a detailed description and tag [@haesleinhuepf](https://github.com/haesleinhuepf).

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/haesleinhuepf/napari-brightness-contrast/issues
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 3 - Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Scientific/Engineering :: Image Processing', 'Topic :: Scientific/Engineering :: Information Analysis', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/haesleinhuepf/napari-brightness-contrast/issues', 'Documentation, https://github.com/haesleinhuepf/napari-brightness-contrast#README.md', 'Source Code, https://github.com/haesleinhuepf/napari-brightness-contrast', 'User Support, https://github.com/haesleinhuepf/napari-brightness-contrast/issues']",,,napari-brightness-contrast.BrightnessContrast,,,,,https://pypi.org/project/napari-brightness-contrast,https://github.com/haesleinhuepf/napari-brightness-contrast,
98,napari-brushsettings,0.0.2,2022-02-10,2023-06-18,napari-brushsettings,Philipp Schoennenbeck,p.schoennenbeck@fz-juelich.de,BSD-3-Clause,https://github.com/Croxa/napari-brushsettings,A simple plugin to set the brush settings for segmentation in napari,>=3.7,"['napari-plugin-engine (>=0.1.4)', 'numpy']","# napari-brushsettings

[![License](https://img.shields.io/pypi/l/napari-brushsettings.svg?color=green)](https://github.com/Croxa/napari-brushsettings/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-brushsettings.svg?color=green)](https://pypi.org/project/napari-brushsettings)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-brushsettings.svg?color=green)](https://python.org)
[![tests](https://github.com/Croxa/napari-brushsettings/workflows/tests/badge.svg)](https://github.com/Croxa/napari-brushsettings/actions)
[![codecov](https://codecov.io/gh/Croxa/napari-brushsettings/branch/master/graph/badge.svg)](https://codecov.io/gh/Croxa/napari-brushsettings)

A simple plugin to set the brush settings for segmentation in napari

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/docs/plugins/index.html
-->

## Installation

You can install `napari-brushsettings` via [pip]:

    pip install napari-brushsettings

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-brushsettings"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/Croxa/napari-brushsettings/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/


","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/Croxa/napari-brushsettings/issues', 'Documentation, https://github.com/Croxa/napari-brushsettings#README.md', 'Source Code, https://github.com/Croxa/napari-brushsettings', 'User Support, https://github.com/Croxa/napari-brushsettings/issues']",,,napari-brushsettings.Brushsize,,,,,https://pypi.org/project/napari-brushsettings,https://github.com/Croxa/napari-brushsettings,
99,Bud Cell Segmenter,0.1.4,2023-11-18,2023-11-18,napari-bud-cell-segmenter,Aurelien Maillot,aurelien.maillot@protonmail.com,BSD-3-Clause,https://pypi.org/project/napari-bud-cell-segmenter,A plugin to segment embryonic mammary bud cells and detect 2 RNA probes,>=3.8,"['numpy', 'magicgui', 'qtpy', 'pandas', 'scikit-image', 'napari', 'tifffile', 'matplotlib', 'scipy', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-bud-cell-segmenter

[![License BSD-3](https://img.shields.io/pypi/l/napari-bud-cell-segmenter.svg?color=green)](https://github.com/AurelienMaillot/napari-bud-cell-segmenter/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-bud-cell-segmenter.svg?color=green)](https://pypi.org/project/napari-bud-cell-segmenter)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-bud-cell-segmenter.svg?color=green)](https://python.org)
[![tests](https://github.com/AurelienMaillot/napari-bud-cell-segmenter/workflows/tests/badge.svg)](https://github.com/AurelienMaillot/napari-bud-cell-segmenter/actions)
[![codecov](https://codecov.io/gh/AurelienMaillot/napari-bud-cell-segmenter/branch/main/graph/badge.svg)](https://codecov.io/gh/AurelienMaillot/napari-bud-cell-segmenter)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-bud-cell-segmenter)](https://napari-hub.org/plugins/napari-bud-cell-segmenter)

A plugin to segment embryonic mammary bud cells and detect 2 RNA probes

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-bud-cell-segmenter` via [pip]:

    pip install napari-bud-cell-segmenter



To install latest development version :

    pip install git+https://github.com/AurelienMaillot/napari-bud-cell-segmenter.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-bud-cell-segmenter"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/AurelienMaillot/napari-bud-cell-segmenter/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/AurelienMaillot/napari-bud-cell-segmenter/issues', 'Documentation, https://github.com/AurelienMaillot/napari-bud-cell-segmenter#README.md', 'Source Code, https://github.com/AurelienMaillot/napari-bud-cell-segmenter', 'User Support, https://github.com/AurelienMaillot/napari-bud-cell-segmenter/issues']",napari-bud-cell-segmenter.get_reader,napari-bud-cell-segmenter.write_multiple,napari-bud-cell-segmenter.load_data,napari-bud-cell-segmenter.make_sample_data,['*.npy'],,['.npy'],https://pypi.org/project/napari-bud-cell-segmenter,,
100,napari BudAnnotation,0.1.6,2023-04-11,2023-06-18,napari-buds,Sander van Otterdijk,scvanotterdijk@gmail.com,BSD-3-Clause,https://github.com/SanderSMFISH/napari-buds,Random-forest automated bud annotation,>=3.8,"['numpy', 'magicgui', 'qtpy', 'pandas', 'napari', 'magic-class', 'scipy', 'scikit-learn', 'scikit-image', 'matplotlib', 'joblib', 'imageio-ffmpeg', 'stackview', 'jupyterlab', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-buds

[![License BSD-3](https://img.shields.io/pypi/l/napari-buds.svg?color=green)](https://github.com/SanderSMFISH/napari-buds/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-buds.svg?color=green)](https://pypi.org/project/napari-buds)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-buds.svg?color=green)](https://python.org)
[![tests](https://github.com/SanderSMFISH/napari-buds/workflows/tests/badge.svg)](https://github.com/SanderSMFISH/napari-buds/actions)
[![codecov](https://codecov.io/gh/SanderSMFISH/napari-buds/branch/main/graph/badge.svg)](https://codecov.io/gh/SanderSMFISH/napari-buds)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-buds)](https://napari-hub.org/plugins/napari-buds)

Random-forest automated bud annotation

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

make sure you already have installed napari. 

Next, You can install `napari-buds` via [pip]:

    pip install napari-buds



To install latest development version :

    pip install git+https://github.com/SanderSMFISH/napari-buds.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## Documentation
Napari-Buds is a random forest based mother-bud annotation plugin for Napari devevoped by the TutucciLab (https://www.tutuccilab.com/) of the systems biology group at the Vrije Universiteit van Amsterdam. Mother-bud annotation requires single or multichannel 2D images of budding yeast and a fluorescent marker that localizes to the bud. In the example dataset provided smFISH DNA-probes were used as localized bud marker.The GUI layout for random forest based classification was inspired by ImageJ 'plugin Weka Segmentation' [1]. **Before installation make sure you have a working version of napari installed (pip install ""napari[all]"").** Napari-Buds is a random forest based mother-bud annotation plugin for Napari developed by the TutucciLab (https://www.tutuccilab.com/) of the systems biology group at the Vrije Universiteit van Amsterdam. Mother-bud annotation requires single or multichannel 2D images of budding yeast and a fluorescent marker that localizes to the bud. In the example dataset provided smFISH DNA-probes were used as localized bud marker.The GUI layout for random forest based classification was inspired by ImageJ 'plugin Weka Segmentation' [1]. 

Please follow the workflow described underneath to perform mother-bud annotation:

1. Open images in napari and create empty label layer.
For multichannel images each channel should be provided seperately to napari.
An example (jupyter) notebook (Open Test Images Napari.ipynb) for loading test data in napari is provided in the notebooks folder. 
Example dataset can be downloaded from https://zenodo.org/record/7004556#.YwM1_HZBztU. 
    
2. If multichannel images are unaligned the  translate widget under Plugins>napari-buds>Translate can be used. 
Select which layer should be translated to align to the layers in widget menu. Then use the aswd keys to translate (move) the selected layer. 
To register changes and update coordinates of the translated image in napari press t. 
    
### Random forest classification
3. To open the mother-bud annotation plugin go to Plugins>napari-buds>bud annotation.
    
4. To train a random forest classifier, in the created label layer draw examples of cells, buds and background (see tutorial gif below). 
In the Define Label segment of the widget you define which label value (class #label_value) corresponds to cells, buds and background. 
Currently, cells and backgrounds and buds **have to be defined in the Define Label segment**  if you want to be able to segment the classification as well.
In the segment **Layers to extract Features from** we can select which layers will be used in training the random forest classifier. 
Next press **Train classifier**. After training is completed a result layer is added to layer list. 
Inspect the results carefully to asses classifier performance. The trained classifier can be saved using the **save classifier** button.
Previously trained classifier can be loaded by pressing **Load classifier**. Loaded classifier can applied to new images by pressing **Classify**, resulting again in a results layer.
It is possible to change the random forest parameters with **the Set random forest parameters** button and changing the values in the pop up menu.
Press **Run** to register changed settings. For an example of the parameters used see: 
https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html and 
https://scikit-image.org/docs/stable/auto_examples/segmentation/plot_trainable_segmentation.html. 
    
5. Next, we want to perfom watershed segmentation using the result layer. However, for watershed segmentation seeds (also called markers) are required
(for an explanation of watershed segmenation see: https://en.wikipedia.org/wiki/Watershed_(image_processing)). 
To define the seeds we can either simply threshold on one of the supplied image layers or we can use distance tranform (https://scikit-image.org/docs/stable/auto_examples/segmentation/plot_watershed.html#sphx-glr-auto   examples-segmentation-plot-watershed-py).The resulting seeds layer can be adjusted manually by editing in napari.
A good seeds layers correspond to each cell having a single seed (buds are not single cells). To perform watershed segmentation press the **Segment** button.
    
6. Carefully inspect the resulting cell mask and bud layer. Correct the mistakes in both layers. 
Bud label values should correspond to the label value of the cell mask of mother cell. To verify mother bud relations were drawn correctly
press **Draw Mother-Bud relations**. If Mother-Bud relations are correct, you can save both label layers. Mother and buds simply share the same label number.
Thus, either the mother or bud layer can be manually corrected for mistakes. Corrections can be checked by clicking **Draw Mother-Bud relations** again. 
mother and buds layer can be saved manually in napari. When using Jupyter notebook mother and bud layers can be saved as shown in Open Test Images Napari.ipynb.

7. An example notebook for dataextraction of the created cell and bud masks can be found in the example notebooks folder (Extract_Mother_Buds_relations_from_Masks_and_intergrate_FQ_spot_data.ipynb).This notebooks relates RNA spots (smFISH data found on zenodo) to the mother or bud compartment. 


See video for clarification:

![Watch the video](https://github.com/SanderSMFISH/napari-buds/blob/main/videos/Napari_bud_gif.gif)

## Similar Napari plugins 

1-napari-accelerated-pixel-and-object-classification (APOC) by Robert Haase.

2-napari-feature-classifier.

## License

Distributed under the terms of the [BSD-3] license,
""napari-buds"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

### Known Issues

If window geometry of the window is unable to be set, this might lead to issues in the display of the widget. For example, part of the widget might fall of the screen.
In these cases, it might help to adjust in your display setting the display scaling to a lower setting. 

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/SanderSMFISH/napari-buds/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/

## References
1. Arganda-Carreras, I., Kaynig, V., Rueden, C., Eliceiri, K. W., Schindelin, J., Cardona, A., & Sebastian Seung, H. (2017). Trainable Weka Segmentation: a machine learning tool for microscopy pixel classification. Bioinformatics, 33(15), 2424–2426. doi:10.1093/bioinformatics/btx180
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/SanderSMFISH/napari-buds/issues', 'Documentation, https://github.com/SanderSMFISH/napari-buds#README.md', 'Source Code, https://github.com/SanderSMFISH/napari-buds', 'User Support, https://github.com/SanderSMFISH/napari-buds/issues']",napari-buds.get_reader,napari-buds.write_multiple,napari-buds.translate,napari-buds.make_sample_data,['*.npy'],,['.npy'],https://pypi.org/project/napari-buds,https://github.com/SanderSMFISH/napari-buds,
101,napari Calibration,0.0.14,,,napari-calibration,Tristan Cotte,tristan.cotte@sgs.com,BSD-3-Clause,,Plug in which enables to make camera calibration,>=3.7,"['napari', 'numpy', 'qt-material', 'opencv-python']","# napari-calibration

[![License](https://img.shields.io/pypi/l/napari-calibration.svg?color=green)](https://github.com/tcotte/napari-calibration/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-calibration.svg?color=green)](https://pypi.org/project/napari-calibration)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-calibration.svg?color=green)](https://python.org)
[![tests](https://github.com/tcotte/napari-calibration/workflows/tests/badge.svg)](https://github.com/tcotte/napari-calibration/actions)
[![codecov](https://codecov.io/gh/tcotte/napari-calibration/branch/main/graph/badge.svg)](https://codecov.io/gh/tcotte/napari-calibration)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-calibration)](https://napari-hub.org/plugins/napari-calibration)

Plug in which enables to make camera calibration

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/stable/index.html
-->

## Installation

You can install `napari-calibration` via [pip]:

    pip install napari-calibration



To install latest development version :

    pip install git+https://github.com/tcotte/napari-calibration.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-calibration"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/tcotte/napari-calibration/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/tcotte/napari-calibration/issues', 'Documentation, https://github.com/tcotte/napari-calibration#README.md', 'Source Code, https://github.com/tcotte/napari-calibration', 'User Support, https://github.com/tcotte/napari-calibration/issues']",,,napari-calibration.ImageForm,,,,,https://pypi.org/project/napari-calibration,,
102,CAphid,0.0.1,2023-10-29,2023-10-29,napari-caphid,Herearii Metuarea,herearii.metuarea@gmail.com,BSD-3-Clause,https://pypi.org/project/napari-caphid,Annotation of aphid and update table,>=3.8,"['numpy', 'magicgui', 'qtpy', 'opencv-python', 'tqdm', 'pandas', 'Pillow', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-caphid

[![License BSD-3](https://img.shields.io/pypi/l/napari-caphid.svg?color=green)](https://github.com/hereariim/napari-caphid/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-caphid.svg?color=green)](https://pypi.org/project/napari-caphid)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-caphid.svg?color=green)](https://python.org)
[![tests](https://github.com/hereariim/napari-caphid/workflows/tests/badge.svg)](https://github.com/hereariim/napari-caphid/actions)
[![codecov](https://codecov.io/gh/hereariim/napari-caphid/branch/main/graph/badge.svg)](https://codecov.io/gh/hereariim/napari-caphid)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-caphid)](https://napari-hub.org/plugins/napari-caphid)

Annotation of aphid and update table

----------------------------------

Napari-caphid was developed for updating table of quantitative data from images. Napari-caphid was developed by Imhorphen Team (french team of University of Angers and INRAe Angers) for ECLECTIC Team (french team of University of Paris-Saclay and CNRS).

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-caphid` via [pip]:

    pip install napari-caphid



To install latest development version :

    pip install git+https://github.com/hereariim/napari-caphid.git

## Getting started

### Foreword

Before using the plugin, the directory must be structured as follows:

```
└── Directory
    ├── France
    │   ├── image
    │   │   ├── img_1.tif
    │   │   ├── img_2.tif
    │   │   ...
    │   │   └── img_n.tif
    │   ├── mask
    │   │   ├── msk_1.tif
    │   │   ├── msk_2.tif
    │   │   ...
    │   │   └── msk_n.tif
    │   ├── img_1.tif
    │   ├── msk_1.tif
    │   ├── img_2.tif
    │   ├── msk_2.tif
    │   ...
    │   ├── img_n.tif
    │   └── msk_n.tif
    │ 
    ├── Belgium
    │   ├── image
    │   │   └── ...
    │   ├── mask
    │   │   └── ...
    │   └── ...
    ├── Spain
    │   ├── image
    │   │   └── ...
    │   ├── mask
    │   │   └── ...
    │   └── ...
    └── Aphid.csv
```

Some explanation about structure. The directory contained three folders (France, Spain, Belgium) and one file (Aphid.csv).
- Each folders (France, Spain, Belgium) contains a set of images and masks and two folders (image, mask). The folder image contains images from the set of images. The folder mask contains masks from the set of masks.
- The file Aphid.csv is a table with quantitative data of aphids from inital process of aphid image processing.

Important:
- The structure of directory is very important because it will be useful to get image name.

### Getting started

The widget get three input:
- Mask : Mask stack
- Pick a table : Path/to/Directory/Aphid.csv
- Country : The country where images were taken

The widget gives one output:
- A new table .csv which is the Aphid.csv updated.

### What's it for ?

This widget gives quantitative data from Mask stack. These quantitative data will be contained into dataframe. Quantitative data linked to current masks contained in the Aphid.csv file will be deleted. Then, the new quantitative data contained in the dataframe will be integrated into the Aphid.csv file. In this way, the Aphid.csv file is updated.

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-caphid"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/hereariim/napari-caphid/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/hereariim/napari-caphid/issues', 'Documentation, https://github.com/hereariim/napari-caphid#README.md', 'Source Code, https://github.com/hereariim/napari-caphid', 'User Support, https://github.com/hereariim/napari-caphid/issues']",napari-caphid.get_reader,napari-caphid.write_multiple,napari-caphid.make_process_func,,['*.npy'],,['.npy'],https://pypi.org/project/napari-caphid,,
103,napari-ccp4map,1.0,2022-01-31,2023-06-18,napari-ccp4map,Simon Biberger,dev@biberger.xyz,BSD-3-Clause,https://github.com/biberger/napari-ccp4map,Enables napari to read .map files in the ccp4 format. Drag&Drop or press Ctrl+O to read files.,>=3.7,"['napari-plugin-engine (>=0.1.4)', 'numpy', 'gemmi']","# napari-ccp4map

[![License](https://img.shields.io/pypi/l/napari-ccp4map.svg?color=green)](https://github.com/biberger/napari-ccp4map/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-ccp4map.svg?color=green)](https://pypi.org/project/napari-ccp4map)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-ccp4map.svg?color=green)](https://python.org)
[![tests](https://github.com/biberger/napari-ccp4map/workflows/tests/badge.svg)](https://github.com/biberger/napari-ccp4map/actions)
[![codecov](https://codecov.io/gh/biberger/napari-ccp4map/branch/master/graph/badge.svg)](https://codecov.io/gh/biberger/napari-ccp4map)

Enables napari to read .map files in the ccp4 format.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/docs/plugins/index.html
-->

## Installation

You can install `napari-ccp4map` via [pip]:

    pip install napari-ccp4map

## Usage
If the plugin was installed correctly, it will pop up in a napari window under Plugins->Install/Uninstall Plugins.
You can either drag&drop filed into the window to read them, or search for a folder/file using Ctrl+O.

## How it works
This plugin simply reads a file and allows [gemmi](https://github.com/project-gemmi/gemmi) to interact with it. Then, numpy turns the file into an array.

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-ccp4map"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/biberger/napari-ccp4map/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/


","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/biberger/napari-ccp4map/issues', 'Documentation, https://github.com/biberger/napari-ccp4map#README.md', 'Source Code, https://github.com/biberger/napari-ccp4map', 'User Support, https://github.com/biberger/napari-ccp4map/issues']",napari-ccp4map.napari_get_reader,,,,['*'],,,https://pypi.org/project/napari-ccp4map,https://github.com/biberger/napari-ccp4map,
104,3D cell centroid annotator,0.0.1,2023-04-12,2023-06-18,napari-cell-centroid-annotator,Tim Van De Looverbosch,tim.vandelooverbosch@gmail.com,MIT,https://github.com/tim-vdl/napari-cell-centroid-annotator,A simple plugin to annotate cell centroids in 3D images,>=3.8,"['numpy', 'pandas', 'tifffile', 'pathlib', 'napari', 'napari-plugin-engine', 'napari-layer-table', 'magicgui', 'qtpy', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-cell-centroid-annotator

[![License MIT](https://img.shields.io/pypi/l/napari-cell-centroid-annotator.svg?color=green)](https://github.com/tim-vdl/napari-cell-centroid-annotator/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-cell-centroid-annotator.svg?color=green)](https://pypi.org/project/napari-cell-centroid-annotator)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-cell-centroid-annotator.svg?color=green)](https://python.org)
[![tests](https://github.com/tim-vdl/napari-cell-centroid-annotator/workflows/tests/badge.svg)](https://github.com/tim-vdl/napari-cell-centroid-annotator/actions)
[![codecov](https://codecov.io/gh/tim-vdl/napari-cell-centroid-annotator/branch/main/graph/badge.svg)](https://codecov.io/gh/tim-vdl/napari-cell-centroid-annotator)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-cell-centroid-annotator)](https://napari-hub.org/plugins/napari-cell-centroid-annotator)

A simple plugin to annotate cell centroids in 3D images

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-cell-centroid-annotator` via [pip]:

    pip install napari-cell-centroid-annotator



To install latest development version :

    pip install git+https://github.com/tim-vdl/napari-cell-centroid-annotator.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [MIT] license,
""napari-cell-centroid-annotator"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/tim-vdl/napari-cell-centroid-annotator/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: MIT License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/tim-vdl/napari-cell-centroid-annotator/issues', 'Documentation, https://github.com/tim-vdl/napari-cell-centroid-annotator#README.md', 'Source Code, https://github.com/tim-vdl/napari-cell-centroid-annotator', 'User Support, https://github.com/tim-vdl/napari-cell-centroid-annotator/issues']",napari-cell-centroid-annotator.get_reader,,napari-cell-centroid-annotator.make_annotate_centroids_widget,,"['*.tif', '*.tiff', '*.csv', '*.npy']",,,https://pypi.org/project/napari-cell-centroid-annotator,https://github.com/tim-vdl/napari-cell-centroid-annotator,
105,napari-chatgpt | Omega,2024.3.26.3,,,napari-chatgpt,Loic A. Royer and contributors,royerloic@gmail.com,BSD-3-Clause,,A napari plugin to process and analyse images with chatGPT.,>=3.9,"['numpy', 'magicgui', 'scikit-image', 'qtpy', 'QtAwesome', 'langchain ==0.1.11', 'langchain-openai ==0.0.8', 'langchain-anthropic ==0.1.4', 'openai ==1.13.3', 'anthropic', 'fastapi', 'uvicorn', 'websockets', 'tiktoken', 'wikipedia', 'lxml', 'gTTS', 'playsound', 'matplotlib', 'xarray', 'arbol', 'playwright', 'duckduckgo-search', 'ome-zarr', 'transformers', 'cryptography', 'tabulate', 'numba', 'imageio[ffmpeg,pyav]', 'notebook', 'nbformat', 'jedi', 'black', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","## Home of _Omega_, a napari-aware autonomous LLM-based agent specialized in image processing and analysis.

[![License BSD-3](https://img.shields.io/pypi/l/napari-chatgpt.svg?color=green)](https://github.com/royerlab/napari-chatgpt/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-chatgpt.svg?color=green)](https://pypi.org/project/napari-chatgpt)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-chatgpt.svg?color=green)](https://python.org)
[![tests](https://github.com/royerlab/napari-chatgpt/actions/workflows/test_and_deploy.yml/badge.svg)](https://github.com/royerlab/napari-chatgpt/actions/workflows/test_and_deploy.yml)
[![codecov](https://codecov.io/gh/royerlab/napari-chatgpt/branch/main/graph/badge.svg)](https://codecov.io/gh/royerlab/napari-chatgpt)
[![Downloads](https://pepy.tech/badge/napari-chatgpt)](https://pepy.tech/project/napari-chatgpt)
[![Downloads](https://pepy.tech/badge/napari-chatgpt/month)](https://pepy.tech/project/napari-chatgpt)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-chatgpt)](https://napari-hub.org/plugins/napari-chatgpt)
[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.10828225.svg)](https://doi.org/10.5281/zenodo.10828225)
[![GitHub stars](https://img.shields.io/github/stars/royerlab/napari-chatgpt?style=social)](https://github.com/royerlab/napari-chatgpt/)
[![GitHub forks](https://img.shields.io/github/forks/royerlab/napari-chatgpt?style=social)](https://git:hub.com/royerlab/napari-chatgpt/)

<img src='https://github.com/royerlab/napari-chatgpt/assets/1870994/c85185d2-6d16-472d-a2c8-5680ea869bf2' height='300'>
<img height=""300"" alt=""image"" src=""https://github.com/royerlab/napari-chatgpt/assets/1870994/f3ea245e-dd86-4ff2-802e-48c2073cb6f9"">


A [napari](napari.org) plugin that leverages OpenAI's Large Language Model
ChatGPT to implement _Omega_
a napari-aware agent capable of performing image processing and analysis tasks
in a conversational manner.

This repository started as a 'week-end project'
by [Loic A. Royer](https://twitter.com/loicaroyer)
who leads a [research group](https://royerlab.org) at
the [Chan Zuckerberg Biohub](https://royerlab.org). It
leverages [OpenAI](https://openai.com)'s ChatGPT API via
the [LangChain](https://python.langchain.com/en/latest/index.html) Python
library, as well as [napari](https://napari.org), a fast, interactive,
multi-dimensional
image viewer for
Python, [another](https://ilovesymposia.com/2019/10/24/introducing-napari-a-fast-n-dimensional-image-viewer-in-python/)
week-end project, initially started by Loic and [Juan Nunez-Iglesias](https://github.com/jni).

# What is Omega?

Omega is an LLM-based and tool-armed autonomous agent that demonstrates the
potential for Large Language Models (LLMs) to be applied to image processing,
analysis and visualization.
Can LLM-based agents write image processing code and napari widgets, correct its
coding mistakes, performing follow-up analysis, and controlling the napari viewer? 
The answer appears to be yes.

The preprint can be downloaded here: [10.5281/zenodo.10828225](https://doi.org/10.5281/zenodo.10828225)


#### In this video, I ask Omega to segment an image using the [SLIC](https://www.iro.umontreal.ca/~mignotte/IFT6150/Articles/SLIC_Superpixels.pdf) algorithm. It makes a first attempt using the implementation in scikit-image but fails because of an inexistent 'multichannel' parameter. Realizing that, Omega tries again, and this time succeeds:

https://user-images.githubusercontent.com/1870994/235768559-ca8bfa84-21f5-47b6-b2bd-7fcc07cedd92.mp4

#### After loading a sample 3D image of cell nuclei in napari, I asked Omega to segment the nuclei using the Otsu method. My first request was vague, so it just segmented foreground versus background. I then ask to segment the foreground into distinct segments for each connected component. Omega does a rookie mistake by forgetting to 'import np'. No problem; it notices, tries again, and succeeds:

https://user-images.githubusercontent.com/1870994/235769990-a281a118-1369-47aa-834a-b491f706bd48.mp4

#### In this video, one of my favorites, I ask Omega to make a 'Max color projection widget.' It is not a trivial task, but it manages!

https://github.com/royerlab/napari-chatgpt/assets/1870994/bb9b35a4-d0aa-4f82-9e7c-696ef5859a2f

As LLMs improve, Omega will become even more adept at handling complex
image processing and analysis tasks. GPT 4.0 has been a significant upgrade
compared to GPT 3.5, and many of the videos (see below and here) are highly reproducible, 
with a typically 90% success rate (see preprint for a reproducibility analysis).
While open-source models are promising and rapidly improving, they must get better to run Omega reliably. 
More recent models by OpenAI's competitors, such as Google and Anthropic, are great news, 
but Omega still needs to support these newer models fully -- it seems every week comes with a new batch of models.

Omega could eventually help non-experts process and analyze images, especially
in the bioimage domain.
It is also potentially valuable for educative purposes as it could
assist in teaching image processing and analysis, making it more accessible.
Although ChatGPT, which powers Omega, may still need to be on par with an expert image
analyst or computer vision expert, it is just a matter of time...

Omega holds a conversation with the user and uses different tools to answer questions, 
download and operate on images, write widgets for napari, and more.

## Omega's Built-in AI-Augmented Code Editor

The Omega AI-Augmented Code Editor is a new feature within Omega, designed to enhance the Omega's user experience. This editor is not just a text editor; it's a powerful interface that interacts with the Omega dialogue agent to generate, optimize, and manage code for advanced image analysis tasks.

<img src='https://github.com/royerlab/napari-chatgpt/assets/1870994/cf9b1c15-f11a-4e25-a73d-d96915c46c6a' width='800'>

#### Key Features
- **Code Highlighting and Completion**: For ease of reading and writing, the code editor comes with built-in syntax highlighting and intelligent code completion features.
- **LLM-Augmented Tools**: The editor is equipped with AI tools that assist in commenting, cleaning up, fixing, modifying, and performing safety checks on the code.
- **Persistent Code Snippets**: Users can save and manage snippets of code, preserving their work across multiple Napari sessions.
- **Network Code Sharing (Code-Drop)**: Facilitates the sharing of code snippets across the local network, empowering collaborative work and knowledge sharing.

#### Usage Scenarios
- **Widget Creation**: Expert users can create widgets using the Omega dialogue agent and retain them for future use.
- **Collaboration**: Share custom widgets with colleagues or the community, even if they don't have access to an API key.
- **Learning**: New users can learn from the AI-augmented suggestions, improving their coding skills in Python and image analysis workflows.

You can find more information in the corresponding [wiki page](https://github.com/royerlab/napari-chatgpt/wiki/OmegaCodeEditor).

----------------------------------

## Omega's Installation instructions:

Assuming you have a Python environment with a working napari installation, you can simply:

    pip install napari-chatgpt

Or install the plugin from napari's plugin installer.

For detailed instructions and variations, check [this page](http://github.com/royerlab/napari-chatgpt/wiki/InstallOmega) of our wiki.
    
## Requirements:

You need an OpenAI key; there is no way around this, I have been experimenting with 
other models, including open-source models, but right now, the best results, by far, are obtained with ChatGPT 4 (and to
a lesser extent 3.5). Check [here](https://github.com/royerlab/napari-chatgpt/wiki/OpenAIKey) for details on how to get your OpenAI key. In particular, check [this](https://github.com/royerlab/napari-chatgpt/wiki/AccessToGPT4) for how to gain access to GPT-4 models.

## Usage:

Check this [page](https://github.com/royerlab/napari-chatgpt/wiki/HowToStartOmega) of our [wiki](https://github.com/royerlab/napari-chatgpt/wiki) for details on how to start Omega. 

## Tips, Tricks, and Example prompts:

Check our guide on how to prompt Omega and some examples [here](https://github.com/royerlab/napari-chatgpt/wiki/Tips&Tricks).

## Video Demos:

You can check the original release videos [here](https://github.com/royerlab/napari-chatgpt/wiki/VideoDemos).
You can also find the latest preprint videos on [Vimeo](https://vimeo.com/showcase/10983382).

## How does Omega work?

Check our preprint here: [10.5281/zenodo.8240289](10.5281/zenodo.8240289)
and our [wiki page](https://github.com/royerlab/napari-chatgpt/wiki/OmegaDesign) on Omega's design and architecture.

## Cost:

Developing the initial version of Omega cost me $13.97, hardly a fortune. 
OpenAI [pricing](https://openai.com/pricing) on ChatGPT 4 is very reasonable at 0.01 dollars per 1K tokens, which means $1 per 750000 words. 

Note: you can limit the burn rate to a certain amount of dollars per month, just
in case you let Omega think over the weekend and forget to stop it (don't worry, 
this is actually **not** possible).

## Disclaimer:

Do not use this software lightly; it will download libraries of its own volition
and write any code it deems necessary; it might do what you ask, even
if it is a very bad idea. Also, beware that it might _misunderstand_ what you ask and
then do something bad in ways that elude you. For example, it is unwise to use Omega to delete 
'some' files from your system; it might end up deleting more than that if you are unclear in 
your request.  
Omega is generally safe as long as you do not make dangerous requests. To be 100% safe, and
if your experiments with Omega could be potentially problematic, I recommend using this 
software from within a sandboxed virtual machine.

THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A
PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR
THE USE OR OTHER DEALINGS IN THE SOFTWARE.

## Contributing

Contributions are extremely welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-chatgpt"" is free and open-source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed
description.

[napari]: https://github.com/napari/napari

[Cookiecutter]: https://github.com/audreyr/cookiecutter

[@napari]: https://github.com/napari

[MIT]: http://opensource.org/licenses/MIT

[BSD-3]: http://opensource.org/licenses/BSD-3-Clause

[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt

[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt

[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0

[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt

[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/royerlab/napari-chatgpt/issues

[napari]: https://github.com/napari/napari

[tox]: https://tox.readthedocs.io/en/latest/

[pip]: https://pypi.org/project/pip/

[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/royerlab/napari-chatgpt/issues', 'Documentation, https://github.com/royerlab/napari-chatgpt#README.md', 'Source Code, https://github.com/royerlab/napari-chatgpt', 'User Support, https://github.com/royerlab/napari-chatgpt/issues']",,,napari-chatgpt.start_omega,,,,,https://pypi.org/project/napari-chatgpt,,
106,napari-checkerboard,0.0.3,,,napari-checkerboard,Viktor van der Valk,v.o.van_der_valk@lumc.nl,Apache Software License 2.0,,Compare two images with the itk checkerboard filter,>=3.6,"['napari-plugin-engine (>=0.1.4)', 'numpy (>=1.19.0)', 'napari (>=0.4.6)', 'magicgui (>=0.2.6)', 'itk-elastix (>=0.11.1)', 'itk-napari-conversion (>=0.3.1)', 'napari-itk-io (>=0.1.0)']","# napari-checkerboard

[![License](https://img.shields.io/pypi/l/napari-checkerboard.svg?color=green)](https://github.com/ViktorvdValk/napari-checkerboard/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-checkerboard.svg?color=green)](https://pypi.org/project/napari-checkerboard)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-checkerboard.svg?color=green)](https://python.org)
[![tests](https://github.com/ViktorvdValk/napari-checkerboard/workflows/tests/badge.svg)](https://github.com/ViktorvdValk/napari-checkerboard/actions)
[![codecov](https://codecov.io/gh/ViktorvdValk/napari-checkerboard/branch/master/graph/badge.svg)](https://codecov.io/gh/ViktorvdValk/napari-checkerboard)

Compare two images with the itk checkerboard filter


<img width=""1430"" alt=""Screenshot 2021-05-12 at 15 03 17"" src=""https://user-images.githubusercontent.com/33719474/117979519-48bd4680-b333-11eb-874c-d9ec09681d93.png"">


----------------------------------

This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/docs/plugins/index.html
-->

## Installation

You can install `napari-checkerboard` via [pip]:

    pip install napari-checkerboard

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [Apache Software License 2.0] license,
""napari-checkerboard"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/ViktorvdValk/napari-checkerboard/issues
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/


","['Development Status :: 4 - Beta', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: Apache Software License']",,,,napari-checkerboard.checkerboard,,,,,https://pypi.org/project/napari-checkerboard,,
107,napari-clemreg,0.2.0,,,napari-clemreg,Daniel Krentzel,dkrentzel@pm.me,MIT,,A plugin for registering multimodal image volumes based on common segmented structures of interest with point-clouds.,>=3.7,"['typing-extensions', 'setuptools', 'packaging', 'numpy ==1.22.0', 'magicgui ==0.7.3', 'scipy ==1.10.1', 'napari', 'scikit-image ==0.21.0', 'h5py ==3.9.0', 'matplotlib ==3.7.3', 'imageio ==2.31.5', 'tifffile ==2023.7.10', 'probreg ==0.3.6', 'open3d ==0.17.0', 'transforms3d ==0.4.1', 'tqdm ==4.66.1', 'empanada-dl ==0.1.7', 'torch ==2.0.1', 'connected-components-3d ==3.12.3']","# napari-clemrerg
### An automated point cloud based registration algorithm for correlative light and volume electron microscopy

[![License](https://img.shields.io/pypi/l/napari-clemreg.svg?color=green)](https://github.com/krentzd/napari-clemreg/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-clemreg.svg?color=green)](https://pypi.org/project/napari-clemreg)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-clemreg.svg?color=green)](https://python.org)

[//]: # ([![codecov]&#40;https://codecov.io/gh/krentzd/napari-clemreg/branch/master/graph/badge.svg&#41;]&#40;https://codecov.io/gh/krentzd/napari-clemreg&#41;)
[//]: # ([![tests]&#40;https://github.com/krentzd/napari-clemreg/workflows/tests/badge.svg&#41;]&#40;https://github.com/krentzd/napari-clemreg/actions&#41;)

## Installation

To install `napari-clemreg` it is recommended to create a fresh [conda] environment with Python 3.9:

```
conda create -n clemreg_env python=3.9
```
Next, install `napari` with the following command via [pip]: 

```
pip install ""napari[all]""
```

Finally, `napari-clemreg` can be installed with:
```
pip install napari-clemreg
```
When installing `napari-clemreg` on a Windows machine, the following error might appear:
```
error Microsoft Visual C++ 14.0 is required
```
Ensure that [Visual Studios C++ 14.00](https://visualstudio.microsoft.com/thank-you-downloading-visual-studio/?sku=BuildTools&rel=16) is installed
## Usage
CLEM-reg is the combination of 5 main steps, MitoNet segmentation, LoG segmentation,
point cloud sampling, point cloud registration and lastly image warping. These 5 steps 
can be run all at once using the run registration widget shown below with the tick next to it.
Alternatively, they can be run individually with the numbered widgets.

![clemreg_widget_options.png](docs%2Fimages%2Fclemreg_widget_options.png)

### Run Registration



![registration_labels.png](docs%2Fimages%2FCLEMreg-fig.png)

1. **Moving Image** - Here you select your light microscopy (LM) data which will
be warped to align with the fixed electron microscopy (EM) image.
2. **Fixed Image** - Here you select your EM data which will
act as the reference point for the LM to be aligned to.
3. **Registration Algorithm** - Here you can decide which type of registration algorith
will be used for the registration of inputted LM and EM. In terms of speed of each algorithm
the following is the generally true, Rigid CPD > Affine CPD > BCPD.
4. **MitoNet Segmentation Parameters** - Here are the advanced options for the segmentation
of the mitochondria in the EM data.
   1. Prediction Across Three Axis - By selecting this option MitoNet will run segmentation
across all three axis of the EM volume and then these three predictions will be aggregate.
5. **LoG Segmentation Parameters** - Here are the advanced options for the segmentation of 
the mitochondria in the LM data.
   1. Sigma - Sigma value for the Laplacian of Gaussian filter.
   2. Threshold - Threshold value for the segmenting the LM data.
6. **Point Cloud Sampling** - Here are the advanced options for the point cloud sampling of the 
segmentations of the LM and EM data.
   1. Sampling Frequency - Frequency of point sampling from the fixed and moving segmentation. The greater the value the more points in the point cloud.
   2. Sigma - Sigma value for the canny edge filter.
7. **Point Cloud Registration** - Here are the advanced options for the registration of the point clouds
of both the LM and EM data.
   1. Voxel Size - The size voxel size of each point. Smaller the size the less memory consumption.
   2. Subsampling - Downsampling of the point clouds to reduce memory consumption. Greater the number the fewer points in the point cloud.
   3. Maximum Iterations - The number of round of point cloud registration. If too small it won't converge on an opitmal registration.
8. **Image Warping** - Here are the advanced options for the image warping of the moving LM images.
   1. Interpolation Order - The order of the spline interpolation.
   2. Aproximate Grid - Controls the ""resolution"" of the grid onto which you're warping. A higher value reduces the step size between coordinates.
   3. Sub-division Factor - Controls the size of the chunk when applying the warping.
9. **Save Parameters** - Here you can select the option to save the advanced options you've selected
to a JSON file which can be kept for reproducibility as well as running the registration again.
10. **Visualise Intermediate Results** - Here you can select to view the outputs of each step as they
are completed.

### Split Registration
As well as being able to run all the steps of CLEM-reg in one widget (the `Run registration` widget),
you are also able to do all these steps independently using the `Split Registration` functionality. 

There are four separate widgets that encapsulate the 5 steps of CLEM-reg each of which have
their own unique input and output:
1. `MitoNet Segmentation` 
   - **Input**: EM Image
   - **Output**: EM Segmentation
2. `LoG Segmentation`
   - **Input**: LM Image
   - **Output**: LM Segmentation
3. `Point Cloud Sampling`
   - **Input**: LM Segmentation & EM Segmentation
   - **Output**: LM Point Cloud & LM Point Cloud
4. `Point Cloud Registration & Image Warping`
   - **Input**: EM Image, LM Image, LM Point Cloud & EM Point Cloud
   - **Output**: Registered LM Image, Registered LM Point Cloud

### Registering Multiple LM Channels
One can register multiple LM channels at once by doing the following.

1. Start by splitting the LM channels into the separate layers by right-clicking on
the layer and then selecting `Split Stack`.
![merged-channel-split-options.png](docs%2Fimages%2Fmerged-channel-split-options.png)
This will result in each of the channels having their own individual layer. 

2. Once this is done we must link all the LM layers together, this is done 
by selecting all the layers which will highlight them in blue, once again right-clicking
on the layer and then selecting `Link Layers.`
![split-channels-link-layers.png](docs%2Fimages%2Fsplit-channels-link-layers.png)

3. When you finally go to run CLEM-reg ensure that for the `Moving Image`
you select the LM layer that contains mitochondria.

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [MIT] license,
""napari-clemreg"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/krentzd/napari-clemreg/issues
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
[conda]: https://docs.conda.io/en/latest/

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.
","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: MIT License']","['Bug Tracker, https://github.com/krentzd/napari-clemreg/issues', 'Documentation, https://github.com/krentzd/napari-clemreg#README.md', 'Source Code, https://github.com/krentzd/napari-clemreg', 'User Support, https://github.com/krentzd/napari-clemreg/issues']",napari-clemreg.get_reader,,napari-clemreg.make_run_registration,napari-clemreg.sample_data,"['*.tif', '*.tiff']",,,https://pypi.org/project/napari-clemreg,,
108,napari clipboard,0.0.1,2023-10-29,2023-10-29,napari-clipboard,Kyle Harrington,czi@kyleharrington.com,BSD-3-Clause,https://pypi.org/project/napari-clipboard,A plugin for creating napari layers from the System clipboard,>=3.8,"['numpy', 'magicgui', 'qtpy', 'napari', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-clipboard

[![License BSD-3](https://img.shields.io/pypi/l/napari-clipboard.svg?color=green)](https://github.com/kephale/napari-clipboard/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-clipboard.svg?color=green)](https://pypi.org/project/napari-clipboard)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-clipboard.svg?color=green)](https://python.org)
[![tests](https://github.com/kephale/napari-clipboard/workflows/tests/badge.svg)](https://github.com/kephale/napari-clipboard/actions)
[![codecov](https://codecov.io/gh/kephale/napari-clipboard/branch/main/graph/badge.svg)](https://codecov.io/gh/kephale/napari-clipboard)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-clipboard)](https://napari-hub.org/plugins/napari-clipboard)

A plugin for creating napari layers from the System clipboard

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-clipboard` via [pip]:

    pip install napari-clipboard



To install latest development version :

    pip install git+https://github.com/kephale/napari-clipboard.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-clipboard"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/kephale/napari-clipboard/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/kephale/napari-clipboard/issues', 'Documentation, https://github.com/kephale/napari-clipboard#README.md', 'Source Code, https://github.com/kephale/napari-clipboard', 'User Support, https://github.com/kephale/napari-clipboard/issues']",,,napari-clipboard.image_from_clipboard,,,,,https://pypi.org/project/napari-clipboard,,
109,napari-clusters-plotter,0.7.3,2022-02-17,2023-09-06,napari-clusters-plotter,"Laura Zigutyte, Ryan Savill, Johannes Müller, Marcelo Zoccoler, Thorsten Wagner, Robert Haase","zigutyte@gmail.com, robert.haase@tu-dresden.de",BSD-3-Clause,https://github.com/BiAPoL/napari-clusters-plotter,A plugin to use with napari for clustering objects according to their properties,>=3.7,"['napari-plugin-engine >=0.1.4', 'numpy <=1.23.5,>=1.21', 'scikit-learn', 'matplotlib', 'pandas', 'umap-learn', 'napari-tools-menu', 'napari-skimage-regionprops >=0.3.1', 'hdbscan', 'joblib']","# napari-clusters-plotter

[![License](https://img.shields.io/pypi/l/napari-clusters-plotter.svg?color=green)](https://github.com/lazigu/napari-clusters-plotter/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-clusters-plotter.svg?color=green)](https://pypi.org/project/napari-clusters-plotter)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-clusters-plotter.svg?color=green)](https://python.org)
[![Anaconda-Server Badge](https://anaconda.org/conda-forge/napari-clusters-plotter/badges/version.svg)](https://anaconda.org/conda-forge/napari-clusters-plotter)
[![tests](https://github.com/BiAPoL/napari-clusters-plotter/workflows/tests/badge.svg)](https://github.com/BiAPoL/napari-clusters-plotter/actions)
[![codecov](https://codecov.io/gh/BiAPoL/napari-clusters-plotter/branch/main/graph/badge.svg?token=R6W2KO1NJ8)](https://codecov.io/gh/BiAPoL/napari-clusters-plotter)
[![pre-commit](https://img.shields.io/badge/pre--commit-enabled-brightgreen?logo=pre-commit&logoColor=white)](https://github.com/pre-commit/pre-commit)
[![Anaconda-Server Badge](https://anaconda.org/conda-forge/napari-clusters-plotter/badges/downloads.svg)](https://anaconda.org/conda-forge/napari-clusters-plotter)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-clusters-plotter)](https://www.napari-hub.org/plugins/napari-clusters-plotter)
[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.7011471.svg)](https://doi.org/10.5281/zenodo.7011471)

A napari-plugin for clustering objects according to their properties.

<img src=""https://github.com/BiAPoL/napari-clusters-plotter/raw/main/images/screencast2_timelapse.gif"" width=""700""/>

----------------------------------

Jump to:
- [Usage](#usage)
  - [Starting point](#starting-point)
  - [Measurements](#measurements)
  - [Time-Lapse Measurements](#time-lapse-measurements)
  - [Plotting](#plotting)
  - [Time-Lapse Plotting](#time-lapse-plotting)
  - [Dimensionality reduction: UMAP, t-SNE or PCA](#dimensionality-reduction-umap-t-sne-or-pca)
  - [Clustering](#clustering)
  - [Plotting clustering results](#plotting-clustering-results)
- [Installation](#installation)
- [Troubleshooting installation](#troubleshooting-installation)
- [Contributing](#contributing)
- [License](#license)
- [Acknowledgements](#acknowledgements)


## Usage

### Starting point
For clustering objects according to their properties, the starting point is a [grey-value image](example_data/blobs.tif) and a label image
representing a segmentation of objects. For segmenting objects, you can for example use the
[Voronoi-Otsu-labelling approach](https://github.com/haesleinhuepf/napari-segment-blobs-and-things-with-membranes#voronoi-otsu-labelling)
in the napari plugin [napari-segment-blobs-and-things-with-membranes](https://www.napari-hub.org/plugins/napari-segment-blobs-and-things-with-membranes).

![](https://github.com/BiAPoL/napari-clusters-plotter/raw/main/images/starting_point.png)

In case you have 2D time-lapse data you need to convert it into a suitable shape using the menu `Tools > Utilities > Convert 3D stack to 2D time-lapse (time-slicer)` ([documentation](https://www.napari-hub.org/plugins/napari-time-slicer)).

### Measurements
The first step is deriving measurements from the labeled image and the corresponding pixels in the grey-value image.
Use the menu `Tools > Measurement tables > Regionprops (scikit-image, nsr)` to get to the measurement widget ([documentation](https://www.napari-hub.org/plugins/napari-skimage-regionprops)).
Select the image, the corresponding label image and the measurements to analyse and click on `Run`.
A table with the measurements will open and afterwards, you can save and/or close the measurement table.
At this point it is recommended to close the table and the Measure widget to free space for following steps.

You can also load your own measurements you can do this using the menu `Tools > Measurement tables > Load from CSV (nsr)`.
If you load custom measurements, please make sure that there is a `label` column that specifies the which measurement belongs to which labeled object.
Tables for time-lapse data need to include an additional column named `frame`.

### Plotting

Once measurements were saved in the labels layer which was analysed, you can then plot these measurements using the menu `Tools > Visualization > Plot measurements (ncp)`.

In this widget, you can select the labels layer which was analysed and the measurements which should be plotted
on the X- and Y-axis. Click on `Plot` to draw the data points in the plot area.

![](https://github.com/BiAPoL/napari-clusters-plotter/raw/main/images/plot_plain.png)

Under advanced options, you can also select the plot type histogram which will visualize a 2D histogram. 2D histogram visualization is recommended if you have a very high number of data points.

![img.png](https://github.com/BiAPoL/napari-clusters-plotter/raw/main/images/histogram_2d.png)

If you choose the same measurement for the X and the Y axis, a histogram will be shown.

![img.png](https://github.com/BiAPoL/napari-clusters-plotter/raw/main/images/histogram_1d.png)

Under advanced options you will also find the checkbox determining whether not-selected data points should be hidden (shown in grey) or automatically
clustered as another cluster.

### Manual clustering

You can manually select a region in the plot. To use lasso (freehand) tool use left mouse click, and to use a
rectangle - right click. The resulting manual clustering will also be visualized in the original image. To optimize
visualization in the image, turn off the visibility of the analysed labels layer.

<img src=""https://github.com/BiAPoL/napari-clusters-plotter/raw/main/images/screencast.gif"" width=""700""/>

Hold down the SHIFT key while annotating regions in the plot to manually select multiple clusters.

![](https://github.com/BiAPoL/napari-clusters-plotter/raw/main/images/multi-select-manual-clustering.gif)

### Saving manual clustering

Manual clustering results can be saved by going to `Tools > Measurement > Show table (nsr)`, and clicking on `Save as csv`.
The saved table will contain a ""MANUAL_CLUSTER_ID"" column. This column is overwritten every time different clusters are manually selected.

### Time-Lapse analysis

When you plot your time-lapse datasets you will notice that the plots look slightly different.
Datapoints of the current time frame are highlighted in bright color and you can see the datapoints move through the plot while you navigate through time:

![](https://github.com/BiAPoL/napari-clusters-plotter/raw/main/images/plotting_time-lapse_data_as_movie.gif)

You can also manually select groups using the lasso tool and plot a measurement per frame and see how the group behaves in time.
Furthermore, you could also select a group in time and see where the datapoints lie in a different feature space:

![](https://github.com/BiAPoL/napari-clusters-plotter/raw/main/images/timelapse_manual_clustering_tips.gif)

If you have custom measurements from tracking data where each column specifies measurements for a track instead of a label at a specific time point, the `frame` column must not be added.

### Dimensionality reduction

For getting more insights into your data, you can reduce the dimensionality of the measurements, using these algorithms:
* [Uniform Manifold Approximation Projection (UMAP)](https://umap-learn.readthedocs.io/en/latest/)
* [t-distributed stochastic neighbor embedding (t-SNE)](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html)
* [Principal Component Analysis (PCA)](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html)
* [Non-linear dimensionality reduction through Isometric Mapping (Isomap)](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.Isomap.html)
* [Multi-dimensional Scaling (MDS)](https://scikit-learn.org/stable/modules/manifold.html#multidimensional-scaling)

To apply them to your data use the menu `Tools > Measurement post-processing > Dimensionality reduction (ncp)`.
Select the label image that was analysed and in the list below, select all measurements that should be dimensionality reduced.
By default, all measurements are selected in the box.
You can read more about parameters of both algorithms by hovering over question marks or by clicking on them.
When you are done with the selection, click on `Run` and after a moment, the table of measurements will re-appear with two additional columns representing the reduced dimensions of the dataset.
These columns are automatically saved in the labels layer and can be further processed by other plugins.

![](https://github.com/BiAPoL/napari-clusters-plotter/raw/main/images/umap.png)

Afterwards, you can again save and/or close the table.

### Clustering
If manual clustering, as shown above, is not an option, you can automatically cluster your data, using these implemented algorithms:
* [k-means clustering (KMEANS)](https://towardsdatascience.com/k-means-clustering-algorithm-applications-evaluation-methods-and-drawbacks-aa03e644b48a)
* [Hierarchical Density-Based Spatial Clustering of Applications with Noise (HDBSCAN)](https://hdbscan.readthedocs.io/en/latest/how_hdbscan_works.html)
* [Gaussian Mixture Model (GMM)](https://scikit-learn.org/stable/modules/mixture.html)
* [Mean Shift (MS)](https://scikit-learn.org/stable/auto_examples/cluster/plot_mean_shift.html#sphx-glr-auto-examples-cluster-plot-mean-shift-py)
* [Agglomerative clustering (AC)](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.AgglomerativeClustering.html)

Therefore, click the menu `Tools > Measurement post-processing > Clustering (ncp)`,
select the analysed labels layer.
Select the measurements for clustering, e.g. select _only_ the `UMAP` measurements.
Select the clustering method `KMeans` and click on `Run`.
The table of measurements will reappear with an additional column `ALGORITHM_NAME_CLUSTERING_ID` containing the cluster
ID of each datapoint.

![](https://github.com/BiAPoL/napari-clusters-plotter/raw/main/images/clustering.png)

Afterwards, you can save and/or close the table.

### Plotting clustering results

Return to the Plotter widget using the menu `Tools > Visualization > Plot measurement (ncp)`.
Select `UMAP_0` and `UMAP_1` as X- and Y-axis and the `ALGORITHM_NAME_CLUSTERING_ID` as `Clustering`, and click on `Plot`.

![](https://github.com/BiAPoL/napari-clusters-plotter/raw/main/images/hdbscan_clusters_plot.png)

## Installation
### Devbio-napari installation

The easiest way to install this plugin is to install the [devbio-napari](https://github.com/haesleinhuepf/devbio-napari) plugin collection. The napari-clusters-plotter is part of it.

### Minimal installation
* Get a python environment, e.g. via [mini-conda](https://docs.conda.io/en/latest/miniconda.html).
  If you never used mamba/conda environments before, please follow the instructions
  [in this blog post](https://biapol.github.io/blog/mara_lampert/getting_started_with_mambaforge_and_python/readme.html) first.

* Create a new environment, for example, like this:

```
mamba create --name ncp-env python=3.9
```

* Activate the new environment via conda:

```
mamba activate ncp-env
```

* Install [napari], e.g. via [conda]:

```
mamba install -c conda-forge napari
```

Afterwards, you can install `napari-clusters-plotter`, e.g. via [conda]:

```
mamba install -c conda-forge napari-clusters-plotter
```

## Troubleshooting installation

- `Error: Could not build wheels for hdbscan which use PEP 517 and cannot be installed directly`

This can happen if you used pip for the installation. To solve this error, install hdbscan via conda before installing the plugin:

```
mamba install -c conda-forge hdbscan
```

- `ValueError: numpy.ndarray size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject`

Similar to the above-described error, this error can occur when importing hdbscan through pip or in the wrong order. This can be fixed by installing packages separately through conda and in the following order:
```bash
mamba install -c conda-forge napari hdbscan
pip install napari-clusters-plotter
```

## Contributing

Contributions are very welcome. Tests can be run with [pytest], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-clusters-plotter"" is free and open source software

## Acknowledgements
This project was supported by the Deutsche Forschungsgemeinschaft under Germany’s Excellence Strategy – EXC2068 - Cluster of Excellence ""Physics of Life"" of TU Dresden.
This project has been made possible in part by grant number [2021-240341 (Napari plugin accelerator grant)](https://chanzuckerberg.com/science/programs-resources/imaging/napari/improving-image-processing/) from the Chan Zuckerberg Initiative DAF, an advised fund of the Silicon Valley Community Foundation.

## Issues

If you encounter any problems, please [file an issue](https://github.com/BiAPoL/napari-clusters-plotter/issues) along
with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[napari]: https://github.com/napari/napari
[pytest]: https://docs.pytest.org/en/7.0.x/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
[conda]: https://docs.conda.io/projects/conda/en/latest/
","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/BiAPoL/napari-clusters-plotter/issues', 'Documentation, https://github.com/BiAPoL/napari-clusters-plotter', 'Source Code, https://github.com/BiAPoL/napari-clusters-plotter', 'User Support, https://github.com/BiAPoL/napari-clusters-plotter/issues']",,,napari-clusters-plotter.PlotterWidget,,,,,https://pypi.org/project/napari-clusters-plotter,https://github.com/BiAPoL/napari-clusters-plotter,
110,napari-compressed-labels-io,0.0.2,2022-01-31,2023-06-18,napari-compressed-labels-io,Draga Doncila,ddoncila@gmail.com,MIT,https://github.com/DragaDoncila/napari-compressed-labels-io,Plugin exploring different options for reading and writing compressed and portable labels layers in napari.,>=3.6,"['napari-plugin-engine (>=0.1.4)', 'numpy', 'zarr', 'dask[complete]']","# napari-compressed-labels-io

[![License](https://img.shields.io/pypi/l/napari-compressed-labels-io.svg?color=green)](https://github.com/DragaDoncila/napari-compressed-labels-io/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-compressed-labels-io.svg?color=green)](https://pypi.org/project/napari-compressed-labels-io)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-compressed-labels-io.svg?color=green)](https://python.org)
[![tests](https://github.com/DragaDoncila/napari-compressed-labels-io/workflows/tests/badge.svg)](https://github.com/DragaDoncila/napari-compressed-labels-io/actions)
[![codecov](https://codecov.io/gh/DragaDoncila/napari-compressed-labels-io/branch/master/graph/badge.svg)](https://codecov.io/gh/DragaDoncila/napari-compressed-labels-io)


## Description

This napari plugin provides readers and writers for labels and their corresponding image layers into zarr format for compression and portability. Each reader/writer pair supports a round trip of saving and loading image and labels layers.

## Writers
Two writers are provided by this plugin, each with its own reader.

### `labels_to_zarr`
This writer is an alternative to napari's default label writer and will write an entire labels layer, regardless of its dimensions, into a single zarr file. This writer provides the best compression option and its associated reader `get_zarr_labels` will read the layer back into napari.

This writer will be called when the user tries to save a selected labels layer into a path ending with .zarr

### `label_image_pairs_to_zarr`
This writer will save 3-dimensional labels and image layers from the viewer into individual zarrs for portability and convenience. For example, given one labels and one image layer of the shape (10, 200, 200) saved to my_stacks.zarr, 10 subdirectories will be created, each with two zarrs inside of shape (200, 200) corresponding to the labels and image layer.

This writer allows users to load stacks of associated images, label them, and then quickly save these stacks out into individual slices for easy loading, viewing and interaction. Its associated reader supports the loading into napari of the whole stack, all layers at one slice of the stack, and an individual layer of a given slice of the stack.

The writer currently supports only 3D layers, with the exception of RGB images of the form (z, y, x, 3), which are also supported.


## Readers

Two readers are provided by this plugin for loading the formats saved by each writer. These are detailed below.

### `get_zarr_labels`

This reader will open any zarr file with a .zarray at the top level in `path` as a labels layer. This is to be used in conjunction with `labels_to_zarr`.


### `get_label_image_stack`

This reader will open any zarr containing a `.zmeta` file as layers into napari. Depending on what is being opened, the reader will either load a full stack of labels and images, one slice of a stack of images and labels or an individual layer within a slice. This is to be used in conjunction with `label_image_pairs_to_zarr`.

## .zmeta

This metadata file contains information about the layer types in the stack and in each individual slice, as well as the number of image/label slices. This allows the reader plugin to load the correct layer types with appropriate names both at a stack level and at the individual slice level.

### An example .zmeta specification

```json
{
    ""meta"": {
        ""stack"": 7                               # number of slices in the entire stack (1 for an individual slice, 0 for a layer within a slice)
    },
    ""data"": {
        ""image"" : [                              # all image layers must be listed here
            {
                ""name"": ""leaves_example_data"",
                ""shape"": [790, 790, 3],
                ""dtype"": ""uint8"",
                ""rgb"": true                      # where rgb is false the image will be loaded as greyscale (colormap support has not yet been implemented)
            }
        ],
        ""labels"" : [
            {
                ""name"": ""oak"",
                ""shape"": [790, 790],
                ""dtype"": ""int64""
            },
            {
                ""name"": ""bg"",
                ""shape"": [790, 790],
                ""dtype"": ""int64""
            }
        ]
    }
}

```


----------------------------------

This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/docs/plugins/index.html
-->

## Installation

You can install `napari-compressed-labels-io` via [pip]:

    pip install napari-compressed-labels-io

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [MIT] license,
""napari-compressed-labels-io"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/DragaDoncila/napari-compressed-labels-io/issues
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/


","['Development Status :: 4 - Beta', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: MIT License']",,napari-compressed-labels-io.get_zarr_labels,napari-compressed-labels-io.labels_to_zarr,,,['*'],,,https://pypi.org/project/napari-compressed-labels-io,https://github.com/DragaDoncila/napari-compressed-labels-io,
111,Napari Conference,0.1.0,,,napari-conference,Kyle Harrington,czi@kyleharrington.com,BSD-3-Clause,,A simple plugin that allows you to use napari + your webcam in video calls,>=3.8,"['numpy', 'magicgui', 'qtpy', 'opencv-python', 'pyvirtualcam', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-conference

[![License BSD-3](https://img.shields.io/pypi/l/napari-conference.svg?color=green)](https://github.com/kephale/napari-conference/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-conference.svg?color=green)](https://pypi.org/project/napari-conference)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-conference.svg?color=green)](https://python.org)
[![tests](https://github.com/kephale/napari-conference/workflows/tests/badge.svg)](https://github.com/kephale/napari-conference/actions)
[![codecov](https://codecov.io/gh/kephale/napari-conference/branch/main/graph/badge.svg)](https://codecov.io/gh/kephale/napari-conference)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-conference)](https://napari-hub.org/plugins/napari-conference)

A simple plugin that allows you to use napari + your webcam in video
calls

![Example screenshot of a person using napari conference with the
napari viewer and napari conference widget shown](napari_conference_example.png)

## Usage

1. `Plugins>start conference`
2. Check `running` checkbox
3. Press `Update` button to update any setting (and start/stop)

If things work in zoom but you don't show up, then make sure `blur
background` is disabled.

## Installation

### Prerequisites

You will need to:

- follow `pyvirtualcam`'s installation instructions:
https://github.com/letmaik/pyvirtualcam#installation
- install `napari` from source to get the new async slicing updates 

Note: I needed to install `pyvirtualcam` from source on my MacOS M1
with python=3.10.



[Not available on pypi yet] You can install `napari-conference` via [pip]:

    pip install napari-conference



To install latest development version :

    pip install git+https://github.com/kephale/napari-conference.git


## Known Issues

- resizing the napari window while streaming causes a crash
- cannot be restarted after stopping the widget

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-conference"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/kephale/napari-conference/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/kephale/napari-conference/issues', 'Documentation, https://github.com/kephale/napari-conference#README.md', 'Source Code, https://github.com/kephale/napari-conference', 'User Support, https://github.com/kephale/napari-conference/issues']",,,napari-conference.make_widget,,,,,https://pypi.org/project/napari-conference,,
112,Conidie,1.0.2,2023-04-11,2023-06-18,napari-conidie,Herearii Metuarea,herearii.metuarea@gmail.com,BSD-3-Clause,https://github.com/hereariim/napari-conidie,A segmentation tool to get conidie and hyphe,>=3.8,"['numpy', 'magicgui', 'qtpy', 'pandas', 'h5py', 'scikit-image', 'napari', 'matplotlib', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-conidie

[![License BSD-3](https://img.shields.io/pypi/l/napari-conidie.svg?color=green)](https://github.com/hereariim/napari-conidie/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-conidie.svg?color=green)](https://pypi.org/project/napari-conidie)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-conidie.svg?color=green)](https://python.org)
[![tests](https://github.com/hereariim/napari-conidie/workflows/tests/badge.svg)](https://github.com/hereariim/napari-conidie/actions)
[![codecov](https://codecov.io/gh/hereariim/napari-conidie/branch/main/graph/badge.svg)](https://codecov.io/gh/hereariim/napari-conidie)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-conidie)](https://napari-hub.org/plugins/napari-conidie)

A segmentation tool to get conidie and hyphe

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

This plugin is a use case for obtaining conidia and hyphae surface from images. This plugin is a private tool dedicated exclusively to the work of the QUASAV team.

## Installation

This private tool cannot be found in the built-in napari. The installation therefore follows two steps:

1 - Install latest development version :

    git clone https://github.com/hereariim/napari-conidie.git

## Getting started

As prerequisite, user must have installed ilastik in its computer.

Before using the plugin, you must have two data:

- The ilastik model
- The compressed file contained your images structured as followed :

```
└── Compressed file
    ├── Folder1
    │   ├── img0_1.jpg
    │   ├── img0_2.jpg
    │   ...
    │   └── img0_n.jpg
    │ 
    ├── Folder2
    │   ├── img1_1.jpg
    │   ├── img1_2.jpg
    │   ...
    │   └── img1_n.jpg
    ...
    │
    └──  Foldern
        ├── imgn_1.jpg
        ├── imgn_2.jpg
        ...
        └── imgn_n.jpg
```

## Plugin

![here](https://github.com/hereariim/napari-conidie/assets/93375163/07cf6bc3-3d55-4ae1-94ac-8e8b33193963)

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-conidie"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/hereariim/napari-conidie/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/hereariim/napari-conidie/issues', 'Documentation, https://github.com/hereariim/napari-conidie#README.md', 'Source Code, https://github.com/hereariim/napari-conidie', 'User Support, https://github.com/hereariim/napari-conidie/issues']",,,napari-conidie.segmentation,,,,,https://pypi.org/project/napari-conidie,https://github.com/hereariim/napari-conidie,
113,napari-console,0.0.9,2021-02-06,2023-11-04,napari-console,Nicholas Sofroniew,sofroniewn@gmail.com,BSD-3-Clause,https://github.com/napari/napari-console,A plugin that adds a console to napari,>=3.8,"['IPython >=7.7.0', 'ipykernel >=5.2.0', 'qtconsole !=4.7.6,!=5.4.2,>=4.5.1', 'qtpy >=1.7.0']","# napari-console (WIP, under active development)

[![License](https://img.shields.io/pypi/l/napari-console.svg?color=green)](https://github.com/napari/napari-console/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-console.svg?color=green)](https://pypi.org/project/napari-console)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-console.svg?color=green)](https://python.org)
[![tests](https://github.com/sofroniewn/napari-console/workflows/tests/badge.svg)](https://github.com/sofroniewn/napari-console/actions)
[![codecov](https://codecov.io/gh/sofroniewn/napari-console/branch/master/graph/badge.svg)](https://codecov.io/gh/sofroniewn/napari-console)

A plugin that adds a console to napari

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/docs/plugins/index.html
-->

## Installation

You can install `napari-console` via [pip]:

    pip install napari-console

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-console"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/sofroniewn/napari-console/issues
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 4 - Beta', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Topic :: Software Development :: Testing']",,,,,,,,,https://pypi.org/project/napari-console,https://github.com/napari/napari-console,
114,napari ConvPaint,0.4.0,2023-12-04,2023-12-10,napari-convpaint,Guillaume Witz,guillaume.witz@unibe.ch,BSD-3-Clause,https://github.com/guiwitz/napari-convpaint,A plugin for segmentation by pixel classification using convolutional feature extraction,>=3.8,"['einops', 'joblib', 'magicgui', 'napari', 'napari-annotation-project', 'napari-guitils', 'numpy', 'pyyaml', 'qtpy', 'scikit-learn', 'scikit-image', 'tifffile', 'torch', 'torchvision >=0.13.0', 'pandas', 'zarr', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","
[![License](https://img.shields.io/pypi/l/napari-convpaint.svg?color=green)](https://github.com/guiwitz/napari-convpaint/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-convpaint.svg?color=green)](https://pypi.org/project/napari-convpaint)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-convpaint.svg?color=green)](https://python.org)
[![tests](https://github.com/guiwitz/napari-convpaint/workflows/tests/badge.svg)](https://github.com/guiwitz/napari-convpaint/actions)
[![codecov](https://codecov.io/gh/guiwitz/napari-convpaint/branch/main/graph/badge.svg)](https://codecov.io/gh/guiwitz/napari-convpaint)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-convpaint)](https://napari-hub.org/plugins/napari-convpaint)

# napari-convpaint

![overview conv-paint](/images/overview_github.png)
This napari plugin can be used to segment objects in images based on a few brush strokes providing examples of foreground and background. Based on the same idea as other tools like ilastik, its main strength is that it provides good results without adjusting any parameters. The filters used to generate features for classification are indeed taken from layers of trained deep learning networks and don't need to be chosen manually. Find more information in the [docs](https://guiwitz.github.io/napari-convpaint/).

![overview conv-paint](/images/network_github.png)

**The idea behind the plugin comes directly from the work of Lucien Hinderling (University of Bern) and can be found here: https://github.com/hinderling/napari_pixel_classifier.**
## Installation

You can install `napari-convpaint` via [pip]

    pip install napari-convpaint

To install latest development version :

    pip install git+https://github.com/guiwitz/napari-convpaint.git

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-convpaint"" is free and open source software

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

# Authors

The idea behind this napari plugin was first developed by Lucien Hinderling in the group of [Olivier Pertz](https://www.pertzlab.net/), at the Institute of Cell Biology, University of Bern. The code has first been shared as open source resource in form of a [Jupyter Notebook](https://github.com/hinderling/napari_pixel_classifier). With the desire to make this resource accessible to a broader public in the scientific community, the Pertz lab obtained a CZI napari plugin development grant with the title [""Democratizing Image Analysis with an Easy-to-Train Classifier""](https://chanzuckerberg.com/science/programs-resources/imaging/napari/democratizing-image-analysis-with-an-easy-to-train-classifier/) which supported the adaptation of the initial concept as a napari plugin called napari-convpaint. The plugin has been developed by Guillaume Witz, Mykhailo Vladymyrov and Ana Stojiljkovic at the [Data Science Lab](https://www.dsl.unibe.ch/), University of Bern, in tight collaboration with the Pertz lab.

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/guiwitz/napari-convpaint/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/guiwitz/napari-convpaint/issues', 'Documentation, https://github.com/guiwitz/napari-convpaint#README.md', 'Source Code, https://github.com/guiwitz/napari-convpaint', 'User Support, https://github.com/guiwitz/napari-convpaint/issues']",,,napari-convpaint.make_qwidget,napari-convpaint.labelcell3d,,,,https://pypi.org/project/napari-convpaint,https://github.com/guiwitz/napari-convpaint,
115,Cookiecut,0.1.1,,,napari-cookiecut,Sean Martin,martins7@tcd.ie,BSD-3-Clause,,Fixed cut,>=3.8,"['numpy', 'magicgui', 'qtpy', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-cookiecut

[![License BSD-3](https://img.shields.io/pypi/l/napari-cookiecut.svg?color=green)](https://github.com/seankmartin/napari-cookiecut/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-cookiecut.svg?color=green)](https://pypi.org/project/napari-cookiecut)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-cookiecut.svg?color=green)](https://python.org)
[![tests](https://github.com/seankmartin/napari-cookiecut/workflows/tests/badge.svg)](https://github.com/seankmartin/napari-cookiecut/actions)
[![codecov](https://codecov.io/gh/seankmartin/napari-cookiecut/branch/main/graph/badge.svg)](https://codecov.io/gh/seankmartin/napari-cookiecut)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-cookiecut)](https://napari-hub.org/plugins/napari-cookiecut)

A fixed version of a cookiecut napari plugin template that has been set up with all the basic functionality following the README for reference.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-cookiecut` via [pip]:

    pip install napari-cookiecut



To install latest development version :

    pip install git+https://github.com/seankmartin/napari-cookiecut.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-cookiecut"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/seankmartin/napari-cookiecut/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/seankmartin/napari-cookiecut/issues', 'Documentation, https://github.com/seankmartin/napari-cookiecut#README.md', 'Source Code, https://github.com/seankmartin/napari-cookiecut', 'User Support, https://github.com/seankmartin/napari-cookiecut/issues']",napari-cookiecut.get_reader,napari-cookiecut.write_multiple,napari-cookiecut.make_qwidget,napari-cookiecut.make_sample_data,['*.npy'],,['.npy'],https://pypi.org/project/napari-cookiecut,,
116,Napari Correct Drift,0.4.0,2023-08-01,2023-11-06,napari-correct-drift,Christoph Sommer,christoph.sommer@ist.ac.at,BSD-3-Clause,https://github.com/sommerc/napari-correct-drift,Drift correction 2D/3D for Napari similar to Fijis Correct 3D drift macro,>=3.8,"['napari', 'numpy', 'qtpy', 'pandas', 'scikit-image', 'scipy', 'dask', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-correct-drift

[![License BSD-3](https://img.shields.io/pypi/l/napari-correct-drift.svg?color=green)](https://github.com/sommerc/napari-correct-drift/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-correct-drift.svg?color=green)](https://pypi.org/project/napari-correct-drift)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-correct-drift.svg?color=green)](https://python.org)
[![tests](https://github.com/sommerc/napari-correct-drift/workflows/tests/badge.svg)](https://github.com/sommerc/napari-correct-drift/actions)
[![codecov](https://codecov.io/gh/sommerc/napari-correct-drift/branch/main/graph/badge.svg)](https://codecov.io/gh/sommerc/napari-correct-drift)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-correct-drift)](https://napari-hub.org/plugins/napari-correct-drift)
[![Documentation Status](https://readthedocs.org/projects/napari-correct-drift/badge/?version=latest)](https://napari-correct-drift.readthedocs.io/en/latest/?badge=latest)

Napari-correct-drift brings the functionality of Fiji’s popular Correct-3D-drift macro to Napari for flexible and efficient correction of stage and sample drift common in time-lapse microscopy.

Napari-correct-drift supports drift correction for 2D/3D multi-channel data.

----------------------------------
## Example

https://user-images.githubusercontent.com/895863/235100349-83379350-06a5-4fe7-9323-f3e5771cca2e.mp4


## Test data
Napari-correct-drift contains synthetic sample data. To test it on real data download an example Arabidopsis growing [root tip](https://seafile.ist.ac.at/f/b05362d4f358430c8c59/?dl=1) file.

## Installation

You can install `napari-correct-drift` via [pip]:

    pip install napari-correct-drift

To install latest development version :

    pip install git+https://github.com/sommerc/napari-correct-drift.git

## Roadmap

- [x] Basic CorrectDrift interface
- [x] Synthetic test data
- [x] Unit tests
- [x] 2D/3D multi-channel support
- [x] ROI support (rectangles)
- [x] Saving and loading of drift tables
- [x] Outlier handling
- [x] Sphinx documentation
- [x] How-tos
- [x] Tutorials and Guides

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-correct-drift"" is free and open source software

### Acknowledgment
This project has been made possible in part by grant number NP2-0000000051 from the napari Plugin Foundations Grants (Cycle 2).
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/sommerc/napari-correct-drift/issues', 'Documentation, https://github.com/sommerc/napari-correct-drift#README.md', 'Source Code, https://github.com/sommerc/napari-correct-drift', 'User Support, https://github.com/sommerc/napari-correct-drift/issues']",,,napari-correct-drift.make_qwidget,napari-correct-drift.sample_2d,,,,https://pypi.org/project/napari-correct-drift,https://github.com/sommerc/napari-correct-drift,
117,napari-cosmos-ts,0.1.2,,,napari-cosmos-ts,Marcel Goldschen-Ohm,Marcel Goldschen-Ohm <goldschen-ohm@utexas.edu>,MIT,,napari plugin for colocalization single-molecule spectroscopy (CoSMoS) time series (TS) analysis,>=3.10,"['napari>=0.4.19.post1', 'pyqtgraph>=0.13.4', 'pystackreg>=0.2.7', 'pycpd>=2.0.0']","# napari-cosmos-ts
[napari](https://napari.org/stable/) plugin for colocalization single-molecule spectroscopy (CoSMoS) time series (TS) analysis.

# Install
1. Install the `conda` package manager. Simplest is to download [Miniconda](https://docs.conda.io/en/main/miniconda.html) and run the installer.
2. Create a virtual python environment named `napari-env` (or name it whatever you want) in which to install [napari](https://napari.org/stable/) and this plugin. In a command shell or terminal run the following command:
```shell
conda create --name napari-env python
```
3. Activate your virtual environment. *!!! Note you will have to do this every time you open a new command shell or terminal.* In a command shell or terminal run the following command:
```shell
conda activate napari-env
```
4. Install `napari` and `napari-cosmos-ts` into your virtual environment. In a command shell or terminal *where you have activated your virtual environment* run the following command:
```shell
pip install ""napari[all]"" napari-cosmos-ts
```

# Run
1. Activate your virtual environment (see [Install](#install), replace napari-env with the name of your environment). In a command shell or terminal run the following command:
```shell
conda activate napari-env
```
2. Launch the `napari` viewer. In a command shell or terminal *where you have activated your virtual environment* run the following command:
```shell
napari
```
3. Launch the `napari-cosmos-ts` plugin. From the napari viewer `Plugins menu`, select `Colocalization Single-Molecule Time Series (napari-cosmos-ts)`. This should bring up a docked widget within the viewer. **Now you are good to go!**
","['Development Status :: 3 - Alpha', 'Intended Audience :: Science/Research', 'License :: OSI Approved :: MIT License', 'Framework :: napari', 'Programming Language :: Python :: 3 :: Only']","['Homepage, https://github.com/marcel-goldschen-ohm/napari-cosmos-ts', 'Repository, https://github.com/marcel-goldschen-ohm/napari-cosmos-ts']",,,napari-cosmos-ts.main_widget,,,,,https://pypi.org/project/napari-cosmos-ts,,
118,CryoET Data Portal,0.3.1,,,napari-cryoet-data-portal,Andy Sweet,andrewdsweet@gmail.com,MIT,,"List, preview, and open data from the CZII CryoET Data Portal",>=3.8,"['cryoet-data-portal ~=3.0', 'fsspec[http,s3]', 'npe2', 'numpy', 'napari-ome-zarr', 'ndjson', 'qtpy', 'superqt', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-mock ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-cryoet-data-portal

[![MIT License](https://img.shields.io/pypi/l/napari-cryoet-data-portal.svg?color=green)](https://github.com/chanzuckerberg/napari-cryoet-data-portal/raw/main/LICENSE)
[![Python package index](https://img.shields.io/pypi/v/napari-cryoet-data-portal.svg?color=green)](https://pypi.org/project/napari-cryoet-data-portal)
[![Supported Python versions](https://img.shields.io/pypi/pyversions/napari-cryoet-data-portal.svg?color=green)](https://python.org)
[![Test status](https://github.com/chanzuckerberg/napari-cryoet-data-portal/workflows/tests/badge.svg)](https://github.com/chanzuckerberg/napari-cryoet-data-portal/actions)
[![Code coverage](https://codecov.io/gh/chanzuckerberg/napari-cryoet-data-portal/branch/main/graph/badge.svg)](https://codecov.io/gh/chanzuckerberg/napari-cryoet-data-portal)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-cryoet-data-portal)](https://napari-hub.org/plugins/napari-cryoet-data-portal)

List and open tomograms from the CZ Imaging Institute's [CryoET Data Portal] in [napari].

![Plugin showing tomogram TS_043](https://github.com/chanzuckerberg/napari-cryoet-data-portal/assets/2608297/61427a1f-df88-4e12-a680-32b8a10b6e6b)

## Installation

You can install the latest stable version using [pip]:

    pip install napari-cryoet-data-portal

You will also need to install napari separately as a Python package in the same environment.
One way to do that with Qt included is to run:

    pip install ""napari[all]""

but more generally you should follow the [latest napari installation instructions].

## Usage

See the following video for a demonstration of basic usage of the plugin.

https://github.com/chanzuckerberg/napari-cryoet-data-portal/assets/2608297/51207e08-68af-446a-87bb-3de9c6756d35

Click the *Connect* button to establish a connection to the data portal.

![Connect button and URL to the portal](https://github.com/chanzuckerberg/napari-cryoet-data-portal/assets/2608297/acefbbe8-855a-490b-be44-45a003069b08)

You can optionally query a subset of datasets, runs, voxel spacings, or tomograms using their corresponding IDs.
This can speed up the listing process as the portal grows.
To do so, select an ID type in the associated drop-down box from this panel, then enter the IDs of interest separated by commas in the text box next to it.
For example, if you only want to list datasets 10000 and 10001, select *Dataset IDs* from the drop-down box and enter the text *10000,10001* in the text box.
By default, all datasets are listed.

After connecting to the portal, datasets are added below as they are found.

![Datasets and tomograms in the portal shown as an interactive tree](https://github.com/chanzuckerberg/napari-cryoet-data-portal/assets/2608297/7af78e00-bbba-4c5b-a286-fb865ca8cff0)

Datasets and tomograms can be filtered by specifying a regular expression pattern.

![Datasets and tomograms filtered by the text 26, so that only two are shown](https://github.com/chanzuckerberg/napari-cryoet-data-portal/assets/2608297/96a57f4c-290e-4932-aa2d-95d13edd2d8c)

Selecting a dataset displays its metadata, which can be similarly explored and filtered.

![Metadata of dataset 10000 shown as an interactive tree of keys and values](https://github.com/chanzuckerberg/napari-cryoet-data-portal/assets/2608297/b230720a-9083-4e35-a9db-44071c979fcc)

Selecting a tomogram displays its metadata and also opens the lowest resolution tomogram and all of its associated point annotations in the napari viewer.

![Metadata of tomogram TS_026 shown as an interactive tree of keys and values](https://github.com/chanzuckerberg/napari-cryoet-data-portal/assets/2608297/386b3116-ba16-4f5d-840d-4eafa3dc62b0)

Higher resolution tomograms can be loaded instead by selecting a different resolution and clicking the *Open* button.

![Open button and resolution selector showing high resolution](https://github.com/chanzuckerberg/napari-cryoet-data-portal/assets/2608297/d84c93b2-e6e7-43ee-aeb9-acd1a314637e)

In this case, napari only loads the data that needs to be displayed in the canvas.
While this can reduce the amount of data loaded, it may also cause performance problems when initially opening and exploring the data.
By default, opening a new tomogram clears all the existing layers in napari.
If instead you want to keep those layers, uncheck the associated check-box in this panel.

In general, finding and fetching data from the portal can take a long time.
All plugin operations that fetch data from the portal try to run concurrently in order to keep interaction with napari and the plugin as responsive as possible.
These operations can also be cancelled by clicking the *Cancel* button.

![Progress bar with loading status and cancel button](https://github.com/chanzuckerberg/napari-cryoet-data-portal/assets/2608297/2dc316ae-5231-4159-bc93-785548dbf6a5)

## Contributing

This is still in early development, but contributions and ideas are welcome!
Don't hesitate to [open an issue] or [open a pull request] to help improve this plugin.

To setup a development environment, fork this repository, clone your fork, change into its top level directory and run:

    pip install -e "".[testing]""

This project adheres to the [Contributor Covenant code of conduct].
By participating, you are expected to uphold this code.
Please report unacceptable behavior to opensource@chanzuckerberg.com.

## Security

If you believe you have found a security issue, please see our [security policy] on how to report it.

## License

Distributed under the terms of the [MIT] license, ""napari-cryoet-data-portal"" is free and open source software. See the [license file] for more details.

## Acknowledgements

This plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.


[napari]: https://github.com/napari/napari
[@napari]: https://github.com/napari
[CryoET Data Portal]: https://chanzuckerberg.github.io/cryoet-data-portal
[pip]: https://pypi.org/project/pip/
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[MIT]: http://opensource.org/licenses/MIT
[security policy]: /SECURITY.md
[license file]: /LICENSE
[Contributor Covenant code of conduct]: https://github.com/chanzuckerberg/.github/tree/master/CODE_OF_CONDUCT.md
[open an issue]: https://github.com/chanzuckerberg/napari-cryoet-data-portal/issues
[open a pull request]: https://github.com/chanzuckerberg/napari-cryoet-data-portal/pulls
[latest napari installation instructions]: https://napari.org/stable/tutorials/fundamentals/installation.html#install-as-python-package-recommended
","['Development Status :: 4 - Beta', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: MIT License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/chanzuckerberg/napari-cryoet-data-portal/issues', 'Documentation, https://github.com/chanzuckerberg/napari-cryoet-data-portal#README.md', 'Source Code, https://github.com/chanzuckerberg/napari-cryoet-data-portal', 'User Support, https://github.com/chanzuckerberg/napari-cryoet-data-portal/issues']",napari-cryoet-data-portal.tomogram_ome_zarr_reader,,napari-cryoet-data-portal.DataPortalWidget,napari-cryoet-data-portal.tomogram_10000_ts_026,['*.zarr'],,,https://pypi.org/project/napari-cryoet-data-portal,,
119,napari-cryofibsem-monitor,0.0.3,2022-01-29,2023-06-18,napari-cryofibsem-monitor,Johannes Elferich,jojotux123@hotmail.com,MIT,https://github.com/jojoelfe/napari-cryofibsem-monitor,A plugin to monitor the creation of lamella using AutoTEM on a TFS Acquilos instrument,>=3.7,"['napari-plugin-engine (>=0.1.4)', 'numpy', 'tifffile', 'imreg-dft', 'matplotlib']","# napari-cryofibsem-monitor

[![License](https://img.shields.io/pypi/l/napari-cryofibsem-monitor.svg?color=green)](https://github.com/jojoelfe/napari-cryofibsem-monitor/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-cryofibsem-monitor.svg?color=green)](https://pypi.org/project/napari-cryofibsem-monitor)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-cryofibsem-monitor.svg?color=green)](https://python.org)
[![tests](https://github.com/jojoelfe/napari-cryofibsem-monitor/workflows/tests/badge.svg)](https://github.com/jojoelfe/napari-cryofibsem-monitor/actions)
[![codecov](https://codecov.io/gh/jojoelfe/napari-cryofibsem-monitor/branch/main/graph/badge.svg)](https://codecov.io/gh/jojoelfe/napari-cryofibsem-monitor)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-cryofibsem-monitor)](https://napari-hub.org/plugins/napari-cryofibsem-monitor)

A plugin to monitor the creation of lamella using AutoTEM on a TFS Acquilos instrument


https://user-images.githubusercontent.com/6081039/201448228-fdd8b429-8ff6-4934-ad58-e80fbfcbaef0.mp4

## Changelog

- **v0.0.3** 
    - Update data during milling
    - Align images to keep lamella in the center
    - Monitor thickness

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/docs/plugins/index.html
-->

## Installation

You can install `napari-cryofibsem-monitor` via [pip]:

    pip install napari-cryofibsem-monitor



To install latest development version :

    pip install git+https://github.com/jojoelfe/napari-cryofibsem-monitor.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [MIT] license,
""napari-cryofibsem-monitor"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/jojoelfe/napari-cryofibsem-monitor/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: MIT License']","['Bug Tracker, https://github.com/jojoelfe/napari-cryofibsem-monitor/issues', 'Documentation, https://github.com/jojoelfe/napari-cryofibsem-monitor#README.md', 'Source Code, https://github.com/jojoelfe/napari-cryofibsem-monitor', 'User Support, https://github.com/jojoelfe/napari-cryofibsem-monitor/issues']",,,napari-cryofibsem-monitor.ExampleQWidget,,,,,https://pypi.org/project/napari-cryofibsem-monitor,https://github.com/jojoelfe/napari-cryofibsem-monitor,
120,napari-cupy-image-processing,0.4.1,2022-02-11,2023-08-17,napari-cupy-image-processing,Robert Haase,robert.haase@tu-dresden.de,MIT,https://github.com/haesleinhuepf/napari-cupy-image-processing,GPU-accelerated image processing using CUDA,>=3.7,"['napari-plugin-engine >=0.1.4', 'numpy', 'toolz', 'cupy', 'napari-tools-menu', 'scikit-image', 'napari-time-slicer >=0.4.8', 'napari-skimage-regionprops', 'napari-assistant', 'stackview >=0.3.2']","# napari-cupy-image-processing

[![License](https://img.shields.io/pypi/l/napari-cupy-image-processing.svg?color=green)](https://github.com/haesleinhuepf/napari-cupy-image-processing/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-cupy-image-processing.svg?color=green)](https://pypi.org/project/napari-cupy-image-processing)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-cupy-image-processing.svg?color=green)](https://python.org)
[![tests](https://github.com/haesleinhuepf/napari-cupy-image-processing/workflows/tests/badge.svg)](https://github.com/haesleinhuepf/napari-cupy-image-processing/actions)
[![codecov](https://codecov.io/gh/haesleinhuepf/napari-cupy-image-processing/branch/master/graph/badge.svg)](https://codecov.io/gh/haesleinhuepf/napari-cupy-image-processing)
[![Development Status](https://img.shields.io/pypi/status/napari-cupy-image-processing.svg)](https://en.wikipedia.org/wiki/Software_release_life_cycle#Alpha)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-cupy-image-processing)](https://napari-hub.org/plugins/napari-cupy-image-processing)


GPU-accelerated image processing using [cupy](https://cupy.dev) and [CUDA](https://en.wikipedia.org/wiki/CUDA)

## Usage

This napari plugin adds some menu entries to the Tools menu. You can recognize them with their suffix `(n-cupy)` in brackets.
Furthermore, it can be used from the [napari-assistant](https://www.napari-hub.org/plugins/napari-assistant) graphical user interface. 
Therefore, just click the menu `Tools > Utilities > Assistant (na)` or run `naparia` from the command line.

![img.png](https://github.com/haesleinhuepf/napari-cupy-image-processing/raw/main/docs/screenshot-with-tools-menu.png)

You can also call operations from python, e.g. as shown in this [demo notebook](https://github.com/haesleinhuepf/napari-cupy-image-processing/raw/main/docs/demo.ipynb).

## Installation

You can install `napari-cupy-image-processing` using conda:

    mamba install -c conda-forge cupy cudatoolkit=11.2 napari-cupy-image-processing

## Troubleshooting installation

In case of issues, follow the [instructions for installing cupy](https://docs.cupy.dev/en/stable/install.html#installing-cupy-from-conda-forge). 

A more detailed example for installation (change 11.2 to your desired CUDA version):
```
mamba create --name cupy_p39 python=3.9 
conda activate cupy_p39
```
And then:
```
mamba install -c conda-forge cupy cudatoolkit=11.2 napari-cupy-image-processing
```

## Contributing

Contributions are very welcome. Adding [cupy ndimage](https://docs.cupy.dev/en/stable/reference/ndimage.html) functions is quite easy as you can see in the 
[implementation of the current operations](https://github.com/haesleinhuepf/napari-cupy-image-processing/blob/main/napari_cupy_image_processing/_cupy_image_processing.py#L48). 
If you need another function in napari, just send a PR. Please make sure the tests pass locally before submitting a PR.

```
pip install pytest-cov pytest-qt
pytest --cov=napari_cupy_image_processing
```

This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.

## License

Distributed under the terms of the [MIT] license,
""napari-cupy-image-processing"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/haesleinhuepf/napari-cupy-image-processing/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 3 - Alpha', 'Intended Audience :: Science/Research', 'Framework :: napari', 'Topic :: Scientific/Engineering :: Image Processing', 'Topic :: Scientific/Engineering :: Information Analysis', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: MIT License']","['Bug Tracker, https://github.com/haesleinhuepf/napari-cupy-image-processing/issues', 'Documentation, https://github.com/haesleinhuepf/napari-cupy-image-processing#README.md', 'Source Code, https://github.com/haesleinhuepf/napari-cupy-image-processing', 'User Support, https://github.com/haesleinhuepf/napari-cupy-image-processing/issues']",,,napari-cupy-image-processing.napari_experimental_provide_function,,,,,https://pypi.org/project/napari-cupy-image-processing,https://github.com/haesleinhuepf/napari-cupy-image-processing,
121,Cursor tracker,0.1.3,2023-10-29,2023-10-29,napari-cursor-tracker,Florian Aymanns,florian.aymanns@epfl.ch,BSD-3-Clause,https://pypi.org/project/napari-cursor-tracker,Plugin for easy manual annotation/tracking of 3D or 2D + t dataset by following the cursor.,>=3.8,"['numpy', 'magicgui', 'qtpy', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-cursor-tracker

[![License BSD-3](https://img.shields.io/pypi/l/napari-cursor-tracker.svg?color=green)](https://github.com/faymanns/napari-cursor-tracker/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-cursor-tracker.svg?color=green)](https://pypi.org/project/napari-cursor-tracker)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-cursor-tracker.svg?color=green)](https://python.org)
[![tests](https://github.com/faymanns/napari-cursor-tracker/workflows/tests/badge.svg)](https://github.com/faymanns/napari-cursor-tracker/actions)
[![codecov](https://codecov.io/gh/faymanns/napari-cursor-tracker/branch/main/graph/badge.svg)](https://codecov.io/gh/faymanns/napari-cursor-tracker)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-cursor-tracker)](https://napari-hub.org/plugins/napari-cursor-tracker)

Plugin for easy manual annotation/tracking of 3D or 2D + t dataset by following the cursor.

----------------------------------

<!--
This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-cursor-tracker` via [pip]:

    pip install napari-cursor-tracker

## Getting Started with napari-cursor-tracker

Welcome to `napari-cursor-tracker`, a tool that simplifies the annotation of points in stacks of images by tracking your cursor's position. This documentation will guide you through the process of setting up and using this plugin effectively.

### Points Layer Setup

Before you can start tracking, you need to create a points layer, which will store the positions of your cursor for each image in the stack. Here's how to set it up:

1. **Choose a Reference Image:** Start by selecting a ""Reference image"" from your image stack. The number of frames or slices in the reference image determines how many points your new layer will have (one per frame/slice).

2. **Specify Point Name:** Assign a name to the tracked point. This name will also serve as the name for the new layer. This step is particularly useful when tracking multiple points.

3. **Create the Layer:** Click on ""Add new layer"" to create the points layer. Initially, all points will be located at the origin (0, 0, 0), but their positions will be updated as you start tracking.

### Tracking Your Cursor

Now that you have set up the points layer, you can start tracking your cursor's position. Follow these steps:

1. **Select the Active Layer:** Choose the points layer where you want to save the tracking results as the ""Active layer.""

2. **Initiate Tracking:** Begin tracking your cursor's position by pressing the 't' key on your keyboard. To stop tracking, press 't' again. If the ""Auto play when tracking is started"" option is enabled, playback will start automatically when you press 't'. Alternatively, you can manually scroll through the images, and your cursor's position will be saved whenever the slice/frame index changes.

3. **Customize Playback:** To facilitate or expedite tracking, you can adjust playback parameters as needed.

### Tracking Multiple Points

If you need to track multiple points of interest, you can follow these steps:

1. **Create Individual Layers:** Create a separate points layer for each point you want to track.

2. **Select Active Layer:** Use the ""Active layer"" dropdown menu to select the specific points layer you want to work with.

3. **Start Tracking:** Begin tracking the selected point following the previously mentioned tracking process.

### Saving Your Results

The results from your tracking sessions can be saved as CSV files. Any points that were not tracked will be marked at the origin point (0, 0, 0) in the saved file.

With these guidelines, you should be well-prepared to efficiently annotate points in your image stacks using `napari-cursor-tracker`. Happy tracking!


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-cursor-tracker"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']",,,,napari-cursor-tracker.make_qwidget,napari-cursor-tracker.make_sample_data,,,,https://pypi.org/project/napari-cursor-tracker,,
122,napari-curtain,0.1.1,2022-02-04,2023-06-18,napari-curtain,Robert Haase,robert.haase@tu-dresden.de,BSD-3-Clause,https://github.com/haesleinhuepf/napari-curtain,View one image over another as curtain,>=3.7,"['napari-plugin-engine (>=0.1.4)', 'numpy', 'napari-tools-menu']","# napari-curtain

[![License](https://img.shields.io/pypi/l/napari-curtain.svg?color=green)](https://github.com/haesleinhuepf/napari-curtain/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-curtain.svg?color=green)](https://pypi.org/project/napari-curtain)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-curtain.svg?color=green)](https://python.org)
[![tests](https://github.com/haesleinhuepf/napari-curtain/workflows/tests/badge.svg)](https://github.com/haesleinhuepf/napari-curtain/actions)
[![codecov](https://codecov.io/gh/haesleinhuepf/napari-curtain/branch/main/graph/badge.svg)](https://codecov.io/gh/haesleinhuepf/napari-curtain)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-curtain)](https://napari-hub.org/plugins/napari-curtain)

View one image over another as curtain

![](https://github.com/haesleinhuepf/napari-curtain/raw/main/docs/curtain_screencast.gif)

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

## Usage

You find the `Curtain` plugin in the menu `Tools > Visualization > Curtain`. Move the position of the slider left/right 
as shown in the video above. In case one image is much bright than the other, you can modify the `factors` above the 
slider until visualization pleases.

## Installation

You can install `napari-curtain` via [pip]:

    pip install napari-curtain


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-curtain"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/haesleinhuepf/napari-curtain/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/


","['Development Status :: 3 - Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Scientific/Engineering :: Image Processing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/haesleinhuepf/napari-curtain/issues', 'Documentation, https://github.com/haesleinhuepf/napari-curtain#README.md', 'Source Code, https://github.com/haesleinhuepf/napari-curtain', 'User Support, https://github.com/haesleinhuepf/napari-curtain/issues']",,,napari-curtain.curtain,,,,,https://pypi.org/project/napari-curtain,https://github.com/haesleinhuepf/napari-curtain,
123,Curviewer,0.1.0,,,napari-curviewer,Romain Fernandez,romain.fernandez@cirad.fr,LGPL-3.0-only,,A plugin to unroll organs along their curved central line,>=3.8,"['numpy', 'magicgui', 'qtpy', 'scikit-image', 'vedo', 'vtk', 'scipy', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-curviewer

[![License GNU LGPL v3.0](https://img.shields.io/pypi/l/napari-curviewer.svg?color=green)](https://github.com/Rocsg/napari-curviewer/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-curviewer.svg?color=green)](https://pypi.org/project/napari-curviewer)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-curviewer.svg?color=green)](https://python.org)
[![tests](https://github.com/Rocsg/napari-curviewer/workflows/tests/badge.svg)](https://github.com/Rocsg/napari-curviewer/actions)
[![codecov](https://codecov.io/gh/Rocsg/napari-curviewer/branch/main/graph/badge.svg)](https://codecov.io/gh/Rocsg/napari-curviewer)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-curviewer)](https://napari-hub.org/plugins/napari-curviewer)

A plugin to unroll organs along their curved central line

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-curviewer` via [pip]:

    pip install napari-curviewer



To install latest development version :

    pip install git+https://github.com/Rocsg/napari-curviewer.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [GNU LGPL v3.0] license,
""napari-curviewer"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/Rocsg/napari-curviewer/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: GNU Lesser General Public License v3 (LGPLv3)', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/Rocsg/napari-curviewer/issues', 'Documentation, https://github.com/Rocsg/napari-curviewer#README.md', 'Source Code, https://github.com/Rocsg/napari-curviewer', 'User Support, https://github.com/Rocsg/napari-curviewer/issues']",napari-curviewer.get_reader,napari-curviewer.write_multiple,napari-curviewer.make_container_widget,napari-curviewer.make_sample_data,['*.npy'],,['.npy'],https://pypi.org/project/napari-curviewer,,
124,CZANN Segmentation,0.0.18,2022-08-18,2023-07-28,napari-czann-segment,Sebastian Rhode,sebrhode@gmail.com,BSD-3-Clause,https://github.com/sebi06/napari-czann-segment,Semantic Segmentation using Deep Learning ONNX models packaged as *.czann files,>=3.9,"['numpy', 'magicgui', 'qtpy', 'napari', 'cztile', 'czmodel[pytorch] >=5', 'onnxruntime-gpu', 'aicsimageio', 'pytest', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-czann-segment

[![License](https://img.shields.io/pypi/l/napari-czann-segment.svg?color=green)](https://github.com/sebi06/napari-czann-segment/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-czann-segment.svg?color=green)](https://pypi.org/project/napari-czann-segment)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-czann-segment.svg?color=green)](https://python.org)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-czann-segment)](https://napari-hub.org/plugins/napari-czann-segment)

Semantic Segmentation of multidimensional images using Deep Learning ONNX models packaged as *.czann files.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

![Train on APEER and use model in Napari](https://github.com/sebi06/napari-czann-segment/raw/main/readme_images/Train_APEER_run_Napari_CZANN_no_highlights_small.gif)

## Installation

Before installing, please setup a conda environment. If you have never worked with conda environments, go through [this tutorial](https://biapol.github.io/blog/johannes_mueller/anaconda_getting_started/) first.

You can then install `napari-czann-segment` via [pip]:

    pip install napari-czann-segment

## What does the plugin do

The plugin allows you to:

- Use a *.czann file containing the Deep Neural Network (ONNX) for semantic segmentation and metadata
- Segmentation will be applied per 2D plane for all dimensions
- Processing larger multidimensional images it uses the [cztile] package to chunk the individual 2d arrays using a specific overlap.
- multidimensional images will be processed plane-by-plane

## What does the plugin NOT do

**Before one can actually use a model it needs to be trained, which is NOT done by this plugin**.

There are two main ways hwo such a model can be created:

- Train the segmentation model fully automated on [APEER] and download the *.czann file
- Train your model in a Jupyter notebook etc. and package it using the [czmodel] python package as an *.czann

## Using this plugin

### Sample Data

A test image and a *.czann model file can be downloaded [here](https://github.com/sebi06/napari-czann-segment/tree/main/src/napari_czann_segment/_data).

- `PGC_20X.ome.tiff` --> use `PGC_20X_nucleus_detector.czann` to segment

In order to use this plugin the user has to do the following things:

- Open the image using ""File - Open Files(s)"" (requires [napari-aicsimageio] plugin).
- Click **napari-czann-segment: Segment with CZANN model** in the ""Plugins"" menu.
- **Select a czann file** to use the model for segmentation.
- metadata of the model will be shown (see example below)

| Parameter    | Value                                        | Explanation                                             |
| :----------- | :------------------------------------------- | ------------------------------------------------------- |
| model_type   | ModelType.SINGLE_CLASS_SEMANTIC_SEGMENTATION | see: [czmodel] for details                              |
| input_shape  | [1024, 1024, 1]                              | tile dimensions of model input                          |
| output_shape | [1024, 1024, 3]                              | tile dimensions of model output                         |
| model_id     | ba32bc6d-6bc9-4774-8b47-20646c7cb838         | unique GUID for that model                              |
| min_overlap  | [128, 128]                                   | tile overlap used during training (for this model)      |
| classes      | ['background', 'grains', 'inclusions']       | available classes                                       |
| model_name   | APEER-trained model                          | name of the model                                       |

![Napari - Image loaded and czann selected](https://github.com/sebi06/napari-czann-segment/raw/main/readme_images/napari_czann1.png)

- Adjust the **minimum overlap** for the tiling (optional, see [cztile] for details).
- Select the **layer** to be segmented.
- Toggle **Use GPU for inference** checkbox to enable / disable using a GPU (Nvidia) for the segmentation (experimental feature).
- Press **Segment Selected Image Layer** to run the segmentation.

![Napari - Image successfully segmented](https://github.com/sebi06/napari-czann-segment/raw/main/readme_images/napari_czann3.png)

A successful is obviously only the starting point for further image analysis steps to extract the desired numbers from the segmented image.
Another example is shown below demonstrating a simple ""Grain Size Analysis"" using a deep-learning model trained on [APEER] used in [napari]

![Napari - Simple Grain Size Analysis](https://github.com/sebi06/napari-czann-segment/raw/main/readme_images/grainsize_czann_napari.png)

### Remarks

> **IMPORTANT**: Currently the plugin only supports using models trained on a **single channel** image. Therefore, make sure that during the training on [APEER] or somewhere else the correct inputs images are used.
> It is quite simple to train a single RGB image, which actually has three channels, load this image in [napari] and notice only then that the model will not work, because the image will 3 channels inside [napari].

- Only the CPU will be used for the inference using the ONNX runtime for the [ONNX-CPU] runtime
- GPUs are supported but require the [ONNX-GPU] runtime and the respective CUDA libraries.
- Please check the [YAML](env_napari_czann_segment.yml) for an example environment with GPU support.
- See also [pytorch] for instruction on how to install pytorch

## For developers

- **Please clone this repository first using your favorite tool.**

- **Ideally one creates a new [conda] environment or use an existing environment that already contains [Napari].**

Feel free to create a new environment using the [YAML](env_napari_czann_segment.yml) file at your own risk:

    cd the-github-repo-with-YAML-file
    conda env create --file conda_env_napari_czann_segment.yml
    conda activate napari_czmodel

- **Install the plugin locally**

Please run the following command:

    pip install -e .

To install latest development version:

    pip install git+https://github.com/sebi06/napari_czann_segment.git

## Contributing

Contributions and Feedback are very welcome.

## License

Distributed under the terms of the [BSD-3] license,
""napari-czann-segment"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/sebi06/napari-czann-segment/issues
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
[czmodel]: https://pypi.org/project/czmodel/
[cztile]: https://pypi.org/project/cztile/
[APEER]: https://www.apeer.com
[napari-aicsimageio]: https://github.com/AllenCellModeling/napari-aicsimageio
[ONNX-GPU]: https://pypi.org/project/onnxruntime-gpu/
[ONNX-CPU]: https://pypi.org/project/onnxruntime/
[conda]: https://docs.conda.io/projects/conda/en/latest/user-guide/getting-started.html
[pytorch]: https://pytorch.org/get-started/locally
","['Development Status :: 3 - Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'Intended Audience :: Science/Research', 'License :: OSI Approved :: BSD License', 'Operating System :: Unix', 'Operating System :: Microsoft :: Windows', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/sebi06/napari-czann-segment/issues', 'Documentation, https://github.com/sebi06/napari-czann-segment#README.md', 'Source Code, https://github.com/sebi06/napari-czann-segment', 'User Support, https://github.com/sebi06/napari-czann-segment/issues']",,,napari-czann-segment.get_czann_widget,,,,,https://pypi.org/project/napari-czann-segment,https://github.com/sebi06/napari-czann-segment,
125,napari-czifile2,0.2.7,2022-01-31,2023-06-18,napari-czifile2,Jonas Windhager,jonas.windhager@uzh.ch,MIT,https://github.com/BodenmillerGroup/napari-czifile2,Carl Zeiss Image (.czi) file support for napari,>=3.8,"['czifile', 'imagecodecs', 'numpy', 'tifffile']","# napari-czifile2

<a href=""https://pypi.org/project/napari-czifile2/"">
    <img src=""https://img.shields.io/pypi/v/napari-czifile2"" alt=""PyPI"" />
</a>
<a href=""https://github.com/BodenmillerGroup/napari-czifile2/blob/main/LICENSE.md"">
    <img src=""https://img.shields.io/pypi/l/napari-czifile2"" alt=""License"" />
</a>
<a href=""https://www.python.org/"">
    <img src=""https://img.shields.io/pypi/pyversions/napari-czifile2"" alt=""Python"" />
</a>
<a href=""https://github.com/BodenmillerGroup/napari-czifile2/issues"">
    <img src=""https://img.shields.io/github/issues/BodenmillerGroup/napari-czifile2"" alt=""Issues"" />
</a>
<a href=""https://github.com/BodenmillerGroup/napari-czifile2/pulls"">
    <img src=""https://img.shields.io/github/issues-pr/BodenmillerGroup/napari-czifile2"" alt=""Pull requests"" />
</a>

Carl Zeiss Image (.czi) file type support for napari

Open .czi files and interactively view scenes co-registered in the machine's coordinate system using napari

## Installation

You can install napari-czifile2 via [pip](https://pypi.org/project/pip/):

    pip install napari-czifile2

Alternatively, you can install napari-czifile2 via [conda](https://conda.io/):

    conda install -c conda-forge napari-czifile2

## Authors

Created and maintained by Jonas Windhager [jonas.windhager@uzh.ch](mailto:jonas.windhager@uzh.ch)

## Contributing

[Contributing](https://github.com/BodenmillerGroup/napari-czifile2/blob/main/CONTRIBUTING.md)

## Changelog

[Changelog](https://github.com/BodenmillerGroup/napari-czifile2/blob/main/CHANGELOG.md)

## License

[MIT](https://github.com/BodenmillerGroup/napari-czifile2/blob/main/LICENSE.md)
","['Development Status :: 4 - Beta', 'Intended Audience :: Science/Research', 'Framework :: napari', 'Topic :: Scientific/Engineering :: Bio-Informatics', 'Topic :: Scientific/Engineering :: Image Processing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Operating System :: OS Independent', 'License :: OSI Approved :: MIT License']","['Bug Tracker, https://github.com/BodenmillerGroup/napari-czifile2/issues', 'Documentation, https://github.com/BodenmillerGroup/napari-czifile2#README.md', 'Source Code, https://github.com/BodenmillerGroup/napari-czifile2', 'User Support, https://github.com/BodenmillerGroup/napari-czifile2/issues']",napari-czifile2.get_reader,,,,['*.czi'],,,https://pypi.org/project/napari-czifile2,https://github.com/BodenmillerGroup/napari-czifile2,
126,napari-data-preview,0.0.3a0,,,napari-data-preview,"Vivien Gaillet, Jules Scholler",jules.scholler@wysscenter.ch,MPL-2.0,,"Preview lightsheet microscopes acquisition, and allow the creation of an XML for importing the data into TeraStitcher.",>=3.7,"['numpy', 'napari[all]', 'lxml', 'napari-tools-menu', 'magic-class', 'napari-plugin-engine (>=0.1.4)', 'dask', 'tifffile', 'dask-image', 'elementpath', 'tk (>=0.1.0)', 'zarr', 'scikit-image', 'PySimpleGUI', 'pytest-shutil']","# napari-data-preview

Preview lightsheet microscopes acquisition, and allow the creation of an XML for importing the data into TeraStitcher.

This package is very experimental, and you should expect bug/errors.

## Installation

You can install `napari-data-preview` via [pip]:

    pip install napari-data-preview

To install latest development version :

    pip install git+https://github.com/WyssCenter/napari-data-preview.git
","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: Mozilla Public License 2.0 (MPL 2.0)']",,napari-data-preview.napari_get_reader,,napari-data-preview.DataPreview,,['*'],,,https://pypi.org/project/napari-data-preview,,
127,Napari DeepFinder,0.0.1,,,napari-deepfinder,Constantin Aronssohn,cnstt@tutanota.com,GPL-3.0-only,,"A napari plugin for the DeepFinder library which includes display, annotation, target generation, segmentation and clustering functionalities. An orthoslice view has been added for an easier visualisation and annotation process.",>=3.8,"['em-deepfinder', 'numpy', 'magicgui', 'qtpy', 'napari', 'scikit-image', 'typing', 'pandas', 'lxml', 'pillow', 'h5py', 'mrcfile', 'scipy', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'""]","# napari-deepfinder

[![License GNU GPL v3.0](https://img.shields.io/pypi/l/napari-deepfinder.svg?color=green)](https://github.com/deep-finder/napari-deepfinder/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-deepfinder.svg?color=green)](https://pypi.org/project/napari-deepfinder)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-deepfinder.svg?color=green)](https://python.org)
[![tests](https://github.com/deep-finder/napari-deepfinder/workflows/tests/badge.svg)](https://github.com/deep-finder/napari-deepfinder/actions)
[![codecov](https://codecov.io/gh/deep-finder/napari-deepfinder/branch/main/graph/badge.svg)](https://codecov.io/gh/deep-finder/napari-deepfinder)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-deepfinder)](https://napari-hub.org/plugins/napari-deepfinder)

A napari plugin for the DeepFinder library which includes display, annotation, target generation, segmentation and clustering functionalities.
An orthoslice view has been added for an easier visualisation and annotation process.

**The documentation for users is available [here](https://deep-finder.github.io/napari-deepfinder/).**

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/index.html
-->

## Installation

You can install `napari-deepfinder` via [pip]:

    pip install napari-deepfinder



To install latest development version :

    pip install git+https://github.com/deep-finder/napari-deepfinder.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [GNU GPL v3.0] license,
""napari-deepfinder"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/deep-finder/napari-deepfinder/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 3 - Alpha', 'Intended Audience :: Education', 'Intended Audience :: Science/Research', 'Framework :: napari', 'Topic :: Scientific/Engineering', 'Topic :: Scientific/Engineering :: Visualization', 'Topic :: Scientific/Engineering :: Information Analysis', 'Topic :: Scientific/Engineering :: Bio-Informatics', 'Topic :: Scientific/Engineering :: Artificial Intelligence', 'Topic :: Scientific/Engineering :: Image Processing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Operating System :: OS Independent', 'License :: OSI Approved :: GNU General Public License v3 (GPLv3)']","['Bug Tracker, https://github.com/deep-finder/napari-deepfinder/issues', 'Documentation, https://deep-finder.github.io/napari-deepfinder/', 'Source Code, https://github.com/deep-finder/napari-deepfinder', 'User Support, https://github.com/deep-finder/napari-deepfinder/issues']",napari-deepfinder.get_reader,napari-deepfinder.write_annotations,napari-deepfinder.make_reorder_widget,,"['*.mrc', '*.map', '*.rec', '*.h5', '*.tif', '*.TIF', '*.xml', '*.ods', '*.xls', '*.xlsx']",['.xml'],['.mrc'],https://pypi.org/project/napari-deepfinder,,
128,napari DeepLabCut,0.2.1.6,2022-07-05,2023-12-08,napari-deeplabcut,"Team DeepLabCut, Lead by Jessy Lauer",admin@deeplabcut.org,BSD-3-Clause,https://github.com/DeepLabCut/napari-deeplabcut,napari + DeepLabCut annotation tool,>=3.9,"['dask-image', 'matplotlib >=3.3', 'napari ==0.4.18', 'natsort', 'numpy', 'opencv-python-headless', 'pandas', 'pyyaml', 'qtpy >=2.4', 'scikit-image', 'tables', ""pyside6 ==6.4.2 ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""tox ; extra == 'testing'""]","# napari-deeplabcut: keypoint annotation for pose estimation



<img src=""https://images.squarespace-cdn.com/content/v1/57f6d51c9f74566f55ecf271/1d409ffe-c9f4-47e1-bde2-3010c1c40455/naparidlc.png?format=750w"" width=""450"" title=""napari-deeplabcut"" alt=""napari+deeplabcut"" align=""right"" vspace = ""80"">

[📚Documentation](https://deeplabcut.github.io/DeepLabCut/README.html) |
[🛠️ DeepLabCut Installation](https://deeplabcut.github.io/DeepLabCut/docs/installation.html) |
[🌎 Home Page](https://www.deeplabcut.org) |

[![License: BSD-3](https://img.shields.io/badge/License-BSD3-blue.svg)](https://www.gnu.org/licenses/bsd3)
[![PyPI](https://img.shields.io/pypi/v/napari-deeplabcut.svg?color=green)](https://pypi.org/project/napari-deeplabcut)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-deeplabcut.svg?color=green)](https://python.org)
[![tests](https://github.com/DeepLabCut/napari-deeplabcut/workflows/tests/badge.svg)](https://github.com/DeepLabCut/napari-deeplabcut/actions)
[![codecov](https://codecov.io/gh/DeepLabCut/napari-deeplabcut/branch/main/graph/badge.svg)](https://codecov.io/gh/DeepLabCut/napari-deeplabcut)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-deeplabcut)](https://napari-hub.org/plugins/napari-deeplabcut)

A napari plugin for keypoint annotation, also used within DeepLabCut!


## Installation

If you installed DeepLabCut[gui], this plugin is already installed. However, you can also use this as a stand-alone keypoint annotator without using DeepLabCut. Instructions below!

Start by installing PySide6 with `pip install ""pyside6==6.4.2""`; this is the library we now use to build GUIs.

You can then install `napari-deeplabcut` via [pip]:

    pip install napari-deeplabcut



Alternatively, to install the latest development version, run:

    pip install git+https://github.com/DeepLabCut/napari-deeplabcut.git


## Usage

To use the plugin, please run:

    napari

Then, activate the plugin in Plugins > napari-deeplabcut: Keypoint controls.

All accepted files (config.yaml, images, h5 data files) can be loaded
either by dropping them directly onto the canvas or via the File menu.

The easiest way to get started is to drop a folder (typically a folder from within a DeepLabCut's `labeled-data` directory), and, if labeling from scratch, drop the corresponding `config.yaml` to automatically add a `Points layer` and populate the dropdown menus.

[🎥 DEMO
](https://youtu.be/hsA9IB5r73E)

**Tools & shortcuts are:**

- `2` and `3`, to easily switch between labeling and selection mode
- `4`, to enable pan & zoom (which is achieved using the mouse wheel or finger scrolling on the Trackpad)
- `M`, to cycle through regular (sequential), quick, and cycle annotation mode (see the description [here](https://github.com/DeepLabCut/napari-deeplabcut/blob/5a5709dd38868341568d66eab548ae8abf37cd63/src/napari_deeplabcut/keypoints.py#L25-L34))
- `E`, to enable edge coloring (by default, if using this in refinement GUI mode, points with a confidence lower than 0.6 are marked
in red)
- `F`, to toggle between animal and body part color scheme.
- `V`, to toggle visibility of the selected layer.
- `backspace` to delete a point.
- Check the box ""display text"" to show the label names on the canvas.
- To move to another folder, be sure to save (`Ctrl+S`), then delete the layers, and re-drag/drop the next folder.
- One can jump to a specific image by double-clicking and editing the current frame number (located to the right of the slider).
- Selected points can be copied with `Ctrl+C`, and pasted onto other images with `Ctrl+V`.


### Save Layers

Annotations and segmentations are saved with `File > Save Selected Layer(s)...` (or its shortcut `Ctrl+S`).
Only when saving segmentation masks does a save file dialog pop up to name the destination folder;
keypoint annotations are otherwise automatically saved in the corresponding folder as `CollectedData_<ScorerName>.h5`.
- As a reminder, DLC will only use the H5 file; so be sure if you open already labeled images you save/overwrite the H5.
- Note, before saving a layer, make sure the points layer is selected. If the user clicked on the image(s) layer first, does `Save As`, then closes the window, any labeling work during that session will be lost!
- Modifying and then saving points in a `machinelabels...` layer will add to or overwrite the existing `CollectedData` layer and will **not** save to the `machinelabels` file.


### Video frame extraction and prediction refinement

Since v0.0.4, videos can be viewed in the GUI.

Since v0.0.5, trailing points can be visualized; e.g., helping in the identification
of swaps or outlier, jittery predictions.

Loading a video (and its corresponding output h5 file) will enable the video actions
at the top of the dock widget: they offer the option to manually extract video
frames from the GUI, or to define cropping coordinates.
Note that keypoints can be displaced and saved, as when annotating individual frames.


## Workflow

Suggested workflows, depending on the image folder contents:

1. **Labeling from scratch** – the image folder does not contain `CollectedData_<ScorerName>.h5` file.

    Open *napari* as described in [Usage](#usage) and open an image folder together with the DeepLabCut project's `config.yaml`.
    The image folder creates an *image layer* with the images to label.
    Supported image formats are: `jpg`, `jpeg`, `png`.
    The `config.yaml` file creates a *Points layer*, which holds metadata (such as keypoints read from the config file) necessary for labeling.
    Select the *Points layer* in the layer list (lower left pane on the GUI) and click on the *+*-symbol in the layer controls menu (upper left pane) to start labeling.
    The current keypoint can be viewed/selected in the keypoints dropdown menu (right pane).
    The slider below the displayed image (or the left/right arrow keys) allows selecting the image to label.

    To save the labeling progress refer to [Save Layers](#save-layers).
    `Data successfully saved` should be shown in the status bar, and the image folder should now contain a `CollectedData_<ScorerName>.h5` file.
    (Note: For convenience, a CSV file with the same name is also saved.)

2. **Resuming labeling** – the image folder contains a `CollectedData_<ScorerName>.h5` file.

    Open *napari* and open an image folder (which needs to contain a `CollectedData_<ScorerName>.h5` file).
    In this case, it is not necessary to open the DLC project's `config.yaml` file, as all necessary metadata is read from the `h5` data file.

    Saving works as described in *1*.

    ***Note that if a new body part has been added to the `config.yaml` file after having started to label, loading the config in the GUI is necessary to update the dropdown menus and other metadata.***

    ***As `viridis` is `napari-deeplabcut` default colormap, loading the config in the GUI is also needed to update the color scheme.***

3. **Refining labels** – the image folder contains a `machinelabels-iter<#>.h5` file.

    The process is analog to *2*.
    Open *napari* and open an image folder.
    If the video was originally labeled, *and* had outliers extracted it will contain a `CollectedData_<ScorerName>.h5` file and a `machinelabels-iter<#>.h5` file. In this case, select the `machinelabels` layer in the GUI, and type `e` to show edges. Red indicates likelihood < 0.6. As you navigate through frames, images with labels with edges will need to be refined (moved, deleted, etc). Images with labels without edges will be on the `CollectedData` (previous manual annotations) layer and shouldn't need refining. However, you can switch to that layer and fix errors. You can also right-click on the `CollectedData` layer and select `toggle visibility` to hide that layer. Select the `machinelabels` layer before saving which will append your refined annotations to `CollectedData`.

    If the folder only had outliers extracted and wasn't originally labeled, it will not have a `CollectedData` layer. Work with the `machinelabels` layer selected to refine annotation positions, then save.

    In this case, it is not necessary to open the DLC project's `config.yaml` file, as all necessary metadata is read from the `h5` data file.

    Saving works as described in *1*.

4. **Drawing segmentation masks**

    Drop an image folder as in *1*, manually add a *shapes layer*. Then select the *rectangle* in the layer controls (top left pane),
    and start drawing rectangles over the images. Masks and rectangle vertices are saved as described in [Save Layers](#save-layers).
    Note that masks can be reloaded and edited at a later stage by dropping the `vertices.csv` file onto the canvas.

### Workflow flowchart

```mermaid
%%{init: {""flowchart"": {""htmlLabels"": false}} }%%
graph TD
  id1[What stage of labeling?]
  id2[deeplabcut.label_frames]
  id3[deeplabcut.refine_labels]
  id4[Add labels to, or modify in, \n `CollectedData...` layer and save that layer]
  id5[Modify labels in `machinelabels` layer and save \n which will create a `CollectedData...` file]
  id6[Have you refined some labels from the most recent iteration and saved already?]
  id7[""All extracted frames are already saved in `CollectedData...`.
1. Hide or trash all `machinelabels` layers.
2. Then modify in and save `CollectedData`""]
  id8[""
1. hide or trash all `machinelabels` layers except for the most recent.
2. Select most recent `machinelabels` and hit `e` to show edges.
3. Modify only in `machinelabels` and skip frames with labels without edges shown.
4. Save `machinelabels` layer, which will add data to `CollectedData`.
	- If you need to revisit this video later, ignore `machinelabels` and work only in `CollectedData`""]

  id1 -->|I need to manually label new frames \n or fix my labels|id2
  id1 ---->|I need to refine outlier frames \nfrom analyzed videos|id3
  id2 -->id4
  id3 -->|I only have a `machinelabels...` file|id5
  id3 ---->|I have both `machinelabels` and `CollectedData` files|id6
  id6 -->|yes|id7
  id6 ---->|no, I just extracted outliers|id8
```

### Labeling multiple image folders

Labeling multiple image folders has to be done in sequence; i.e., only one image folder can be opened at a time.
After labeling the images of a particular folder is done and the associated *Points layer* has been saved, *all* layers should be removed from the layers list (lower left pane on the GUI) by selecting them and clicking on the trashcan icon.
Now, another image folder can be labeled, following the process described in *1*, *2*, or *3*, depending on the particular image folder.


### Defining cropping coordinates

Prior to defining cropping coordinates, two elements should be loaded in the GUI:
a video and the DLC project's `config.yaml` file (into which the crop dimensions will be stored).
Then it suffices to add a `Shapes layer`, draw a `rectangle` in it with the desired area,
and hit the button `Store crop coordinates`; coordinates are automatically written to the configuration file.


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

To locally install the code, please git clone the repo and then run `pip install -e .`

## License

Distributed under the terms of the [BSD-3] license,
""napari-deeplabcut"" is free and open source software.

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[file an issue]: https://github.com/DeepLabCut/napari-deeplabcut/issues


## Acknowledgements


This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template. We thank the Chan Zuckerberg Initiative (CZI) for funding the initial development of this work!

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/stable/index.html
-->


[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Artificial Intelligence', 'Topic :: Scientific/Engineering :: Image Processing', 'Topic :: Scientific/Engineering :: Visualization']","['Bug Tracker, https://github.com/DeepLabCut/napari-deeplabcut/issues', 'Documentation, https://github.com/DeepLabCut/napari-deeplabcut#README.md', 'Source Code, https://github.com/DeepLabCut/napari-deeplabcut', 'User Support, https://github.com/DeepLabCut/napari-deeplabcut/issues']",napari-deeplabcut.get_hdf_reader,napari-deeplabcut.write_hdf,napari-deeplabcut.make_keypoint_controls,,['*.h5'],['.h5'],['.csv'],https://pypi.org/project/napari-deeplabcut,https://github.com/DeepLabCut/napari-deeplabcut,
129,napari DeepMeta,2.1,2022-02-14,2023-06-18,napari-deepmeta,Edgar Lefevre,lefevreedg@gmail.com,MIT,https://github.com/EdgarLefevre/napari-deepmeta,Mice lungs and metastases segmentation tool.,>=3.8,"['connected-components-3d', 'magicgui', 'napari', 'numpy', 'opencv-python', 'qtpy', 'scikit-image', 'torch', ""connected-components-3d ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""opencv-python ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""tox ; extra == 'testing'""]","# napari-deepmeta

[![License MIT](https://img.shields.io/pypi/l/napari-deepmeta.svg?color=green)](https://github.com/EdgarLefevre/napari-deepmeta/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-deepmeta.svg?color=green)](https://pypi.org/project/napari-deepmeta)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-deepmeta.svg?color=green)](https://python.org)
[![tests](https://github.com/EdgarLefevre/napari-deepmeta/workflows/tests/badge.svg)](https://github.com/EdgarLefevre/napari-deepmeta/actions)
[![codecov](https://codecov.io/gh/EdgarLefevre/napari-deepmeta/branch/main/graph/badge.svg)](https://codecov.io/gh/EdgarLefevre/napari-deepmeta)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-deepmeta)](https://napari-hub.org/plugins/napari-deepmeta)

Mice lungs and metastases segmentation tool.
This tool is a demo tool for DeepMeta network.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

## Installation

You can install `napari-deepmeta` via [pip]:

    pip install napari-deepmeta



To install latest development version :

    pip install git+https://github.com/EdgarLefevre/napari-deepmeta.git


## Usage

This plugin is designed to process your mouse MRI images with our dataset. It comes with a demo, including one of our
test images.

By opening the deepmeta demo plugin, you will see an interface with one unique button, by clicking on it, it will load an image,
run prediction and then draw the masks contours on each slice.

If you open the deepmeta plugin, you will see an interface with one button and 3 checkboxes.
By checking the checkboxes, you add steps to the pipeline (enhance contrast, do postprocessing, segment metastases).
Once everything is setup, just click on the button and wait (the waiting time depends on your computer performance.)

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [MIT] license,
""napari-deepmeta"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/EdgarLefevre/napari-deepmeta/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: MIT License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Software Development :: Testing']","['Bug Tracker, https://github.com/EdgarLefevre/napari-deepmeta/issues', 'Documentation, https://github.com/EdgarLefevre/napari-deepmeta#README.md', 'Source Code, https://github.com/EdgarLefevre/napari-deepmeta', 'User Support, https://github.com/EdgarLefevre/napari-deepmeta/issues']",,,napari-deepmeta.make_qwidget,,,,,https://pypi.org/project/napari-deepmeta,https://github.com/EdgarLefevre/napari-deepmeta,
130,napari-DeepSpot,0.0.7,2022-02-23,2023-06-18,napari-DeepSpot,Emmanuel Bouilhol,emmanuel.bouilhol@u-bordeaux.fr,MIT,https://github.com/ebouilhol/napari-DeepSpot,RNA spot enhancement for fluorescent microscopy images,>=3.7,"['napari-plugin-engine (>=0.1.4)', 'numpy', 'pytest', 'pytest-cov', 'pytest-xvfb', 'pytest-qt', 'napari', 'qtpy (==1.9.0)', 'pyqt5', 'tensorflow', 'scikit-image', 'opencv-python']","# napari-DeepSpot

[![License](https://img.shields.io/pypi/l/napari-DeepSpot.svg?color=green)](https://github.com/ebouilhol/napari-DeepSpot/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-DeepSpot.svg?color=green)](https://pypi.org/project/napari-DeepSpot)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-DeepSpot.svg?color=green)](https://python.org)
[![tests](https://github.com/ebouilhol/napari-DeepSpot/workflows/tests/badge.svg)](https://github.com/ebouilhol/napari-DeepSpot/actions)
[![codecov](https://codecov.io/gh/ebouilhol/napari-DeepSpot/branch/main/graph/badge.svg)](https://codecov.io/gh/ebouilhol/napari-DeepSpot)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-DeepSpot)](https://napari-hub.org/plugins/napari-DeepSpot)

RNA spot enhancement for fluorescent microscopy images.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/docs/plugins/index.html
-->

## Installation

You can install `napari-DeepSpot` via [pip]:

    pip install napari-DeepSpot

## Build from source

This plugin is using Tensorflow, make sure your Python environment has Tensorflow, on create a new environment using the following commands:
* Conda:  
`conda env create -f environment.yml`  
`conda activate deepspot-napari`
* Or pip:   
`pip install -r requirements.txt`

## Usage

Open one or multiple images using Napari GUI : 
File > Open > Select your image

The images are then displayed on Napari

Load the Plugin:
Plugins > Napari-DeepSpot:Enhance Spot

![Usage](./image/napari.png)

Click on the right panel Button ""Enhance""

Wait a few seconds for the magic to happen :

![Usage](./image/napari_enhance.png)

You can see the original images and the enhanced version in the left panel in the layer section.

To save the images : File > Save all layers or File > Save selected layers.


![Usage](./image/napari_video.gif)



## Citation
If you use this plugin please cite the [paper](https://www.biorxiv.org/content/10.1101/2021.11.25.469984v1):

>@article {Bouilhol2021DeepSpot,  
>	 author = {Bouilhol, Emmanuel and Lefevre, Edgar and Dartigues, Benjamin and Brackin, Robyn and Savulescu, Anca Flavia and Nikolski, Macha},  
>	 title = {DeepSpot: a deep neural network for RNA spot enhancement in smFISH microscopy images},  
>	 elocation-id = {2021.11.25.469984},  
>	 year = {2021},  
>	 doi = {10.1101/2021.11.25.469984},  
>	 publisher = {Cold Spring Harbor Laboratory},  
>	 URL = {https://www.biorxiv.org/content/early/2021/11/25/2021.11.25.469984},  
>	 eprint = {https://www.biorxiv.org/content/early/2021/11/25/2021.11.25.469984.full.pdf},  
>	 journal = {bioRxiv}  
>}  

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [MIT] license,
""napari-DeepSpot"" is free and open source software

## Known Issues

If you have troubles with the Python packages `typing extensions`, use the command :  
`pip install typing-extensions --upgrade`  

When using ""Enhance"" on multiple images, Napari may freeze. Just wait until it comes to life again, the images will still be enhanced. This is due to Napari memory usage and will be fix one day.


## Other Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/ebouilhol/napari-DeepSpot/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/


","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: MIT License']","['Bug Tracker, https://github.com/ebouilhol/napari-DeepSpot/issues', 'Documentation, https://github.com/ebouilhol/napari-DeepSpot#README.md', 'Source Code, https://github.com/ebouilhol/napari-DeepSpot', 'User Support, https://github.com/ebouilhol/napari-DeepSpot/issues']",,,napari-DeepSpot.EnhanceSpot,,,,,https://pypi.org/project/napari-DeepSpot,https://github.com/ebouilhol/napari-DeepSpot,
131,Demo plugin ported from npe2 example,0.2.5,,,napari-demo,napari hub team,team@napari-hub.org,BSD-3,,example plugin for napari plugin developers,>=3.7,"['pydantic', 'npe2', 'numpy']","# napari-demo

[![License](https://img.shields.io/pypi/l/napari-demo.svg?color=green)](https://github.com/chanzuckerberg/napari-demo/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-demo.svg?color=green)](https://pypi.org/project/napari-demo)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-demo.svg?color=green)](https://python.org)
[![tests](https://github.com/chanzuckerberg/napari-demo/workflows/tests/badge.svg)](https://github.com/chanzuckerberg/napari-demo/actions)
[![codecov](https://codecov.io/gh/chanzuckerberg/napari-demo/branch/master/graph/badge.svg)](https://codecov.io/gh/chanzuckerberg/napari-demo)

This is a demo plugin implementation of https://github.com/napari/napari/blob/master/examples/magic_image_arithmetic.py

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/docs/plugins/index.html
-->

## Installation

You can install `napari-demo` via [pip]:

    pip install napari-demo

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-demo"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.
To report security issues, see [security](SECURITY.md)

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/chanzuckerberg/napari-demo/issues
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/


## Code of Conduct

This project adheres to the Contributor Covenant [code of conduct](https://github.com/chanzuckerberg/.github/blob/master/CODE_OF_CONDUCT.md). By participating, you are expected to uphold this code. Please report unacceptable behavior to [opensource@chanzuckerberg.com](mailto:opensource@chanzuckerberg.com).

","['Development Status :: 4 - Beta', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Programming Language :: Python', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Software Development :: Testing', 'Operating System :: OS Independent', 'Framework :: napari']","['Source Code, https://github.com/chanzuckerberg/napari-demo']",napari-demo.some_reader,napari-demo.my_writer,napari-demo.image_arithmetic,napari-demo.generate_random_data,"['*.fzy', '*.fzzy']","['.tif', '.tiff']","['.pcd', '.e57']",https://pypi.org/project/napari-demo,,
132,DenoiSeg,0.0.1rc2,,,napari-denoiseg,"Tom Burke, Joran Deschamps",joran.deschamps@fht.org,BSD-3-Clause,,A napari plugin performing joint denoising and segmentation of microscopy images using DenoiSeg.,>=3.7,"['numpy', 'pyqtgraph', 'denoiseg (>=0.3.0)', 'bioimageio.core', 'magicgui', 'qtpy', 'napari-time-slicer (>=0.4.9)', 'napari (<=0.4.15)', 'vispy (<=0.9.6)', 'imageio (!=2.11.0,!=2.22.1,>=2.5.0)', 'tensorflow ; platform_system != ""Darwin"" or platform_machine != ""arm64""', 'tensorflow-macos ; platform_system == ""Darwin"" and platform_machine == ""arm64""', 'tensorflow-metal ; platform_system == ""Darwin"" and platform_machine == ""arm64""', ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-denoiseg

[![License](https://img.shields.io/pypi/l/napari-denoiseg.svg?color=green)](https://github.com/juglab/napari-denoiseg/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-denoiseg.svg?color=green)](https://pypi.org/project/napari-denoiseg)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-denoiseg.svg?color=green)](https://python.org)
[![tests](https://github.com/juglab/napari-denoiseg/workflows/build/badge.svg)](https://github.com/juglab/napari-denoiseg/actions)
[![codecov](https://codecov.io/gh/juglab/napari-denoiseg/branch/main/graph/badge.svg)](https://codecov.io/gh/juglab/napari-denoiseg)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-denoiseg)](https://napari-hub.org/plugins/napari-denoiseg)

A napari plugin performing joint denoising and segmentation of microscopy images using [DenoiSeg](https://github.com/juglab/DenoiSeg).

<img src=""https://raw.githubusercontent.com/juglab/napari-denoiseg/master/docs/images/example.png"" width=""800"" />
----------------------------------

## Installation

Check out the [documentation](https://juglab.github.io/napari-denoiseg/installation.html) for more detailed installation 
instructions. 


## Quick demo

You can try out a demo by loading the `DenoiSeg Demo prediction` plugin and directly clicking on `Predict`.


<img src=""https://raw.githubusercontent.com/juglab/napari-denoiseg/master/docs/images/prediction.gif"" width=""800"" />


## Documentation

Documentation is available on the [project website](https://juglab.github.io/napari-denoiseg/).


## Contributing and feedback

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request. You can also 
help us improve by [filing an issue] along with a detailed description or contact us
through the [image.sc](https://forum.image.sc/) forum (tag @jdeschamps).


## Cite us


Tim-Oliver Buchholz, Mangal Prakash, Alexander Krull and Florian Jug, ""[DenoiSeg: Joint Denoising and Segmentation](https://arxiv.org/abs/2005.02987)"" _arxiv_ (2020)


## Acknowledgements

This plugin was developed thanks to the support of the Silicon Valley Community Foundation (SCVF) and the 
Chan-Zuckerberg Initiative (CZI) with the napari Plugin Accelerator grant _2021-239867_.


Distributed under the terms of the [BSD-3] license,
""napari-denoiseg"" is a free and open source software.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[filing an issue]: https://github.com/juglab/napari-denoiseg/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Framework :: napari', 'Development Status :: 3 - Alpha', 'Intended Audience :: Science/Research', 'Topic :: Scientific/Engineering :: Image Processing', 'Topic :: Scientific/Engineering :: Information Analysis', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/juglab/napari_denoiseg/issues', 'Documentation, https://juglab.github.io/napari-denoiseg/', 'Source Code, https://github.com/juglab/napari_denoiseg', 'User Support, https://github.com/juglab/napari_denoiseg/issues']",,,napari-denoiseg.make_train_widget,napari-denoiseg.denoiseg_data_2D_n0,,,,https://pypi.org/project/napari-denoiseg,,
133,DEXP,0.0.7,2022-04-01,2023-06-18,napari-dexp,Jordao Bragantini,jordao.bragantini@czbiohub.org,BSD-3,https://github.com/royerlab/napari-dexp,A simple plugin to use with napari,>=3.7,"['napari', 'napari-plugin-engine (>=0.1.4)', 'dexp', 'numpy']","# napari-DEXP

[![License](https://img.shields.io/pypi/l/napari-dexp.svg?color=green)](https://github.com/royerlab/napari-dexp/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-dexp.svg?color=green)](https://pypi.org/project/napari-dexp)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-dexp.svg?color=green)](https://python.org)
[![tests](https://github.com/royerlab/napari-dexp/workflows/tests/badge.svg)](https://github.com/royerlab/napari-dexp/actions)
[![codecov](https://codecov.io/gh/royerlab/napari-dexp/branch/master/graph/badge.svg)](https://codecov.io/gh/royerlab/napari-dexp)

A plugin to interface [DEXP](https://github.com/royerlab/dexp) with [napari](https://github.com/napari/napari).

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/docs/plugins/index.html
-->

## Installation

You can install `napari-dexp` via [pip]:

    pip install napari-dexp

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-dexp"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/royerlab/napari-dexp/issues
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']",,napari-dexp.get_reader,napari-dexp.write_image,,,"['*.zarr', '*.zarr.zip']",['.zarr'],['.zarr'],https://pypi.org/project/napari-dexp,https://github.com/royerlab/napari-dexp,
134,napari-dv,0.3.0,2022-02-02,2023-07-10,napari-dv,Talley Lambert,talley.lambert@gmail.com,MIT,https://github.com/tlambert03/napari-dv,Deltavision/MRC file reader for napari,>=3.7,"['mrc (>=0.2.0)', 'napari-plugin-engine (>=0.1.4)', ""numpy ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'""]","# napari-dv

[![License](https://img.shields.io/pypi/l/napari-dv.svg?color=green)](https://github.com/tlambert03/napari-dv/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-dv.svg?color=green)](https://pypi.org/project/napari-dv)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-dv.svg?color=green)](https://python.org)
[![tests](https://github.com/tlambert03/napari-dv/workflows/tests/badge.svg)](https://github.com/tlambert03/napari-dv/actions)
[![codecov](https://codecov.io/gh/tlambert03/napari-dv/branch/master/graph/badge.svg)](https://codecov.io/gh/tlambert03/napari-dv)

Deltavision/MRC file reader for napari.

This wraps the [mrc](https://github.com/tlambert03/mrc) library.

See also [napari-aicsimageio](https://github.com/AllenCellModeling/napari-aicsimageio), which also uses the [mrc](https://github.com/tlambert03/mrc) to provide dv file support,
along with many other common file formats.

## Installation

You can install `napari-dv` via [pip]:

    pip install napari-dv

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [MIT] license,
""napari-dv"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[file an issue]: https://github.com/tlambert03/napari-dv/issues
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/


","['Development Status :: 4 - Beta', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: MIT License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10']","['Bug Tracker, https://github.com/tlambert03/napari-dv/issues', 'Documentation, https://github.com/tlambert03/napari-dv#README.md', 'Source Code, https://github.com/tlambert03/napari-dv', 'User Support, https://github.com/tlambert03/napari-dv/issues']",napari-dv.get_reader,napari-dv.write_image,,,"['*.dv', '*.mrc']","['.dv', '.mrc']",,https://pypi.org/project/napari-dv,https://github.com/tlambert03/napari-dv,
135,napari-dvid,0.2.0,2022-02-10,2023-06-18,napari-dvid,Emma Zhou,emma@emmazhou.com,MIT,https://github.com/emmazhou/napari-dvid,"DVID loader for napari, from a url",>=3.7,"['napari-plugin-engine (>=0.1.4)', 'numpy', 'requests']","# napari-dvid

[![License](https://img.shields.io/pypi/l/napari-dvid.svg?color=green)](https://github.com/emmazhou/napari-dvid/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-dvid.svg?color=green)](https://pypi.org/project/napari-dvid)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-dvid.svg?color=green)](https://python.org)
[![tests](https://github.com/emmazhou/napari-dvid/workflows/tests/badge.svg)](https://github.com/emmazhou/napari-dvid/actions)
[![codecov](https://codecov.io/gh/emmazhou/napari-dvid/branch/master/graph/badge.svg)](https://codecov.io/gh/emmazhou/napari-dvid)

DVID loader for napari, from a url

---

This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/docs/plugins/index.html
-->

## Installation

You can install `napari-dvid` via [pip]:

    pip install napari-dvid

## Examples

Once installed, run `napari --with napari-dvid` to get the plugin sidebar:

![Screenshot](screenshot.png)

Paste in a URL to a DVID volume and hit ""Load"" to load the volume! As an example, try:

`https://emdata.janelia.org/api/node/ab6e610d4/grayscale/raw/0_1_2/256_256_256/7500_7000_4400`

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [MIT] license,
""napari-dvid"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[mit]: http://opensource.org/licenses/MIT
[bsd-3]: http://opensource.org/licenses/BSD-3-Clause
[gnu gpl v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[gnu lgpl v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[apache software license 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[mozilla public license 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/emmazhou/napari-dvid/issues
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[pypi]: https://pypi.org/


","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: MIT License']","['Bug Tracker, https://github.com/emmazhou/napari-dvid/issues', 'Documentation, https://github.com/emmazhou/napari-dvid#README.md', 'Source Code, https://github.com/emmazhou/napari-dvid', 'User Support, https://github.com/emmazhou/napari-dvid/issues']",napari-dvid.napari_get_reader,,napari-dvid.UrlWidget,,['*'],,,https://pypi.org/project/napari-dvid,https://github.com/emmazhou/napari-dvid,
136,napari-dzi-zarr,0.1.2,2022-01-30,2023-06-18,napari-dzi-zarr,Trevor Manz,trevor.j.manz@gmail.com,BSD-3,https://github.com/manzt/napari-dzi-zarr,An experimental plugin for viewing Deep Zoom Images (DZI) with napari and zarr.,>=3.6,"['napari-plugin-engine (>=0.1.4)', 'numpy (>=0.1.19)', 'zarr (>=0.2.4)', 'dask[array] (>=2.23.0)', 'fsspec (>=0.8.0)', 'requests (>=2.24.0)', 'aiohttp (>=3.6.2)', 'imageio (>=2.9.0)']","# napari-dzi-zarr

[![License](https://img.shields.io/pypi/l/napari-dzi-zarr.svg?color=green)](https://github.com/napari/napari-dzi-zarr/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-dzi-zarr.svg?color=green)](https://pypi.org/project/napari-dzi-zarr)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-dzi-zarr.svg?color=green)](https://python.org)
[![tests](https://github.com/manzt/napari-dzi-zarr/workflows/tests/badge.svg)](https://github.com/manzt/napari-dzi-zarr/actions)

An experimental plugin for viewing Deep Zoom Images (DZI) with napari + zarr + dask.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.

## Description 

The [DZI File Format](https://github.com/openseadragon/openseadragon/wiki/The-DZI-File-Format) 
is a pyramidal tile source specification where individual tiles are RGB/RGBA JPEG/PNG images. 
DZI is a very popular tile source for zoomable web-viewers like 
[OpenSeadragon](https://openseadragon.github.io/), and as a result many tile sources are available over 
HTTP. This plugin wraps a DZI tile source (local or remote) as a multiscale Zarr, where each pyramidal level is a `zarr.Array` of shape `(level_height, level_width, 3/4)`, allowing the same images to be viewed 
in `napari` + `dask`.

## Installation

You can install `napari-dzi-zarr` via [pip]:

    pip install napari-dzi-zarr


## Usage

This high-resolution scan of Rembrandt's Night Watch is available thanks to [R.G Erdmann](https://twitter.com/erdmann). More examples can be found on [boschproject.org](http://boschproject.org).

    $ napari http://hyper-resolution.org/dzi/Rijksmuseum/SK-C-5/SK-C-5_VIS_20-um_2019-12-21.dzi

![Rembrandt's Night Watch in napari](./night_watch_napari.png)

## Contributing

Contributions are very welcome. Tests can be run with [tox].

## License

Distributed under the terms of the [BSD-3] license,
""napari-dzi-zarr"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/manzt/napari-dzi-zarr/issues
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/


","['Development Status :: 4 - Beta', 'Intended Audience :: Developers', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.6', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: Implementation :: CPython', 'Programming Language :: Python :: Implementation :: PyPy', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License', 'Framework :: napari']",,napari-dzi-zarr.napari_get_reader,,,,['*'],,,https://pypi.org/project/napari-dzi-zarr,https://github.com/manzt/napari-dzi-zarr,
137,eHooke,0.0.6,,,napari-ehooke,António Brito,antmsbrito95@gmail.com,BSD-3-Clause,,eHooke implementation within napari,>=3.8,"['numpy', 'magicgui', 'qtpy', 'napari[all]', 'tensorflow', 'napari-skimage-regionprops', 'stardist-napari', 'scikit-learn', 'pandas', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-ehooke

[![License BSD-3](https://img.shields.io/pypi/l/napari-ehooke.svg?color=green)](https://github.com/antmsbrito/napari-ehooke/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-ehooke.svg?color=green)](https://pypi.org/project/napari-ehooke)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-ehooke.svg?color=green)](https://python.org)
[![tests](https://github.com/antmsbrito/napari-ehooke/workflows/tests/badge.svg)](https://github.com/antmsbrito/napari-ehooke/actions)
[![codecov](https://codecov.io/gh/antmsbrito/napari-ehooke/branch/main/graph/badge.svg)](https://codecov.io/gh/antmsbrito/napari-ehooke)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-ehooke)](https://napari-hub.org/plugins/napari-ehooke)

eHooke implementation within napari

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-ehooke` via [pip]:

    pip install napari-ehooke



To install latest development version :

    pip install git+https://github.com/antmsbrito/napari-ehooke.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-ehooke"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/antmsbrito/napari-ehooke/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/antmsbrito/napari-ehooke/issues', 'Documentation, https://github.com/antmsbrito/napari-ehooke#README.md', 'Source Code, https://github.com/antmsbrito/napari-ehooke', 'User Support, https://github.com/antmsbrito/napari-ehooke/issues']",,,napari-ehooke.compute_mask,napari-ehooke.phase_example,,,,https://pypi.org/project/napari-ehooke,,
138,napari-elementary-numpy-operations,0.0.5,2022-02-10,2023-06-18,napari-elementary-numpy-operations,"Marc Boucsein, Robin Koch",,BSD-3,https://github.com/MBPhys/napari-elementary-numpy-operations,"A napari plugin covers elementary numpy operations like swap axes, flip, sqeeze an array or rotate an arrays by 90° steps",>=3.7,"['napari-plugin-engine (>=0.1.4)', 'numpy', 'qtpy', 'superqt']","# napari-elementary-numpy-operations

[![License](https://img.shields.io/pypi/l/napari-medical-image-formats.svg?color=green)](https://github.com/MBPhys/napari-elementary-numpy-operations/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-elementary-numpy-operations.svg?color=green)](https://pypi.org/project/napari-elementary-numpy-operations)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-elementary-numpy-operations.svg?color=green)](https://python.org)


A napari plugin covers elementary numpy operations like swap axes, flip, sqeeze an array or rotate an arrays by 90° steps.

----------------------------------

## Installation

You can install `napari-elementary-numpy-operations` via [pip]:

    napari-elementary-numpy-operations

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-elementary-numpy-operations"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/MBPhys/napari-elementary-numpy-operations/issues
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/


","['Development Status :: 4 - Beta', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']",,,,napari-elementary-numpy-operations.elementary_numpy,,,,,https://pypi.org/project/napari-elementary-numpy-operations,https://github.com/MBPhys/napari-elementary-numpy-operations,
139,napari-em-reader,0.1.0,2022-02-02,2023-06-18,napari-em-reader,Lorenzo Gaifas,brisvag@gmail.com,BSD-3,https://github.com/brisvag/napari-em-reader,A napari plugin to read .em files,>=3.6,"['napari-plugin-engine (>=0.1.4)', 'numpy', 'emfile (>=0.2)']","# napari-em-reader

[![License](https://img.shields.io/pypi/l/napari-em-reader.svg?color=green)](https://github.com/brisvag/napari-em-reader/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-em-reader.svg?color=green)](https://pypi.org/project/napari-em-reader)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-em-reader.svg?color=green)](https://python.org)
[![tests](https://github.com/brisvag/napari-em-reader/workflows/tests/badge.svg)](https://github.com/brisvag/napari-em-reader/actions)
[![codecov](https://codecov.io/gh/brisvag/napari-em-reader/branch/master/graph/badge.svg)](https://codecov.io/gh/brisvag/napari-em-reader)

A napari plugin to read .em files

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/docs/plugins/index.html
-->

## Installation

You can install `napari-em-reader` via [pip]:

    pip install napari-em-reader

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-em-reader"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/brisvag/napari-em-reader/issues
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/


","['Development Status :: 4 - Beta', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']",,napari-em-reader.napari_get_reader,,,,['*'],,,https://pypi.org/project/napari-em-reader,https://github.com/brisvag/napari-em-reader,
140,EMD File Viewer,0.1.1,2023-12-04,2023-12-08,napari-EMD,Nicolette Shaw,shaw.nicki@gmail.com,BSD-3-Clause,https://pypi.org/project/napari-EMD/,A simple plugin to view .emd files in napari (Velox files),>=3.8,"['numpy', 'h5py', 'magicgui', 'ujson', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-EMD

[![License BSD-3](https://img.shields.io/pypi/l/napari-EMD.svg?color=green)](https://github.com/NickiShaw/napari-EMD/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-EMD.svg?color=green)](https://pypi.org/project/napari-EMD)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-EMD.svg?color=green)](https://python.org)
[![tests](https://github.com/NickiShaw/napari-EMD/workflows/tests/badge.svg)](https://github.com/NickiShaw/napari-EMD/actions)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-EMD)](https://napari-hub.org/plugins/napari-EMD)

A simple plugin to view .emd files in napari (i.e. Velox files). Allows users to track metadata as it changes over the course of a video/stack, developed for analysis of in-situ microscopy data, where users may be changing magnification, focus, etc. during aquisition.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-EMD` via [pip]:

    `pip install napari-EMD`

You can install napari and access the plugin through the GUI. [Reccomended install command for napari](https://napari.org/stable/tutorials/fundamentals/installation.html):

    `python -m pip install ""napari[all]""`

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-EMD"" is free and open source software

## Issues and Requests

> **Warning: The metadata viewer does not work in the current [Napari bundle](https://napari.org/stable/tutorials/fundamentals/installation.html#install-as-a-bundled-app) version (August 2023). Use the [python package version](https://napari.org/stable/tutorials/fundamentals/installation.html#install-as-python-package-recommended) of Napari for this feature.**

If you encounter any problems or would like any functionality added, please [file an issue](https://docs.github.com/en/issues/tracking-your-work-with-issues/creating-an-issue) along with a detailed description.

Current maintainer(s): [Nicki Shaw](https://docs.github.com/en/issues/tracking-your-work-with-issues/creating-an-issue)

## Preview

Images A and B show different frames in the same image stack, the metadata plugin on the right shows the changing focus value.
![NapariEMD screenshots](Images/napariEMD_screenshots.jpg)

## To Do

- Attatch last-opened information, so the widget does not reset when frames are changed and open toggle options are open remain.
- Add a search bar for navigating metadata.
- Output metadata as file option.
- Add note to change order of open files to replacee active metadata view.
- Make Singleframe note update automatically on change of file order.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']",,napari-EMD.get_reader,,napari-EMD.load_widget,,['*.emd'],,,https://pypi.org/project/napari-EMD/,,
141,Napari Error Reporter,0.3.1,2022-06-13,2023-06-18,napari-error-reporter,Talley Lambert,talley.lambert@gmail.com,BSD-3-Clause,https://github.com/tlambert03/napari-error-reporter,Opt-in automated bug/error reporting for napari,>=3.8,"['appdirs', 'qtpy', 'sentry-sdk', ""black ; extra == 'dev'"", ""flake8 ; extra == 'dev'"", ""flake8-docstrings ; extra == 'dev'"", ""ipython ; extra == 'dev'"", ""isort ; extra == 'dev'"", ""jedi (<0.18.0) ; extra == 'dev'"", ""mypy ; extra == 'dev'"", ""pre-commit ; extra == 'dev'"", ""pydocstyle ; extra == 'dev'"", ""pytest ; extra == 'dev'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""tox ; extra == 'testing'"", ""tox-conda ; extra == 'testing'""]","# 🐛 napari-error-reporter

[![License](https://img.shields.io/pypi/l/napari-error-reporter.svg?color=green)](https://github.com/tlambert03/napari-error-reporter/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-error-reporter.svg?color=green)](https://pypi.org/project/napari-error-reporter)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-error-reporter.svg?color=green)](https://python.org)
[![CI](https://github.com/tlambert03/napari-error-reporter/actions/workflows/ci.yml/badge.svg)](https://github.com/tlambert03/napari-error-reporter/actions/workflows/ci.yml)
[![codecov](https://codecov.io/gh/tlambert03/napari-error-reporter/branch/main/graph/badge.svg)](https://codecov.io/gh/tlambert03/napari-error-reporter)

Want to help out napari?  Install this plugin!

This plugin will automatically send error reports to napari (via
[sentry.io](https://sentry.io)) whenever an exception occurs while you are using
napari.

The first time you run napari after installing this plugin an opt-in
notification will appear (Be sure to click ""yes"", otherwise no reports will be
collected or sent).  You may opt back out at any time in napari's help menu.

Every effort is made to strip these reports of personally identifiable
information.  Here is an example exception event:

<details>

<summary>Example bug report</summary>

```python
{
    'breadcrumbs': {
        'values': [
            {
                'category': 'subprocess',
                'data': {},
                'message': 'sw_vers -productVersion',
                'timestamp': '2022-02-02T01:30:00.216738Z',
                'type': 'subprocess'
            }
        ]
    },
    'contexts': {
        'runtime': {
            'build': '3.9.9 | packaged by conda-forge | (main, Dec 20 2021, 02:41:37) \n[Clang 11.1.0 ]',
            'name': 'CPython',
            'version': '3.9.9'
        }
    },
    'environment': 'macOS-10.15.7-x86_64-i386-64bit',
    'event_id': '02dd8ddd3a4b4743af3d7d7a09949df4',
    'exception': {
        'values': [
            {
                'mechanism': None,
                'module': None,
                'stacktrace': {
                    'frames': [
                        {
                            'context_line': '                x = 1 / 0',
                            'filename': 'napari_error_reporter/_util.py',
                            'function': 'get_sample_event',
                            'in_app': True,
                            'lineno': 130,
                            'module': 'napari_error_reporter._util',
                            'post_context': [
                                '            except Exception:',
                                '                with sentry_sdk.push_scope() as scope:',
                                '                    for k, v in _get_tags().items():',
                                '                        scope.set_tag(k, v)',
                                '                    del v, k, scope'
                            ],
                            'pre_context': [
                                ""            # remove locals that wouldn't really be there"",
                                '            del settings, _trans, kwargs, client, EVENT',
                                '            try:',
                                '                some_variable = 1',
                                '                another_variable = ""my_string""'
                            ]
                        }
                    ]
                },
                'type': 'ZeroDivisionError',
                'value': 'division by zero'
            }
        ]
    },
    'extra': {'sys.argv': ['napari']},
    'level': 'error',
    'modules': {
        'aicsimageio': '4.5.2',
        'aicspylibczi': '3.0.4',
        'aiohttp': '3.8.1',
        'aiosignal': '1.2.0',
        'alabaster': '0.7.12',
        'anyio': '3.5.0',
        'appdirs': '1.4.4',
        'appnope': '0.1.2',
        'argon2-cffi': '21.3.0',
        'argon2-cffi-bindings': '21.2.0',
        'arrow': '1.2.1',
        'asciitree': '0.3.3',
        'asttokens': '2.0.5',
        'async-timeout': '4.0.2',
        'atomium': '1.0.11',
        'attrs': '21.4.0',
        'autopep8': '1.6.0',
        'babel': '2.9.1',
        'backcall': '0.2.0',
        'bcrypt': '3.2.0',
        'beautifulsoup4': '4.10.0',
        'binaryornot': '0.4.4',
        'black': '20.8b1',
        'bleach': '4.1.0',
        'bracex': '2.2.1',
        'build': '0.7.0',
        'cachey': '0.2.1',
        'cellpose': '0.6.5',
        'certifi': '2021.10.8',
        'cffi': '1.15.0',
        'cfgv': '3.3.1',
        'chardet': '4.0.0',
        'charset-normalizer': '2.0.10',
        'check-manifest': '0.47',
        'click': '7.1.2',
        'click-option-group': '0.5.3',
        'cloudpickle': '2.0.0',
        'colorama': '0.4.4',
        'commonmark': '0.9.1',
        'cookiecutter': '1.7.3',
        'coverage': '6.2',
        'cryptography': '36.0.1',
        'cycler': '0.11.0',
        'dask': '2022.1.0',
        'debugpy': '1.5.1',
        'decorator': '5.1.1',
        'defusedxml': '0.7.1',
        'distlib': '0.3.4',
        'dnspython': '2.2.0',
        'docstring-parser': '0.13',
        'docutils': '0.16',
        'elementpath': '2.4.0',
        'email-validator': '1.1.3',
        'entrypoints': '0.3',
        'executing': '0.8.2',
        'fancycompleter': '0.9.1',
        'fasteners': '0.17.2',
        'fastremap': '1.12.2',
        'filelock': '3.4.2',
        'flake8': '3.8.4',
        'fonttools': '4.28.5',
        'freetype-py': '2.2.0',
        'frozenlist': '1.3.0',
        'fsspec': '2022.1.0',
        'furo': '2022.1.2',
        'gitdb': '4.0.9',
        'gitpython': '3.1.26',
        'greenlet': '1.1.2',
        'heapdict': '1.0.1',
        'hsluv': '5.0.2',
        'hypothesis': '6.35.1',
        'identify': '2.4.4',
        'idna': '3.3',
        'imagecodecs': '2021.11.20',
        'imageio': '2.10.5',
        'imageio-ffmpeg': '0.4.5',
        'imagesize': '1.3.0',
        'importlib-metadata': '4.10.1',
        'iniconfig': '1.1.1',
        'install': '1.3.5',
        'intervaltree': '3.1.0',
        'ipykernel': '6.7.0',
        'ipython': '8.0.0',
        'ipython-genutils': '0.2.0',
        'ipywidgets': '7.6.5',
        'jedi': '0.18.1',
        'jinja2': '3.0.3',
        'jinja2-time': '0.2.0',
        'jsonschema': '3.2.0',
        'jupyter': '1.0.0',
        'jupyter-book': '0.12.1',
        'jupyter-cache': '0.4.3',
        'jupyter-client': '7.1.1',
        'jupyter-console': '6.4.0',
        'jupyter-core': '4.9.1',
        'jupyter-server': '1.13.3',
        'jupyter-server-mathjax': '0.2.3',
        'jupyter-sphinx': '0.3.2',
        'jupyterlab-pygments': '0.1.2',
        'jupyterlab-widgets': '1.0.2',
        'jupytext': '1.11.5',
        'kiwisolver': '1.3.2',
        'latexcodec': '2.0.1',
        'linkify-it-py': '1.0.3',
        'llvmlite': '0.38.0',
        'locket': '0.2.1',
        'loguru': '0.5.3',
        'lxml': '4.7.1',
        'magicgui': '0.3.5.dev18+g78d1687',
        'markdown-it-py': '1.1.0',
        'markupsafe': '2.0.1',
        'matplotlib': '3.5.1',
        'matplotlib-inline': '0.1.3',
        'mccabe': '0.6.1',
        'mdit-py-plugins': '0.2.8',
        'meshzoo': '0.9.2',
        'mistune': '0.8.4',
        'mrc': '0.2.0',
        'msgpack': '1.0.3',
        'multidict': '5.2.0',
        'mypy': '0.931',
        'mypy-extensions': '0.4.3',
        'myst-nb': '0.13.1',
        'myst-parser': '0.15.2',
        'napari': '0.4.14rc1.dev4+gcdf58d44b',
        'napari-aicsimageio': '0.4.1',
        'napari-console': '0.0.4',
        'napari-dv': '0.2.7.dev0+g54e1691.d20220128',
        'napari-error-reporter': '0.1.dev1+g1b388f2.d20220201',
        'napari-hello': '0.0.1',
        'napari-math': '0.0.1a0',
        'napari-micromanager': '0.0.1rc6.dev14+g5149788.d20220128',
        'napari-molecule-reader': '0.1.2.dev1+gc2ec2de',
        'napari-plugin-engine': '0.2.0',
        'napari-pyclesperanto-assistant': '0.12.0',
        'napari-skimage-regionprops': '0.2.9',
        'napari-svg': '0.1.6',
        'napari-time-slicer': '0.4.2',
        'napari-workflows': '0.1.2',
        'natsort': '8.0.2',
        'nbclient': '0.5.10',
        'nbconvert': '6.4.0',
        'nbdime': '3.1.1',
        'nbformat': '5.1.3',
        'nd2': '0.1.4',
        'nest-asyncio': '1.5.4',
        'networkx': '2.6.3',
        'nodeenv': '1.6.0',
        'notebook': '6.4.7',
        'npe2': '0.1.1',
        'numba': '0.55.0',
        'numcodecs': '0.9.1',
        'numpy': '1.20.3',
        'numpydoc': '1.1.0',
        'ome-types': '0.2.10',
        'opencv-python-headless': '4.5.5.62',
        'packaging': '21.3',
        'pandas': '1.3.5',
        'pandocfilters': '1.5.0',
        'paramiko': '2.9.2',
        'parso': '0.8.3',
        'partd': '1.2.0',
        'pathspec': '0.9.0',
        'pdbpp': '0.10.3',
        'peewee': '3.14.8',
        'pep517': '0.12.0',
        'pexpect': '4.8.0',
        'pickleshare': '0.7.5',
        'pillow': '8.4.0',
        'pint': '0.18',
        'pip': '21.3.1',
        'platformdirs': '2.4.1',
        'pluggy': '1.0.0',
        'pooch': '1.5.2',
        'poyo': '0.5.0',
        'pre-commit': '2.16.0',
        'prometheus-client': '0.12.0',
        'prompt-toolkit': '3.0.24',
        'psutil': '5.9.0',
        'psygnal': '0.2.0',
        'ptyprocess': '0.7.0',
        'pure-eval': '0.2.1',
        'py': '1.11.0',
        'pybtex': '0.24.0',
        'pybtex-docutils': '1.0.1',
        'pyclesperanto-prototype': '0.12.0',
        'pycodestyle': '2.8.0',
        'pycparser': '2.21',
        'pydantic': '1.9.0',
        'pydata-sphinx-theme': '0.7.2',
        'pyflakes': '2.2.0',
        'pygments': '2.11.2',
        'pymmcore': '10.1.1.70.5',
        'pymmcore-plus': '0.1.8',
        'pynacl': '1.5.0',
        'pyopencl': '2021.2.13',
        'pyopengl': '3.1.5',
        'pyparsing': '3.0.6',
        'pyperclip': '1.8.2',
        'pyrepl': '0.9.0',
        'pyro5': '5.13.1',
        'pyrsistent': '0.18.1',
        'pyside2': '5.15.2.1',
        'pytest': '6.2.5',
        'pytest-cookies': '0.6.1',
        'pytest-cov': '3.0.0',
        'pytest-faulthandler': '2.0.1',
        'pytest-order': '1.0.1',
        'pytest-qt': '4.0.2',
        'python-dateutil': '2.8.2',
        'python-dotenv': '0.19.2',
        'python-slugify': '5.0.2',
        'pytomlpp': '1.0.10',
        'pytools': '2021.2.9',
        'pytz': '2021.3',
        'pywavelets': '1.2.0',
        'pyyaml': '6.0',
        'pyzmq': '22.3.0',
        'qtconsole': '5.2.2',
        'qtpy': '2.0.0',
        'regex': '2021.11.10',
        'requests': '2.27.1',
        'rich': '11.0.0',
        'rmsd': '1.4',
        'ruamel.yaml': '0.17.20',
        'ruamel.yaml.clib': '0.2.6',
        'scikit-image': '0.19.1',
        'scipy': '1.7.3',
        'semgrep': '0.78.0',
        'send2trash': '1.8.0',
        'sentry-sdk': '1.5.4',
        'serpent': '1.40',
        'setuptools': '60.5.0',
        'shiboken2': '5.15.2.1',
        'six': '1.16.0',
        'smmap': '5.0.0',
        'sniffio': '1.2.0',
        'snowballstemmer': '2.2.0',
        'sortedcontainers': '2.4.0',
        'soupsieve': '2.3.1',
        'sourcery-cli': '0.10.0',
        'sphinx': '4.4.0',
        'sphinx-autodoc-typehints': '1.12.0',
        'sphinx-book-theme': '0.1.10',
        'sphinx-comments': '0.0.3',
        'sphinx-copybutton': '0.4.0',
        'sphinx-external-toc': '0.2.3',
        'sphinx-jupyterbook-latex': '0.4.6',
        'sphinx-multitoc-numbering': '0.1.3',
        'sphinx-panels': '0.6.0',
        'sphinx-tabs': '3.2.0',
        'sphinx-thebe': '0.0.10',
        'sphinx-togglebutton': '0.2.3',
        'sphinxcontrib-applehelp': '1.0.2',
        'sphinxcontrib-bibtex': '2.2.1',
        'sphinxcontrib-devhelp': '1.0.2',
        'sphinxcontrib-htmlhelp': '2.0.0',
        'sphinxcontrib-jsmath': '1.0.1',
        'sphinxcontrib-qthelp': '1.0.3',
        'sphinxcontrib-serializinghtml': '1.1.5',
        'sqlalchemy': '1.4.29',
        'stack-data': '0.1.4',
        'superqt': '0.2.5.post2.dev7+ga49bcd7',
        'tensorstore': '0.1.16',
        'terminado': '0.12.1',
        'testpath': '0.5.0',
        'text-unidecode': '1.3',
        'tifffile': '2021.11.2',
        'toml': '0.10.2',
        'tomli': '2.0.0',
        'toolz': '0.11.2',
        'torch': '1.10.1',
        'tornado': '6.1',
        'tox': '3.24.5',
        'tox-conda': '0.9.1',
        'tqdm': '4.62.3',
        'traitlets': '5.1.1',
        'transforms3d': '0.3.1',
        'transitions': '0.8.10',
        'typed-ast': '1.5.1',
        'typer': '0.4.0',
        'typing-extensions': '4.0.1',
        'uc-micro-py': '1.0.1',
        'urllib3': '1.26.8',
        'useq-schema': '0.1.1.dev13+g01d1b46.d20220120',
        'valerius': '0.2.0',
        'virtualenv': '20.13.0',
        'vispy': '0.9.4',
        'watchdog': '2.1.6',
        'wcmatch': '8.3',
        'wcwidth': '0.2.5',
        'webencodings': '0.5.1',
        'websocket-client': '1.2.3',
        'wheel': '0.37.1',
        'widgetsnbextension': '3.5.2',
        'wmctrl': '0.4',
        'wrapt': '1.13.3',
        'wurlitzer': '3.0.2',
        'xarray': '0.20.2',
        'xmlschema': '1.9.2',
        'yarl': '1.7.2',
        'zarr': '2.10.3',
        'zipp': '3.7.0'
    },
    'platform': 'python',
    'release': '0.4.14rc1.dev4+gcdf58d44b',
    'sdk': {
        'integrations': [
            'aiohttp',
            'argv',
            'atexit',
            'dedupe',
            'excepthook',
            'logging',
            'modules',
            'sqlalchemy',
            'stdlib',
            'threading',
            'tornado'
        ],
        'name': 'sentry.python',
        'packages': [{'name': 'pypi:sentry-sdk', 'version': '1.5.4'}],
        'version': '1.5.4'
    },
    'server_name': '',
    'tags': {
        'platform.name': 'MacOS 10.15.7',
        'platform.system': 'Darwin',
        'qtpy.API_NAME': 'PySide2',
        'qtpy.QT_VERSION': '5.15.2'
    },
    'timestamp': '2022-02-02T01:30:00.229122Z'
}
```

</details>

> ***NOTE**: in the opt-in dialog, there is a checkbox labeled ""include local variables"",
checking this will include the value of variables in the local scope when an exception
occurs.  While these can be very useful when interpreting a bug report, they may
occasionally include local file path strings.  If that concerns you, please leave this
box unchecked*

## Install

This plugin requires napari version 0.4.15 or greater, or the `main` branch with PR
[napari/napari#4055](https://github.com/napari/napari/pull/4055).

Install via pip with:

```sh
pip install napari-error-reporter
```

or in the built-in plugin installer (a restart will be required):

<img width=""503"" alt=""Untitled"" src=""https://user-images.githubusercontent.com/1609449/153915128-09a5e3d7-8561-4c17-b543-5ea172e3e860.png"">


Thank you!!

## Privacy FAQ

Even with the multiple layers of opt-ins, and the attempts to wipe all personal info
prior to sending reports, we understand that privacy is always a concern.

### Do you collect personal info?

We make every attempt to collect ***no*** personally identifiable information.  No
name, location, IP address, etc...  We do collect your
([`uuid.getnode()`](https://docs.python.org/3.10/library/uuid.html#uuid.getnode)) to
be able to track bug resolution over time. As mentioned above, allowing local
variables to be collected may occasionally include a file path in the log.
If that concerns you, please leave that unchecked.

### Is this shipped with napari?

`napari-error-reporter` is **not** bundled with napari or listed as a napari dependency.
In order for reports to be sent, you must first install this plugin yourself, and then
opt in on the next launch.  If you uninstall the plugin, no more reports can be sent.

### Who can access these reports?

Only the following napari core developers have access to these reports.
If [this](https://raw.githubusercontent.com/tlambert03/napari-error-reporter/main/ADMINS)
list changes in the future, you will be asked to opt-in again in napari:

- Juan Nunez-Iglesias ([@jni](https://github.com/jni))
- Talley Lambert ([@tlambert03](https://github.com/tlambert03))

*This plugin is **not** associated with the Chan Zuckerberg Initiative*.

### How will these reports be used?

Commonly occuring errors will be will be manually purged of file paths and
local variables and posted to https://github.com/napari/napari/issues

### How long is data retained

Sentry retains event data for 90 days by default.  For complete details,
see Sentry's page on [Security & Compliance](https://sentry.io/security/)
","['Development Status :: 3 - Alpha', 'Framework :: napari', 'License :: OSI Approved :: BSD License', 'Natural Language :: English', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10']","['Source Code, https://github.com/tlambert03/napari-error-reporter']",,,,,,,,https://pypi.org/project/napari-error-reporter,https://github.com/tlambert03/napari-error-reporter,
142,Explorer,0.0.2,,,napari-explorer,Tim Monko,timmonko@gmail.com,BSD-3-Clause,,"Browse files in a folder, filter, and open within napari",>=3.8,"['numpy', 'magicgui', 'qtpy', 'napari', 'napari-aicsimageio', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-explorer

[![License BSD-3](https://img.shields.io/pypi/l/napari-explorer.svg?color=green)](https://github.com/TimMonko/napari-explorer/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-explorer.svg?color=green)](https://pypi.org/project/napari-explorer)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-explorer.svg?color=green)](https://python.org)
[![tests](https://github.com/TimMonko/napari-explorer/workflows/tests/badge.svg)](https://github.com/TimMonko/napari-explorer/actions)
[![codecov](https://codecov.io/gh/TimMonko/napari-explorer/branch/main/graph/badge.svg)](https://codecov.io/gh/TimMonko/napari-explorer)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-explorer)](https://napari-hub.org/plugins/napari-explorer)

Browse files in a folder, filter, and open within napari

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-explorer` via [pip]:

    pip install napari-explorer




## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-explorer"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']",,,,napari-explorer.folder_explorer,,,,,https://pypi.org/project/napari-explorer,,
143,napari feature classifier,0.1.1,2022-06-16,2023-07-25,napari-feature-classifier,Joel Luethi and Max Hess,joel.luethi@uzh.ch,BSD-3-Clause,https://github.com/fractal-napari-plugins-collection/napari-feature-classifier,An interactive classifier plugin to use with label images and feature measurements,>=3.9,"['numpy', 'napari', 'matplotlib', 'magicgui', 'pandas', 'scikit-learn (>=1.2.2)', 'pandera', 'xxhash', 'hypothesis']","# napari-feature-classifier

[![License](https://img.shields.io/pypi/l/napari-feature-classifier.svg?color=green)](https://github.com/fractal-napari-plugins-collection/napari-feature-classifier/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-feature-classifier.svg?color=green)](https://pypi.org/project/napari-feature-classifier)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-feature-classifier.svg?color=green)](https://python.org)
[![tests](https://github.com/fractal-napari-plugins-collection/napari-feature-classifier/workflows/tests/badge.svg)](https://github.com/fractal-napari-plugins-collection/napari-feature-classifier/actions)
[![codecov](https://codecov.io/gh/fractal-napari-plugins-collection/napari-feature-classifier/branch/main/graph/badge.svg)](https://codecov.io/gh/fractal-napari-plugins-collection/napari-feature-classifier)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-feature-classifier)](https://napari-hub.org/plugins/napari-feature-classifier)

An interactive classifier plugin that allows the user to assign objects in a label image to multiple classes and train a classifier to learn those classes based on a feature dataframe.

## Usage
<p align=""center""><img src=""https://github.com/fractal-napari-plugins-collection/napari-feature-classifier/assets/18033446/1ebf0890-1a7b-4e4b-a21c-88ca8f1dd800"" /></p>

To use the napari-feature-classifier, you need to have a label image and corresponding measurements: as a csv file, loaded to layer.features or in an [OME-Zarr Anndata table loaded with another plugin](https://github.com/jluethi/napari-ome-zarr-roi-loader). Your feature measurements need to contain a `label` column that matches the label objects in the label image.
These interactive classification workflows are well suited to visually define cell types, find mitotic cells in images, do quality control by automatically detecting missegmented cells and other tasks where a user can easily assign objects to groups.

#### Prepare the label layer:
- Load your label layer into napari and add the features measurements to layer.features of the corresponding label layer. You can have multiple label layers with their features open at the same time
    - To load features from a CSV file: `Plugins -> napari-feature-classifier -> CSV Feature Loader`, then load the features for the correct label image.
    - To load features from an OME-Zarr file: Get both the label layer into memory as a normal label layer (not a pyramidal label layer, currently untested) and the corresponding features. If your OME-Zarr file is created by [Fractal](https://fractal-analytics-platform.github.io/), you can use [this ROI loader plugin](https://github.com/jluethi/napari-ome-zarr-roi-loader).
    - To load features from anywhere else, load them manually to your label_layer.features
- Your feature table should have 2 columns used for indexing (but stored as normal columns in layer.features):
    - The `label` column to match the object in the label image
    - The `roi_id` column to identify the image you're currently classifying (used when a classifier is trained on multiple label images)


#### Initialize a classifier:
- Start the classifier in napari by going to `Plugins -> napari-feature-classifier -> Initialize a Classifier`  
- Select the features you want to use for the classifier (you need to do the feature selection before initializing. The feature selection can't be changed after initialization anymore). Hold the command key to select multiple features. Feature options are always shown for the features available in the last selected label layer, based on layer.features available features.
- (Optional) Give your classes recognizable names (e.g. Mitotic & Interphase, Cell Type a, b and c etc.)
<img width=""1606"" alt=""Screenshot 2023-05-09 at 11 46 35"" src=""https://github.com/fractal-napari-plugins-collection/napari-feature-classifier/assets/18033446/452c0d6a-98a3-4e2d-9233-33bfd5bcad19"">




#### Classify objects:
<img width=""1802"" alt=""Classifier_annotation"" src=""https://github.com/fractal-napari-plugins-collection/napari-feature-classifier/assets/18033446/556739b8-972b-4570-9da4-637738fc6a75"">

- Make sure you have the label layer selected on which you want to classify
- Select the current class with the radio buttons or by pressing 0, 1, 2, etc.
- Click on label objects in the viewer to assign them to the currently selected class
- Once you have trained enough examples, click ""Run Classifier"" to run the classifier and have it make a prediction for all objects. Aim for at least a dozen annotations per class, as the classifier divides your annotations 80/20 in training and test sets. 
- Once you get predictions, correct mistakes the classifier made and retrain it to improve its performance.
- You can save the classifier under a different name or in a different location. Define the new output location and then click `Save Classifier` (you need to click the Save Classifier button. Just defining the new output path does not save it yet. But every run of the classifier triggers an autosave)
<img width=""1802"" alt=""Classifier_prediction"" src=""https://github.com/fractal-napari-plugins-collection/napari-feature-classifier/assets/18033446/69cff600-4585-4a66-9274-d2e7caeb335f"">



#### Apply the classifier to additional images:
- You can apply a classifier trained on one image to additional label images. Use `Plugins -> napari-feature-classifier -> Load Classifier`  
- Select the classifier (.clf file with the name you gave above) while already having the label images ready (see `Prepare the label layer` above).
- Click Load Classifier, proceed as above.
<img width=""1606"" alt=""Screenshot 2023-05-09 at 12 01 00"" src=""https://github.com/fractal-napari-plugins-collection/napari-feature-classifier/assets/18033446/e1143f9f-9729-4f8e-979c-2ab195e0aaca"">



#### Export classifier results
- To export the training data and the results of the classifier, define an Export Name (full path to an output file or just a filename ending in .csv) where the results of the classifier shall be saved. It defaults to the layer name for the selected layer in the last directory you chose (or the current working directory if none was chosen so far)
- Click `Export Classifier Result` (Just selecting a filename is not enough, you need to click the export button). This will export the predictions for the currently selected layer.
- The results of the classifier are save in a csv file. The label is an integer of the label object within that image. The prediction column contains predictions of the classifier for all objects (except those that contained NaNs in their feature data) and the annotation column contains the annotations you made (NaN for unclassified objects, -1 for objects you deselected, 1 - 9 for the classes)
<img width=""1802"" alt=""Classifier_prediction"" src=""https://github.com/fractal-napari-plugins-collection/napari-feature-classifier/assets/18033446/e8f6f7b7-d88b-44f8-b43e-8a2fa81e18d4"">


#### Batch mode result export
(To be updated: Create a new notebook to run batch processing, this is for the older version of the classifier)
There is a simple workflow for the classifier in the examples folder:
- Install jupyter-lab (`pip install jupyterlab`)
- Open the notebook in jupyter lab (Type `jupyter-lab` in the terminal when you are in the examples folder)
- Follow the instructions to generate an example dataframe and an example label image
- Use the classifier in napari with this simplified data


#### Initializing the Annotator
You can use the annotation functionality also independently from the classifier
Start the annotator widget by going to `Plugins -> napari-feature-classifier -> Annotator`
Select names for your classes. You can name up to 9 classes. Only classes that you give a name will be created upon initialization.
Then click `Initialize`.

<img width=""1411"" alt=""Screenshot 2023-02-16 at 14 49 38"" src=""https://user-images.githubusercontent.com/18033446/219384524-9873bd66-270b-4cdd-b913-60d390f6c77a.png"">

A annotator widget opens. Use the Radio-Buttons to select what class you're annotating (or keybindings for 1-9 for classes, 0 for deselect).
The annotator will always work on the currently selected label layer. While the annotator is open, you can't edit the labels. Restart napari to allow editing of labels again.

<img width=""1411"" alt=""Screenshot 2023-02-16 at 14 50 00"" src=""https://user-images.githubusercontent.com/18033446/219384925-b20e4c1a-2eca-4070-8269-902493c5d5ef.png"">

The annotations are saved in the `layer.features` table of the corresponding label layer as an `annotations` column.
<img width=""1411"" alt=""Screenshot 2023-02-16 at 15 01 01"" src=""https://user-images.githubusercontent.com/18033446/219385788-f61bd0a5-fbb6-42d7-81e5-f77ee4d1b4ff.png"">


## Installation

This plugin is written for the new napari npe2 plugin engine. Thus, it requires napari >= 0.4.13.
Activate your environment where you have napari installed (or install napari using `pip install ""napari[all]""`), then install the classifier plugin:

    pip install napari-feature-classifier

The layer.features dataframes have some issues in napari 0.4.17 (see [here](https://github.com/napari/napari/issues/5617)). They seem to be working again in the nighlty builds. To set up a nightly builds napari env, do the following:

```
conda create -n classifier-dev-napari-main -c ""napari/label/nightly"" -c conda-forge napari python=3.10 -y
```
    
## Similar napari plugins
If you're looking for other classification approaches, [apoc](https://github.com/haesleinhuepf/apoc) by [Robert Haase](https://github.com/haesleinhuepf) has a pixel classifier in napari and an object classification workflow:  
[napari-accelerated-pixel-and-object-classification (APOC)](https://github.com/haesleinhuepf/napari-accelerated-pixel-and-object-classification)  
Alternatively, Clément Cazorla has built [napari-svetlana, a deep learning based classifier](https://www.napari-hub.org/plugins/napari-svetlana)

## Release process
1. Update the version number in src/napari-feature-classifier/__init__.py
2. Update the version in setup.cfg
3. Add a Github release with a new version tag (matching the version set above)
4. Once tests pass, this should automatically be deployed to pypi
5. Wait for conda automation to make a PR for an updated conda release (see https://github.com/conda-forge/napari-feature-classifier-feedstock). This can take 1-2 days. Make sure that PR gets merged.


## Contributing

Contributions are very welcome.

## License

Distributed under the terms of the [BSD-3] license,
""napari-feature-classifier"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

## Contributors
[Joel Lüthi](https://github.com/jluethi) & [Max Hess](https://github.com/MaksHess)

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/fractal-napari-plugins-collection/napari-feature-classifier/issues', 'Documentation, https://github.com/fractal-napari-plugins-collection/napari-feature-classifier#napari-feature-classifier', 'Source Code, https://github.com/fractal-napari-plugins-collection/napari-feature-classifier', 'User Support, https://github.com/fractal-napari-plugins-collection/napari-feature-classifier/issues']",,,napari-feature-classifier.annotator_init_widget,,,,,https://pypi.org/project/napari-feature-classifier,https://github.com/fractal-napari-plugins-collection/napari-feature-classifier,
144,napari-features,0.1.4,2022-02-11,2023-06-18,napari-features,Allen Goodman,allen.goodman@icloud.com,MIT,https://github.com/0x00b1/napari-features,extracts image and object features,>=3.7,"['magicgui (>=0.2.9)', 'napari (>=0.4.10)', 'napari-plugin-engine (>=0.1.4)', 'numpy (>=1.19.5)', 'pandas (>=1.2.4)', 'qtpy (>=1.9.0)', 'scikit-image (>=0.18.1)', 'scipy (>=1.4.1)']","# napari-features

[![License](https://img.shields.io/pypi/l/napari-features.svg?color=green)](https://github.com/0x00b1/napari-features/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-features.svg?color=green)](https://pypi.org/project/napari-features)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-features.svg?color=green)](https://python.org)
[![tests](https://github.com/0x00b1/napari-features/workflows/tests/badge.svg)](https://github.com/0x00b1/napari-features/actions)
[![codecov](https://codecov.io/gh/0x00b1/napari-features/branch/master/graph/badge.svg)](https://codecov.io/gh/0x00b1/napari-features)

An extensible, general-purpose feature extraction plug-in for the [Napari](https://napari.org) image viewer.

## Features

### Color

#### Image

    color_image_integrated_intensity
    color_image_maximum_intensity
    color_image_mean_intensity
    color_image_median_absolute_deviation_intensity
    color_image_median_intensity
    color_image_minimum_intensity
    color_image_quantile_1_intensity
    color_image_quantile_3_intensity
    color_image_standard_deviation_intensity

#### Object

    color_object_center_mass_intensity_x
    color_object_center_mass_intensity_y
    color_object_integrated_intensity
    color_object_integrated_intensity_edge
    color_object_mass_displacement
    color_object_maximum_intensity
    color_object_maximum_intensity_edge
    color_object_maximum_intensity_x
    color_object_maximum_intensity_y
    color_object_mean_intensity
    color_object_mean_intensity_edge
    color_object_median_absolute_deviation_intensity
    color_object_median_intensity
    color_object_median_intensity_edge
    color_object_minimum_intensity
    color_object_minimum_intensity_edge
    color_object_quantile_1_intensity
    color_object_quantile_1_intensity_edge   
    color_object_quantile_3_intensity
    color_object_quantile_3_intensity_edge
    color_object_standard_deviation_intensity
    color_object_standard_deviation_intensity_edge
    Object distribution
    color_object_distribution_coefficient_of_variation_intensity
    color_object_distribution_integrated_intensity
    Color_object_distribution_mean_intensity

### Location

#### Object neighborhood

    location_object_neighborhood_angle
    location_object_neighborhood_closest_0_distance
    location_object_neighborhood_closest_0_object_index
    location_object_neighborhood_closest_1_distance
    location_object_neighborhood_closest_1_object_index
    location_object_neighborhood_closest_2_distance
    location_object_neighborhood_closest_2_object_index
    location_object_neighborhood_neighbors
    location_object_neighborhood_touching

### Metadata

#### Image

    metadata_image_checksum
    metadata_image_filename

#### Layer

    metadata_layer_name
    metadata_layer_type

#### Object

    metadata_object_index

### Shape

#### Image

    shape_image_area

#### Image skeleton

    shape_image_skeleton_branches
    shape_image_skeleton_endpoints
    shape_image_skeleton_length
    shape_image_skeleton_trunks

#### Object

    shape_object_area
    shape_object_bounding_box_area
    shape_object_bounding_box_maximum_x
    shape_object_bounding_box_maximum_y
    shape_object_bounding_box_maximum_z
    shape_object_bounding_box_minimum_x
    shape_object_bounding_box_minimum_y
    shape_object_bounding_box_minimum_z
    shape_object_bounding_box_volume
    shape_object_central_moment_0_0_0
    shape_object_central_moment_0_0_1
    shape_object_central_moment_0_1_2
    shape_object_central_moment_0_1_3
    shape_object_central_moment_1_2_0
    shape_object_central_moment_1_2_1
    shape_object_central_moment_1_3_2
    shape_object_central_moment_1_3_3
    shape_object_central_moment_2_0_0
    shape_object_central_moment_2_0_1
    shape_object_central_moment_2_1_2
    shape_object_central_moment_2_1_3
    shape_object_central_moment_3_2_0
    shape_object_central_moment_3_2_1
    shape_object_central_moment_3_3_2
    shape_object_central_moment_3_3_3
    shape_object_centroid_x
    shape_object_centroid_y
    shape_object_centroid_z
    shape_object_compactness
    shape_object_eccentricity
    shape_object_equivalent_diameter
    shape_object_euler_number
    shape_object_extent
    shape_object_form_factor
    shape_object_hu_moment_0
    shape_object_hu_moment_1
    shape_object_hu_moment_2
    shape_object_hu_moment_3
    shape_object_hu_moment_4
    shape_object_hu_moment_5
    shape_object_hu_moment_6
    shape_object_inertia_tensor_eigenvalues_x
    shape_object_inertia_tensor_eigenvalues_y
    shape_object_inertia_tensor_eigenvalues_z
    shape_object_inertia_tensor_x_x
    shape_object_inertia_tensor_x_y
    Shape_object_inertia_tensor_x_z
    shape_object_inertia_tensor_y_x
    shape_object_inertia_tensor_y_y
    shape_object_inertia_tensor_y_z
    shape_object_inertia_tensor_z_x
    shape_object_inertia_tensor_z_y
    shape_object_inertia_tensor_z_z
    shape_object_major_axis_length
    shape_object_maximum_feret_diameter
    shape_object_maximum_radius
    shape_object_mean_radius
    shape_object_median_radius
    shape_object_minimum_feret_diameter
    shape_object_minor_axis_length
    shape_object_normalized_moment_x_y
    shape_object_orientation
    shape_object_perimeter
    shape_object_solidity
    shape_object_spatial_moment_0_0_0
    shape_object_spatial_moment_0_0_1
    shape_object_spatial_moment_0_1_2
    shape_object_spatial_moment_0_1_3
    shape_object_spatial_moment_1_2_0
    shape_object_spatial_moment_1_2_1
    shape_object_spatial_moment_1_3_2
    shape_object_spatial_moment_1_3_3
    shape_object_spatial_moment_2_0_0
    shape_object_spatial_moment_2_0_1
    shape_object_spatial_moment_2_1_2
    shape_object_spatial_moment_2_1_3
    shape_object_spatial_moment_3_2_0
    shape_object_spatial_moment_3_2_1
    shape_object_spatial_moment_3_3_2
    shape_object_spatial_moment_3_3_3
    shape_object_surface_area
    shape_object_volume
    shape_object_zernike shape features
    Object skeleton
    shape_object_skeleton_endpoints
    shape_object_skeleton_branches
    shape_object_skeleton_length
    shape_object_skeleton_trunks

### Texture

#### Object

    texture_object_haralick_angular_second_moment
    texture_object_haralick_contrast
    texture_object_haralick_coorelation
    texture_object_haralick_sum_of_squares_variance
    texture_object_haralick_inverse_difference_moment
    texture_object_haralick_sum_average
    texture_object_haralick_sum_variance
    texture_object_haralick_sum_entropy
    texture_object_haralick_entropy
    texture_object_haralick_difference_variance
    texture_object_haralick_measure_of_correlation_0
    texture_object_haralick_measure_of_correlation_1
    texture_object_haralick_maximum_correlation_coefficient


","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: MIT License']","['Bug Tracker, https://github.com/0x00b1/napari-features/issues', 'Documentation, https://github.com/0x00b1/napari-features#README.md', 'Source Code, https://github.com/0x00b1/napari-features', 'User Support, https://github.com/0x00b1/napari-features/issues']",,,,,,,,https://pypi.org/project/napari-features,https://github.com/0x00b1/napari-features,
145,Features Selection GA,0.0.4,2023-04-12,2023-06-18,napari-features-selector,Sanjeev Kumar,kumar.san96@gmail.com,BSD-3-Clause,https://github.com/kumar-sanjeeev/napari-features-selector,A lightweight widget for features selection.,>=3.8,"['numpy', 'magicgui', 'qtpy', 'pandas', 'scikit-learn', 'sklearn-genetic-opt', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-features-selector

[![License BSD-3](https://img.shields.io/pypi/l/napari-features-selector.svg?color=green)](https://github.com/kumar-sanjeeev/napari-features-selector/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-features-selector.svg?color=green)](https://pypi.org/project/napari-features-selector)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-features-selector.svg?color=green)](https://python.org)
[![tests](https://github.com/kumar-sanjeeev/napari-features-selector/workflows/tests/badge.svg)](https://github.com/kumar-sanjeeev/napari-features-selector/actions)
[![codecov](https://codecov.io/gh/kumar-sanjeeev/napari-features-selector/branch/main/graph/badge.svg)](https://codecov.io/gh/kumar-sanjeeev/napari-features-selector)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-features-selector)](https://napari-hub.org/plugins/napari-features-selector)


An interactive plugin that enables users to choose the important/relevant features from a set of multiple features. These selected features can then be applied to various tasks like object detection, segmentation, classification, among others.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-features-selector` via [pip]:

    pip install napari-features-selector





## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-features-selector"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/kumar-sanjeeev/napari-features-selector/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/kumar-sanjeeev/napari-features-selector/issues', 'Documentation, https://github.com/kumar-sanjeeev/napari-features-selector#README.md', 'Source Code, https://github.com/kumar-sanjeeev/napari-features-selector', 'User Support, https://github.com/kumar-sanjeeev/napari-features-selector/issues']",,,napari-features-selector.gui_GA,,,,,https://pypi.org/project/napari-features-selector,https://github.com/kumar-sanjeeev/napari-features-selector,
146,Figure,0.1.1,,,napari-figure,romainGuiet,romain.guiet@epfl.ch,BSD-3-Clause,,Making Figure with napari more easily,>=3.8,"['numpy', 'magicgui', 'qtpy', 'microfilm', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-figure

[![License BSD-3](https://img.shields.io/pypi/l/napari-figure.svg?color=green)](https://github.com/romainGuiet/napari-figure/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-figure.svg?color=green)](https://pypi.org/project/napari-figure)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-figure.svg?color=green)](https://python.org)
[![tests](https://github.com/romainGuiet/napari-figure/workflows/tests/badge.svg)](https://github.com/romainGuiet/napari-figure/actions)
[![codecov](https://codecov.io/gh/romainGuiet/napari-figure/branch/main/graph/badge.svg)](https://codecov.io/gh/romainGuiet/napari-figure)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-figure)](https://napari-hub.org/plugins/napari-figure)

Making Figure with napari more easily

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-figure` via [pip]:

    pip install napari-figure



To install latest development version :

    pip install git+https://github.com/romainGuiet/napari-figure.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-figure"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/romainGuiet/napari-figure/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/BIOP/napari-figure/issues', 'Documentation, https://github.com/BIOP/napari-figure#README.md', 'Source Code, https://github.com/BIOP/napari-figure', 'User Support, https://github.com/BIOP/napari-figure/issues']",,,napari-figure.make_qwidget,,,,,https://pypi.org/project/napari-figure,,
147,napari 3D filament annotator,0.1.2,2022-12-30,2023-06-18,napari-filament-annotator,Anna Medyukhina,anna.medyukhina@gmail.com,Apache-2.0,https://github.com/amedyukhina/napari-filament-annotator,Annotation of filaments / curvilinear structures in 3D,>=3.8,"['Geometry3D', 'networkx', 'numpy', 'magicgui', 'pandas', 'qtpy', 'scipy', 'sklearn', 'imageio (!=2.22.1)', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# 3D Filament Annotator

[![DOI](https://zenodo.org/badge/513980347.svg)](https://zenodo.org/badge/latestdoi/513980347)
[![License Apache Software License 2.0](https://img.shields.io/pypi/l/napari-filament-annotator.svg?color=green)](https://github.com/amedyukhina/napari-filament-annotator/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-filament-annotator.svg?color=green)](https://pypi.org/project/napari-filament-annotator)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-filament-annotator.svg?color=green)](https://python.org)
[![tests](https://github.com/amedyukhina/napari-filament-annotator/workflows/tests/badge.svg)](https://github.com/amedyukhina/napari-filament-annotator/actions)
[![codecov](https://codecov.io/gh/amedyukhina/napari-filament-annotator/branch/main/graph/badge.svg)](https://codecov.io/gh/amedyukhina/napari-filament-annotator)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-filament-annotator)](https://napari-hub.org/plugins/napari-filament-annotator)

3D Filament Annotator is a tool for annotating filaments and other curvilinear structures in 3D. 
The 3D annotation is done by annotating the filament in two different projections, 
calculating intersection, and refining the filament position with active contours.

![demo](https://raw.githubusercontent.com/amedyukhina/napari-filament-annotator/main/docs/demo_09.gif)


## Installation

### Install napari

    pip install napari[all]

### Install the filament annotator

<!--
You can install `napari-filament-annotator` via [pip]:

    pip install napari-filament-annotator


To install latest development version :
-->
    pip install git+https://github.com/amedyukhina/napari-filament-annotator.git

## Usage

For detailed usage instructions, please refer to the [usage tutorial](docs/tutorial.md).

## Contributing

Contributions are very welcome both with regard to plugin functionality, and
tips on using it and setting parameters. 

Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [Apache Software License 2.0] license,
""napari-filament-annotator"" is free and open source software

## Dependencies

- [napari](https://github.com/napari/napari)
- [scikit-image](https://scikit-image.org/)
- [scikit-learn](https://github.com/scikit-learn/scikit-learn)
- [NetworkX](https://networkx.org/documentation/stable/index.html)
- [Geometry3D](https://github.com/GouMinghao/Geometry3D)


## Issues

If you encounter any problems, please [file an issue] along with a detailed description.


----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.


<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/index.html
-->


[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/amedyukhina/napari-filament-annotator/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 3 - Alpha', 'Framework :: napari', 'Intended Audience :: Science/Research', 'License :: OSI Approved :: Apache Software License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/amedyukhina/napari-filament-annotator/issues', 'Documentation, https://github.com/amedyukhina/napari-filament-annotator#README.md', 'Source Code, https://github.com/amedyukhina/napari-filament-annotator', 'User Support, https://github.com/amedyukhina/napari-filament-annotator/issues']",,,napari-filament-annotator.make_annotator_widget,napari-filament-annotator.load_sample_image,,,,https://pypi.org/project/napari-filament-annotator,https://github.com/amedyukhina/napari-filament-annotator,
148,napari filaments,0.3.0,2022-07-11,2023-08-01,napari-filaments,Hanjin Liu,liuhanjin-sc@g.ecc.u-tokyo.ac.jp,BSD-3-Clause,https://github.com/hanjinliu/napari-filaments,A napari plugin for filament analysis,>=3.9,"['magic-class (>=0.7.3)', 'magicgui', 'matplotlib', 'numpy', 'qtpy', 'scipy', ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""roifile ; extra == 'testing'"", ""tox ; extra == 'testing'""]","# napari-filaments

[![License BSD-3](https://img.shields.io/pypi/l/napari-filaments.svg?color=green)](https://github.com/hanjinliu/napari-filaments/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-filaments.svg?color=green)](https://pypi.org/project/napari-filaments)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-filaments.svg?color=green)](https://python.org)
[![tests](https://github.com/hanjinliu/napari-filaments/workflows/tests/badge.svg)](https://github.com/hanjinliu/napari-filaments/actions)
[![codecov](https://codecov.io/gh/hanjinliu/napari-filaments/branch/main/graph/badge.svg)](https://codecov.io/gh/hanjinliu/napari-filaments)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-filaments)](https://napari-hub.org/plugins/napari-filaments)

A napari plugin for filament analysis.

This plugin helps you to manually track filaments using path shapes of `Shapes` layer.

![](https://github.com/hanjinliu/napari-filaments/raw/main/resources/fit.gif)

Currently implemented functions

- Fit paths to filaments in an image as a 2-D spline curve.
- Clip/extend paths.
- Measurement of filament length at sub-pixel precision.
- Basic quantification (mean, std, etc.) along paths.
- Import paths from ImageJ ROI file.

Basic Usage
-----------

Click `Layers > open image` to open a tif file. You'll find the image you chose and a shapes layer are added to the layer list.

![](https://github.com/hanjinliu/napari-filaments/raw/main/resources/fig-1.png)

- The ""target filaments"" box shows the working shapes layer.
- The ""target image"" box shows the image layer on which fitting and quantification will be conducted.
- The ""filament"" box shows currently selected shape (initially this box is empty).

Add path shapes and push key `F1` to fit the shape to the filament in the target image layer.

- In the ""Spline"" tab, you can cut/extend or re-fit splines.
- In the ""Measure"" tab, click ""measure property"" to measure mean instensity etc along each spline.

How it works
------------

Spline fitting is done as following.

![](https://github.com/hanjinliu/napari-filaments/raw/main/resources/fig-2.png)


----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.


## Installation

You can install `napari-filaments` via [pip]:

    pip install napari-filaments



To install latest development version :

    pip install git+https://github.com/hanjinliu/napari-filaments.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-filaments"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/hanjinliu/napari-filaments/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Topic :: Software Development :: Testing']","['Bug Tracker, https://github.com/hanjinliu/napari-filaments/issues', 'Documentation, https://github.com/hanjinliu/napari-filaments#README.md', 'Source Code, https://github.com/hanjinliu/napari-filaments', 'User Support, https://github.com/hanjinliu/napari-filaments/issues']",,,napari-filaments.make_qwidget,,,,,https://pypi.org/project/napari-filaments,https://github.com/hanjinliu/napari-filaments,
149,napari-file-watcher,0.1.1,2023-11-07,2023-11-07,napari-file-watcher,Xavier Casas Moreno,xaviercm@kth.se,GPL-3.0,https://pypi.org/project/napari-file-watcher,A napari plugin for file watching,,"['napari', 'ome-zarr', 'zarr', 'h5py', 'PyQt5', 'qtpy', 'QScintilla']","# File watcher plugin for napari (napari-file-watcher)


This plugin contains two widgets: file watcher and script editor.


## Usage: file watcher

The file watcher monitors a folder and displays its images (tiff, ome-zarr or hdf5) as napari layers, watch the following video for a demo:

[![IMAGE ALT TEXT](http://img.youtube.com/vi/lFRVwlHgJ-Y/0.jpg)](https://www.youtube.com/watch?v=lFRVwlHgJ-Y ""Demo napari-file-watcher"")

Instructions:

1. Select the folder you want to monitor by pressing ""Browse"".
2. Select the extension of the files: ""zarr"", ""hdf5"" or ""tiff"".
3. Click ""Watch and run"" to display the current items & the newly arrived as napari layers.
4. If you click in one of the files of the list, the metadata will show (for hdf5 and zarr)

## Usage: scripting editor

The script editor is for developing scripts and saving them in the filesystem. 
We have used this widget in the context of developing scripts for microscopy control software that implements another file watcher.

Instructions:

1. Select the folder where you want to save your scripts in ""Browse"".
2. Type the name of the script in the edit box below.
3. Click ""Add"" for saving it into the folder after typing, or ""Open"" to display an existing file.

## Installation

You can install `napari-file-watcher` via [pip]:

    pip install napari-file-watcher

Or if you plan to develop it:

    git clone https://github.com/kasasxav/napari-file-watcher
    cd napari-file-watcher
    pip install -e .

If there is an error message suggesting that git is not installed, run `conda install git`.

## Contributing

Contributions are welcome, tests are run with pytest.

## Issues

Issues can be reported at: https://github.com/kasasxav/napari-file-watcher/issues
","['Framework :: napari', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8']","['Bug Tracker, https://github.com/kasasxav/napari-file-watcher', 'Documentation, https://github.com/kasasxav/napari-file-watcher/blob/main/README.md', 'Source Code, https://github.com/kasasxav/napari-file-watcher', 'User Support, https://github.com/kasasxav/napari-file-watcher/issues']",,,napari-file-watcher.watcher_widget,,,,,https://pypi.org/project/napari-file-watcher,,
150,napari-findaureus,0.0.4,,,napari-findaureus,Shibarjun Mandal,shibarjunmandal@gmail.com,MIT,,Locate bacteria in CLSM obtained infected bone tissue images,>=3.8,"['magicgui', 'qtpy', 'napari[all]', 'aicsimageio ==4.11.0', 'nd2 ==0.5.3', 'aicspylibczi ==3.1.2', 'fsspec ==2023.5.0', 'readlif ==0.6.5', 'czifile ==2019.7.2', 'tifffile ==2023.7.10', 'webcolors ==1.13', 'opencv-python ==4.7.0.72', 'numpy ==1.24.3', 'scikit-image ==0.20.0', 'xmltodict', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-findaureus

""Findaureus"" is now available to use in napari.
<p align=""center"">
<img src=""https://raw.githubusercontent.com/shibarjun/napari-findaureus/main/docs/napari-findaureus.png"" />
</p>

Findaureus is a tool designed to identify bacteria in infected bone tissue images obtained via Confocal Laser Scanning Microscopy (CLSM). This tool can be accessed independently [here](https://github.com/shibarjun/Findaureus). Findaureus has been integrated as a plugin for napari. In addition to its bacteria-locating algorithm, the napari viewer provides improved visualization features, in 2D and 3D perspectives.

----------------------------------
## Installation
### Windows/Linux
If you don’t have conda installed, you can get miniconda or Anaconda from their websites.
1. Open your command line tool and run these commands to create and activate a conda environment:
```
conda create -n napari-findaureus python=3.9
conda activate napari-findaureus
```
2. Install napari and napari-findaureus with this command:
```
pip install ""napari[all]"" napari-findaureus
```
### macOS
1. Create an environment with napari and pyqt5
```
conda create -n napari-findaureus -c conda-forge python=3.9 pyqt imagecodecs napari
```
2. Install the napari-findaureus plugin
```
pip install napari-findaureus
```

## Start napari-findaureus
Launch napari from the terminal while the napari-findaureus environment is running.
```
napari
```
To launch the napari plugin, go to “Plugins” and select “napari-findaureus”.
## Quick demo
To use the `napari-findaureus` plugin, please follow the steps below:

1. First, download some relevant fluorescence-labeled images of infected mouse bone tissues from [Zenodo](https://zenodo.org/doi/10.5281/zenodo.8411791).
2. Next, load the image file through the `napari-findaureus` plugin.
3. Navigate to the “Plugins” menu and select the `napari-findaureus` option to activate the widget.
4. In the viewer, identify the bacteria channel from the ""layer list,"" which is specified in the image file name, and select it.
5. Once the bacteria channel is selected, click on the `Find bacteria!` button.
6. The widget will display the image-related data and bacteria count. If you need additional help, click on the `Instruction` button in the widget.
7. Before you proceed to another image, reset the viewer by clicking on the `Reset` button provided in the widget.

<p align=""center"">
<img src=""https://raw.githubusercontent.com/shibarjun/napari-findaureus/main/docs/napari-findaureus.gif"" />
</p>

Enjoy exploring the fascinating world of bacteria in mouse bone tissues!

----------------------------------
## Contributing
We welcome and appreciate all contributions to the `napari-findaureus` project! Whether it's reporting bugs, suggesting new features, improving documentation, or writing code, your involvement is greatly valued.
When using our dataset or referring to our work, we kindly ask that you acknowledge the dataset and cite the related articles. This helps support our work and allows us to continue improving this project.

Thank you for your interest and support!
## Citations and Dataset
### Findaureus
 Mandal S, Tannert A, Löffler B, Neugebauer U, Silva LB (2024) [Findaureus: An open-source application for locating Staphylococcus aureus in fluorescence-labelled infected bone tissue slices.](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0296854) PLoS ONE 19(1): e0296854.
### Infected mouse bone tissue
Mandal S, Tannert A, Ebert C, Guliev RR, Ozegowski Y, Carvalho L, Wildemann B, Eiserloh S, Coldewey SM, Löffler B, Bastião Silva L, Hoerr V, Tuchscherr L, Neugebauer U. (2023) [Insights into S. aureus-Induced Bone Deformation in a Mouse Model of Chronic Osteomyelitis Using Fluorescence and Raman Imaging.](https://www.mdpi.com/1422-0067/24/11/9762) International Journal of Molecular Sciences 24(11):9762.

### [Dataset](https://zenodo.org/doi/10.5281/zenodo.8411791)
## Acknowledgements

This project is a part of the European Union's Horizon 2020 research and innovation program under grant agreement No 861122 (ITN IMAGE-IN). We acknowledge support from the Jena Biophotonics and Imaging Laboratory (JBIL), from the European Union via EFRE funds within the Thüringer Innovationszentrum für Medizintechnik-Lösungen (ThIMEDOP, FKZ IZN 2018 0002), the BMBF via the funding program Photonics Research Germany (LPI, FKZ: 13N15713) and via the CSCC (FKZ 01EO1502) and the Institute of Anatomical and Molecular Pathology, University Coimbra, Portugal.
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: MIT License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']",,napari-findaureus.get_reader,,napari-findaureus.make_magic_widget,,"['*.czi', '*.nd2', '*.lif', '*.tiff']",,,https://pypi.org/project/napari-findaureus,,
151,FLIM phasor plotter,0.0.6,,,napari-flim-phasor-plotter,"Marcelo L. Zoccoler, Cornelia Wetzker",marzoccoler@gmail.com,BSD-3-Clause,,A plugin that performs phasor plot from TCSPC FLIM data.,>=3.8,"['numpy', 'magicgui', 'qtpy', 'napari-clusters-plotter', 'sdtfile', 'natsort', 'rocket-fft', 'dask', 'zarr', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-flim-phasor-plotter

[![License BSD-3](https://img.shields.io/pypi/l/napari-flim-phasor-plotter.svg?color=green)](https://github.com/zoccoler/napari-flim-phasor-plotter/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-flim-phasor-plotter.svg?color=green)](https://pypi.org/project/napari-flim-phasor-plotter)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-flim-phasor-plotter.svg?color=green)](https://python.org)
[![tests](https://github.com/zoccoler/napari-flim-phasor-plotter/workflows/tests/badge.svg)](https://github.com/zoccoler/napari-flim-phasor-plotter/actions)
[![codecov](https://codecov.io/gh/zoccoler/napari-flim-phasor-plotter/branch/main/graph/badge.svg)](https://codecov.io/gh/zoccoler/napari-flim-phasor-plotter)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-flim-phasor-plotter)](https://napari-hub.org/plugins/napari-flim-phasor-plotter)

Napari-flim-phasor-plotter is a [napari](https://napari.org/stable/) plugin to interactively load and show raw fluorescence lifetime imaging microscopy (FLIM) single images and series and generate phasor plots. These are Fourier transforms of the decay data being visualized using the [napari-clusters-plotter](https://github.com/BiAPoL/napari-clusters-plotter) plotter, adapted to suit the FLIM context. This allows qualitative and quantitative downstream analysis of FLIM images.  

----------------------------------

## Usage

Open a FLIM image to visualize it both as a 'FLIM image series' being a sequence of intensity images each corresponding to an individual time point of the FLIM 'micro-time', plus as a timely summed up image. Scrolling through the FLIM time series provides a first glimpse of lifetimes across image regions.

Call the plugin from the menu `Plugins > FLIM phasor plotter > Make FLIM Phasor Plot` to generate a phasor plot by pixel-wise Fourier transformation of the decay data. Hereby, select the FLIM image to be used, specify the laser pulse frequency if not read properly from metadata. Define an intensity threshold to exclude pixels of low photon counts, optionally a median filter, and a harmonic for optimal visualization. `Run` creates the phasor plot and an additional labels layer in the layer list. Below is a demonstration:

![](https://github.com/zoccoler/napari-flim-phasor-plotter/raw/main/images/napari_FLIM_phasor_calculator_Demo.gif)

Change the color-code of the phasor plot to a density plot of various ‘Colormaps’ from the pulldown `Expand for advanced options` and select `HISTOGRAM`. Manually encircle a region of interest in the phasor plot to highlight the corresponding pixels in the newly created image layer. Hold ‘Shift’ to select and visualize several clusters to investigate image regions of similar FLIM patterns. 

### Input Data

This plugin integrates with [napari-clusters-plotter plugin](https://github.com/BiAPoL/napari-clusters-plotter).

This plugin can read the following FLIM file types:
  - "".ptu""
  - "".sdt""
  - "".tif""
  - "".zarr""

This plugin works with the following data shapes:
  - 2D FLIM images (actually 3D data where FLIM counts are in the first axis).
  - 3D FLIM images (actually 4D data where FLIM counts are in the first axis).
  - 3D timelapse FLIM images (actually 5D data where FLIM counts are in the first axis).
  - Multichannel '.tif' or '.zarr' data may need to be loaded separately.

The plugin outputs data axes in the following order (data from multiple detectors are displayed as distinct napari layers):

(`flim_counts`, `time`, `z`, `y`, `x`)

It also outputs the standard intensity image in another layer by summing the `flim_counts` dimension.

### Data Conversion

If a collection of raw (uncompressed) images are larger than 4GB, we recommend converting them to `.zarr`. This can be done via `Plugins > napari-flim-phasor-plotter > Convert to zarr`.

_Warning: In the current version, lazy loading with `.zarr` is available, but processing may still load all data into memory, so keep track of your memory usage._

![](https://github.com/zoccoler/napari-flim-phasor-plotter/raw/main/images/convert_to_zarr.png)

If you have multiple slices or time-points as separated files, you can choose a folder containing the files. In order for the plugin to properly build a stack, the file names must contain some indication about which slice or time-point they represent, i.e., **each file name should contain a `_t` and/or `_z` followerd by a number**.

Here are a few example templates:
- timelapse:
  - `image_t001.ptu`
  - `image_t002.ptu`
- z-stack:
  - `image_z01.sdt`
  - `image_z02.sdt`
- 3D timelapse:
  - `image_t001_z001.tif`
  - `image_t001_z002.tif`
  - ...
  - `image_t002_z001.tif`


## Installation

You can install `napari-flim-phasor-plotter` via [pip]. Follow these steps from a terminal.

We recommend using `mamba-forge` whenever possible. Click [here](https://github.com/conda-forge/miniforge#mambaforge) to choose the right download option for your OS.
**If you use `mamba-forge`, replace the `conda` term whenever you see it below with `mamba`.**

Create a conda environment:

    conda create -n napari-flim-phasor-env python=3.9
    
Activate the environment:

    conda activate napari-flim-phasor-env
    
Then install `napari` and `napari-clusturs-plotter` (plus git if on Windows):

    conda install -c conda-forge napari==0.4.17 napari-clusters-plotter git pyqt

_Optional: we **strongly** recommend having the `devbio-napari` plugin bundle also installed for post-processing. This can be done with:_

    conda install -c conda-forge devbio-napari

Finally install `napari-flim-phasor-plotter` plugin with:

    pip install napari-flim-phasor-plotter
 
Alternatively, clone this repository and install the latest plugin development version with:

    pip install git+https://github.com/zoccoler/napari-flim-phasor-plotter.git

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-flim-phasor-plotter"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/zoccoler/napari-flim-phasor-plotter/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/zoccoler/napari-flim-phasor-plotter/issues', 'Documentation, https://github.com/zoccoler/napari-flim-phasor-plotter#README.md', 'Source Code, https://github.com/zoccoler/napari-flim-phasor-plotter', 'User Support, https://github.com/zoccoler/napari-flim-phasor-plotter/issues']",napari-flim-phasor-plotter.get_reader,,napari-flim-phasor-plotter.calculate_phasors,napari-flim-phasor-plotter.load_seminal_receptacle_image,"['*.ptu', '*.PTU', '*.sdt', '*.SDT', '*.tif', '*.zarr']",,,https://pypi.org/project/napari-flim-phasor-plotter,,
152,napari-folder-browser,0.1.4,2022-02-04,2023-06-18,napari-folder-browser,Robert Haase,robert.haase@tu-dresden.de,BSD-3-Clause,https://github.com/haesleinhuepf/napari-folder-browser,Browse folders of images and open them using double-click,>=3.7,"['napari-plugin-engine >=0.1.4', 'napari-tools-menu']","# napari-folder-browser

[![License](https://img.shields.io/pypi/l/napari-folder-browser.svg?color=green)](https://github.com/haesleinhuepf/napari-folder-browser/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-folder-browser.svg?color=green)](https://pypi.org/project/napari-folder-browser)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-folder-browser.svg?color=green)](https://python.org)
[![tests](https://github.com/haesleinhuepf/napari-folder-browser/workflows/tests/badge.svg)](https://github.com/haesleinhuepf/napari-folder-browser/actions)
[![codecov](https://codecov.io/gh/haesleinhuepf/napari-folder-browser/branch/master/graph/badge.svg)](https://codecov.io/gh/haesleinhuepf/napari-folder-browser)

Browse folders of images and open them using double-click or <ENTER>. You can also navigate through the list using arrow up/down keys.

![](https://github.com/haesleinhuepf/napari-folder-browser/raw/main/docs/napari-folder-browser.gif)

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.

## Installation

You can install `napari-folder-browser` from within napari by clicking menu `Plugins > Install/uninstall Plugins...` and entering here:
![img.png](https://github.com/haesleinhuepf/napari-folder-browser/raw/main/docs/install.png)

You can install `napari-folder-browser` via [pip]:

    pip install napari-folder-browser

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## Development
### Test the plugin in Napari
Simply use pip install and run napari to test the plugin in the same environment:
```bash
pip install -e .
napari
```

### Conda
If you prefer to use conda, you can create a new environment with the following command:
```bash
conda env create -f environment.yml
conda activate napari-folder-browser
```

## License

Distributed under the terms of the [BSD-3] license,
""napari-folder-browser"" is free and open source software

## Issues

If you encounter any problems, please create a thread on [image.sc] along with a detailed description and tag [@haesleinhuepf].

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/haesleinhuepf/napari-folder-browser/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
[image.sc]: https://image.sc
[@haesleinhuepf]: https://twitter.com/haesleinhuepf

","['Development Status :: 3 - Alpha', 'Intended Audience :: Science/Research', 'Framework :: napari', 'Topic :: Scientific/Engineering :: Image Processing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/haesleinhuepf/napari-folder-browser/issues', 'Documentation, https://github.com/haesleinhuepf/napari-folder-browser#README.md', 'Source Code, https://github.com/haesleinhuepf/napari-folder-browser', 'User Support, https://github.com/haesleinhuepf/napari-folder-browser/issues']",,,napari-folder-browser.FolderBrowser,,,,,https://pypi.org/project/napari-folder-browser,https://github.com/haesleinhuepf/napari-folder-browser,
153,GEMspa,0.0.4,2023-12-08,2023-12-09,napari-gemspa,Sarah Keegan,sarah.keegan@nyulangone.org,BSD-3-Clause,https://github.com/liamholtlab/napari-gemspa,A plugin for analysis of single particle tracking experiments,>=3.8,"['numpy', 'magicgui', 'qtpy', 'pandas', 'napari', 'scikit-image', 'gemspa-spt', 'matplotlib', 'trackpy', 'nd2', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-gemspa

This plugin provides for analysis tools for data from single particle tracking experiments.  It provides an interface for particle localization and tracking using [trackpy](http://soft-matter.github.io/trackpy/dev/index.html).  It also allows for import of tracking data from Mosaic and Trackmate.  These files must be tab/comma delimited text files.  It provides an option to exclude particles/tracks masked with a labels layer.

There are 5 tabs available in the plugin, following the workflow of data analysis:

1) **New/Open**: open nd2/tiff time-lapse movie files and/or import a tracks layer (from Mosaic, Trackmate or napari-gemspa saved tracks layer)
2) **Locate**: locate particles with trackpy
3) **Link**: link particles with trackpy
4) **Filter Links**: filter links with trackpy
5) **Analyze**: Perform analysis on tracks from a tracks layer (can be from imported file from step 1 or layer created in step 3)

**Detailed description of features:**

1) **New/Open**

![My Image](https://raw.githubusercontent.com/liamholtlab/napari-gemspa/main/screen_shots/1_1.png)

**Add layer** button will create a blank 2D (no time dimension) layer that is the same height/width as the currently selected image layer.  Alternatively, a labeled mask can be opened from a file.  The labels layer can be used to provide a mask for excluding areas of the image from analysis.

Track files from other software or previously saved by GEMspa can also be imported in this pane.  Only tab/comma (.csv/.txt/.tsv) delimited text files are allowed.

**GEMspa** expects these columns in the header: ['track_id', 'frame', 'z', 'y', 'x']

**Mosaic** expects these columns in the header: ['Trajectory', 'Frame', 'z', 'y', 'x']

**Trackmate** expects these columns in the header: ['TRACK_ID', 'FRAME', 'POSITION_Z', 'POSITION_Y', 'POSITION_X'],
* 3 rows will be skipped for Trackmate files (assumes data begins at the 4th row after the header)

**Trackpy** expects these columns in the header: ['particle', 'frame', 'z', 'y', 'x']

_(All columns are case and order insensitive)_

2) **Locate**
![My Image](https://raw.githubusercontent.com/liamholtlab/napari-gemspa/main/screen_shots/2_1.png)

In this tab, adjust the parameters and perform particle localization with [trackpy.locate](http://soft-matter.github.io/trackpy/dev/generated/trackpy.locate.html#trackpy.locate).  To first test out parameters on a single frame, check the ""Process only current frame"" checkbox.  Please refer to the trackpy documentation for more details on parameters.

After localization is performed, a new points layer will be created and particles will be shown circled in red.  In the example, we have used a labels layer to exclude particles outside an ROI (this is optional):

![My Image](https://raw.githubusercontent.com/liamholtlab/napari-gemspa/main/screen_shots/2_2.png)

In addition, the mass histogram and subpixel bias histograms will be shown for help with adjusting the mass and diameter parameters:

![My Image](https://raw.githubusercontent.com/liamholtlab/napari-gemspa/main/screen_shots/2_3.png)

3) **Link**

![My Image](https://raw.githubusercontent.com/liamholtlab/napari-gemspa/main/screen_shots/3_1.png)

In this tab, adjust parameters and perform linking with [trackpy.link](http://soft-matter.github.io/trackpy/dev/generated/trackpy.link.html).  Once linking is performed a new tracks layer will be added.  Please refer to the trackpy documentation for more details on parameters.

In addition, scatter plots of mass vs. size and mass vs. eccentricity, as well as the track lengths histogram are shown for help with filtering tracks. (next step)

![My Image](https://raw.githubusercontent.com/liamholtlab/napari-gemspa/main/screen_shots/3_2.png)

4) **Filter**

![My Image](https://raw.githubusercontent.com/liamholtlab/napari-gemspa/main/screen_shots/4_1.png)

In this tab, adjust parameters and filter links from trackpy output.  After filtering, a new layer will be added to napari with the filtered tracks and the same plots as shown in step 4 will be displayed.

5) **Analyze**

![My Image](https://raw.githubusercontent.com/liamholtlab/napari-gemspa/main/screen_shots/5_1.png)

In this tab, adjust parameters and perform analysis.  You may process all tracks or enter a track id and deselect the ""Process all tracks"" check box.  Enter the appropriate parameters for converting pixels to microns and the time lag (in seconds) between frames of the movie.  

GEMspa will calculate the effective diffusion coefficient (D) for each track based on the mean squared displacement values (MSD) for each time-lag using this equation:

![My Image](https://raw.githubusercontent.com/liamholtlab/napari-gemspa/main/screen_shots/5_2.png)

This is the diffusion coefficient with the assumption of Brownian motion.  GEMspa will also calculate the generalized diffusion coefficient and anomalous exponent using this equation:

![My Image](https://raw.githubusercontent.com/liamholtlab/napari-gemspa/main/screen_shots/5_3.png)

The fitting is performed on a log-log scale where the slope corresponds to the anomalous exponent (alpha):

![My Image](https://raw.githubusercontent.com/liamholtlab/napari-gemspa/main/screen_shots/5_4.png)

**Definition of terms:**

![My Image](https://raw.githubusercontent.com/liamholtlab/napari-gemspa/main/screen_shots/5_5.png)

This review: [Manzo et al](https://pubmed.ncbi.nlm.nih.gov/26511974/)  is useful for learning more about these and other analysis methods.

**Min track len for fit**: all tracks less than this length will be excluded from calculations of effective diffusion coefficient and anomalous exponent.

**Max time lag for fit**: GEMspa will fit the MSD up to the max time-lag entered here.  (in frames)

**Fit with error term**: check this box to allow a y-intercept when fitting for effective diffusion coefficient:

![My Image](https://raw.githubusercontent.com/liamholtlab/napari-gemspa/main/screen_shots/5_6.png)

Check these papers by [Martin, et al](https://www.sciencedirect.com/science/article/pii/S0006349502739714) and [Xavier Michalet](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3055791/) for some information on fitting MSD with localization error.

**Rainbow tracks**

GEMspa can output a plot where the tracks are colored by any of the listed quantities.  Check each box that you would like to see.  

For the effective diffusion coefficient and anomalous exponent, set the Min/Max cutoffs for the track color map.  Any tracks at or below the minimum will be colored with the minimum color (blue).  Any tracks at or above the maximum will be colored with the maximum color (red).

![My Image](https://raw.githubusercontent.com/liamholtlab/napari-gemspa/main/screen_shots/5_10.png)

**Plots**

GEMspa will also output summary plots including:
* Ensemble average MSD shown on linear and log-scale with results from fitting the MSD vs time-lag data from the ensemble average MSD.
* Track length histogram, Radius of gyration (for full track lengths) histogram, Scatter plot of track length vs. radius of gyration

![My Image](https://raw.githubusercontent.com/liamholtlab/napari-gemspa/main/screen_shots/5_7.png)

![My Image](https://raw.githubusercontent.com/liamholtlab/napari-gemspa/main/screen_shots/5_8.png)

**Tracks data table**

GEMspa will output a table of data in a new pop-up window with data for each track.  This table will only show one line for each track (not one line for every particle position) and it will output the following data:
* track_id
* frame_start
* frame_end
* radius_gyration: radius of gyration for the full track length (See [Elliot et al](https://doi.org/10.1039/c0cp01805h))
* track_length
* D: effective diffusion coefficient
* E: y-intercept for the fit of MSD for D
* r_sq (lin): R-squared value for goodness-of-fit for the fit of MSD vs time-lag
* K: generalized diffusion coefficient
* a: anomalous exponent (alpha)
* r_sq (log): R-squared value for goodness-of-fit for the fit of log-log MSD vs. time-lag

![My Image](https://raw.githubusercontent.com/liamholtlab/napari-gemspa/main/screen_shots/5_9.png)

**New tracks layer**

GEMspa will add a new tracks layer and save all data for each track in the properties of the tracks layer.  Save the tracks layer to obtain a tab/comma-delimited text file with all analysis results.  The data included for each track is:
* track_id
* frame
* y: y position in pixels
* x: x position in pixels
* frame_start
* frame_end
* y (microns): y position in microns
* x (microns): x position in microns
* tau: time-lag in seconds
* MSD: mean squared displacement 
* t: time in seconds from start of track
* step_size
* radius_gyration: radius of gyration at each time point of track (See [Elliot et al](https://doi.org/10.1039/c0cp01805h))
* track_length
* D: effective diffusion coefficient
* E: y-intercept for the fit of MSD for D
* r_sq (lin): R-squared value for goodness-of-fit for the fit of MSD vs time-lag
* K: generalized diffusion coefficient
* a: anomalous exponent (alpha)
* r_sq (log): R-squared value for goodness-of-fit for the fit of log-log MSD vs. time-lag

To extract this data, save the layer as a tab or comma delimited text file (txt/tsv/csv).  GEMspa will save all track information.

**Analysis for a single track**

GEMspa also provides the option to select a single track and output analysis results.  Detailed information is shown for the selected track, including a plot of the radius of gyration at each time point and a plot of the track itself.  

Here is an example:

![My Image](https://raw.githubusercontent.com/liamholtlab/napari-gemspa/main/screen_shots/5_11.png)

![My Image](https://raw.githubusercontent.com/liamholtlab/napari-gemspa/main/screen_shots/5_12.png)


","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/liamholtlab/napari-gemspa/issues', 'Documentation, https://github.com/liamholtlab/napari-gemspa#README.md', 'Source Code, https://github.com/liamholtlab/napari-gemspa', 'User Support, https://github.com/liamholtlab/napari-gemspa/issues']",napari-gemspa.get_reader,napari-gemspa.write_points,napari-gemspa.make_gemspa_plugin,,"['*.txt', '*.csv', '*.tsv']","['.txt', '.csv', '.tsv']","['.txt', '.csv', '.tsv']",https://pypi.org/project/napari-gemspa,https://github.com/liamholtlab/napari-gemspa,
154,napari generic SIMulator,0.1.2,2022-08-18,2023-06-18,napari-generic-SIMulator,Meizhu Liang,ml2618@ic.ac.uk,BSD-3-Clause,https://github.com/Meizhu-Liang/napari-generic-SIMulator,A napari plugin to simulate raw-image stacks of Structured illumination microscopy (SIM).,>=3.8,"['numpy', 'magicgui', 'qtpy', 'tifffile', 'opt-einsum', 'matplotlib', 'pypcd-imp', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'"", ""tifffile ; extra == 'testing'"", ""pypcd-imp ; extra == 'testing'"", ""opt-einsum ; extra == 'testing'"", ""matplotlib ; extra == 'testing'""]","# napari-generic-SIMulator

[![License BSD-3](https://img.shields.io/pypi/l/napari-generic-SIMulator.svg?color=green)](https://github.com/Meizhu-Liang/napari-generic-SIMulator/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-generic-SIMulator.svg?color=green)](https://pypi.org/project/napari-generic-SIMulator)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-generic-SIMulator.svg?color=green)](https://python.org)
[![tests](https://github.com/Meizhu-Liang/napari-generic-SIMulator/workflows/tests/badge.svg)](https://github.com/Meizhu-Liang/napari-generic-SIMulator/actions)
[![codecov](https://codecov.io/gh/Meizhu-Liang/napari-generic-SIMulator/branch/main/graph/badge.svg)](https://codecov.io/gh/Meizhu-Liang/napari-generic-SIMulator)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-generic-SIMulator)](https://napari-hub.org/plugins/napari-generic-SIMulator)

A napari plugin to simulate raw-image stacks of Structured illumination microscopy (SIM). 

The simulation is originally based on the paper <strong>GPU-accelerated real-time reconstruction in Python of three-dimensional datasets from structured illumination microscopy with hexagonal patterns</strong> by
Hai Gong, Wenjun Guo and Mark A. A. Neil (https://doi.org/10.1098/rsta.2020.0162). 

The calculation can be GPU-accelerated if the CUPY (tested with cupy-cuda11x) is installed. In addition, the TORCH package can complete the acceleration both on CPU if TORCH is installed, and on GPU if TORCH is compiled with the CUDA (tested with torch v1.13.1+cu117) enabled.

Currently applies to:
- conventional 2-beam SIM data with 3 angles and 3 phases
- 3-beam hexagonal SIM data with 7 phases, as described in the paper
- 3-beam hexagonal SIM data with 5 phases at right-angles
- conventional 3-beam 3-D data with 3 angles and 5 phases

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/index.html
-->

## Installation

You can install `napari-generic-SIMulator` via [pip]:

    pip install napari-generic-SIMulator



To install latest development version :

    pip install git+https://github.com/Meizhu-Liang/napari-generic-SIMulator.git

This plugin is compatible with **napari 0.4.17** or above, older versions of napari would show errors in _interpolation_.

## Usage

1) Open napari and create the viewer.


2) Launch two widgets: **Point cloud generator** and **SIM data generator** in ***Plugin***.

   ![raw](https://github.com/Meizhu-Liang/napari-generic-SIMulator/raw/main/images/lauch.png)

   The two widgets can be tabbed together.
   ![raw](https://github.com/Meizhu-Liang/napari-generic-SIMulator/raw/main/images/2tabs.png)


3) Choose the type and other parameters of point cloud as a sample in **Point cloud generator**.

    ![raw](https://github.com/Meizhu-Liang/napari-generic-SIMulator/raw/main/images/pc.png)

    The point cloud can be displayed in three dimensions, and be saved and loaded as .pcd files.
  
    https://user-images.githubusercontent.com/74197598/227589232-9006842b-6706-48b7-9f2b-fe93c6698503.mp4


4) Adjust parameters in SIM data generator to simulate a raw image stack.

   Apart from basic parameters such as the refractive index, the wavelengths and so on, the z scanning can be either 
   **z drift**: the conventional SIM (imaging a raw stack at the same z-position) or **z step**: the drifting case in 
   the papaer mentioned above (imaging only one raw image at a z-position).


   ![raw](https://github.com/Meizhu-Liang/napari-generic-SIMulator/raw/main/images/raw_stack.png)

   The parameters used in the simulation can be saved with the image stack by clicking **save tif with tags**. Tags (of current or of one stack dragged into napari viewer) can be printed in Python by **print tags**. 


5) Three-dimensional point spread function (**PSF**), optical transfer function (**OTF**) and **illumination** patterns applied in the simulation can be showed by buttons. Note the all of these correspond the generated raw-image stack, so keep the parameters the same before showing the **PSF** (or **OTF** and **illumination**).

    https://user-images.githubusercontent.com/74197598/227588321-ad3c8f17-1c61-4079-9e34-9b1f990714c1.mp4
    
    https://user-images.githubusercontent.com/74197598/227586957-b76ad56e-44d5-4d9b-a1cc-2cfd08ca5400.mp4
    
    https://user-images.githubusercontent.com/74197598/227585827-64531265-b4fb-48a9-9698-7f263f22d718.mp4 
   
6) The raw image stacks can be then processed by napari-sim-processor (https://www.napari-hub.org/plugins/napari-sim-processor).
   
   ![raw](https://github.com/Meizhu-Liang/napari-generic-SIMulator/raw/main/images/processor.png)


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-generic-SIMulator"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/Meizhu-Liang/napari-generic-SIMulator/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10']","['Bug Tracker, https://github.com/Meizhu-Liang/napari-generic-SIMulator/issues', 'Documentation, https://github.com/Meizhu-Liang/napari-generic-SIMulator#README.md', 'Source Code, https://github.com/Meizhu-Liang/napari-generic-SIMulator', 'User Support, https://github.com/Meizhu-Liang/napari-generic-SIMulator/issues']",,,napari-generic-SIMulator.make_pointcloud_widget,,,,,https://pypi.org/project/napari-generic-SIMulator,https://github.com/Meizhu-Liang/napari-generic-SIMulator,
155,napari-geojson,0.1.3,2022-01-31,2023-06-18,napari-geojson,Tim Morello,tdmorello@gmail.com,BSD-3-Clause,https://github.com/tdmorello/napari-geojson,Read and write geojson files in napari,>=3.8,"['geojson', 'numpy', ""black ; extra == 'dev'"", ""flake8 ; extra == 'dev'"", ""flake8-black ; extra == 'dev'"", ""flake8-docstrings ; extra == 'dev'"", ""flake8-isort ; extra == 'dev'"", ""isort ; extra == 'dev'"", ""mypy ; extra == 'dev'"", ""pre-commit ; extra == 'dev'"", ""pytest ; extra == 'dev'"", ""pytest-cov ; extra == 'dev'"", ""pytest-qt ; extra == 'dev'"", ""tox ; extra == 'dev'"", ""napari[all] ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""tox ; extra == 'testing'""]","# napari-geojson

[![License](https://img.shields.io/pypi/l/napari-geojson.svg?color=green)](https://github.com/tdmorello/napari-geojson/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-geojson.svg?color=green)](https://pypi.org/project/napari-geojson)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-geojson.svg?color=green)](https://python.org)
[![tests](https://github.com/tdmorello/napari-geojson/workflows/tests/badge.svg)](https://github.com/tdmorello/napari-geojson/actions)
[![codecov](https://codecov.io/gh/tdmorello/napari-geojson/branch/main/graph/badge.svg)](https://codecov.io/gh/tdmorello/napari-geojson)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-geojson)](https://napari-hub.org/plugins/napari-geojson)

Read and write geojson files in napari.

![](https://github.com/tdmorello/napari-geojson/raw/main/resources/output.gif)

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/stable/index.html
-->

## Installation

You can install `napari-geojson` via [pip]:

    pip install napari-geojson



To install latest development version :

    pip install git+https://github.com/tdmorello/napari-geojson.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-geojson"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/tdmorello/napari-geojson/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 3 - Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/tdmorello/napari-geojson/issues', 'Documentation, https://github.com/tdmorello/napari-geojson#README.md', 'Source Code, https://github.com/tdmorello/napari-geojson', 'User Support, https://github.com/tdmorello/napari-geojson/issues']",napari-geojson.get_reader,napari-geojson.write_shapes,,,['*.geojson'],['.geojson'],,https://pypi.org/project/napari-geojson,https://github.com/tdmorello/napari-geojson,
156,Griottes,0.4.1,2023-04-17,2023-06-18,napari-griottes,Andrey Aristov,aaristov@pasteur.fr,BSD-3-Clause,https://github.com/aaristov/napari-griottes,Create graphs,>=3.8,"['griottes', 'networkx', 'numpy', 'pandas (<2)']","# napari-griottes

[![License](https://img.shields.io/pypi/l/napari-griottes.svg?color=green)](https://github.com/BaroudLab/napari-griottes/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-griottes.svg?color=green)](https://pypi.org/project/napari-griottes)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-griottes.svg?color=green)](https://python.org)
[![tests](https://github.com/BaroudLab/napari-griottes/workflows/tests/badge.svg)](https://github.com/BaroudLab/napari-griottes/actions)
[![codecov](https://codecov.io/gh/BaroudLab/napari-griottes/branch/main/graph/badge.svg)](https://codecov.io/gh/BaroudLab/napari-griottes)

[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-griottes)](https://napari-hub.org/plugins/napari-griottes)



Use [🍒  `Griottes` 🍒](https://github.com/BaroudLab/Griottes) in napari!

----------------------------------



https://user-images.githubusercontent.com/11408456/224119160-c381091d-8275-449e-9cf4-679ab474acd2.mp4




## Installation

Install from napari

![image](https://user-images.githubusercontent.com/11408456/224108834-f484ba37-50f4-415e-bdfb-509c6c5b88c4.png)


You can install `napari-griottes` via [pip]:

    pip install napari-griottes



To install latest development version :

    pip install git+https://github.com/BaroudLab/napari-griottes.git



## Usage

### Starting with labels:

1. Open the plugin in Plugins/napari-griottes
2. Make sure the layer with labels is selected
3. Click Run once to get centers
4. Click Run second time to get graph
5. Select the right kind of graph in the drop-down menu
6. Adjust the distance
7. Adjust thickness

![Screenshot from three labels geometric contact mp4](https://user-images.githubusercontent.com/11408456/167371516-05db2ba5-cdfc-47c4-a488-8f46afd0ae5b.png)



https://user-images.githubusercontent.com/11408456/167825581-47c39884-34cf-4b5c-ad84-a4572217559d.mp4



### Starting with Segmented cells

1. Open sample data: File / Open Sample / napari-griottes / Zebrafish 2D with labels
2. Select the top layer and covert it to labels (right click - Convert to labels)
3. Run the plugin once to get the centers of labels
4. Run the plugin twice to get the connections
5. Proceed with graph creation


![Screenshot from cells graphs mp4](https://user-images.githubusercontent.com/11408456/167372895-3c9036b9-af50-4575-bcf3-1805eb261bd7.png)




https://user-images.githubusercontent.com/11408456/168237170-b43afd5a-26a4-4cdc-bc42-d3f46f138536.mp4


### Saving and recovering the graph

Any graph you see in napari can be saved in .json format.
1. Select he layers with connections
2. Click File/Save Selected Layer
3. Choose Griottes in drop-down menu
4. Save

In order to recover a previously saved graph in napari, you can simply drag-n-drop your file into napari, or use file open fialog.



https://user-images.githubusercontent.com/11408456/167845853-e7071199-3f58-4d11-8d7b-c1358a150e6b.mp4


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-griottes"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/BaroudLab/napari-griottes/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Software Development :: Testing']","['Bug Tracker, https://github.com/aaristov/napari-griottes/issues', 'Documentation, https://github.com/aaristov/napari-griottes#README.md', 'Source Code, https://github.com/aaristov/napari-griottes', 'User Support, https://github.com/aaristov/napari-griottes/issues']",napari-griottes.get_reader,napari-griottes.save_graph,napari-griottes.make_graph,napari-griottes.make_cell_properties,"['*.json', '*.npy', '*.tif', '*.tiff', '*.csv', '*.griottes']",['.json'],,https://pypi.org/project/napari-griottes,https://github.com/aaristov/napari-griottes,
157,napari Gruvbox,0.1.1,2023-04-05,2023-06-18,napari-gruvbox,Lorenzo Gaifas,brisvag@gmail.com,GPL-3.0-only,https://github.com/brisvag/napari-gruvbox,Gruvbox theme for napari.,>=3.8,['pygments (>=2.9)'],"# napari-gruvbox

[![License GNU GPL v3.0](https://img.shields.io/pypi/l/napari-gruvbox.svg?color=green)](https://github.com/brisvag/napari-gruvbox/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-gruvbox.svg?color=green)](https://pypi.org/project/napari-gruvbox)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-gruvbox.svg?color=green)](https://python.org)
[![tests](https://github.com/brisvag/napari-gruvbox/workflows/tests/badge.svg)](https://github.com/brisvag/napari-gruvbox/actions)
[![codecov](https://codecov.io/gh/brisvag/napari-gruvbox/branch/main/graph/badge.svg)](https://codecov.io/gh/brisvag/napari-gruvbox)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-gruvbox)](https://napari-hub.org/plugins/napari-gruvbox)

Gruvbox theme for napari. Colors are taken from the palette in https://github.com/morhetz/gruvbox.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-gruvbox` via [pip]:

    pip install napari-gruvbox



To install latest development version :

    pip install git+https://github.com/brisvag/napari-gruvbox.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [GNU GPL v3.0] license,
""napari-gruvbox"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/brisvag/napari-gruvbox/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: GNU General Public License v3 (GPLv3)', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/brisvag/napari-gruvbox/issues', 'Documentation, https://github.com/brisvag/napari-gruvbox#README.md', 'Source Code, https://github.com/brisvag/napari-gruvbox', 'User Support, https://github.com/brisvag/napari-gruvbox/issues']",,,,,,,,https://pypi.org/project/napari-gruvbox,https://github.com/brisvag/napari-gruvbox,
158,napari-h5,0.0.8,2023-10-29,2023-10-29,napari-h5,Luis Perdigao,luis.perdigao@rfi.ac.uk,Apache-2.0,https://pypi.org/project/napari-h5,A hdf5 file reader plugin for napari,>=3.8,"['numpy', 'h5py', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'""]","# napari-h5

[![License Apache Software License 2.0](https://img.shields.io/pypi/l/napari-h5.svg?color=green)](https://github.com/rosalindfranklininstitute/napari-h5/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-h5.svg?color=green)](https://pypi.org/project/napari-h5)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-h5.svg?color=green)](https://python.org)
[![tests](https://github.com/rosalindfranklininstitute/napari-h5/workflows/tests/badge.svg)](https://github.com/rosalindfranklininstitute/napari-h5/actions)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-h5)](https://napari-hub.org/plugins/napari-h5)

A file reader plugin for napari


It opens simple *.h5 files. Reads all Datasets inside the file and converts to
a napari Image object (np.array).

It can also save ""image"" or ""labels"" data. Note that these will be saved individually.

It does not support data organised internally in ""groups"".
For these more complicated h5 data structures please try other plugins.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-h5` via [pip]:

    pip install napari-h5




## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [Apache Software License 2.0] license,
""napari-h5"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: Apache Software License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/rosalindfranklininstitute/napari-h5/issues', 'Documentation, https://github.com/rosalindfranklininstitute/napari-h5#readme', 'Source Code, https://github.com/rosalindfranklininstitute/napari-h5', 'User Support, https://github.com/rosalindfranklininstitute/napari-h5/issues']",napari-h5.get_reader,napari-h5.multi_layer_writer,,,['*.h5'],['.h5'],['.h5'],https://pypi.org/project/napari-h5,,
159,napari-hdf5-labels-io,0.3.dev16,2022-02-23,2023-06-18,napari-hdf5-labels-io,"Duway Nicolas Lesmes Leon, Pranjal Dhole","dlesmesleon@hotmail.com, dhole.pranjal@gmail.com",GNU GPL v3.0,https://github.com/yapic/napari-hdf5-labels-io,Napari plugin to store set of layers in a .h5 file. Label layer are stored in a sparse representation.,<3.9,"['napari-plugin-engine (>=0.1.4)', 'typing', 'numpy', 'sparse', 'h5py (==2.10.0)', 'zarr']","# napari-hdf5-labels-io

[![License](https://img.shields.io/pypi/l/napari-hdf5-labels-io.svg?color=green)](https://github.com/yapic/napari-hdf5-labels-io/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-hdf5-labels-io.svg?color=green)](https://pypi.org/project/napari-hdf5-labels-io)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-hdf5-labels-io.svg?color=green)](https://python.org)
[![tests](https://github.com/yapic/napari-hdf5-labels-io/workflows/tests/badge.svg)](https://github.com/yapic/napari-hdf5-labels-io/actions)
[![codecov](https://codecov.io/gh/yapic/napari-hdf5-labels-io/branch/master/graph/badge.svg)](https://codecov.io/gh/yapic/napari-hdf5-labels-io)

napari plugin to store napari projects in a .h5 file. Label layer are stored in a sparse representation (COO list).

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/docs/plugins/index.html
-->

## Description

This napari plugin provides a writer and reader to store existing layers in the current napari window, all the metadata is stored as well in a HDF5 file. All the stored preferences are included when a project file is opened.

Label layers are stored in a coordinate list sparse representation with the [Sparse module](https://sparse.pydata.org/) to keep the project file size minimum when possible (aiming to implement this in other layers in the future).

## HDF5 file architecture

The project file is a HDF5 generated with the [h5py module](https://docs.h5py.org). The file groups correspond to the different napari layer types and the layer metadata is stored as attributes of each layer.

In the case of the meta dictionary which is nested in the LayerData meta dictionary (napari IO), new keys are generated in the outer dictionary to use them as h5 dataset attributes. This nested dictionary architecture is reconstructed by the reader to ensure format compatibility.

## Installation

You can install `napari-hdf5-labels-io` via [pip]:

    pip install napari-hdf5-labels-io

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [GNU GPL v3.0] license,
""napari-hdf5-labels-io"" is free and open source software.

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/yapic/napari-hdf5-labels-io/issues
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/


","['Development Status :: 4 - Beta', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Operating System :: OS Independent', 'License :: OSI Approved :: GNU General Public License v3 (GPLv3)']",,napari-hdf5-labels-io.h5_to_napari,napari-hdf5-labels-io.napari_write_image,,,['*'],,,https://pypi.org/project/napari-hdf5-labels-io,https://github.com/yapic/napari-hdf5-labels-io,
160,napari Help,0.1.0,2022-08-18,2023-06-18,napari-help,Lorenzo Gaifas,brisvag@gmail.com,GPL-3.0,https://github.com/brisvag/napari-help,Helpful tooltips for napari.,>=3.8,"['napari', 'qtpy', ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""tox ; extra == 'testing'""]","# napari-help

[![License GNU GPL v3.0](https://img.shields.io/pypi/l/napari-help.svg?color=green)](https://github.com/brisvag/napari-help/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-help.svg?color=green)](https://pypi.org/project/napari-help)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-help.svg?color=green)](https://python.org)
[![tests](https://github.com/brisvag/napari-help/workflows/tests/badge.svg)](https://github.com/brisvag/napari-help/actions)
[![codecov](https://codecov.io/gh/brisvag/napari-help/branch/main/graph/badge.svg)](https://codecov.io/gh/brisvag/napari-help)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-help)](https://napari-hub.org/plugins/napari-help)

Helpful tooltips for napari.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-help` via [pip]:

    pip install napari-help



To install latest development version :

    pip install git+https://github.com/brisvag/napari-help.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [GNU GPL v3.0] license,
""napari-help"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/brisvag/napari-help/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: GNU General Public License v3 (GPLv3)', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/brisvag/napari-help/issues', 'Documentation, https://github.com/brisvag/napari-help#README.md', 'Source Code, https://github.com/brisvag/napari-help', 'User Support, https://github.com/brisvag/napari-help/issues']",,,napari-help.help_widget,,,,,https://pypi.org/project/napari-help,https://github.com/brisvag/napari-help,
161,napari-hierarchical,0.1.0,2023-04-17,2023-06-18,napari-hierarchical,Jonas Windhager,jonas.windhager@uzh.ch,MIT,https://github.com/BodenmillerGroup/napari-hierarchical,Hierarchical file format support for napari,"<3.11,>=3.8","['napari (<0.4.18,>=0.4.17)', 'pluggy', 'qtpy', ""dask ; extra == 'all'"", ""h5py ; extra == 'all'"", ""readimc ; extra == 'all'"", ""s3fs ; extra == 'all'"", ""zarr ; extra == 'all'"", ""dask ; extra == 'hdf5'"", ""h5py ; extra == 'hdf5'"", ""dask ; extra == 'imc'"", ""readimc ; extra == 'imc'"", ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'"", ""dask ; extra == 'zarr'"", ""s3fs ; extra == 'zarr'"", ""zarr ; extra == 'zarr'""]","# napari-hierarchical

[![License MIT](https://img.shields.io/pypi/l/napari-hierarchical.svg?color=green)](https://github.com/BodenmillerGroup/napari-hierarchical/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-hierarchical.svg?color=green)](https://pypi.org/project/napari-hierarchical)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-hierarchical.svg?color=green)](https://python.org)
[![tests](https://github.com/BodenmillerGroup/napari-hierarchical/workflows/tests/badge.svg)](https://github.com/BodenmillerGroup/napari-hierarchical/actions)
[![codecov](https://codecov.io/gh/BodenmillerGroup/napari-hierarchical/branch/main/graph/badge.svg)](https://codecov.io/gh/BodenmillerGroup/napari-hierarchical)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-hierarchical)](https://napari-hub.org/plugins/napari-hierarchical)

Hierarchical file format support for napari

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.


## Installation

You can install `napari-hierarchical` via [pip]:

    pip install ""napari-hierarchical[all]""

To install latest development version :

    pip install ""git+https://github.com/BodenmillerGroup/napari-hierarchical.git#egg=napari-hierarchical[all]""

## Usage

The plugin enables the reading, editing and writing of container formats. In the plugin, *groups* represent hierarchically structured collections of *arrays*. Each group can hold zero or more arrays and can have zero or more child groups (hierarchical structure). An array is a logical representation of (image) data on disk and directly corresponds to a napari layer when loaded.

Files can be opened through napari (e.g. `File -> Open File(s)` menu, `Viewer.open(...)` function), as the plugin implements napari's file reader hook. Upon opening a hierarchically structured file, the *Groups* and *Arrays* widgets are displayed. The *Groups* widget allows to browse and restructure the groups tree, while the *Arrays* widget groups arrays from the selected groups by file format-specific metadata (e.g. channel name for MCD files). Selecting arrays also selects the corresponding napari layers, allowing to adjust their properties.

Arrays can be loaded individually by toggling their *loaded* state (circular button), which will add napari layers for the corresponding arrays. Similarly, loaded arrays can be shown or hidden by toggling their *visible* state (eye button), which will toggle the visibility of the associated napari layers. The loaded/visible states of groups (collections of arrays) can be toggled in a similar fashion. Arrays are always loaded into memory (no memory mapping), to allow for editing the tree structure. Loaded root groups can be exported to supported hierarchical file formats.

Currently, reading/writing of HDF5 and Zarr (not: OME-NGFF) files are supported out of the box, as well as reading imaging mass cytometry (IMC) data (i.e., MCD files). For these file formats, sample data is available through the plugin. Additional readers/writers can be implemented using a pluggy-based interface, similar to the first generation `napari-plugin-engine`.

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.


## License

Distributed under the terms of the [MIT] license,
""napari-hierarchical"" is free and open source software


## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/BodenmillerGroup/napari-hierarchical/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Framework :: napari', 'License :: OSI Approved :: MIT License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/BodenmillerGroup/napari-hierarchical/issues', 'Documentation, https://github.com/BodenmillerGroup/napari-hierarchical#README.md', 'Source Code, https://github.com/BodenmillerGroup/napari-hierarchical', 'User Support, https://github.com/BodenmillerGroup/napari-hierarchical/issues']",napari-hierarchical.get_reader,,napari-hierarchical.make_groups_widget,napari-hierarchical.sample_data.imc_mock,['*'],,,https://pypi.org/project/napari-hierarchical,https://github.com/BodenmillerGroup/napari-hierarchical,
162,Hippo,0.1.0,,,napari-hippo,Sam Thiele,s.thiele@hzdr.de,MIT,,A fat and clumsy collection of hyperspectral tools,>=3.8,"['natsort', 'hylite', 'numpy', 'magicgui', 'qtpy', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""hylite ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-hippo

[![License MIT](https://img.shields.io/pypi/l/napari-hippo.svg?color=green)](https://github.com/samthiele/napari-hippo/blob/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-hippo.svg?color=green)](https://pypi.org/project/napari-hippo)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-hippo)](https://napari-hub.org/plugins/napari-hippo)

A large and slightly clumsy plugin for viewing and analysing hyperspectral data in Napari.

![Funky screenshot of the napari-hippo GUI](screenshot.png)

----------------------------------

## Installation

You can install `napari-hippo` via [pip]:

    pip install napari-hippo


## Contributing

Contributions are very welcome :blush:

## License

Distributed under the terms of the [MIT] license,
""napari-hippo"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

## Citation

A citation for this plugin will be announced shortly.
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: MIT License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']",,napari-hippo.get_ENVI_reader,napari-hippo.write_multiple,napari-hippo.make_IOTools,napari-hippo.make_sample_data,"['*.hdr', '*.dat', '*.png', '*.jpg', '*.jpeg', '*.bmp']",,"['.dat', '.hdr']",https://pypi.org/project/napari-hippo,,
163,Hough circle detector,0.0.5,2023-04-17,2023-09-06,napari-hough-circle-detector,Florian Aymanns,florian.aymanns@epfl.ch,,https://pypi.org/project/napari-hough-circle-detector/,An interactive Hough transform for napari.,,"['napari[all]', 'opencv-contrib-python-headless', 'numpy', 'pyqt5', 'scikit-image']","# napari-hough-circle-detector

A plugin for napari that detects circles using the Hough transform.
",['Framework :: napari'],,,,napari-hough-circle-detector.CircleDetectorWidget,,,,,https://pypi.org/project/napari-hough-circle-detector/,,
164,napari IDS,0.0.8,,,napari-IDS,Tristan Cotte,tristan.cotte@sgs.com,BSD-3,,Plug in which enables to take photo with IDS uEye camera,>=3.8,"['opencv-python', 'numpy']","# napari-IDS

[![License](https://img.shields.io/pypi/l/napari-IDS.svg?color=green)](https://github.com/githubuser/napari-IDS/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-IDS.svg?color=green)](https://pypi.org/project/napari-IDS)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-IDS.svg?color=green)](https://python.org)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-IDS)](https://napari-hub.org/plugins/napari-IDS)

A simple plugin to use with napari

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/stable/index.html
-->

## Installation

You can install `napari-IDS` via [pip]:

    pip install napari-IDS



To install latest development version :

    pip install git+https://github.com/githubuser/napari-IDS.git


## First utilisation

Suggested environment : 
- Python 3.8
- IDS 1.2.0.5 version installed

To use this package for the first time :
1. Install Napari `pip install ""napari[all]""`
2. Install napari-IDS package
3. Install IDS Python api thanks to the command `ids_packages`

If your environment is not the suggested environment, you have to install IDS packages manually. 


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-IDS"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/githubuser/napari-IDS/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 4 - Beta', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/tcotte/napari-IDS/issues', 'Documentation, https://github.com/tcotte/napari-IDS#README.md', 'Source Code, https://github.com/tcotte/napari-IDS', 'User Support, https://github.com/tcotte/napari-IDS/issues']",,,napari-IDS.make_qwidget,,,,,https://pypi.org/project/napari-IDS,,
165,napari-image-stacker,0.1.10,2022-02-04,2023-06-18,napari-image-stacker,"Robin Koch, Marc Boucsein",robin.koch@dkfz-heidelberg.de,BSD3,https://github.com/RobAnKo/napari-image-stacker,A plugin designed to convert multiple open layers into a stack or vice versa,>=3.7,"['napari-plugin-engine (>=0.1.4)', 'numpy']","# napari-image-stacker

[![License](https://img.shields.io/pypi/l/napari-image-stacker.svg?color=green)](https://github.com/RobAnKo/napari-image-stacker/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-image-stacker.svg?color=green)](https://pypi.org/project/napari-image-stacker)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-image-stacker.svg?color=green)](https://python.org)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-image-stacker)](https://napari-hub.org/plugins/napari-image-stacker)

A plugin designed to convert multiple open layers into a stack or vice versa

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.


## Installation

You can install `napari-image-stacker` via [pip]:

    pip install napari-image-stacker



To install latest development version :

    pip install git+https://github.com/RobAnKo/napari-image-stacker.git


## Contributing

Contributions are very welcome. Tests can be run with [tox].

## License

Distributed under the terms of the [BSD-3] license,
""napari-image-stacker"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/RobAnKo/napari-image-stacker/issues
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/


","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/RobAnKo/napari-image-stacker/issues', 'Documentation, https://github.com/RobAnKo/napari-image-stacker#README.md', 'Source Code, https://github.com/RobAnKo/napari-image-stacker', 'User Support, https://github.com/RobAnKo/napari-image-stacker/issues']",,,napari-image-stacker.image_stacker_widget,,,,,https://pypi.org/project/napari-image-stacker,https://github.com/RobAnKo/napari-image-stacker,
166,napari-imagej,0.1.0,2023-06-27,2023-06-27,napari-imagej,ImageJ2 developers,ImageJ2 developers <ctrueden@wisc.edu>,BSD-2-Clause,https://github.com/imagej/napari-imagej,ImageJ functionality from napari,"<=3.11.0,>=3.8","['confuse', 'imglyb (>=2.1.0)', 'jpype1 (>=1.4.1)', 'labeling (>=0.1.12)', 'magicgui (>=0.5.1)', 'napari (>=0.4.17)', 'numpy', 'pandas', 'pyimagej (>=1.4.1)', 'scyjava (>=1.8.1)', 'qtconsole (!=5.4.2)', 'typing-extensions (!=4.6.0)', ""autopep8 ; extra == 'dev'"", ""black (>=23.1.0) ; extra == 'dev'"", ""build ; extra == 'dev'"", ""flake8 ; extra == 'dev'"", ""flake8-pyproject ; extra == 'dev'"", ""flake8-typing-imports ; extra == 'dev'"", ""isort ; extra == 'dev'"", ""myst-parser ; extra == 'dev'"", ""pre-commit ; extra == 'dev'"", ""pyqt5 ; extra == 'dev'"", ""pytest ; extra == 'dev'"", ""pytest-cov ; extra == 'dev'"", ""pytest-env ; extra == 'dev'"", ""pytest-qt ; extra == 'dev'"", ""sphinx ; extra == 'dev'"", ""sphinx-copybutton ; extra == 'dev'"", ""sphinx-rtd-theme ; extra == 'dev'"", ""qtpy ; extra == 'dev'"", ""validate-pyproject[all] ; extra == 'dev'""]","# napari-imagej

### A [napari] plugin for access to [ImageJ2]

[![License](https://img.shields.io/pypi/l/napari-imagej.svg?color=green)](https://github.com/imagej/napari-imagej/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-imagej.svg?color=green)](https://pypi.org/project/napari-imagej)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-imagej.svg?color=green)](https://python.org)
[![tests](https://github.com/imagej/napari-imagej/workflows/tests/badge.svg)](https://github.com/imagej/napari-imagej/actions)
[![codecov](https://codecov.io/gh/imagej/napari-imagej/branch/main/graph/badge.svg)](https://codecov.io/gh/imagej/napari-imagej)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-imagej)](https://napari-hub.org/plugins/napari-imagej)

**napari-imagej** aims to provide access to all [ImageJ2] functionality through the [napari] graphical user interface. It builds on the foundation of [PyImageJ], a project allowing ImageJ2 access from Python.

**With napari-imagej, you can access:**

1. The napari-imagej widget, providing *headless access* to:
   * [ImageJ2 Commands] - 100+ image processing algorithms
   * [ImageJ Ops] - 500+ *functional* image processing algorithms
   * [SciJava Scripts] - migrated from Fiji or ImageJ2, or written yourself!
2. The ImageJ user interface, providing access to *the entire ImageJ ecosystem* within napari.

See the [project roadmap](https://github.com/orgs/imagej/projects/2) for future directions.

## Getting Started

Learn more about the project [here](https://napari-imagej.readthedocs.io/en/0.1.0/), or jump straight to [installation](https://napari-imagej.readthedocs.io/en/0.1.0/Install.html)!

## Usage

* [Image Processing with ImageJ Ops](https://napari-imagej.readthedocs.io/en/0.1.0/examples/ops.html)
* [Puncta Segmentation with SciJava Scripts](https://napari-imagej.readthedocs.io/en/0.1.0/examples/scripting.html)

## Troubleshooting

The [FAQ](https://napari-imagej.readthedocs.io/en/0.1.0/Troubleshooting.html) outlines solutions to many common issues.

For more obscure issues, feel free to reach out on [forum.image.sc](https://forum.image.sc).

If you've found a bug, please [file an issue]!

## Contributing

We welcome any and all contributions made onto the napari-imagej repository.

Development discussion occurs on the [Image.sc Zulip chat](https://imagesc.zulipchat.com/#narrow/stream/328100-scyjava).

For technical details involved with contributing, please see [here](https://napari-imagej.readthedocs.io/en/0.1.0/Development.html)

## License

Distributed under the terms of the [BSD-2] license,
""napari-imagej"" is free and open source software.


[Apache Software License 2.0]: https://www.apache.org/licenses/LICENSE-2.0
[black]: https://github.com/psf/black
[BSD-2]: https://opensource.org/licenses/BSD-2-Clause
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[conda]: https://docs.conda.io/
[conda-forge]: https://conda-forge.org/
[file an issue]: https://github.com/imagej/napari-imagej/issues
[flake8]: https://flake8.pycqa.org/
[GNU GPL v3.0]: https://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: https://www.gnu.org/licenses/lgpl-3.0.txt
[ImageJ2]: https://imagej.net/software/imagej2
[ImageJ2 Commands]: https://github.com/imagej/imagej-plugins-commands
[ImageJ Ops]: https://imagej.net/libs/imagej-ops
[install mamba]: https://mamba.readthedocs.io/en/latest/installation.html
[isort]: https://pycqa.github.io/isort/
[mamba]: https://mamba.readthedocs.io/
[MIT]: https://opensource.org/licenses/MIT
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[napari]: https://github.com/napari/napari
[napari hub]: https://www.napari-hub.org/
[npe2]: https://github.com/napari/npe2
[pip]: https://pypi.org/project/pip/
[pull request]: https://docs.github.com/en/pull-requests/collaborating-with-pull-requests/proposing-changes-to-your-work-with-pull-requests/about-pull-requests
[PyImageJ]: https://github.com/imagej/pyimagej
[PyPI]: https://pypi.org/
[SciJava Scripts]: https://imagej.net/scripting
[tox]: https://tox.readthedocs.io/
","['Development Status :: 4 - Beta', 'Intended Audience :: Developers', 'Intended Audience :: Science/Research', 'Framework :: napari', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Operating System :: Microsoft :: Windows', 'Operating System :: Unix', 'Operating System :: MacOS', 'License :: OSI Approved :: BSD License', 'Topic :: Scientific/Engineering', 'Topic :: Scientific/Engineering :: Image Processing', 'Topic :: Scientific/Engineering :: Visualization', 'Topic :: Software Development :: Libraries :: Java Libraries', 'Topic :: Software Development :: Libraries :: Python Modules']","['homepage, https://github.com/imagej/napari-imagej', 'documentation, https://github.com/imagej/napari-imagej#README.md', 'source, https://github.com/imagej/napari-imagej', 'download, https://pypi.org/project/napari-imagej/', 'tracker, https://github.com/imagej/napari-imagej/issues']",napari-imagej.get_trackmate_reader,,napari-imagej.func,,['*.xml'],,,https://pypi.org/project/napari-imagej,https://github.com/imagej/napari-imagej,
167,napari-imaris-loader,0.1.8,2022-02-13,2023-06-18,napari-imaris-loader,Alan M Watson,alan.watson@pitt.edu,BSD-3-Clause,https://github.com/AlanMWatson/napari-imaris-loader,Napari plugin for loading Bitplane imaris files '.ims',>=3.8,"['napari[all]', 'napari-plugin-engine (>=0.1.4)', 'imaris-ims-file-reader (>=0.1.5)', 'numpy', 'h5py', 'dask']","

# Description

This plugin enables viewing of Bitplane Imaris files, including very large datasets.  The GIFs below demonstrate rendering of a ~2TB IMS file containing a 2 color whole mouse brain.  The plugin has been tested on datasets as large as 20TB.

**NOTE: For this plugin to work ""File/Preferences/Experimental/Render Images Asynchronously"" must be selected.**

### Open IMS file:

![Open IMS file GIF](https://i.imgur.com/ByHb0wI.gif ""Open IMS file"")



### Render in 3D:

A plugin is provided to dynamically reload the data after selecting the lowest resolution level to be included in the viewer.  Since napari only renders the lowest resolution, the user can use this plugin to control the quality of 3D rendering.  See features and limitations for tips on suggested usage.

![3D Rendering and Quality Adjustment GIF](https://i.imgur.com/MZNlWtM.gif ""3D Rendering and Quality Adjustment"")

### Features

* Multiscale Rendering
  * Image pyramids which are present in the native IMS format are automatically added to napari during file loading.
* Chunks are implemented by dask and matched to the chunk sizes stored in each dataset.  (Napari appears to only ask for 2D chunks - unclear how helpful this feature is currently)
* Successfully handles multi-terabyte multi-timepoint multi-channel datasets.
* Tested with all sample files provided by Bitplane.
* Higher 3D rendering quality is enabled by a widget that reloads data after specifying the lowest resolution level (higher number = lower resolution) to be included in the multiscale series.

### Known Issues / limitations

* Currently, this is **only an image loader**, and there are no features for loading or viewing objects
* Napari sometimes throws errors indicating that it expected a 3D or 5D array but receives the other.
  * This sometimes *but relatively rarely* causes napari to crash
  * Would like to enable Asynchronous Tiling of Images, but this results in more instability and causes crashes.


----------------------------------

This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/docs/plugins/index.html
-->

## Installation

You can install `napari-imaris-loader` via [pip]:

    pip install napari-imaris-loader

## Change Log:

##### <u>v0.1.2:</u>

**Fixed:** Issue where .ims files containing a single color 2D image would not open.

**Fixed:** Issue where using the widget to change resolutions while in 3D rendering would cause a crash.  Now the viewer is automatically forced into 2D rendering mode when the widget is used.

**Dependency change:** The loader is now dependent in a separate package for loading IMS files.  https://pypi.org/project/imaris-ims-file-reader/

**v0.1.3:**

Documentation

**v0.1.4:**

Add napari to install requirements for plugin compatibility

**v0.1.5:**

Changes to napari:

- now requires napari[all] upon install.
- requires >=v0.1.5 of imaris-ims-file-reader

**v0.1.6:**

- Fix issue #7 where contrastLimits possibly unbound in reader

**v0.1.7:**

- For squeeze_output=False when opening .ims file for Napari compatibility

**v0.1.8:**

- Add automatic determination of contrast_limits
- Fix bug in squeeze_output

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-imaris-loader"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/AlanMWatson/napari-imaris-loader/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/


","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/AlanMWatson/napari-imaris-loader/issues', 'Documentation, https://github.com/AlanMWatson/napari-imaris-loader#README.md', 'Source Code, https://github.com/AlanMWatson/napari-imaris-loader', 'User Support, https://github.com/AlanMWatson/napari-imaris-loader/issues']",napari-imaris-loader.napari_get_reader,,napari-imaris-loader.resolution_change,,['*'],,,https://pypi.org/project/napari-imaris-loader,https://github.com/AlanMWatson/napari-imaris-loader,
168,napari-imc,0.6.5,2022-02-02,2023-06-18,napari-imc,Jonas Windhager,jonas.windhager@uzh.ch,MIT,https://github.com/BodenmillerGroup/napari-imc,Imaging Mass Cytometry (IMC) file type support for napari,>=3.8,"['numpy', 'qtpy', 'readimc', 'superqt']","# napari-imc

[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-imc)](https://napari-hub.org/plugins/napari-imc)
[![PyPI](https://img.shields.io/pypi/v/napari-imc.svg?color=green)](https://pypi.org/project/napari-imc)
[![License](https://img.shields.io/pypi/l/napari-imc.svg?color=green)](https://github.com/BodenmillerGroup/napari-imc/raw/main/LICENSE)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-imc.svg?color=green)](https://python.org)
[![Issues](https://img.shields.io/github/issues/BodenmillerGroup/napari-imc)](https://github.com/BodenmillerGroup/napari-imc/issues)
[![Pull requests](https://img.shields.io/github/issues-pr/BodenmillerGroup/napari-imc)](https://github.com/BodenmillerGroup/napari-imc/pulls)

Imaging Mass Cytometry (IMC) file type support for napari

Load panoramas and multi-channel acquisitions co-registered within the machine's coordinate system from Fluidigm TXT/MCD files

## Installation

You can install napari-imc via [pip](https://pypi.org/project/pip/):

    pip install napari-imc
    
Alternatively, you can install napari-imc via [conda](https://conda.io/):

    conda install -c conda-forge napari-imc
    
For example, to install napari and napari-imc in a fresh conda environment using pip:

    conda create -n napari-imc python=3.9
    conda activate napari-imc
    pip install ""napari[all]"" napari-imc
    
## Usage

Simply open your Fluidigm TXT/MCD file using napari.

## Authors

Created and maintained by Jonas Windhager [jonas.windhager@uzh.ch](mailto:jonas.windhager@uzh.ch)

## Citation

Please cite the following paper when using napari-imc in your work:

> Windhager J, Bodenmiller B, Eling N (2021). An end-to-end workflow for multiplexed image processing and analysis. bioRxiv. doi: https://doi.org/10.1101/2021.11.12.468357.

    @article{Windhager2021,
      author = {Windhager, Jonas and Bodenmiller, Bernd and Eling, Nils},
      title = {An end-to-end workflow for multiplexed image processing and analysis},
      year = {2021},
      doi = {10.1101/2021.11.12.468357},
      URL = {https://www.biorxiv.org/content/early/2021/11/13/2021.11.12.468357},
      journal = {bioRxiv}
    }

## Contributing

[Contributing](https://github.com/BodenmillerGroup/napari-imc/blob/main/CONTRIBUTING.md)

## Changelog

[Changelog](https://github.com/BodenmillerGroup/napari-imc/blob/main/CHANGELOG.md)

## License

[MIT](https://github.com/BodenmillerGroup/napari-imc/blob/main/LICENSE.md)
","['Development Status :: 4 - Beta', 'Intended Audience :: Science/Research', 'Framework :: napari', 'Topic :: Scientific/Engineering :: Bio-Informatics', 'Topic :: Scientific/Engineering :: Image Processing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Operating System :: OS Independent', 'License :: OSI Approved :: MIT License']","['Bug Tracker, https://github.com/BodenmillerGroup/napari-imc/issues', 'Documentation, https://github.com/BodenmillerGroup/napari-imc#README.md', 'Source Code, https://github.com/BodenmillerGroup/napari-imc', 'User Support, https://github.com/BodenmillerGroup/napari-imc/issues']",napari-imc.get_reader,,napari-imc.IMCWidget,,"['*.mcd', '*.txt']",,,https://pypi.org/project/napari-imc,https://github.com/BodenmillerGroup/napari-imc,
169,Napari Imod Model,1.0.2,,,napari-imodmodel,Moritz Wachsmuth-Melm,mail@moritzwm.de,BSD-3-Clause,,Open IMOD model files in napari,>=3.8,"['numpy', 'imodmodel', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'""]","# napari-imodmodel

[![License BSD-3](https://img.shields.io/pypi/l/napari-imodmodel.svg?color=green)](https://github.com/MoritzWM/napari-imodmodel/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-imodmodel.svg?color=green)](https://pypi.org/project/napari-imodmodel)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-imodmodel.svg?color=green)](https://python.org)
[![tests](https://github.com/MoritzWM/napari-imodmodel/workflows/tests/badge.svg)](https://github.com/MoritzWM/napari-imodmodel/actions)
[![codecov](https://codecov.io/gh/MoritzWM/napari-imodmodel/branch/main/graph/badge.svg)](https://codecov.io/gh/MoritzWM/napari-imodmodel)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-imodmodel)](https://napari-hub.org/plugins/napari-imodmodel)

Open IMOD model files in napari

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-imodmodel` via [pip]:

    pip install napari-imodmodel



To install latest development version :

    pip install git+https://github.com/MoritzWM/napari-imodmodel.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-imodmodel"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/MoritzWM/napari-imodmodel/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/MoritzWM/napari-imodmodel/issues', 'Documentation, https://github.com/MoritzWM/napari-imodmodel#README.md', 'Source Code, https://github.com/MoritzWM/napari-imodmodel', 'User Support, https://github.com/MoritzWM/napari-imodmodel/issues']",napari-imodmodel.get_reader,,,napari-imodmodel.make_sample_data,['*.mod'],,,https://pypi.org/project/napari-imodmodel,,
170,napari-imsmicrolink,0.1.9,2022-02-07,2023-06-18,napari-imsmicrolink,Nathan Heath Patterson,heath.patterson@vanderbilt.edu,MIT,https://github.com/nhpatterson/napari-imsmicrolink,Plugin to perform IMS to microscopy registration using laser ablation marks.,>=3.8,"['numpy', 'tifffile', 'dask', 'zarr (>=2.10.3)', 'qtpy', 'aicsimageio[bioformats]', 'bioformats-jar', 'SimpleITK', 'pandas', 'h5py', 'opencv-python', 'czifile', 'imagecodecs', 'napari[all]']","# napari-imsmicrolink
![microlink-logo-update](https://user-images.githubusercontent.com/17855764/146078168-dd557089-ff10-46d6-b24d-268f5d21a9ee.png)

[![License](https://img.shields.io/pypi/l/napari-imsmicrolink.svg?color=green)](https://github.com/nhpatterson/napari-imsmicrolink/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-imsmicrolink.svg?color=green)](https://pypi.org/project/napari-imsmicrolink)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-imsmicrolink.svg?color=green)](https://python.org)
[![tests](https://github.com/nhpatterson/napari-imsmicrolink/workflows/tests/badge.svg)](https://github.com/nhpatterson/napari-imsmicrolink/actions)

[napari] plugin to perform MALDI IMS - microscopy registration using laser ablation marks as described in [Anal. Chem. 2018, 90, 21, 12395–12403](https://pubs.acs.org/doi/abs/10.1021/acs.analchem.8b02884). This plugin is a work-in-progress but is mostly functional.

__N.B.__ This tool is __NOT__ a general purpose registration framework to find transforms between IMS (MALDI or otherwise)
and microscopy. It is built to align MALDI IMS pixels to their corresponding laser ablation marks as captured by microscopy AFTER the IMS experiment. 
This approach has the advantage of providing direct evidence of registration performance as IMS pixels are aligned 
to their _explicit spatial origin_ in microscopy space, improving overall accuracy and confidence of microscopy-driven IMS 
data analysis.

## Installation

You can install `napari-imsmicrolink` via [pip]:

    pip install napari-imsmicrolink

### Typical experiment workflow
1. Acquire pre-IMS microscopy (autofluorescence, brightfield) - _optional_
2. Perform normal IMS sample preparation.
3. Acquire post-IMS microscopy (autofluorescence, brightfield) with matrix still on sample
that reveals laser ablation marks.

4. Gather IMS data that contains XY integer coordinates for the IMS experiment
   (.imzML, Bruker spotlist (.txt, .csv), Bruker peaks.sqlite (_FTICR_),
   Bruker .tsf (TIMS qTOF only))

5. Run `napari-imsmicrolink` with data 3 and 4

6. Once registered, use `wsireg` to align other microscopy modalities to IMS-registered post-IMS
microscopy

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/docs/plugins/index.html
-->


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [MIT] license,
""napari-imsmicrolink"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/nhpatterson/napari-imsmicrolink/issues
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 3 - Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Operating System :: OS Independent', 'License :: OSI Approved :: MIT License']","['Bug Tracker, https://github.com/nhpatterson/napari-imsmicrolink/issues', 'Documentation, https://github.com/nhpatterson/napari-imsmicrolink#README.md', 'Source Code, https://github.com/nhpatterson/napari-imsmicrolink', 'User Support, https://github.com/nhpatterson/napari-imsmicrolink/issues']",,,napari-imsmicrolink.IMSMicroLink,,,,,https://pypi.org/project/napari-imsmicrolink,https://github.com/nhpatterson/napari-imsmicrolink,
171,indices,0.0.2,2023-12-08,2023-12-08,napari-indices,Emmanuella OKAFOR,eokafor010@gmail.com,BSD-3-Clause,https://pypi.org/project/napari-indices,Calculer les indices de végétation,>=3.8,"['numpy', 'magicgui', 'qtpy', 'spectral', 'matplotlib', 'tifffile', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-indices

[![License BSD-3](https://img.shields.io/pypi/l/napari-indices.svg?color=green)](https://github.com/Emmanulla0/napari-indices/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-indices.svg?color=green)](https://pypi.org/project/napari-indices)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-indices.svg?color=green)](https://python.org)
[![tests](https://github.com/Emmanulla0/napari-indices/workflows/tests/badge.svg)](https://github.com/Emmanulla0/napari-indices/actions)
[![codecov](https://codecov.io/gh/Emmanulla0/napari-indices/branch/main/graph/badge.svg)](https://codecov.io/gh/Emmanulla0/napari-indices)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-indices)](https://napari-hub.org/plugins/napari-indices)

Calculer les indices de végétation

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->
Emmanuella OKAFOR (L3 PA CMI-PSI_Université d'Angers) developed this plugin during her internship with a french team called ImHorPHen (lead by David ROUSSEAU). This plugin realises vegetation indexes computation with hyperspectral images. For the momment, there are five vegetation indexes : NDVI, TCARI, NPCI, SGI, NDGI.
## Installation

You can install `napari-indices` via [pip]:

    pip install napari-indices



To install latest development version :

    pip install git+https://github.com/Emmanulla0/napari-indices.git

## Plugin description


Using this plugin requires importing the bands of a hyperspectral image into a **tif file**, in our case, 160 bands. You must launch it by accessing the **Plugins > napari-indices> Vegetation indices** menu.

![Capture d'écran 2023-05-29 124720](https://github.com/Emmanuella0/napari-indices/assets/132358490/3b3895df-d0a7-466e-8ada-92bd4b642852)

Then select the vegetation index to be calculated and the different bands to be used, then click the **Run** button to start the calculation. This results in the images corresponding to the calculated indices.

![etape_2](https://github.com/Emmanuella0/napari-indices/assets/132358490/4875f0fc-3435-4875-ba4e-8881cb179b96)


The areas of interest to be analysed must then be defined. To do this, click the **Shapes** button on the Napari interface and choose the **add rectangle** shape from the menu that appears. Using the mouse, it is then possible to draw a rectangle on each of the two areas to be analyzed, for example a tree sheet and a green sheet of paper. 

![etape_3](https://github.com/Emmanuella0/napari-indices/assets/132358490/fc8612fe-5deb-4290-b4c3-9cac20acf1ce)


To perform the Fisher ratio calculation and display the histogram, it is necessary to go back to the **Plugins > napari-indices > ExempleQWidget** menu and click the **Click me! **. This action opens a new window displaying the best vegetation index to use, its corresponding Fisher ratio and the histogram of the two selected regions on the image of the vegetation index concerned. A video explaining the plugin is available at: https://uabox.univ-angers.fr/index.php/s/LqB0qs11n3jxZVJ.

![Histogram](https://github.com/Emmanuella0/napari-indices/assets/132358490/be176176-1972-402c-9a01-8e367347d9d8)

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-indices"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/Emmanulla0/napari-indices/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/Emmanulla0/napari-indices/issues', 'Documentation, https://github.com/Emmanulla0/napari-indices#README.md', 'Source Code, https://github.com/Emmanulla0/napari-indices', 'User Support, https://github.com/Emmanulla0/napari-indices/issues']",napari-indices.get_reader,napari-indices.write_multiple,napari-indices.make_qwidget,napari-indices.make_sample_data,['*.npy'],,['.npy'],https://pypi.org/project/napari-indices,,
172,Input Visualizer,0.0.1,,,napari-input-visualizer,David Bauer,dbauer@brc.hu,BSD-3-Clause,,Visualize keyboard and mouse button presses,>=3.8,"['numpy', 'magicgui', 'qtpy', 'napari', 'imageio-ffmpeg', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-input-visualizer

[![License BSD-3](https://img.shields.io/pypi/l/napari-input-visualizer.svg?color=green)](https://github.com/bauerdavid/napari-input-visualizer/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-input-visualizer.svg?color=green)](https://pypi.org/project/napari-input-visualizer)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-input-visualizer.svg?color=green)](https://python.org)
[![tests](https://github.com/bauerdavid/napari-input-visualizer/workflows/tests/badge.svg)](https://github.com/bauerdavid/napari-input-visualizer/actions)
[![codecov](https://codecov.io/gh/bauerdavid/napari-input-visualizer/branch/main/graph/badge.svg)](https://codecov.io/gh/bauerdavid/napari-input-visualizer)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-input-visualizer)](https://napari-hub.org/plugins/napari-input-visualizer)

Visualize keyboard and mouse button presses

A simple tool to visualize input events like keyboard presses or mouse clicking and scrolling. Use it to create tutorial videos or to demonstrate a bug you encountered!

## Demo:


https://user-images.githubusercontent.com/36735863/194586424-1e6288d3-2c2f-412c-a1cb-91d139f787bd.mp4



----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-input-visualizer` via [pip]:

    pip install napari-input-visualizer



To install latest development version :

    pip install git+https://github.com/bauerdavid/napari-input-visualizer.git


## Contributing

Contributions are very welcome.

## License

Distributed under the terms of the [BSD-3] license,
""napari-input-visualizer"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/bauerdavid/napari-input-visualizer/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/bauerdavid/napari-input-visualizer/issues', 'Documentation, https://github.com/bauerdavid/napari-input-visualizer#README.md', 'Source Code, https://github.com/bauerdavid/napari-input-visualizer', 'User Support, https://github.com/bauerdavid/napari-input-visualizer/issues']",,,napari-input-visualizer.input_visualizer_widget,,,,,https://pypi.org/project/napari-input-visualizer,,
173,Image Processing Workflow,0.0.3,2022-07-06,2023-06-18,napari-IP-workflow,Jay Unruh,jru@stowers.org,GPL-3.0-only,https://github.com/jayunruh/napari-IP-workflow,"A plugin to do image preprocessing, segmentation, and measurements on other images.",>=3.8,"['numpy', 'magicgui', 'qtpy', 'pandas', 'skimage', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-IP-workflow

[![License](https://img.shields.io/pypi/l/napari-IP-workflow.svg?color=green)](https://github.com/jayunruh/napari-IP-workflow/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-IP-workflow.svg?color=green)](https://pypi.org/project/napari-IP-workflow)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-IP-workflow.svg?color=green)](https://python.org)
[![tests](https://github.com/jayunruh/napari-IP-workflow/workflows/tests/badge.svg)](https://github.com/jayunruh/napari-IP-workflow/actions)
[![codecov](https://codecov.io/gh/jayunruh/napari-IP-workflow/branch/main/graph/badge.svg)](https://codecov.io/gh/jayunruh/napari-IP-workflow)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-IP-workflow)](https://napari-hub.org/plugins/napari-IP-workflow)

A plugin to do image preprocessing, segmentation, and measurements on other images.  The typical workflow is background subtraction followed by smoothing, thresholding, and size filtering.  This is typically done on nuclear stained images.  Segmentation can optionally be followed by circular label expansion to find cytoplasmic signals. The labeled signals are then measured on background subtracted images.

##General organization

The code is separated into non-interactive processing functions (ipfunctions module) and an interactive widget (segwidget module).  Please look at the code on github for examples: [Github](https://github.com/jayunruh/napari-ip-workflow). The expected workflow is from jupyter notebooks with an interactive workflow shown in src/napari-ip-workflow/_tests/standard_segementation_widget.ipynb and a non-interactive workflow shown in src/napari-ip-workflow/_tests/standard_segmentation.ipynb.  The expectation is to find the best parameters in an interactive way (ideally testing on several images) and then use the non-interactive workflow to batch through more data sets.  All image processing algorithms are in the ipfunctions module and the segwidget module has the Napari widget code.  Below I describe the strategies that are utilized in the workflow.

## Background subtraction strategy

Automated background subtraction (e.g. as in Fiji) is often accomplished with a low pass filter-style approach like rolling ball background subtraction.  This approach fails as feature sizes grow larger or measurements approach the background.  Manual selection of the background is more robust but introduces human variability and isn't compatible with high throughput analyses.  Our approach is to attempt to automate regional selection of background as follows.  First the image is smoothed with a Gaussian filter to eliminate background noise.  Next, minimum values are subtracted from each channel and the resulting images are summed.   Next, a uniform 2D boxcar smoothing is applied to the image--background level regions in the resulting image are at least the boxcar size distance away from foreground objects.  The minimum pixel in that resulting image is a good approximation for the background region of the image.  A thick border is specified to avoid lower intensity regions at the border of the image.  This algorithm is implemented in the ipfunctions module as findBackground.  Once the background region is found, it can be measured with measureCirc.

## Segmentation and thresholding strategy

There are many automated thresholding algorithms available via python and, by extension, Napari.  This program uses a very simplistic but powerful method.  Most segmentable images consist of foreground and background components.  In imaging, the foreground is more noisy than the background.  Ideally a smoothed background subtracted image will have a maximum intensity that represents the foreground well and a background intensity of 0.  In that case, the threshold level can be easily defined as a fraction of that smoothed maximum intensity.  A threshold fraction of 0.25 tends to work well but lower values may be more robust if background is fairly smooth and the foreground is noisier.  In some cases the foreground has anomalous high values that will skew the estimation.  In that case it may be better to estimate the foreground as e.g. the 99th percentile of the intensity.  In some cases it may be useful to use the average intensity as a reference point instead or use the raw intensity value (statistic is Identity).  Those last options tend to be less robust and it may be desired in those cases to use some of the more complex autothresholding methods.  After thresholding, objects on the image edge are eliminated and objects are filtered according to size.  The minimum area can easy remove small debris that can contaminate a measurement.  The maximum area can be used for large contaminants or poorly segmented clusters of cells that might not be desired in the analysis.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/index.html
-->

## Installation

You can install `napari-IP-workflow` via [pip]:

    pip install napari-IP-workflow



To install latest development version :

    pip install git+https://github.com/jayunruh/napari-IP-workflow.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [GNU GPL v3.0] license,
""napari-IP-workflow"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/jayunruh/napari-IP-workflow/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Operating System :: OS Independent', 'License :: OSI Approved :: GNU General Public License v3 (GPLv3)']","['Bug Tracker, https://github.com/jayunruh/napari-IP-workflow/issues', 'Documentation, https://github.com/jayunruh/napari-IP-workflow#README.md', 'Source Code, https://github.com/jayunruh/napari-IP-workflow', 'User Support, https://github.com/jayunruh/napari-IP-workflow/issues']",,,napari-ip-workflow.segwidget,,,,,https://pypi.org/project/napari-IP-workflow,https://github.com/jayunruh/napari-IP-workflow,
174,Napari-ISM,1.0.7,2022-06-16,2023-09-07,napari-ISM,Alessandro Zunino,Alessandro Zunino <alessandro.zunino@iit.it>,,https://github.com/VicidominiLab/napari-ISM,A Napari plugin for analysing and simulating ISM images,>=3.7,"['numpy', 'scipy', 'h5py', 'PyQt5', 'brighteyes-ism >=1.2.2', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-ISM

[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-ISM)](https://napari-hub.org/plugins/napari-ISM)
[![License](https://img.shields.io/pypi/l/napari-ISM.svg?color=green)](https://github.com/VicidominiLab/napari-ISM/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-ISM.svg?color=green)](https://pypi.org/project/napari-ISM)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-ISM.svg?color=green)](https://python.org)


This plugin is built upon the python package [BrightEyes-ISM]. Napari-ISM enables the simulation, loading, and analysis of ISM datasets.
More in detail, it performs:

* Loading and compression of .h5 files generated by the [MCS software].
* Simulation of a realistic dataset of tubulin filaments.
* Simulation of realistic ISM Point Spread Functions.
* Summing over the detector array dimension
* Adaptive Pixel Reassignment
* Multi-image deconvolution
* Focus-ISM

----------------------------------

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/index.html
-->

## Installation

You can install `napari-ISM` via [PyPI]:

    pip install napari-ISM
    
or by using [napari hub].

It requires the following Python packages

    numpy
    scipy
    h5py
    PyQt5
    brighteyes-ism>=1.2.0

## Documentation

To generate a simulated dataset, go to `File > Open Sample > ISM dataset`. 

![](https://github.com/VicidominiLab/napari-ISM/raw/main/docs/sample.png)

To acces the plugin list, go to `Plugins > Napari-ISM`.

![](https://github.com/VicidominiLab/napari-ISM/raw/main/docs/plugin_list.png)

To open a .h5 file, go to `File > Open `.
You can then sum over the dimensions that are not needed, using the command `integrateDims`.
The default axes are 0 (repetition), 1 (axial position), and 4 (time).

![](https://github.com/VicidominiLab/napari-ISM/raw/main/docs/file.png)

Note that all the analysis commands expect an input with size `X x Y X Ch`.

To see the result of summing over the SPAD dimensions `Ch`, use the plugin command `Sum`. Then, press `Run`.

![](https://github.com/VicidominiLab/napari-ISM/raw/main/docs/sum.png)

To see the result of Adaptive Pixel Reassignment, use the plugin command `APR_stack`.
Select as reference image (`ref`) the central one. Select an upsampling factor (`usf`), 
which corresponds to the sub-pixel precision of the shift-vector estimation. Then, press `Run`.

![](https://github.com/VicidominiLab/napari-ISM/raw/main/docs/apr.png)

To generate the PSFs, use the plugin command `PSFs`. Select an image layer (`img layer`), 
it will be used to determine the number of pixels and the pixel size.
Then, select the detector pixel size (`pxsize`) and pixel pitch (`pxpitch`) in microns.
Select the magnification of the system (`M`). Select the excitation (`exWl`) and emission wavelength (`emWl`) in nanometers.
Then, press `Run`.

![](https://github.com/VicidominiLab/napari-ISM/raw/main/docs/PSF.png)

To see the result of multi-image deconvolution, use the plugin command `Deconvolution`.
Select an image layer (`img layer`) containing the ISM dataset to deconvolve and another image layer (`psf layer`) containing the PSFs, either simulated or experimental.
Then, press `Run`.

![](https://github.com/VicidominiLab/napari-ISM/raw/main/docs/deconv.png)

To use Focus-ISM, first select a region on the input dataset using a `shapes` layer.
Select a rectangle containing mainly in-focus emitters. It will be used as a calibration.
Then, use the plugin command `Focus-ISM`. Select an image layer (`img layer`) containing the ISM dataset and a shape layer (`shape layer`) defining the calibration region.
Select a lower bound for the standard deviation of the out-of-focus curve (`sigma B bound`) in units of standard deviations of the in-focus term. We suggest to never select a value below 2.
Select a threshold (`threshold`) in units of photon counts. Scan coordinates with less photons than the threshold will be skipped in the analysis and classified as background. Then, press `Run`.

![](https://github.com/VicidominiLab/napari-ISM/raw/main/docs/shapes.png)

To use FRC, prepare the dataset to be in the shape `xyt`.
Select the theshodling method (`method`) and smoothing method (`smoothing`) among those available.
Then, press `Calculate`.

![](https://github.com/VicidominiLab/napari-ISM/raw/main/docs/frc.png)

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [GNU LGPL v3.0] license,
""napari-ISM"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/VicidominiLab/napari-ISM/issues

[napari hub]: https://www.napari-hub.org/plugins/napari-ISM
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/project/napari-ISM/

[BrightEyes-ISM]: https://github.com/VicidominiLab/BrightEyes-ISM
[MCS software]: https://github.com/VicidominiLab/BrightEyes-MCS
","['Framework :: napari', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Operating System :: OS Independent', 'License :: OSI Approved :: GNU General Public License v3 or later (GPLv3+)']","['Homepage, https://github.com/VicidominiLab/napari-ism', 'Documentation, https://brighteyes-ism.readthedocs.io']",napari-ISM.get_reader,napari-ISM.write_multiple,napari-ISM.APR_stack,napari-ISM.make_sample_data,"['*.npy', '*.h5']",,"['.npy', '.h5']",https://pypi.org/project/napari-ISM,https://github.com/VicidominiLab/napari-ISM,
175,napari-itk-io,0.3.0,2022-04-01,2023-07-26,napari-itk-io,Matt McCormick,matt.mccormick@kitware.com,Apache-2.0,https://github.com/InsightSoftwareConsortium/napari-itk-io,File IO with itk for napari,>=3.8,"['numpy', 'napari-plugin-engine (>=0.2.0)', 'itk-io (>=5.2.0)', 'itk-napari-conversion']","# napari-itk-io

[![License](https://img.shields.io/pypi/l/napari-itk-io.svg?color=green)](https://github.com/InsightSoftwareConsortium/napari-itk-io/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-itk-io.svg?color=green)](https://pypi.org/project/napari-itk-io)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-itk-io.svg?color=green)](https://python.org)
[![tests](https://github.com/InsightSoftwareConsortium/napari-itk-io/workflows/tests/badge.svg)](https://github.com/InsightSoftwareConsortium/napari-itk-io/actions)
[![codecov](https://codecov.io/gh/InsightSoftwareConsortium/napari-itk-io/branch/master/graph/badge.svg)](https://codecov.io/gh/InsightSoftwareConsortium/napari-itk-io)

File IO with [itk](https://itk.org) for [napari](https://napari.org).

Image metadata, e.g. the pixel spacing, origin, and metadata tags, are preserved and passed into napari.

Supported image file formats:

- [BioRad](http://www.bio-rad.com/)
- [BMP](https://en.wikipedia.org/wiki/BMP_file_format)
- [DICOM](http://dicom.nema.org/)
- [DICOM Series](http://dicom.nema.org/)
- [ITK HDF5](https://support.hdfgroup.org/HDF5/)
- [JPEG](https://en.wikipedia.org/wiki/JPEG_File_Interchange_Format)
- [GE4,GE5,GEAdw](http://www3.gehealthcare.com)
- [Gipl (Guys Image Processing Lab)](https://www.ncbi.nlm.nih.gov/pubmed/12956259)
- [LSM](http://www.openwetware.org/wiki/Dissecting_LSM_files)
- [MetaImage](https://itk.org/Wiki/ITK/MetaIO/Documentation)
- [MINC 2.0](https://en.wikibooks.org/wiki/MINC/SoftwareDevelopment/MINC2.0_File_Format_Reference)
- [MGH](https://surfer.nmr.mgh.harvard.edu/fswiki/FsTutorial/MghFormat)
- [MRC](http://www.ccpem.ac.uk/mrc_format/mrc_format.php)
- [NifTi](https://nifti.nimh.nih.gov/nifti-1)
- [NRRD](http://teem.sourceforge.net/nrrd/format.html)
- [Portable Network Graphics (PNG)](https://en.wikipedia.org/wiki/Portable_Network_Graphics)
- [Tagged Image File Format (TIFF)](https://en.wikipedia.org/wiki/TIFF)
- [VTK legacy file format for images](http://www.vtk.org/VTK/img/file-formats.pdf)

For DICOM Series, select the folder containing the series with *File -> Open
Folder...*. The first series will be selected and sorted spatially.

## Installation

You can install `napari-itk-io` via [pip]:

    pip install napari-itk-io

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

Follow the [itk contributing
guidelines](https://github.com/InsightSoftwareConsortium/ITK/blob/master/CONTRIBUTING.md)
and the [itk code of
conduct](https://github.com/InsightSoftwareConsortium/ITK/blob/master/CODE_OF_CONDUCT.md).

## License

Distributed under the terms of the [Apache Software License 2.0] license,
""napari-itk-io"" is free and open source software.

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/InsightSoftwareConsortium/napari-itk-io/issues
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 4 - Beta', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Operating System :: OS Independent', 'License :: OSI Approved :: Apache Software License']",,napari-itk-io.get_reader,napari-itk-io.write_multiple,,,['*'],,['.nii'],https://pypi.org/project/napari-itk-io,https://github.com/InsightSoftwareConsortium/napari-itk-io,
176,napari-J,0.3,2022-02-11,2023-06-18,napari-J,Volker Baecker,volker.baecker@mri.cnrs.fr,MIT,https://github.com/MontpellierRessourcesImagerie/napari-J,A plugin to exchange data with FIJI and to use FIJI image analysis from napari,>=3.7,"['JPype1 (>=1.2.1)', 'matplotlib', 'imageio-ffmpeg', ""matplotlib ; extra == 'testing'"", ""imageio-ffmpeg ; extra == 'testing'"", ""python-matplotlib-qt5 ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'""]","# napari-J

[![License](https://img.shields.io/pypi/l/napari-J.svg?color=green)](https://github.com/MontpellierRessourcesImagerie/napari-J/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-J.svg?color=green)](https://pypi.org/project/napari-J)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-J.svg?color=green)](https://python.org)
[![tests](https://github.com/MontpellierRessourcesImagerie/napari-J/workflows/tests/badge.svg)](https://github.com/MontpellierRessourcesImagerie/napari-J/actions)
[![codecov](https://codecov.io/gh/MontpellierRessourcesImagerie/napari-J/branch/master/graph/badge.svg)](https://codecov.io/gh/MontpellierRessourcesImagerie/napari-J)

A plugin to exchange data with FIJI and to use FIJI image analysis from napari.
Current features are:

 * get the active image from FIJI
 * send a screenshot to FIJI
 * get a set of points from the FIJI results table
 * filter the points in napari
 * send the filtered points back to FIJI
 
Known problems:

* Crashes on linux  when the file-dialog is opened. Workaround: Set the option ``Use JFileChooser to open/save`` from the ``Edit>Options>Input/Output`` menu.
* 03.05.2022 - Currently you need to have the range of the quality values for point between 0 and 255, in the new version they can have any range, but we are waiting for the bug in napari 0.4.15 to be fixed to release this. 

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/docs/plugins/index.html
-->

## Installation

You can install `napari-J` via [pip]:

    pip install napari-J

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [MIT] license,
""napari-J"" is free and open source software

## Issues

If you encounter any problems, please [file an issue](https://github.com/MontpellierRessourcesImagerie/napari-J/issues) along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/MontpellierRessourcesImagerie/napari-J/issues
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 4 - Beta', 'Intended Audience :: Science/Research', 'Topic :: Scientific/Engineering', 'License :: OSI Approved :: MIT License', 'Operating System :: OS Independent', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Framework :: napari']","['Bug Tracker, https://github.com/MontpellierRessourcesImagerie/napari-J/issues', 'Documentation, https://github.com/MontpellierRessourcesImagerie/napari-J#README.md', 'Source Code, https://github.com/MontpellierRessourcesImagerie/napari-J', 'User Support, https://github.com/MontpellierRessourcesImagerie/napari-J/issues']",,,napari-J.Connection,,,,,https://pypi.org/project/napari-J,https://github.com/MontpellierRessourcesImagerie/napari-J,
177,napari-kics,0.0.3rc6,2022-07-06,2023-06-18,napari-kics,Alexandr Dibrov,dibrov@mpi-cbg.de,BSD-3-Clause,https://github.com/mpicbg-csbd/napari-kics,A plugin to estimate chromosome sizes from karyotype images.,>=3.7,"['napari-plugin-engine (>=0.1.4)', 'numpy', 'napari[all]', 'scikit-image', 'pandas', 'pulp', 'pyqtgraph']","# napari-kics

![napari-kics](https://github.com/mpicbg-csbd/napari-kics/raw/main/docs/banner.png?sanitize=true&raw=true)

[![standard-readme compliant](https://img.shields.io/badge/readme%20style-standard-brightgreen.svg)](https://github.com/RichardLitt/standard-readme)
[![License](https://img.shields.io/pypi/l/napari-kics.svg?color=green)](./LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-kics.svg?color=green)](https://pypi.org/project/napari-kics)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-kics.svg?color=green)](https://python.org)
[![Python package](https://github.com/mpicbg-csbd/napari-kics/actions/workflows/python-package.yml/badge.svg)](https://github.com/mpicbg-csbd/napari-kics/actions/workflows/python-package.yml)


> A plugin to estimate chromosome sizes from karyotype images.

<small>*This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.*</small>


## Table of Contents

- Install
- Usage
- Example
- Citation
- Maintainer
- Contributing
- License


## Install

You can install `napari-kics` via [pip]:

```sh
pip install napari-kics
```

This will install all required dependencies as well. We recommend installing it in a virtual environment, e.g. using [conda]:

```sh
conda create -n kics python
conda activate kics
pip install napari-kics
```

We recommend using [mamba] as a faster alternative to conda.


## Usage

1. Launch Napari via command line (`napari`).
2. Activate the plugin via menu `Plugins -> napari-kics: Karyotype Widget`.
3. Select file via `File -> Open File`.
4. Follow instructions in the panel on the right.

You may use the interactive analysis plots directly via command line:

```sh
karyotype-analysis-plots
```


## Example

1. Launch Napari via command line (`napari`).
2. Activate the plugin via menu `Plugins -> napari-kics: Karyotype Widget`.
3. Select file via `File -> Open Sample -> napari-kics: sample`.
4. Follow instructions in the panel on the right.

Try out the interactive analysis plots directly via command line:

```sh
karyotype-analysis-plots --example
```


## Citation

> Arne Ludwig, Alexandr Dibrov, Gene Myers, Martin Pippel.
> Estimating chromosome sizes from karyotype images enables validation of
> *de novo* assemblies. To be published.


## License

Distributed under the terms of the [BSD-3] license,
""napari-kics"" is free and open source software


## Issues

If you encounter any problems, please [file an issue] along with a detailed description.


## Contributing

Contributions are very welcome. Please [file a pull request] with your
contribution.

You can setup a local development environment for `napari-kics` via [pip]:

```sh
git clone https://github.com/mpicbg-csbd/napari-kics.git
cd napari-kics
pip install -e .
```


[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[@napari]: https://github.com/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[conda]: https://www.anaconda.com/products/distribution
[mamba]: https://github.com/mamba-org/mamba
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
[file an issue]: https://github.com/mpicbg-csbd/napari-kics/issues
[file a pull request]: https://github.com/mpicbg-csbd/napari-kics/pulls

## Overview
https://user-images.githubusercontent.com/17703905/139654249-685703b5-2196-4a73-a036-d40d578ebcdf.mp4




","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Scientific/Engineering :: Image Processing', 'Topic :: Scientific/Engineering :: Information Analysis', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']",,,,napari-kics.KaryotypeWidget,napari-kics.load_sample_data,,,,https://pypi.org/project/napari-kics,https://github.com/mpicbg-csbd/napari-kics,
178,napari label interpolator,0.1.1,2023-03-27,2023-06-18,napari-label-interpolator,Lorenzo Gaifas,brisvag@gmail.com,GPL-3.0-only,https://github.com/brisvag/napari-label-interpolator,A napari plugin to interpolate any number of nd-labels across a single dimension.,>=3.8,"['magicgui', 'edt', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-label-interpolator

[![License GNU GPL v3.0](https://img.shields.io/pypi/l/napari-label-interpolator.svg?color=green)](https://github.com/brisvag/napari-label-interpolator/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-label-interpolator.svg?color=green)](https://pypi.org/project/napari-label-interpolator)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-label-interpolator.svg?color=green)](https://python.org)
[![tests](https://github.com/brisvag/napari-label-interpolator/workflows/tests/badge.svg)](https://github.com/brisvag/napari-label-interpolator/actions)
[![codecov](https://codecov.io/gh/brisvag/napari-label-interpolator/branch/main/graph/badge.svg)](https://codecov.io/gh/brisvag/napari-label-interpolator)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-label-interpolator)](https://napari-hub.org/plugins/napari-label-interpolator)

A napari plugin to interpolate any number of nd-labels across a single dimension.

To use, simply label a few slices along the desired dimension, then use the widget to interpolate along the desired axis.

![](https://user-images.githubusercontent.com/23482191/189153632-40ef38b7-be89-40b3-b583-b17f3241c67b.png)

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-label-interpolator` via [pip]:

    pip install napari-label-interpolator



To install latest development version :

    pip install git+https://github.com/brisvag/napari-label-interpolator.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [GNU GPL v3.0] license,
""napari-label-interpolator"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/brisvag/napari-label-interpolator/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: GNU General Public License v3 (GPLv3)', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/brisvag/napari-label-interpolator/issues', 'Documentation, https://github.com/brisvag/napari-label-interpolator#README.md', 'Source Code, https://github.com/brisvag/napari-label-interpolator', 'User Support, https://github.com/brisvag/napari-label-interpolator/issues']",,,napari-label-interpolator.make_widget,,,,,https://pypi.org/project/napari-label-interpolator,https://github.com/brisvag/napari-label-interpolator,
179,napari-labelimg4classification,0.1.1,2022-02-02,2023-06-18,napari-labelimg4classification,Hiroki Kawai,h.kawai888@gmail.com,MIT,https://github.com/hiroalchem/napari-labelimg4classification,Image-Level labeling tool,>=3.7,"['napari-plugin-engine (>=0.1.4)', 'napari', 'numpy', 'napari-tools-menu', 'pandas']","# napari-labelimg4classification

[![License](https://img.shields.io/pypi/l/napari-labelimg4classification.svg?color=green)](https://github.com/hiroalchem/napari-labelimg4classification/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-labelimg4classification.svg?color=green)](https://pypi.org/project/napari-labelimg4classification)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-labelimg4classification.svg?color=green)](https://python.org)
[![tests](https://github.com/hiroalchem/napari-labelimg4classification/workflows/tests/badge.svg)](https://github.com/hiroalchem/napari-labelimg4classification/actions)
[![codecov](https://codecov.io/gh/hiroalchem/napari-labelimg4classification/branch/main/graph/badge.svg)](https://codecov.io/gh/hiroalchem/napari-labelimg4classification)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-labelimg4classification)](https://napari-hub.org/plugins/napari-labelimg4classification)

A simple image-level annotation tool supporting multi-channel images for napari.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

## Usage
Start the labeling tool from the menu `Utilities > label tool for classification`.   
First, click on the Choose directory button to open the folder selection window, and select the folder that contains the
 images you want to label and annotate.   
It will automatically list and display the images of tif, png, jpg, and bmp formats.
If you want to view the channels of a multi-channel image separately, check the split channels checkbox.
![](https://github.com/hiroalchem/napari-labelimg4classification/raw/main/docs/open.gif)

Initially, all channels will be opened in grayscale, but the pseudo-color and contrast adjustments you specified will be
 carried over when you open the next image.   
Thanks to napari, you can freely merge channels and turn them on and off.   
Label classes can be added, and can be removed by typing the same name as an already added class.
![](https://github.com/hiroalchem/napari-labelimg4classification/raw/main/docs/color_and_label.gif)


It will automatically save the labels.csv file with the image path and label, and the class.txt file with the class of the label.
![](https://github.com/hiroalchem/napari-labelimg4classification/raw/main/docs/class_and_labels.png)

If labels.csv and class.txt are already in the folder, they will be loaded and reflected automatically.
![](https://github.com/hiroalchem/napari-labelimg4classification/raw/main/docs/reopen.gif)

## Installation

You can install `napari-labelimg4classification` via [pip]:

    pip install napari-labelimg4classification



To install latest development version :

    pip install git+https://github.com/hiroalchem/napari-labelimg4classification.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [MIT] license,
""napari-labelimg4classification"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/hiroalchem/napari-labelimg4classification/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/


","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: MIT License']","['Bug Tracker, https://github.com/hiroalchem/napari-labelimg4classification/issues', 'Documentation, https://github.com/hiroalchem/napari-labelimg4classification#README.md', 'Source Code, https://github.com/hiroalchem/napari-labelimg4classification', 'User Support, https://github.com/hiroalchem/napari-labelimg4classification/issues']",,,napari-labelimg4classification.L4CWidget,,,,,https://pypi.org/project/napari-labelimg4classification,https://github.com/hiroalchem/napari-labelimg4classification,
180,napari Labeling,0.1.2,2022-07-07,2023-06-18,napari-labeling,Tom Burke,burke@mpi-cbg.de,BSD-3-Clause,https://github.com/Labelings/napari-labeling,A napari plugin for handling overlapping labeling data,>=3.7,"['numpy', 'labeling']","# napari-labeling

[![License](https://img.shields.io/pypi/l/napari-labeling.svg?color=green)](https://github.com/tomburke-rse/napari-labeling/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-labeling.svg?color=green)](https://pypi.org/project/napari-labeling)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-labeling.svg?color=green)](https://python.org)
[![tests](https://github.com/tomburke-rse/napari-labeling/workflows/tests/badge.svg)](https://github.com/tomburke-rse/napari-labeling/actions)
[![codecov](https://codecov.io/gh/tomburke-rse/napari-labeling/branch/main/graph/badge.svg)](https://codecov.io/gh/tomburke-rse/napari-labeling)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-labeling)](https://napari-hub.org/plugins/napari-labeling)

This is a napari-plugin based on the [labeling project].

It allows the generation of overlapping labels in one layer, save and load of this layer in a json-based file format and
it contains a widget to explore the overlapping labels layer and select specific segments with a mouse click .

Please note that currently, the widget part only works by adding it through code with:

    from napari_labeling import edit_widget
    viewer = napari.Viewer()
    viewer.window.add_dock_widget(edit_widget)

An example on how to achieve this can be found in the [main.py] on GitHub.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/stable/index.html
-->

## Installation

You can install `napari-labeling` via [pip]:

    pip install napari-labeling




## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-labeling"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/

[labeling project]: https://github.com/Labelings/Labeling
[main.py]: https://github.com/Labelings/Labeling/blob/main/main.py
[file an issue]: https://github.com/Labelings/napari-labeling/issues


","['Development Status :: 4 - Beta', 'Intended Audience :: Developers', 'Intended Audience :: Science/Research', 'Framework :: napari', 'Topic :: Scientific/Engineering :: Image Processing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']",,napari-labeling.napari_get_reader,napari-labeling.write_single_image,napari-labeling.make_magic_widget,,['*.lbl.json'],,,https://pypi.org/project/napari-labeling,https://github.com/Labelings/napari-labeling,
181,napari-labelling-assistant,0.0.5,2022-01-28,2023-06-18,napari-labelling-assistant,Pranjal Dhole,dhole.pranjal@gmail.com,MIT,https://github.com/pranjaldhole/napari-labelling-assistant,A lightweight plugin for visualizing labelling statistics.,>=3.7,"['napari-plugin-engine (>=0.1.4)', 'numpy', 'matplotlib']","# napari-labelling-assistant

[![License](https://img.shields.io/pypi/l/napari-labelling-assistant.svg?color=green)](https://github.com/pranjaldhole/napari-labelling-assistant/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-labelling-assistant.svg?color=green)](https://pypi.org/project/napari-labelling-assistant)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-labelling-assistant.svg?color=green)](https://python.org)
[![tests](https://github.com/pranjaldhole/napari-labelling-assistant/workflows/tests/badge.svg)](https://github.com/pranjaldhole/napari-labelling-assistant/actions)
[![codecov](https://codecov.io/gh/pranjaldhole/napari-labelling-assistant/branch/main/graph/badge.svg)](https://codecov.io/gh/pranjaldhole/napari-labelling-assistant)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-labelling-assistant)](https://napari-hub.org/plugins/napari-labelling-assistant)

A lightweight plugin for visualizing labelling statistics.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/stable/index.html
-->

## Installation

You can install `napari-labelling-assistant` via [pip]:

    pip install napari-labelling-assistant



To install latest development version :

    pip install git+https://github.com/pranjaldhole/napari-labelling-assistant.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [MIT] license,
""napari-labelling-assistant"" is free and open source software.

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/pranjaldhole/napari-labelling-assistant/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/


","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: MIT License']","['Bug Tracker, https://github.com/pranjaldhole/napari-labelling-assistant/issues', 'Documentation, https://github.com/pranjaldhole/napari-labelling-assistant#README.md', 'Source Code, https://github.com/pranjaldhole/napari-labelling-assistant', 'User Support, https://github.com/pranjaldhole/napari-labelling-assistant/issues']",,,napari-labelling-assistant.LabellingAssistant,,,,,https://pypi.org/project/napari-labelling-assistant,https://github.com/pranjaldhole/napari-labelling-assistant,
182,napari Label Propagation,1.0.0,2023-11-18,2023-11-18,napari-labelprop,nathandecaux,nathan.decaux@imt-atlantique.fr,BSD-3-Clause,https://pypi.org/project/napari-labelprop,Label propagation through deep registration,>=3.8,"['deep-labelprop', 'napari-nifti', 'numpy', 'magicgui', 'qtpy', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-labelprop

[![License](https://img.shields.io/pypi/l/napari-labelprop.svg?color=green)](https://github.com/nathandecaux/napari-labelprop/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-labelprop.svg?color=green)](https://pypi.org/project/napari-labelprop)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-labelprop.svg?color=green)](https://python.org)
[![tests](https://github.com/nathandecaux/napari-labelprop/workflows/tests/badge.svg)](https://github.com/nathandecaux/napari-labelprop/actions)
[![codecov](https://codecov.io/gh/nathandecaux/napari-labelprop/branch/main/graph/badge.svg)](https://codecov.io/gh/nathandecaux/napari-labelprop)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-labelprop)](https://napari-hub.org/plugins/napari-labelprop)



3D semi-automatic segmentation using deep registration-based 2D label propagation
---------------------------------------------------------------------------------
---

This [napari][napari] plugin was generated with [Cookiecutter][Cookiecutter] using [@napari][@napari]'s [cookiecutter-napari-plugin][cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/stable/index.html
-->

## About

See ""Semi-automatic muscle segmentation in MR images using deep registration-based label propagation"" paper : 

[[Paper]![Paper](https://www.integrad.nl/assets/uploads/2016/02/cta-elsevier_logo-no_bg.png)](https://www.sciencedirect.com/science/article/pii/S0031320323002297?casa_token=r5FPBVXYXX4AAAAA:mStyUXb0i4lGqBmfF1j5fV1T9FuCMrpYfwh3lwQve2XAnzUBPZviAiFgMtH7lv6hdcWsA7yM) [[PDF]![PDF](https://www.ouvrirlascience.fr/wp-content/uploads/2018/12/HAL-3.png)](https://hal.science/hal-03945559/document)
<p>
  <img src=""https://github.com/nathandecaux/labelprop.github.io/raw/main/demo_cut.gif"" width=""600"">
</p>

## Installation

To install this project :

    pip install napari['all']
    pip install git+https://github.com/nathandecaux/napari-labelprop.git

## Usage

Download [pretrained weights](https://raw.githubusercontent.com/nathandecaux/napari-labelprop/main/pretrained.ckpt).

Open napari from terminal and start using functions from 'napari-labelprop' plugin (Under Plugins scrolling menu).

Available functions are :

- Inference : Propagate labels from trained weights (Pytorch checkpoint required)
- Training : Start training from scratch or from the pretrained weights.

PS : ""Unsupervised pretraining"" is not yet implemented. See CLI option at [LabelProp](https://github.com/nathandecaux/labelprop) repository.

Every operation is done in the main thread. So, napari is not responsive during training or inference, but you can still follow the progress in the terminal.

##### Training

To train a model, reach the plugin in the menu bar :

    Plugins > napari-labelprop > Training

Fill the fields with the following information :

- `Image` : Select a loaded napari.layers.Image layer to segment
- `Labels` : Select a loaded napari.layers.Labels layer with the initial labels
- `hints` : Select a loaded napari.layers.Labels layer with scribbled pseudo labels
- `Pretrained checkpoint` : Select a pretrained checkpoint from the server-side checkpoint directory
- `Slices shape` : Slices are resample to this shape for training and inference, then resampled to original shape. So far, slices must be squares.  
- `Propagation axis` : Set the axis to use for the propagation dimension
- `Max epochs` : Set the maximum number of epochs to train the model
- `Checkpoint output directory`
- `Checkpoint name`
- `Weighting criteria` : Defines the criteria used to weight each direction of propagation `ncc = normalized cross correlation (slow but smooth), distance = distance to the nearest label (fast but less accurate)`
- `Reduction` : When using ncc, defines the reduction to apply to the ncc map `mean / local_mean / none`. Default is `none`
- `Use GPU` : Set if whether to use the GPU or not. Default is `True` (GPU). GPU:0 is used by default. To use another GPU, set the `CUDA_VISIBLE_DEVICES` environment variable before launching napari.

##### Inference

To run inference on a model, reach the plugin in the menu bar :

    Plugins > napari-labelprop-remote > Inference

Fill the fields like in the training section. Then, click on the `Run` button.

## Contributing

Contributions are very welcome. Tests can be run with [tox][tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3][BSD-3] license,
""napari-labelprop"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']",,,,napari-labelprop.inference_widget,napari-labelprop.make_sample_data,,,,https://pypi.org/project/napari-labelprop,,
183,napari labels overlap,0.0.3,2022-02-11,2023-06-18,napari-labels-overlap,Chi-Li Chiu,cchiu@chanzuckerberg.com,BSD-3-Clause,https://github.com/chili-chiu/napari-labels-overlap,create an overlap labels layer from two labels layers,>=3.7,['scikit-image'],"# napari-labels-overlap

[![License](https://img.shields.io/pypi/l/napari-labels-overlap.svg?color=green)](https://github.com/chili-chiu/napari-labels-overlap/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-labels-overlap.svg?color=green)](https://pypi.org/project/napari-labels-overlap)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-labels-overlap.svg?color=green)](https://python.org)
[![tests](https://github.com/chili-chiu/napari-labels-overlap/workflows/tests/badge.svg)](https://github.com/chili-chiu/napari-labels-overlap/actions)
[![codecov](https://codecov.io/gh/chili-chiu/napari-labels-overlap/branch/main/graph/badge.svg)](https://codecov.io/gh/chili-chiu/napari-labels-overlap)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-labels-overlap)](https://napari-hub.org/plugins/napari-labels-overlap)

create an overlap labels layer from two labels layers

## Description

This plugin takes two labels layers (layerA, layerB) as inputs, and generate the overlapped regions as a binary labels layer.
Three modes:<br>
(1) A_OR_B: new layer = layerA OR layerB (union)<br>
(2) A_AND_B: new layer = layerA AND layerB (intersection)<br>
(3) A_OUTSIDE_B: new layer = layerA OUTSIDE layerB (complement)<br>

[comment]: <need to update the gif>

![labels_overlap](https://user-images.githubusercontent.com/89602983/144129087-9a88d55f-f1a0-4825-bd01-770909bfc64f.gif)

## Applicaions
- Object colocalization
- Merge separately identified objects

## Future work
- Support N labels layers
- Basic coloc stats (% volume overlap)
- Output Labels with distinct IDs and links to original label IDs

## Release log
- 0.0.2<br>
-- Run on npe2<br>
-- Add output types: binary/connected component<br>
- 0.0.1<br>
-- Run on npe1<br>


----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/docs/plugins/index.html
-->

## Installation

You can install `napari-labels-overlap` via [pip]:

    pip install napari-labels-overlap



To install latest development version :

    pip install git+https://github.com/chili-chiu/napari-labels-overlap.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-labels-overlap"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/chili-chiu/napari-labels-overlap/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/chili-chiu/napari-labels-overlap/issues', 'Documentation, https://github.com/chili-chiu/napari-labels-overlap#README.md', 'Source Code, https://github.com/chili-chiu/napari-labels-overlap', 'User Support, https://github.com/chili-chiu/napari-labels-overlap/issues']",,,napari-labels-overlap.labels_overlap,,,,,https://pypi.org/project/napari-labels-overlap,https://github.com/chili-chiu/napari-labels-overlap,
184,NLII,0.0.2,2023-02-21,2023-06-18,napari-large-image-importer,Hiroki Kawai,h.kawai888@gmail.com,BSD-3-Clause,https://github.com/hiroalchem/napari-large-image-importer,"Napari plugin for easy, memory-efficient import of large images.",>=3.8,"['numpy', 'magicgui', 'qtpy', 'tifffile', 'zarr', 'dask', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-large-image-importer

[![License BSD-3](https://img.shields.io/pypi/l/napari-large-image-importer.svg?color=green)](https://github.com/hiroalchem/napari-large-image-importer/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-large-image-importer.svg?color=green)](https://pypi.org/project/napari-large-image-importer)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-large-image-importer.svg?color=green)](https://python.org)
[![tests](https://github.com/hiroalchem/napari-large-image-importer/workflows/tests/badge.svg)](https://github.com/hiroalchem/napari-large-image-importer/actions)
[![codecov](https://codecov.io/gh/hiroalchem/napari-large-image-importer/branch/main/graph/badge.svg)](https://codecov.io/gh/hiroalchem/napari-large-image-importer)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-large-image-importer)](https://napari-hub.org/plugins/napari-large-image-importer)

Napari plugin for easy, memory-efficient import of large images.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-large-image-importer` via [pip]:

    pip install napari-large-image-importer



To install latest development version :

    pip install git+https://github.com/hiroalchem/napari-large-image-importer.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-large-image-importer"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/hiroalchem/napari-large-image-importer/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/hiroalchem/napari-large-image-importer/issues', 'Documentation, https://github.com/hiroalchem/napari-large-image-importer#README.md', 'Source Code, https://github.com/hiroalchem/napari-large-image-importer', 'User Support, https://github.com/hiroalchem/napari-large-image-importer/issues']",,,napari-large-image-importer.make_qwidget,,,,,https://pypi.org/project/napari-large-image-importer,https://github.com/hiroalchem/napari-large-image-importer,
185,Lattice Lightsheet Analysis,0.2.7,,,napari-lattice,"Pradeep Rajasekhar, Lachlan Whitehead,Robert Haase",bioimageanalysis@wehi.edu.au,GPL-3.0-only,,Napari plugin for analysing and visualizing lattice lightsheet and Oblique Plane Microscopy data.,>=3.8,"['aicsimageio (>=4.9.1)', 'aicspylibczi (>=3.0.5)', 'dask', 'dask-image', 'dask[distributed]', 'magic-class (>=0.6.13)', 'magicgui', 'napari[all]', 'pyopencl', 'read-roi', 'gputools', 'pyclesperanto-prototype (>=0.20.0)', 'napari-aicsimageio (>=0.7.2)', 'napari-spreadsheet', 'napari-workflows (>=0.2.8)', 'napari-workflow-inspector', 'npy2bdv', 'redlionfish', 'tifffile', 'fsspec (>=2022.8.2)', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'""]","# napari-lattice

[![License](https://img.shields.io/pypi/l/napari-lattice.svg?color=green)](https://github.com/githubuser/napari_lattice/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-lattice.svg?color=green)](https://pypi.org/project/napari_lattice)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-lattice.svg?color=green)](https://python.org)
[![tests](https://github.com/BioimageAnalysisCoreWEHI/napari_lattice/actions/workflows/test_and_deploy.yml/badge.svg)](https://github.com/BioimageAnalysisCoreWEHI/napari_lattice/actions/workflows/test_and_deploy.yml)
[![PyPI - Downloads](https://img.shields.io/pypi/dm/napari-lattice)](https://pypistats.org/packages/napari-lattice)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-lattice)](https://napari-hub.org/plugins/napari-lattice)

This napari plugin allows deskewing, cropping, visualisation and designing custom analysis pipelines for lattice lightsheet data, particularly from the Zeiss Lattice Lightsheet. The plugin has also been otpimixed to run in headless mode.


## **Documentation**

Check the [Wiki page](https://github.com/BioimageAnalysisCoreWEHI/napari_lattice/wiki) for documentation on how to get started.


*************


<p align=""left"">
<img src=""https://raw.githubusercontent.com/BioimageAnalysisCoreWEHI/napari_lattice/master/resources/LLSZ_window.png"" alt=""LLSZ_overview"" width=""500"" >
</p>

**Functions**

* Deskewing and deconvolution of Zeiss lattice lightsheet images
  * Ability to preview deskewed image at channel or timepoint of interest
* Crop and process only a small portion of the image 
* Import ImageJ ROIs for cropping
* Create image processing workflows using napari-workflows
* Run deskewing, deconvolution and custom image processing workflows from the terminal
* Files can be saved as h5 (BigDataViewer/BigStitcher) or tiff files
* Run in terminal without napari, enabling processing workflows on the HPC

**Key Features**

Apply custom image processing workflows using `napari-workflows`. 
* [Interactive workflow generation (no coding experience needed)](https://github.com/BioimageAnalysisCoreWEHI/napari_lattice/wiki/5.-Workflows-(Interactive:-no-coding)#workflow)
* [Use custom python functions/modules within workflows](https://github.com/BioimageAnalysisCoreWEHI/napari_lattice/wiki/5.1-Workflows-(Custom-workflow))
* [How to use Cellpose for cell segmentation](https://github.com/BioimageAnalysisCoreWEHI/napari_lattice/wiki/5.1-Workflows-(Custom-workflow)#cellpose)


Support will be added for more file formats in the future.

Sample lattice lightsheet data download: https://doi.org/10.5281/zenodo.7117784

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/index.html
-->


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [GPL-3.0 License] license,
""napari_lattice"" is free and open source software

## Acknowledgment

 This project was supported by funding from the [Rogers Lab at the Centre for Dynamic Imaging at the Walter and Eliza Hall Institute of Medical Research](https://imaging.wehi.edu.au/). This project has been made possible in part by [Napari plugin accelerator grant](https://chanzuckerberg.com/science/programs-resources/imaging/napari/lattice-light-sheet-data-analysis-toolset/) from the Chan Zuckerberg Initiative DAF, an advised fund of the Silicon Valley Community Foundation.

 Thanks to the developers and maintainers of the amazing open-source plugins such as [pyclesperanto](https://github.com/clEsperanto/pyclesperanto_prototype), [aicsimageio](https://github.com/AllenCellModeling/aicsimageio), [dask](https://github.com/dask/dask) and [pycudadecon](https://github.com/tlambert03/pycudadecon).
 Thanks in particular to the developers of open source projects: [LLSpy](https://github.com/tlambert03/LLSpy) and [lls_dd](https://github.com/VolkerH/Lattice_Lightsheet_Deskew_Deconv) as they were referred to extensively for developing napari-lattice.
 Thanks to the imagesc forum!

## Issues

If you encounter any problems, please [file an issue](https://github.com/BioimageAnalysisCoreWEHI/napari_lattice/issues) along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GGPL-3.0 License]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Operating System :: OS Independent', 'License :: OSI Approved :: GNU General Public License v3 (GPLv3)']","['Bug Tracker, https://github.com/BioimageAnalysisCoreWEHI/napari_lattice/issues', 'Documentation, https://github.com/BioimageAnalysisCoreWEHI/napari_lattice/wiki', 'Source Code, https://github.com/BioimageAnalysisCoreWEHI/napari_lattice', 'User Support, https://github.com/BioimageAnalysisCoreWEHI/napari_lattice/issues']",napari-lattice.get_reader,,napari-lattice._dock_widget,,['*.h5'],,,https://pypi.org/project/napari-lattice,,
186,napari-layer-details-display,0.1.5,2022-02-04,2023-06-18,napari-layer-details-display,Robert Haase,robert.haase@tu-dresden.de,BSD-3-Clause,https://github.com/haesleinhuepf/napari-layer-details-display,A display for layer information and properties,>=3.7,"['napari-plugin-engine (>=0.1.4)', 'numpy', 'napari-tools-menu']","# napari-layer-details-display

[![License](https://img.shields.io/pypi/l/napari-layer-details-display.svg?color=green)](https://github.com/haesleinhuepf/napari-layer-details-display/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-layer-details-display.svg?color=green)](https://pypi.org/project/napari-layer-details-display)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-layer-details-display.svg?color=green)](https://python.org)
[![tests](https://github.com/haesleinhuepf/napari-layer-details-display/workflows/tests/badge.svg)](https://github.com/haesleinhuepf/napari-layer-details-display/actions)
[![codecov](https://codecov.io/gh/haesleinhuepf/napari-layer-details-display/branch/main/graph/badge.svg)](https://codecov.io/gh/haesleinhuepf/napari-layer-details-display)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-layer-details-display)](https://napari-hub.org/plugins/napari-layer-details-display)

A display for layer information and properties

![img.png](https://github.com/haesleinhuepf/napari-layer-details-display/raw/main/images/screenshot.png)

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

## Installation

You can install `napari-layer-details-display` via [pip]:

    pip install napari-layer-details-display



To install latest development version :

    pip install git+https://github.com/haesleinhuepf/napari-layer-details-display.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-layer-details-display"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/haesleinhuepf/napari-layer-details-display/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Scientific/Engineering :: Image Processing', 'Topic :: Scientific/Engineering :: Information Analysis', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/haesleinhuepf/napari-layer-details-display/issues', 'Documentation, https://github.com/haesleinhuepf/napari-layer-details-display#README.md', 'Source Code, https://github.com/haesleinhuepf/napari-layer-details-display', 'User Support, https://github.com/haesleinhuepf/napari-layer-details-display/issues']",,,napari-layer-details-display.LayerDetailsDisplay,,,,,https://pypi.org/project/napari-layer-details-display,https://github.com/haesleinhuepf/napari-layer-details-display,
187,Layer Table,0.0.12,2022-07-07,2023-06-18,napari-layer-table,Robert Cudmore,rhcudmore@ucdavis.edu,GPL-3.0-only,https://github.com/mapmanager/napari-layer-table,A plugin to display a layer as a table.,>=3.8,['numpy'],"# napari-layer-table

[![License: GPL v3](https://img.shields.io/badge/License-GPLv3-blue.svg)](https://www.gnu.org/licenses/gpl-3.0)
[![PyPI version](https://badge.fury.io/py/napari-layer-table.svg)](https://badge.fury.io/py/napari-layer-table)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-layer-table)](https://napari-hub.org/plugins/napari-layer-table)
[![Python](https://img.shields.io/badge/python-3.7|3.8|3.9|3.10-blue.svg)](https://www.python.org/downloads/release/python-3100/)
[![OS](https://img.shields.io/badge/OS-Linux|Windows|macOS-blue.svg)]()
[![tests](https://github.com/mapmanager/napari-layer-table/workflows/Tests/badge.svg)](https://github.com/mapmanager/napari-layer-table/actions)
[![codecov](https://codecov.io/gh/mapmanager/napari-layer-table/branch/main/graph/badge.svg?token=8S8EFI8NBC)](https://codecov.io/gh/mapmanager/napari-layer-table)
<!-- [![PyPI](https://img.shields.io/pypi/v/napari-layer-table.svg?color=green)](https://pypi.org/project/napari-layer-table) -->
<!-- [![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-layer-table)](https://napari-hub.org/plugins/napari-layer-table) -->

A plugin to display a layer as a table.

This will work well with point layers. We are debugging shapes and labeled layers, come back to check on that!

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/stable/index.html
-->

## Installation

You can install `napari-layer-table` via [pip]:

    pip install napari-layer-table



To install latest development version :

    pip install git+https://github.com/mapmanager/napari-layer-table.git

## Using the Plugin

You can use the napari-layer-table plugin to display points layer as a table.

- Open a napari viewer with a Points layer
- Add the plugin to the napari viewer from Plugins menu -> Add dock widget -> napari-layer-table: Points Table
- The selected layer is displayed in the table.
- The table has columns for:
    - Point symbol with face color
    - Point coordinates (x,y,z)
    - If the layer has properties, they are also shown as columns

![](plugin-2.gif)

## Plugin Features

- Bi-directional selection between layer and table.
- Bi-directional deletion between layer and table.
- Points added to the layer are added to the table.
- Points moved in the layer are updated in the table.
- Multiple points selected in the layer are also selected in the table
- Changes to face color and symbol in the layer are updated in the table.
- Ability to sort individual columns from low to high or high to low
- `Refresh` button to manually refresh the table data
- `btf` button to manually bring the layer whose table data is being shown to front

Right-click for context menu to:

- Toggle table columns on/off.
- Toggle shift+click to add a point to the layer (no need to switch viewer mode)
- Copy table to clipboard

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [GNU GPL v3.0] license,
""napari-layer-table"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/mapmanager/napari-layer-table/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Operating System :: OS Independent', 'License :: OSI Approved :: GNU General Public License v3 (GPLv3)']","['Bug Tracker, https://github.com/mapmanager/napari-layer-table/issues', 'Documentation, https://github.com/mapmanager/napari-layer-table#README.md', 'Source Code, https://github.com/mapmanager/napari-layer-table', 'User Support, https://github.com/mapmanager/napari-layer-table/issues']",,,napari-layer-table.make_my_qwidget,,,,,https://pypi.org/project/napari-layer-table,https://github.com/mapmanager/napari-layer-table,
188,napari-lazy-openslide,0.3.0,2022-02-17,2023-06-18,napari-lazy-openslide,Trevor Manz,trevor.j.manz@gmail.com,BSD-3,https://github.com/manzt/napari-lazy-openslide,A plugin to lazily load multiscale whole-slide images with openslide and dask,>=3.6,"['napari-plugin-engine (>=0.1.4)', 'zarr (>=2.11.0)', 'numpy', 'dask[array]', 'openslide-python']","# napari-lazy-openslide

[![License](https://img.shields.io/pypi/l/napari-lazy-openslide.svg?color=green)](https://github.com/manzt/napari-lazy-openslide/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-lazy-openslide.svg?color=green)](https://pypi.org/project/napari-lazy-openslide)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-lazy-openslide.svg?color=green)](https://python.org)
[![tests](https://github.com/manzt/napari-lazy-openslide/workflows/tests/badge.svg)](https://github.com/manzt/napari-lazy-openslide/actions)

An experimental plugin to lazily load multiscale whole-slide tiff images with openslide and dask.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.

## Installation

**Step 1.)** Make sure you have OpenSlide installed. Download instructions [here](https://openslide.org/download/).

> NOTE: Installation on macOS is easiest via Homebrew: `brew install openslide`. Up-to-date and multiplatform 
> binaries for `openslide` are also avaiable via `conda`: `conda install -c sdvillal openslide-python`

**Step 2.)** Install `napari-lazy-openslide` via `pip`:

    pip install napari-lazy-openslide

## Usage

### Napari plugin

```bash
$ napari tumor_004.tif
```
By installing this package via `pip`, the plugin should be recognized by `napari`. The plugin
attempts to read image formats recognized by `openslide` that are multiscale 
(`openslide.OpenSlide.level_count > 1`). 

It should be noted that `napari-lazy-openslide` is experimental and has primarily 
been tested with `CAMELYON16` and `CAMELYON17` datasets, which can be 
downloaded [here](https://camelyon17.grand-challenge.org/Data/).

![Interactive deep zoom of whole-slide image](tumor_004.gif)


### Using `OpenSlideStore` with Zarr and Dask

The `OpenSlideStore` class wraps an `openslide.OpenSlide` object as a valid Zarr store. 
The underlying `openslide` image pyramid is translated to the Zarr multiscales extension,
where each level of the pyramid is a separate 3D `zarr.Array` with shape `(y, x, 4)`.

```python
import dask.array as da
import zarr

from napari_lazy_openslide import OpenSlideStore

store = OpenSlideStore('tumor_004.tif')
grp = zarr.open(store, mode=""r"")

# The OpenSlideStore implements the multiscales extension
# https://forum.image.sc/t/multiscale-arrays-v0-1/37930
datasets = grp.attrs[""multiscales""][0][""datasets""]

pyramid = [grp.get(d[""path""]) for d in datasets]
print(pyramid)
# [
#   <zarr.core.Array '/0' (23705, 29879, 4) uint8 read-only>,
#   <zarr.core.Array '/1' (5926, 7469, 4) uint8 read-only>,
#   <zarr.core.Array '/2' (2963, 3734, 4) uint8 read-only>,
# ]

pyramid = [da.from_zarr(store, component=d[""path""]) for d in datasets]
print(pyramid)
# [
#   dask.array<from-zarr, shape=(23705, 29879, 4), dtype=uint8, chunksize=(512, 512, 4), chunktype=numpy.ndarray>,
#   dask.array<from-zarr, shape=(5926, 7469, 4), dtype=uint8, chunksize=(512, 512, 4), chunktype=numpy.ndarray>,
#   dask.array<from-zarr, shape=(2963, 3734, 4), dtype=uint8, chunksize=(512, 512, 4), chunktype=numpy.ndarray>,
# ]

# Now you can use numpy-like indexing with openslide, reading data into memory lazily!
low_res = pyramid[-1][:]
region = pyramid[0][y_start:y_end, x_start:x_end]
```

## Contributing

Contributions are very welcome. Tests can be run with `tox`, please ensure
the coverage at least stays the same before you submit a pull request.

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/manzt/napari-lazy-openslide/issues
[PyPI]: https://pypi.org/
","['Development Status :: 4 - Beta', 'Intended Audience :: Developers', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License', 'Framework :: napari']",,napari-lazy-openslide.napari_get_reader,,,,['*'],,,https://pypi.org/project/napari-lazy-openslide,https://github.com/manzt/napari-lazy-openslide,
189,napari LF,0.1.6,2023-11-18,2023-11-18,napari-LF,"Geneva Schlafly, Amitabh Verma, Rudolf Oldenbourg","gschlafly@uchicago.edu, averma@mbl.edu, rudolfo@mbl.edu",BSD-3-Clause,https://pypi.org/project/napari-LF,Light field imaging plugin for napari,>=3.7,"['numpy', 'h5py', 'pyopencl', 'napari[all]', 'opencv-python', 'torch', 'torchvision', 'pytorch-lightning']","# napari-LF

[![License](https://img.shields.io/pypi/l/napari-LF.svg?color=green)](https://github.com/PolarizedLightFieldMicroscopy/napari-LF/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-LF.svg?color=green)](https://pypi.org/project/napari-LF)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-LF.svg?color=green)](https://python.org)
[![tests](https://github.com/PolarizedLightFieldMicroscopy/napari-LF/workflows/tests/badge.svg)](https://github.com/PolarizedLightFieldMicroscopy/napari-LF/actions)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-LF)](https://napari-hub.org/plugins/napari-LF)
[![Downloads](https://static.pepy.tech/badge/napari-lf)](https://pepy.tech/project/napari-lf)
<!-- [![codecov](https://codecov.io/gh/PolarizedLightFieldMicroscopy/napari-LF/branch/main/graph/badge.svg)](https://codecov.io/gh/PolarizedLightFieldMicroscopy/napari-LF) -->

Light field imaging plugin for napari

----------------------------------

Deconvolves a 4D light field image into a full 3D focus stack reconstruction

https://user-images.githubusercontent.com/23206511/236919283-d53ca97a-9bdd-4598-b553-34996f688237.mp4

napari-LF contains an analytic and neural net analysis methods for light field images. To download example light field images, see our repository [napari-LF-docs-samples](https://github.com/PolarizedLightFieldMicroscopy/napari-LF-docs-samples).

### LF Analyze
**LF Analyze**, the analytic method, provides three basic processes to Calibrate, Rectify, and Deconvolve light field images:

The **Calibrate** process generates a calibration file that represents the optical setup that was used to record the light field images. The same calibration file can be used to rectify and deconvolve all light field images that were recorded with the same optical setup, usually the same microscope and light field camera. The Calibrate process requires as input the radiometry frame, dark frame, optical parameters, and volume parameters to generate the calibration file, which is subsequently used to rectify and deconvolve related light field images. The calibration file includes a point spread function (PSF) derived from the optical and volume parameters and is stored in HDF5 file format.

The **Rectify** process uses the calibration file for an affine transformation to scale and rotate experimental light field images that were recorded with a light field camera whose microlens array was (slightly) rotated with respect to the pixel array of the area detector and whose pixel pitch is not commensurate with the microlens pitch. After rectification, the rectified light field has the same integer number of pixels behind each microlens. When the Deconvolve process is called for an experimental light field image, rectifying the light field image is automatically applied before the iterative deconvolution does begin. However, the rectified light field image is not saved and is not available for viewing. Therefore, by pushing the Rectify button in the middle of the napari-LF widget, only the rectification step is invoked and the rectified light field image is saved to the project directory.

The **Deconvolve** process uses the PSF and a wave optics model to iteratively deconvolve a light field image into a stack of optical sections.

The **Parameter** panels, located in the lower half of the napari-LF widget, allows the user to specify settings for the reconstruction process. Once the appropriate parameters are selected, the Calibrate button followed by the Deconvolve button can be pushed to complete the reconstruction.

### Neural Net
**Neural Net** provides a method of applying a trained neural net model to deconvolve a light field image. Based on Pytorch Lightning and a provided [base class](https://github.com/PolarizedLightFieldMicroscopy/napari-LF/blob/main/src/napari_lf/lfa/neural_nets/LFNeuralNetworkProto.py), you can either create your own network, or use the pre-shipped networks (LFMNet, VCDNet, ...).

## Quickstart
1. Install the napari-LF plugin into your napari environment, as described below under **Installation**.
1. From the napari Plugins menu, select the napari-LF plugin to install its widget into the napari viewer.
### LF Analyze
1. Near the top of the widget, select your project folder containing the following images: light field, radiometry, and dark frame.
1. Calibration
    1. In the processing panel, navigate to **Calibrate, Required** (top tab **Calibrate**, bottom tab **Required**), which is the default selection.
    1. Select **radiometry** and **dark frame** images from pull down menus.
    1. Write the name of the **calibration file** you would like to produce, e.g. calibration.lfc.
    1. Enter the appropriate **optical parameters** according to your microscope and sample material.
    1. Enter the **volume parameters** you would like for your 3D reconstuction.
    1. Push the `Calibrate` button.
1. Deconvolution
    1. In the processing panel, navigate to **Deconvolve, Required**.
    1. Select **light field** image and **calibration file** from pull down menus.
    1. Write the name of the **output image stack** you would like to produce, e.g. output_stack.tif.
    1. Push the `Deconvolve` button.
The 3D focal stack reconstruction will display in the napari viewer and be saved in your original project folder.

### Neural Net
1. Click on the **LF Analyze** logo to toggle to the **Neural Net** mode.
1. Near the top of the widget, select your project folder containing the light field image and the trained neural net. If you do not already have a trained model, you can train a model using this [Jupyter notebook](https://github.com/PolarizedLightFieldMicroscopy/napari-LF/blob/main/src/napari_lf/lfa/main_train_neural_net.ipynb).
1. In the processing panel, select your **light field image** and **neural net model**.
1. Write the name of the **output image stack** you would like to produce, e.g. output_stack.tif.
1. Push the `Deconvolve` button.
The 3D focal stack reconstruction will display in the napari viewer and be saved in your original project folder.

## Getting Help
For details about each parameter, hover over each parameter textbox to read the tooltip description.
For additional information about the reconstruction process, see our [User Guide](docs/napari-LF_UserGuide_12May2023.pdf).

## Installation

After you have [napari] installed, you can one of the methods below to install `napari-LF`.

Method 1: You can install `napari-LF` via [pip]:

    pip install napari-LF

Method 2: Use the napari plugin menu.

1. Open napari from the command line:

        napari

1. From the napari menu, select **Plugins > Install/uninstall Packages**.

1. Either (a) scroll through the list of available plugins to find `napari-LF`, or (b) drag and drop a downloaded `napari-LF` directory into the bottom bar.

1. Select **Install** to install the light field plugin.

Method 3: Install the latest development version from the command line.

    pip install git+https://github.com/PolarizedLightFieldMicroscopy/napari-LF.git

Lastly, to access the installed plugin, open napari from the command line:

    napari

From the napari menu, select **Plugins > Main Menu (napari-LF)**. Note that you may need to close and reopen napari for the `napari-LF` to appear.

### Installation for developers

Create a virtual environment from the command line for napari with the python libraries necessary for the light field plugin:

    conda create --name napari-lf python==3.9
    conda activate napari-lf

Clone the github repository:

    conda install git
    git clone https://github.com/PolarizedLightFieldMicroscopy/napari-LF.git
    cd napari-LF
    pip install -e .

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-LF"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/PolarizedLightFieldMicroscopy/napari-LF/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Intended Audience :: Science/Research', 'Framework :: napari', 'Topic :: Scientific/Engineering :: Image Processing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/PolarizedLightFieldMicroscopy/napari-LF/issues', 'Documentation, https://github.com/PolarizedLightFieldMicroscopy/napari-LF#README.md', 'Source Code, https://github.com/PolarizedLightFieldMicroscopy/napari-LF', 'User Support, https://github.com/PolarizedLightFieldMicroscopy/napari-LF/issues']",napari-LF.get_reader,napari-LF.write_multiple,napari-LF.make_lfqwidget,napari-LF.make_sample_data,['*.npy'],,['.npy'],https://pypi.org/project/napari-LF,,
190,Napari Listener,0.1.0b1.post1,,,napari-listener,Ashley Anderson,aandersoniii@chanzuckerberg.com,MIT,,Control napari via local socket.,>=3.8,"['napari', 'qtpy', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-listener

[![License MIT](https://img.shields.io/pypi/l/napari-listener.svg?color=green)](https://github.com/aganders3/napari-listener/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-listener.svg?color=green)](https://pypi.org/project/napari-listener)
[![tests](https://github.com/aganders3/napari-listener/workflows/tests/badge.svg)](https://github.com/aganders3/napari-listener/actions)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-listener)](https://napari-hub.org/plugins/napari-listener)

Opens a socket to listen for commands to control napari from other processes.
This can be useful for controlling napari programmatically from other
applications, or for improving general OS integration (e.g. opening data from a
file or UrL in a running instance of napari).

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s
[cookiecutter-napari-plugin] template.

## Installation

You can install `napari-listener` via [pip]:

    pip install napari-listener

## Usage

Once installed, `napari-listener` can be started from the `napari > Plugins >
Start Listening` menu. You will see a new docked widget that displays the
address and port for the listener.

The listener is a TCP server that expects app-model command IDs. It will
execute any valid app-model command, but `napari-listener` registers its own
additional commands for demonstration purposes in
https://github.com/aganders3/napari-listener/blob/main/src/napari_listener/_actions.py.

You can test `napari-listener` using a TCP client such as
[netcat](https://linux.die.net/man/1/nc) or
[curl](https://curl.se/docs/manpage.html) to send an app-model command (and
optional args). For example:

```shell
% nc 127.0.0.1 40256 <<< ""napari:open-file /path/to/local/file""
```

<img src=""https://raw.githubusercontent.com/aganders3/napari-listener/main/napari-listener-demo.gif"" alt=""quick demo of napari-listener"">

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [MIT] license,
""napari-listener"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed
description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: MIT License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11']","['Bug Tracker, https://github.com/aganders3/napari-listener/issues', 'Documentation, https://github.com/aganders3/napari-listener#README.md', 'Source Code, https://github.com/aganders3/napari-listener', 'User Support, https://github.com/aganders3/napari-listener/issues']",,,napari-listener.start_listening,,,,,https://pypi.org/project/napari-listener,,
191,Napari Live Flim,0.1.1,,,napari-live-flim,Kevin Tan,kktangent@gmail.com,GPL-3.0-only,,A plugin for real-time FLIM analysis,>=3.8,"['dataclasses-json', 'flimlib', 'magicgui', 'matplotlib', 'numpy', 'qtpy', 'scipy', 'superqt', 'vispy', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-live-flim

[![License GNU GPL v3.0](https://img.shields.io/pypi/l/napari-live-flim.svg?color=green)](https://github.com/uw-loci/napari-live-flim/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-live-flim.svg?color=green)](https://pypi.org/project/napari-live-flim)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-live-flim.svg?color=green)](https://python.org)
[![tests](https://github.com/uw-loci/napari-live-flim/workflows/tests/badge.svg)](https://github.com/uw-loci/napari-live-flim/actions)
[![codecov](https://codecov.io/gh/uw-loci/napari-live-flim/branch/main/graph/badge.svg)](https://codecov.io/gh/uw-loci/napari-live-flim)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-live-flim)](https://napari-hub.org/plugins/napari-live-flim)

A plugin for real-time FLIM analysis

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/index.html
-->

## Required dependencies

- [OpenScan] TCSPC module and all dependencies.
    - Verify FLIM electronics are compatible with OpenScan
- Python and the [napari] package and all dependencies

You can install `napari` via [pip]:

    pip install napari[all]

## Installation

You can install `napari-live-flim` via [pip]:

    pip install napari-live-flim

## Usage

1. In MicroManager, set a port number in the device property setting named `OpenScanFLIM-BH-TCSPC-SendFLIMHistogramsToUDPPort`
2. In Napari, select **Plugins > FLIM Viewer (napari-live-flim)** to run the plugin. Enter the same port number to connect to OpenScan.
3. Begin acquisition within MicroManager.
4. Interact with the FLIM data in real-time within napari.
    - Modify the FLIM Parameters and Display Filters settings as desired.
    - Add selections to the Lifetime Image or Phasor Plot by clicking the relevant New Selection buttons.
    - Manipulate the selections with the mouse cursor and modify the selection layer with the layer controls.
    - Click the Snapshot button during acquisition to take a snapshot.
    - Use the scroll bar under the Lifetime Image to recall a specific snapshot.
5. Stop scanning within MicroManager to end acquisition.

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [GNU GPL v3.0] license,
""napari-live-flim"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/uw-loci/napari-live-flim/issues
[OpenScan]: https://github.com/openscan-lsm/OpenScan

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: GNU General Public License v3 (GPLv3)', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Software Development :: Testing']",,,,napari-live-flim.open,,,,,https://pypi.org/project/napari-live-flim,,
192,napari-live-recording,0.3.8,2022-02-02,2024-03-16,napari-live-recording,jacopo.abramo@gmail.com,jacopo.abramo@gmail.com,MIT,https://github.com/jethro33/napari-live-recording,A napari plugin for live video recording with a generic camera device.,>=3.9,"['superqt', 'numpy', 'opencv-python', 'tifffile', 'napari[all]', 'qtpy', 'microscope >=0.7.0', 'pims', 'pyqtgraph', 'pymmcore-plus >=0.6.7', 'pymmcore-widgets', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-live-recording

[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](https://github.com/jacopoabramo/napari-live-recording/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-live-recording.svg?color=green)](https://pypi.org/project/napari-live-recording)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-live-recording.svg?color=green)](https://python.org)
![tests](https://github.com/jacopoabramo/napari-live-recording/actions/workflows/test_and_deploy.yaml/badge.svg)
[![codecov](https://codecov.io/github/jacopoabramo/napari-live-recording/graph/badge.svg?token=WhI2MO452Z)](https://codecov.io/github/jacopoabramo/napari-live-recording) \
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-live-recording)](https://napari-hub.org/plugins/napari-live-recording)
[![Chan-Zuckerberg Initiative](https://custom-icon-badges.demolab.com/badge/Chan--Zuckerberg_Initiative-red?logo=czi)](https://chanzuckerberg.com/)

This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.

## Description

`napari-live-recording` (or `nlr`, if you like acronyms) is a <a href=""#why-medium-weight"">medium-weight</a> plugin part of the napari ecosystem that provides an easy 
access point for controlling area detector devices (most commonly reffered to as cameras) with a common interface.
Other than that, the plugin also allows to create computation pipelines that can be executed real-time in a flow starting directly from the camera stream.

> [!NOTE]
> 
> ### Why medium weight?
> `napari-live-recording` relies on multithreading to handle camera control,
> image processing and data storage via a common pipelined infrastructure.
> More details are provided in the documentation.

The plugin allows the following operations:

- snapping: capture a single image
- live view: continously acquiring from the currently active camera and show the collected data on the napari viewer;
- recording: stream data to disk from the currently active cameras

When recording, the plugin allows to store images according to the following formats:

- ImageJ TIFF
- OME-TIFF

> [!NOTE]
> Future releases will also add further file formats to the recording options, specifically:
> - HDF5
> - MP4
>
> We will also provide a method to add custom metadata to the recorded image files.

## Supported cameras

`napari-live-recording` aims to maintain itself agnostic for the type of cameras it controls. Via a common API (Application Programming Interface),
it possible to define a controller for a specific camera. Instructions
on how to do so are provided in the documentation.

By default, the plugin is shipped with the following interfaces:

- an [OpenCV](./src/napari_live_recording/control/devices/opencv.py) camera grabber;
- a [Micro-Manager](./src/napari_live_recording/control/devices/micro_manager.py) interface via the package [`pymmcore-plus`](https://pypi.org/project/pymmcore-plus/);
- an interface to the [microscope](./src/napari_live_recording/control/devices/pymicroscope.py) python package.

## Documentation

To install and use the plugin you can review the documentation [here](./docs/documentation.md).

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## Acknowledgments

The developers would like to thank the [Chan-Zuckerberg Initiative (CZI)](https://chanzuckerberg.com/) for providing funding
for this project via the [napari Ecosystem Grants](https://chanzuckerberg.com/science/programs-resources/imaging/napari/napari-live-recording-camera-control-through-napari/).

<p align=""center"">
  <img src=""https://images.squarespace-cdn.com/content/v1/63a48a2d279afe2a328b2823/5830fddc-a02b-451a-827b-3d4446dcf57b/Chan_Zuckerberg_Initiative.png"" width=""150"">
</p>

## License

Distributed under the terms of the [MIT] license,
""napari-live-recording"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/jacopoabramo/napari-live-recording/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 4 - Beta', 'Intended Audience :: Developers', 'Intended Audience :: Science/Research', 'Intended Audience :: Education', 'Framework :: napari', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Operating System :: OS Independent', 'License :: OSI Approved :: MIT License', 'Topic :: Scientific/Engineering :: Image Processing', 'Topic :: Scientific/Engineering :: Visualization']","['Bug Tracker, https://github.com/jacopoabramo/napari-live-recording/issues', 'Documentation, https://github.com/jacopoabramo/napari-live-recording#README.md', 'Source Code, https://github.com/jacopoabramo/napari-live-recording', 'User Support, https://github.com/jacopoabramo/napari-live-recording/issues']",,,napari-live-recording.open,,,,,https://pypi.org/project/napari-live-recording,https://github.com/jethro33/napari-live-recording,
193,napari-locan,0.5.0,2023-11-10,2023-12-08,napari-locan,napari-locan Developers,,BSD 3-Clause,https://pypi.org/project/napari-locan,Use locan methods in napari for single-molecule localization microscopy data.,>=3.9,"['locan >=0.18', 'matplotlib', 'napari', 'napari-matplotlib', 'numpy', 'qtpy', ""black ; extra == 'dev'"", ""build ; extra == 'dev'"", ""coverage[toml] ; extra == 'dev'"", ""mypy ; extra == 'dev'"", ""pre-commit ; extra == 'dev'"", ""ruff ; extra == 'dev'"", ""twine ; extra == 'dev'"", ""furo ; extra == 'docs'"", ""ipython ; extra == 'docs'"", ""myst-nb ; extra == 'docs'"", ""napari >=0.4.17 ; extra == 'docs'"", ""sphinx ; extra == 'docs'"", ""sphinx-autodoc-typehints ; extra == 'docs'"", ""sphinx-copybutton ; extra == 'docs'"", ""pytest ; extra == 'test'"", ""pytest-qt ; extra == 'test'""]","![logo](./docs/_static/logo.png) napari-locan
==================================================

[![License](https://img.shields.io/github/license/super-resolution/napari-locan)](https://github.com/super-resolution/napari-locan/blob/main/LICENSE.md)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-locan)](https://napari-hub.org/plugins/napari-locan)
[![PyPI](https://img.shields.io/pypi/v/napari-locan.svg?color=green)](https://pypi.org/project/napari-locan)
[![Conda (channel only)](https://img.shields.io/conda/vn/conda-forge/napari-locan)](https://anaconda.org/conda-forge/napari-locan)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-locan.svg?color=green)](https://python.org)
[![tests](https://github.com/super-resolution/napari-locan/workflows/tests/badge.svg)](https://github.com/super-resolution/napari-locan/actions)
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)
[![codecov](https://codecov.io/gh/super-resolution/napari-locan/branch/main/graph/badge.svg)](https://codecov.io/gh/super-resolution/napari-locan)
[![Documentation Status](https://readthedocs.org/projects/napari-locan/badge/?version=latest)](https://napari-locan.readthedocs.io/en/latest/?badge=latest)

Load, visualize and analyze single-molecule localization microscopy (SMLM) data.

napari-locan is a napari plugin that implements a subset of methods from [locan],
a python-based library with code for analyzing SMLM data.
Locan provides extended functionality that is better suited for script- or
notebook-based analysis procedures.
napari-locan is well suited for exploratory data analysis within napari.

For details on usage and development of napari-locan please read the [documentation].

## Installation

Make sure to have Qt bindings installed in your python environment of choice.

You can install napari-locan from PyPI:

    pip install napari-locan

or from conda-forge:

    mamba install -c conda-forge napari-locan

Please read the [documentation on installation] for more details.

## Usage

![](https://github.com/super-resolution/napari-locan/raw/main/docs/resources/screenshot_0.png?raw=true)

Please read the [documentation] for details.

## Contributing

Contributions are very welcome.
Please read the [documentation on development] for details.

## Credit

The plugin was developed in the Department of Biotechnology and Biophysics,
Würzburg University, Germany.
It is based on locan. So credit goes to the [locan developers]
and can be [cited](https://github.com/super-resolution/napari-locan/blob/main/CITATION.cff).

## License

Distributed under the terms of the
[BSD-3](http://opensource.org/licenses/BSD-3-Clause)
license, ""napari-locan"" is free and open source software.
See the [LICENSE](https://github.com/super-resolution/napari-locan/blob/main/LICENSE.md) file for details.

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[locan]: https://github.com/super-resolution/locan
[locan developers]: https://github.com/super-resolution/locan

[documentation]: https://napari-locan.readthedocs.io
[documentation on installation]: https://napari-locan.readthedocs.io/en/latest/source/installation.html
[documentation on development]: https://napari-locan.readthedocs.io/en/latest/source/development.html
[file an issue]: https://github.com/super-resolution/napari-locan/issues
","['Development Status :: 3 - Alpha', 'Environment :: X11 Applications :: Qt', 'Framework :: napari', 'Intended Audience :: Education', 'Intended Audience :: Science/Research', 'License :: OSI Approved :: BSD License', 'Operating System :: MacOS', 'Operating System :: Microsoft :: Windows', 'Operating System :: POSIX', 'Operating System :: Unix', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Topic :: Scientific/Engineering', 'Topic :: Scientific/Engineering :: Bio-Informatics', 'Topic :: Scientific/Engineering :: Image Processing', 'Topic :: Scientific/Engineering :: Information Analysis', 'Topic :: Scientific/Engineering :: Visualization']","['homepage, https://github.com/super-resolution/napari-locan', 'documentation, https://napari-locan.readthedocs.io/', 'issues, https://github.com/super-resolution/napari-locan/issues', 'discussions, https://github.com/super-resolution/napari-locan/discussions', 'changelog, https://github.com/super-resolution/napari-locan/CHANGES.rst', 'Source Code, https://github.com/super-resolution/napari-locan', 'Bug Tracker, https://github.com/super-resolution/napari-locan/issues', 'User Support, https://github.com/super-resolution/napari-locan/discussions']",,,napari-locan.smlm_data_qwidget,napari-locan.make_image_npc,,,,https://pypi.org/project/napari-locan,,
194,napari-locpix,0.0.6,2023-03-30,2023-06-18,napari-locpix,Oliver Umney,scou@leeds.ac.uk,MIT,https://github.com/oubino/napari-locpix,Load in SMLM data and annotate within napari,>=3.8,"['numpy', 'qtpy', 'polars', 'pyarrow', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-locpix

[![License MIT](https://img.shields.io/pypi/l/napari-locpix.svg?color=green)](https://github.com/oubino/napari-locpix/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-locpix.svg?color=green)](https://pypi.org/project/napari-locpix)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-locpix.svg?color=green)](https://python.org)
[![tests](https://github.com/oubino/napari-locpix/workflows/tests/badge.svg)](https://github.com/oubino/napari-locpix/actions)
[![codecov](https://codecov.io/gh/oubino/napari-locpix/branch/main/graph/badge.svg)](https://codecov.io/gh/oubino/napari-locpix)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-locpix)](https://napari-hub.org/plugins/napari-locpix)

Load in SMLM data and annotate within napari

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-locpix` via [pip]:

    pip install napari-locpix


To install latest development version :

    pip install git+https://github.com/oubino/napari-locpix.git


## Usage

This plugin allows a user to

1. Read in SMLM data
2. Visualise SMLM data in a histogram
3. Add segmentations to the data
4. Extract the underlying localisations from the segmentations

### IO

The input data can be in the form of a .csv or .parquet.

We expect there to be 4 columns at least, which should he identified inthe file column selection:

* X coordinate
* Y coordinate
* Frame
* Channel

If the data has been annotated with this software we can also load this in.
Note however we currently only support loading in annotated data saved as a .parquet folder.
Therefore, we recommend always keeping a .parquet copy until loading in an annotated .csv
is supported.

The data can be outputted to a .parquet or a .csv

Drop localisations with zero label, gives you the option to only save the localisations which have been annotated i.e. labels 1 and above.

Channels labels allows you to give a real name label to each of the channels e.g. Chan 0 label: 'Alexa 647'

### Visualisation

Using the render button you can render the loaded in data according to the histogram settings

X/Y bins defines the number of bins for the histogram

Vis interpolation defines how to interpolate the image before viewing

### Annotations

Annotations can be added using Napari's viewer.

Simply click the add Labels.

Note that this software will expect the labels to be called ""Labels""

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [MIT] license,
""napari-locpix"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/oubino/napari-locpix/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: MIT License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/oubino/napari-locpix/issues', 'Documentation, https://github.com/oubino/napari-locpix#README.md', 'Source Code, https://github.com/oubino/napari-locpix', 'User Support, https://github.com/oubino/napari-locpix/issues']",,,napari-locpix.widget,napari-locpix.make_sample_data,,,,https://pypi.org/project/napari-locpix,https://github.com/oubino/napari-locpix,
195,napari macro-kit,0.0.1,2023-03-30,2023-06-18,napari-macrokit,Hanjin Liu,liuhanjin-sc@g.ecc.u-tokyo.ac.jp,BSD-3-Clause,https://github.com/hanjinliu/napari-macrokit,Executable script generation for napari plugins,>=3.8,"['numpy', 'magicgui', 'qtpy', 'macro-kit (>=0.4.0)', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-macrokit

[![License BSD-3](https://img.shields.io/pypi/l/napari-macrokit.svg?color=green)](https://github.com/hanjinliu/napari-macrokit/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-macrokit.svg?color=green)](https://pypi.org/project/napari-macrokit)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-macrokit.svg?color=green)](https://python.org)
[![tests](https://github.com/hanjinliu/napari-macrokit/workflows/tests/badge.svg)](https://github.com/hanjinliu/napari-macrokit/actions)
[![codecov](https://codecov.io/gh/hanjinliu/napari-macrokit/branch/main/graph/badge.svg)](https://codecov.io/gh/hanjinliu/napari-macrokit)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-macrokit)](https://napari-hub.org/plugins/napari-macrokit)

Executable script generation for napari plugins.

![](https://github.com/hanjinliu/napari-macrokit/blob/main/images/example.gif)
&uarr; [Example](https://github.com/hanjinliu/napari-macrokit/blob/main/examples/regionprops.py) showing the real-time recording of GUI operation.

This napari plugin aims at making image analysis reproducible with arbitrary input/output types.

## Usage

Create a macro object, decorate functions with `record` method and run!

```python
from napari_macrokit import get_macro

macro = get_macro(""my-plugin-specifier"")  # get macro object

# define a function
@macro.record
def add(a: float, b: float) -> float:
    return a + b

# run
result = add(3.2, 5.4)
add(result, 1.0)

macro

# Out:
# >>> float0 = add(3.2, 5.4)
# >>> float1 = add(float0, 1.0)
```

## Record GUI Operations

You can use recordable functions in your widgets to keep tracks of GUI operations.
More simply, you can double-decorate functions with `record` and `magicgui`.

```python
import numpy as np
from magicgui import magicgui
import napari
from napari.types import ImageData
from napari_macrokit import get_macro

macro = get_macro(""my-plugin-specifier"")  # get macro object

# define recordable magicgui
@magicgui
@macro.record
def add(image: ImageData, b: float) -> ImageData:
    return image + b

viewer = napari.Viewer()  # launch a viewer
viewer.add_image(np.random.random((100, 100)))  # image data
viewer.window.add_dock_widget(add)  # add magicgui to the viewer
```

Running add twice in GUI and you'll find macro updated like below.

```python
macro
# Out
# >>> image0 = add(viewer.layers['Image'].data, 0.06)
# >>> image1 = add(image0, 0.12)
```

## Combining Plugins

Suppose you have two modules that use `napari-macrokit`.

```python
# napari_module_0.py

from napari.types import ImageData
from scipy import ndimage as ndi
from napari_macrokit import get_macro

macro = get_macro(""napari-module-0"")

@macro.record
def gaussian_filter(image: ImageData, sigma: float) -> ImageData:
    return ndi.gaussian_filter(image, sigma=sigma)

@macro.record
def threshold(image: ImageData, value: float) -> ImageData:
    return image > value
```

```python
# napari_module_1.py

from napari.types import ImageData
import numpy as np
from napari_macrokit import get_macro
macro = get_macro(""napari-module-1"")

@macro.record
def estimate_background(image: ImageData) -> float:
    return np.percentile(image, 10.0)

```

You can use functions from both modules to build an analysis workflow by collecting existing macro objects with `collect_macro` function. All the recordable actions in the modules will also be recorded to the returned macro object.

```python
import numpy as np
from napari_macrokit import collect_macro
from napari_module_0 import gaussian_filter, threshold
from napari_module_1 import estimate_background

# global_macro will record all the macro available at this point
global_macro = collect_macro()

# start image analysis!
image = np.random.random((100, 100))

out = gaussian_filter(image, 2.0)
thresh = estimate_background(out)
binary = threshold(out, thresh)

macro
# Out
# >>> image0 = gaussian_filter(arr0, 2.0)
# >>> float0 = estimate_background(image0)
# >>> image1 = threshold(image1, float0)
```

---------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

## Installation

You can install `napari-macrokit` via [pip]:

    pip install napari-macrokit



To install latest development version :

    pip install git+https://github.com/hanjinliu/napari-macrokit.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-macrokit"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/hanjinliu/napari-macrokit/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/hanjinliu/napari-macrokit/issues', 'Documentation, https://github.com/hanjinliu/napari-macrokit#README.md', 'Source Code, https://github.com/hanjinliu/napari-macrokit', 'User Support, https://github.com/hanjinliu/napari-macrokit/issues']",,,napari-macrokit.make_qwidget,,,,,https://pypi.org/project/napari-macrokit,https://github.com/hanjinliu/napari-macrokit,
196,Manual Transforms,0.0.3,2022-07-11,2023-06-18,napari-manual-transforms,Talley Lambert,talley.lambert@gmail.com,BSD-3-Clause,https://github.com/tlambert03/napari-manual-transforms,Interface to manually edit layer affine transforms,>=3.8,"['magicgui', 'napari', 'numpy', 'pytransform3d', 'qtpy', 'scipy', 'vispy', ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""tox ; extra == 'testing'""]","# napari-manual-transforms

[![License](https://img.shields.io/pypi/l/napari-manual-transforms.svg?color=green)](https://github.com/tlambert03/napari-manual-transforms/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-manual-transforms.svg?color=green)](https://pypi.org/project/napari-manual-transforms)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-manual-transforms.svg?color=green)](https://python.org)
[![tests](https://github.com/tlambert03/napari-manual-transforms/workflows/tests/badge.svg)](https://github.com/tlambert03/napari-manual-transforms/actions)
[![codecov](https://codecov.io/gh/tlambert03/napari-manual-transforms/branch/main/graph/badge.svg)](https://codecov.io/gh/tlambert03/napari-manual-transforms)

Interface to manually edit layer affine transforms.

- express rotations as quaternion, euler angle, or axis + angle.
- allows rotation around arbitrary origin
- currently, focusing on rigid rotations
- Alt-Drag to rotate a layer independently of the rest.
- image resampling (i.e. ""apply"" the transformation to create new dataset that can be saved)

![Plugin Preview](/preview.jpeg)

caveats:

- only works on 3D Image layers for now, open a feature request for other dims/layers.
- will likely result in ""Non-orthogonal slicing is being requested"" warnings in 2D view.

## Try it out

```python

import napari

v = napari.Viewer()
v.dims.ndisplay = 3
v.open_sample('napari', 'cells3d')
v.window.add_plugin_dock_widget('napari-manual-transforms')

napari.run()

```

----------------------------------

## Installation

You can install `napari-manual-transforms` via [pip]:

```sh
pip install napari-manual-transforms
```

To install latest development version :

```sh
pip install git+https://github.com/tlambert03/napari-manual-transforms.git
```

## License

Distributed under the terms of the [BSD-3] license,
""napari-manual-transforms"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/tlambert03/napari-manual-transforms/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/


","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Software Development :: Testing']","['Bug Tracker, https://github.com/tlambert03/napari-manual-transforms/issues', 'Documentation, https://github.com/tlambert03/napari-manual-transforms#README.md', 'Source Code, https://github.com/tlambert03/napari-manual-transforms', 'User Support, https://github.com/tlambert03/napari-manual-transforms/issues']",,,napari-manual-transforms.make_rotation_helper,,,,,https://pypi.org/project/napari-manual-transforms,https://github.com/tlambert03/napari-manual-transforms,
197,napari mat file reader,0.0.2,2023-04-11,2023-06-18,napari-mat-file-reader,Ruben Lopez,rjlopez2@gmail.com,BSD-3-Clause,https://github.com/rjlopez2/napari-mat-file-reader,This is a simple wraper to read .mat files from Matlab,>=3.8,"['numpy', 'mat73', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'""]","# napari-mat-file-reader

[![License BSD-3](https://img.shields.io/pypi/l/napari-mat-file-reader.svg?color=green)](https://github.com/rjlopez2/napari-mat-file-reader/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-mat-file-reader.svg?color=green)](https://pypi.org/project/napari-mat-file-reader)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-mat-file-reader.svg?color=green)](https://python.org)
[![tests](https://github.com/rjlopez2/napari-mat-file-reader/workflows/tests/badge.svg)](https://github.com/rjlopez2/napari-mat-file-reader/actions)
[![codecov](https://codecov.io/gh/rjlopez2/napari-mat-file-reader/branch/main/graph/badge.svg)](https://codecov.io/gh/rjlopez2/napari-mat-file-reader)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-mat-file-reader)](https://napari-hub.org/plugins/napari-mat-file-reader)

This is a simple wraper to read .mat files from Matlab

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-mat-file-reader` via [pip]:

    pip install napari-mat-file-reader



To install latest development version :

    pip install git+https://github.com/rjlopez2/napari-mat-file-reader.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-mat-file-reader"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/rjlopez2/napari-mat-file-reader/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/rjlopez2/napari-mat-file-reader/issues', 'Documentation, https://github.com/rjlopez2/napari-mat-file-reader#README.md', 'Source Code, https://github.com/rjlopez2/napari-mat-file-reader', 'User Support, https://github.com/rjlopez2/napari-mat-file-reader/issues']",napari-mat-file-reader.get_reader,,,napari-mat-file-reader.make_sample_data,['*.mat'],,,https://pypi.org/project/napari-mat-file-reader,https://github.com/rjlopez2/napari-mat-file-reader,
198,napari-mat-images,0.1.3,2022-02-04,2023-06-18,napari-mat-images,Hector Munoz,hectormz.git@gmail.com,BSD-3,https://github.com/hectormz/napari-mat-images,A plugin to load images stored in MATLAB .mat files with napari,>=3.6,"['dask[delayed]', 'h5py', 'numpy', 'pluggy', 'scipy']","# napari-mat-images

[![PyPI version](https://img.shields.io/pypi/v/napari-mat-images.svg)](https://pypi.org/project/napari-mat-images)

[![Python versions](https://img.shields.io/pypi/pyversions/napari-mat-images.svg)](https://pypi.org/project/napari-mat-images)

[![See Build Status on Azure Pipelines](https://dev.azure.com/hectormz-1/napari-mat-images/_apis/build/status/hectormz.napari-mat-images?branchName=main)](https://dev.azure.com/hectormz-1/napari-mat-images/_build/latest?definitionId=1&branchName=main)

## Features

This plugin loads image variables stored in `MATLAB` `.mat` files into [napari](https://github.com/napari/napari).

It loads any variable that looks like an image.
Presently, that includes any array with more than two dimensions with size greater than 20 pixels (determined by `shape_is_image()`).

If loading a variable with 3 or more dimensions, the plugin assumes that it is a stack of images, and the dimension with greatest size is the axis of the stack.

### Loading Large Files

If loading a large `.mat` file saved in `HDF5`/`v7.3` format, chunks of the images are loaded as needed, resulting in fast initial load, but potentially slower scrolling.

Slices of the image stacks are randomly sampled to determine min/max contrast values.

## Requirements

This plugin relies on `scipy` to load small `.mat` files and `h5py` (with `dask`) to load larger `HDF5`/`v7.3` `.mat` files.

It implicitly requires `napari` for use.

## Installation

`napari-mat-images` requires [napari](https://github.com/napari/napari) to be installed, although it is not listed as a requirement for installation.
This plugin relies on plugin functionality found in `napari` version \> `0.2.12`. This can be installed via [pip](https://pypi.org/project/pip/) from [PyPI](https://pypi.org/project):

    $ pip install napari>0.2.12

You can install `napari-mat-images` via [pip](https://pypi.org/project/pip/) from [PyPI](https://pypi.org/project):

    $ pip install napari-mat-images

## Usage

Once installed, the plugin will be used whenever trying to load a `.mat` file.
This can be done from the `napari` GUI or commandline:

    $ napari my_file.mat

## Contributing

Contributions are very welcome.
Tests can be run with [pytest](https://docs.pytest.org/en/latest/),
please ensure the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3](http://opensource.org/licenses/BSD-3-Clause) license, `napari-mat-images` is free and open source software

## Issues

If you encounter any problems, please [file an issue](https://github.com/hectormz/napari-mat-images/issues) along with a detailed description.

---

This [napari](https://github.com/napari/napari) plugin was generated with [Cookiecutter](https://github.com/audreyr/cookiecutter) along with [napari](https://github.com/napari/napari)\'s [cookiecutter-napari-plugin](https://github.com/napari/cookiecutter-napari-plugin) template.


","['Development Status :: 4 - Beta', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.6', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: Implementation :: CPython', 'Programming Language :: Python :: Implementation :: PyPy', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']",,,,,,,,,https://pypi.org/project/napari-mat-images,https://github.com/hectormz/napari-mat-images,
199,napari math,0.0.1b0,2022-01-28,2023-06-18,napari-math,"Zach Marin, Talley Lambert",zach.marin@yale.edu,MIT,https://github.com/zacsimile/napari-math,"Simple mathematical operations on image, point and surface layers.",>=3.7,['numpy'],"# napari-math

[![License](https://img.shields.io/pypi/l/napari-math.svg?color=green)](https://github.com/zacsimile/napari-math/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-math.svg?color=green)](https://pypi.org/project/napari-math)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-math.svg?color=green)](https://python.org)
[![tests](https://github.com/zacsimile/napari-math/workflows/tests/badge.svg)](https://github.com/zacsimile/napari-math/actions)
[![codecov](https://codecov.io/gh/zacsimile/napari-math/branch/main/graph/badge.svg)](https://codecov.io/gh/zacsimile/napari-math)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-math)](https://napari-hub.org/plugins/napari-math)

This package provides a GUI interfrace for simple mathematical operations on image, point and surface layers.

- addition
- subtraction
- multiplication
- division
- logical and, or, xor
- z-projection (mean and sum)

Operations can be peformed on a single layer or between Image layers (functionaly pending for Surface and Point layers), 
for example adding one layer to another.

When performing operations on two images of different sizes, the result will be the size of the smallest
of the two images.

----------------------------------

<!--
This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.
-->

## Installation

You can install `napari-math` via [pip]:

    pip install napari-math




## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [MIT] license,
""napari-math"" is free and open source software

## Issues

If you encounter any problems, please file an [issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/


","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Operating System :: OS Independent', 'License :: OSI Approved :: MIT License']","['Bug Tracker, https://github.com/zacsimile/napari-math/issues', 'Documentation, https://github.com/zacsimile/napari-math#README.md', 'Source Code, https://github.com/zacsimile/napari-math', 'User Support, https://github.com/zacsimile/napari-math/issues']",,,napari-math.math_widget,,,,,https://pypi.org/project/napari-math,https://github.com/zacsimile/napari-math,
200,napari Matplotlib,2.0.1,2022-06-08,2024-01-24,napari-matplotlib,David Stansby,d.stansby@ucl.ac.uk,BSD-3-Clause,https://github.com/matplotlib/napari-matplotlib,A plugin to use Matplotlib with napari,>=3.9,"['matplotlib', 'napari', 'numpy', 'tinycss2', ""napari[all] ==0.4.19rc3 ; extra == 'docs'"", ""numpydoc ; extra == 'docs'"", ""pydantic <2 ; extra == 'docs'"", ""pydata-sphinx-theme ; extra == 'docs'"", ""qtgallery ; extra == 'docs'"", ""sphinx ; extra == 'docs'"", ""sphinx-automodapi ; extra == 'docs'"", ""sphinx-gallery ; extra == 'docs'"", ""napari[pyqt6_experimental] >=0.4.18 ; extra == 'testing'"", ""pooch ; extra == 'testing'"", ""pyqt6 ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-mock ; extra == 'testing'"", ""pytest-mpl ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""tox ; extra == 'testing'"", 'pytest-xvfb ; (sys_platform == ""linux"") and extra == \'testing\'']","# napari-matplotlib

[![License](https://img.shields.io/pypi/l/napari-matplotlib.svg?color=green)](https://github.com/matplotlib/napari-matplotlib/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-matplotlib.svg?color=green)](https://pypi.org/project/napari-matplotlib)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-matplotlib.svg?color=green)](https://python.org)
[![tests](https://github.com/matplotlib/napari-matplotlib/workflows/tests/badge.svg)](https://github.com/matplotlib/napari-matplotlib/actions)
[![codecov](https://codecov.io/gh/matplotlib/napari-matplotlib/branch/main/graph/badge.svg)](https://codecov.io/gh/matplotlib/napari-matplotlib)
[![pre-commit.ci status](https://results.pre-commit.ci/badge/github/matplotlib/pytest-mpl/master.svg)](https://results.pre-commit.ci/latest/github/matplotlib/pytest-mpl/master)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-matplotlib)](https://napari-hub.org/plugins/napari-matplotlib)

A plugin to create Matplotlib plots from napari layers

----------------------------------

## Introduction
`napari-matplotlib` is a bridge between `napari` and `matplotlib`, making it easy to create publication quality `Matplotlib` plots based on the data loaded in `napari` layers.

Documentaiton can be found at https://napari-matplotlib.github.io/

## Contributing

Contributions are very welcome! Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
`napari-matplotlib` is free and open source software.

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[@napari]: https://github.com/napari
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause

[file an issue]: https://github.com/dstansby/napari-matplotlib/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 5 - Production/Stable', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Topic :: Software Development :: Testing']","['Bug Tracker, https://github.com/matplotlib/napari-matplotlib/issues', 'Documentation, https://napari-matplotlib.github.io', 'Source Code, https://github.com/matplotlib/napari-matplotlib', 'User Support, https://github.com/matplotlib/napari-matplotlib/issues']",,,napari-matplotlib.histogram,,,,,https://pypi.org/project/napari-matplotlib,https://github.com/matplotlib/napari-matplotlib,
201,napari-mclabel,1.0.1.dev0,2023-08-02,2023-08-02,napari-mclabel,Jonas Utz,jonas.utz@fau.de,BSD-3-Clause,https://pypi.org/project/napari-mclabel,Napari plugin for semi-automatic labeling of macrophages,>=3.8,"['napari[all]', 'napari-plugin-engine (>=0.1.4)', 'imaris-ims-file-reader (>=0.1.5)', 'numpy', 'h5py', 'dask', 'napari-imaris-loader', 'scikit-image', 'scipy']","# Napari McLabel

## What is the purpose of this tool?

McLabel is a semi-automatic local thresholding tool that can help to label cellular objects such as macrophages in fluorescence microscopy images. In cases where a global threshold does not yield satisfactory results, a local threshold based on a ROI drawn by the user may give better results. See the video for an example:
![Mclabel](./img/Mclabel.gif)



## Installation

The plugin can be installed using pip:
```bash
pip install napari-mclabel
```

After succesfull installation the plugin will appear in the plugins menu of napari.

## Usage

![gui](./img/gui.png)

The GUI of McLabel lives in the right pane of napari. If multiple layers are loaded, select the layer that you want to segment. The theshold finding algorithm is by default is triangle, however there are plenty of alternatives and depending on the data another algorithm might be better suited. 

1. Press ""Draw Label""
2. Draw a rough outline around the object of interest. 
3. Press ""Compute Label""
4. If not satisfied with result, adjust threshold using the slider
5. Continue with next object

![gui](./img/gui.gif) 

## Reference

If you use McLabel in your work, consider citing our background paper:
https://doi.org/10.1007/978-3-658-41657-7_20



```tex
@InProceedings{10.1007/978-3-658-41657-7_20,
author=""Utz, Jonas
and Schlereth, Maja
and Qiu, Jingna
and Thies, Mareike
and Wagner, Fabian
and Brahim, Oumaima B.
and Gu, Mingxuan
and Uderhardt, Stefan
and Breininger, Katharina"",
editor=""Deserno, Thomas M.
and Handels, Heinz
and Maier, Andreas
and Maier-Hein, Klaus
and Palm, Christoph
and Tolxdorff, Thomas"",
title=""McLabel"",
booktitle=""Bildverarbeitung f{\""u}r die Medizin 2023"",
year=""2023"",
publisher=""Springer Fachmedien Wiesbaden"",
address=""Wiesbaden"",
pages=""82--87"",
abstract=""In this work, we present a semi-automatic labelling tool for the annotation of complex cellular structures such as macrophages in fluorescence microscopy images. We present McLabel, a napari plugin that allows users to label structures of interest by simply scribbling outlines around the area of interest, using the triangle thresholding method with post-processing to identify the desired structure. Additionally, manual adaption of the threshold allows for quick and fine-grained local correction of the segmentation. The tool is evaluated in a user study with five experts, who annotated images both with and without the tool. The results show that variability in annotations between experts is reduced when the labelling tool is used and annotation time is reduced by a factor of five on average."",
isbn=""978-3-658-41657-7""
}
```

","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://gitlab.cs.fau.de/xo04syge/mclabel/-/issues', 'Documentation, https://gitlab.cs.fau.de/xo04syge/mclabel/-/blob/main/README.md', 'Source Code, https://gitlab.cs.fau.de/xo04syge/mclabel', 'User Support, https://gitlab.cs.fau.de/xo04syge/mclabel/-/issues']",,,napari-mclabel.McLabel,,,,,https://pypi.org/project/napari-mclabel,,
202,napari-medical-image-formats,0.3.8,2022-02-13,2023-06-18,napari-medical-image-formats,"Marc Boucsein, Marc Buckmakowski",,BSD-3,https://github.com/MBPhys/napari-medical-image-formats,A Plugin in order to read medical image formats such as DICOM and NIfTI,>=3.7,"['napari-plugin-engine (>=0.1.4)', 'numpy', 'pydicom', 'SimpleITK', 'itk', 'itk-napari-conversion']","# napari-medical-image-formats

[![License](https://img.shields.io/pypi/l/napari-medical-image-formats.svg?color=green)](https://github.com/MBPhys/napari-medical-image-formats/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-medical-image-formats.svg?color=green)](https://pypi.org/project/napari-medical-image-formats)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-medical-image-formats.svg?color=green)](https://python.org)


A Plugin in order to read and write medical image formats such as DICOM, DICOM Series and NIfTI. The meta information is supported by the package napari-itk-io. 

----------------------------------

## Installation

You can install `napari-medical-image-formats` via [pip]:

    pip install napari-medical-image-formats

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-medical-image-formats"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/MBPhys/napari-medical-image-formats/issues
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/


","['Development Status :: 4 - Beta', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']",,napari-medical-image-formats.napari_get_reader,napari-medical-image-formats.napari_write_image,,,['*'],,,https://pypi.org/project/napari-medical-image-formats,https://github.com/MBPhys/napari-medical-image-formats,
203,Melt Pool Tracker,0.1.1,2023-11-18,2023-11-18,napari-melt-pool-tracker,Florian Aymanns,florian.aymanns@epfl.ch,BSD-3-Clause,https://pypi.org/project/napari-melt-pool-tracker,Plugin for tracking the width and depth of the melt pool and keyhole in x-ray images of laser powder bed fusion experiments.,>=3.8,"['numpy', 'magicgui', 'qtpy', 'h5py', 'scikit-learn', 'napari-cursor-tracker', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-melt-pool-tracker

[![License BSD-3](https://img.shields.io/pypi/l/napari-melt-pool-tracker.svg?color=green)](https://github.com/faymanns/napari-melt-pool-tracker/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-melt-pool-tracker.svg?color=green)](https://pypi.org/project/napari-melt-pool-tracker)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-melt-pool-tracker.svg?color=green)](https://python.org)
[![tests](https://github.com/faymanns/napari-melt-pool-tracker/workflows/tests/badge.svg)](https://github.com/faymanns/napari-melt-pool-tracker/actions)
[![codecov](https://codecov.io/gh/faymanns/napari-melt-pool-tracker/branch/main/graph/badge.svg)](https://codecov.io/gh/faymanns/napari-melt-pool-tracker)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-melt-pool-tracker)](https://napari-hub.org/plugins/napari-melt-pool-tracker)

Plugin for tracking the width and depth of the melt pool and keyhole in x-ray images of laser powder bed fusion experiments.

----------------------------------

## Installation

You can install `napari-melt-pool-tracker` via [pip]:

    pip install napari-melt-pool-tracker

# Getting Started with napari-melt-pool-tracker

## Reading Data

- The `napari-melt-pool-tracker` plugin can read h5 files from the ID19 and TOMCAT beam lines.
- When opening an h5 file in napari, select the ""Melt Pool Tracker"" as the reader for the mentioned beamlines.
- Once the data is loaded, you have the option to save the layer as a tif file if needed.

## Pre-processing

- For large images, it is recommended to crop them in both time and space to include only the relevant parts of the image stack.

## 1. Determine Laser Speed and Position

- This step helps identify the laser in the images for later reslicing the stack with a moving window following the laser.
- It generates a projection of the stack along the y-axis, creating an x-t image where the laser's position appears as an oblique line in the projection.

**To perform this step:**

1. Select the stack you want to work on using the ""Input"" drop-down menu.
2. Choose one of three projection modes:
   - Default: Maximum projection along y.
   - Pre mean: Divide each frame by the mean projection along the t-axis (to remove background) and then perform a maximum projection along y.
   - Post median: Perform a maximum projection along y and then divide the projected images by a median-filtered version in the x-direction (to remove horizontal strips).
3. Click ""Run"" to generate a new layer with the projected image and a shapes layer with a line.
4. Select the line layer, use the ""Select vertices"" tool to match the line with the laser in the projected image.

## 2. Reslice with Moving Window

- This step reslices the stack with a moving window that follows the laser's position.

**To perform this step:**

1. Select the input stack using the ""Stack"" drop-down menu.
2. Choose the line layer with the laser's position using the ""Line"" drop-down menu.
3. Adjust the ""Left margin"" and ""Right margin"" sliders to set the size of the window to the left and right of the laser's position.
4. Click ""Run"" to create three new layers: a resliced stack, a shapes layer indicating the laser's position based on your previous annotation, and a shapes layer with lines indicating the window's position in the original image.
5. If the window size doesn't fit the melt pool correctly, adjust it using the margin sliders. Disable the ""Auto run"" checkbox for large stacks to control when reslicing occurs.

## 3. Filter Image

- This step aims to reduce noise in the images by applying a median filter.

**To filter the image:**

- Select the resliced layer as the input.
- Use the ""Kernel"" sliders to set the size of the median filter along different axes.
- Disable ""Auto run"" for large stacks due to the computational cost. After median filtering, the function applies Otsu thresholding to remove the background. Adjust the contrast as needed.

## 4. Calculate Radial Gradient

- This step calculates the gray value gradient in the radial direction with respect to a point on the surface, forming the origin. You can set the horizontal position of the origin using the position slider.

**To calculate the radial gradient:**

- Select the resliced and filtered stack as input.
- Adjust the contrast for the new radial gradient layer.

## 5. Annotate

- Annotation of points is done using the [napari-cursor-tracker](https://www.napari-hub.org/plugins/napari-cursor-tracker) plugin.

**To annotate points:**

- Select any of the resliced layers as your reference image.
- Change the name in the ""Name of the tracked point"" text box to define the point you want to track, e.g., 'MP depth'.
- Click ""Add new layer"" to create a new points layer with the specified name, automatically selected as the active layer.
- Start tracking by pressing 't' on your keyboard. Enable ""Auto play when tracking is started"" for automatic playback.
- Adjust playback parameters as needed. Setting ""Loop mode"" to 'once' is advised to prevent overwriting tracked points. You can track points manually by scrolling through slices/frames (hold down `ctrl`) and saving your cursor positions at each index change.

## Saving and Processing Results

- You can save the 'window_coordinates' layer and point layers with tracked points as CSV files for further processing with external software.


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-melt-pool-tracker"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']",,napari-melt-pool-tracker.get_reader,napari-melt-pool-tracker.write_multiple,napari-melt-pool-tracker.make_qwidget,napari-melt-pool-tracker.make_sample_data,['*.h5'],,['.npy'],https://pypi.org/project/napari-melt-pool-tracker,,
204,StarDist OPP,0.1.1,2023-12-04,2023-12-04,napari-merge-stardist-masks,Niklas Netter,niknett@gmail.com,BSD-3-Clause,https://pypi.org/project/napari-merge-stardist-masks,Segment non-star-convex objects with StarDist by merging masks.,>=3.8,"['numpy', 'magicgui', 'qtpy', 'importlib-resources', 'stardist-napari >=2022.7.5', 'merge-stardist-masks >=0.1.0', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# StarDist OPP napari plugin

[![License BSD-3](https://img.shields.io/pypi/l/napari-merge-stardist-masks.svg?color=green)](https://github.com/gatoniel/napari-merge-stardist-masks/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-merge-stardist-masks.svg?color=green)](https://pypi.org/project/napari-merge-stardist-masks)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-merge-stardist-masks.svg?color=green)](https://python.org)
[![tests](https://github.com/gatoniel/napari-merge-stardist-masks/workflows/tests/badge.svg)](https://github.com/gatoniel/napari-merge-stardist-masks/actions)
[![codecov](https://codecov.io/gh/gatoniel/napari-merge-stardist-masks/branch/main/graph/badge.svg)](https://codecov.io/gh/gatoniel/napari-merge-stardist-masks)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-merge-stardist-masks)](https://napari-hub.org/plugins/napari-merge-stardist-masks)

This is the [napari] plugin for [StarDist OPP]. Checkout our [paper] for more information.

----------------------------------

## Usage

Read the [tutorial] and download pre-trained models from our [Zenodo repository].

In PowerShell, when you do not have sufficient GPU support, run napari without CUDA support, i.e.,:
```
$env:CUDA_VISIBLE_DEVICES=-1; napari
```


## Installation

You can install `napari-merge-stardist-masks` via [pip]:

    pip install napari-merge-stardist-masks



To install latest development version :

    pip install git+https://github.com/gatoniel/napari-merge-stardist-masks.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-merge-stardist-masks"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

## How to cite
```bibtex
@article{https://doi.org/10.1111/mmi.15064,
author = {Jelli, Eric and Ohmura, Takuya and Netter, Niklas and Abt, Martin and Jiménez-Siebert, Eva and Neuhaus, Konstantin and Rode, Daniel K. H. and Nadell, Carey D. and Drescher, Knut},
title = {Single-cell segmentation in bacterial biofilms with an optimized deep learning method enables tracking of cell lineages and measurements of growth rates},
journal = {Molecular Microbiology},
volume = {n/a},
number = {n/a},
pages = {},
keywords = {3D segmentation, biofilm, deep learning, image analysis, image cytometry, Vibrio cholerae},
doi = {https://doi.org/10.1111/mmi.15064},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/mmi.15064},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/mmi.15064},
abstract = {Abstract Bacteria often grow into matrix-encased three-dimensional (3D) biofilm communities, which can be imaged at cellular resolution using confocal microscopy. From these 3D images, measurements of single-cell properties with high spatiotemporal resolution are required to investigate cellular heterogeneity and dynamical processes inside biofilms. However, the required measurements rely on the automated segmentation of bacterial cells in 3D images, which is a technical challenge. To improve the accuracy of single-cell segmentation in 3D biofilms, we first evaluated recent classical and deep learning segmentation algorithms. We then extended StarDist, a state-of-the-art deep learning algorithm, by optimizing the post-processing for bacteria, which resulted in the most accurate segmentation results for biofilms among all investigated algorithms. To generate the large 3D training dataset required for deep learning, we developed an iterative process of automated segmentation followed by semi-manual correction, resulting in >18,000 annotated Vibrio cholerae cells in 3D images. We demonstrate that this large training dataset and the neural network with optimized post-processing yield accurate segmentation results for biofilms of different species and on biofilm images from different microscopes. Finally, we used the accurate single-cell segmentation results to track cell lineages in biofilms and to perform spatiotemporal measurements of single-cell growth rates during biofilm development.}
}
```

## Credits

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

[paper]: https://doi.org/10.1111/mmi.15064
[StarDist OPP]: https://github.com/gatoniel/merge-stardist-masks
[tutorial]: https://merge-stardist-masks.readthedocs.io/en/latest/napari-plugin.html
[Zenodo repository]: https://doi.org/10.5281/zenodo.7704410

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/gatoniel/napari-merge-stardist-masks/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/gatoniel/napari-merge-stardist-masks/issues', 'Documentation, https://github.com/gatoniel/napari-merge-stardist-masks#README.md', 'Source Code, https://github.com/gatoniel/napari-merge-stardist-masks', 'User Support, https://github.com/gatoniel/napari-merge-stardist-masks/issues']",,,napari-merge-stardist-masks.stardist_opp_widget,napari-merge-stardist-masks.stardist_opp_sample_data,,,,https://pypi.org/project/napari-merge-stardist-masks,,
205,meshio,0.0.1,2023-03-30,2023-06-18,napari-meshio,Genevieve Buckley,yourname@example.com,MIT,https://github.com/GenevieveBuckley/napari-meshio,I/O for mesh files.,>=3.8,"['numpy', 'meshio', 'pooch', 'rich', ""mkdocs ; extra == 'testing'"", ""mkdocs-gen-files ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'""]","# napari-meshio

[![License MIT](https://img.shields.io/pypi/l/napari-meshio.svg?color=green)](https://github.com/GenevieveBuckley/napari-meshio/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-meshio.svg?color=green)](https://pypi.org/project/napari-meshio)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-meshio.svg?color=green)](https://python.org)
[![tests](https://github.com/GenevieveBuckley/napari-meshio/workflows/tests/badge.svg)](https://github.com/GenevieveBuckley/napari-meshio/actions)
[![codecov](https://codecov.io/gh/GenevieveBuckley/napari-meshio/branch/main/graph/badge.svg)](https://codecov.io/gh/GenevieveBuckley/napari-meshio)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-meshio)](https://napari-hub.org/plugins/napari-meshio)

This napari plugin uses [meshio](https://github.com/nschloe/meshio) to read and write mesh files to surfaces in napari.

![Screenshot: Stanford bunny example data in napari](assets/bunny-screenshot.png)

*Image caption: screenshot of the [Stanford bunny](http://graphics.stanford.edu/data/3Dscanrep/) example surface mesh open in napari.*

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

- [Installation](#installation)
- [How to use napari-meshio](#how-to-use-napari-meshio)
    - [Read surface data from file](#read-surface-data-from-file)
    - [Open example surface data](#open-example-surface-data)
    - [Save surface data](#save-surface-data)
    - [Supported mesh file formats](#supported-mesh-file-formats)
- [Contributing](#contributing)
- [License](#license)
- [Issues](#issues)

## Installation

You can install `napari-meshio` via [pip]:

    pip install napari-meshio



To install latest development version :

    pip install git+https://github.com/GenevieveBuckley/napari-meshio.git


## How to use napari-meshio

### Read surface data from file

Drag and drop the file onto the napari viewer.

*Note: [Here](https://people.sc.fsu.edu/~jburkardt/data/ply/ply.html) are a number of `.ply` example files you can download to try, like [this airplane](https://people.sc.fsu.edu/~jburkardt/data/ply/airplane.ply) (see [image](https://people.sc.fsu.edu/~jburkardt/data/ply/airplane.png)).*

### Open example surface data

Launch the napari viewer, then open one of the sample datasets (eg: the [Stanford bunny](http://graphics.stanford.edu/data/3Dscanrep/)) from the file menu:

`File` > `Open Sample` > `napari-meshio` > `bunny`

Or, open sample data from python with:

```python
import napari

viewer = napari.Viewer(ndisplay=3)
viewer.open_sample('napari-meshio', 'bunny')
```

### Save surface data

To save a surface layer, click the layer name to select it, and then choose save from the file menu:

`File` > `Save selected layer(s)`

You can also use keyboard shortcuts to save the selected surface layer:
- Windows/Linux: `Control` + `S`
- Mac: `⌘` + `S`

Or, save surface layers from python with:
```python
filename = ""bunny.stl""
viewer.layers['bunny'].save(filename)
```
*Note: this code example assumes you have the Stanford bunny example dataset loaded.*

A [wide variety of surface mesh file formats are supported](#supported-mesh-file-formats) by
[meshio](https://github.com/nschloe/meshio).
If no file extension is provided when saving a surface layer,
the default is the `.ply` polygon file format.

### Supported mesh file formats

*Note: Only triangular mesh faces are supported by napari.*

The [meshio](https://github.com/nschloe/meshio) library documentation describes the supported file formats:

> There are various mesh formats available for representing unstructured meshes.
meshio can read and write all of the following and smoothly converts between them:
>
>> [Abaqus](http://abaqus.software.polimi.it/v6.14/index.html) (`.inp`),
>> ANSYS msh (`.msh`),
>> [AVS-UCD](https://lanl.github.io/LaGriT/pages/docs/read_avs.html) (`.avs`),
>> [CGNS](https://cgns.github.io/) (`.cgns`),
>> [DOLFIN XML](https://manpages.ubuntu.com/manpages/jammy/en/man1/dolfin-convert.1.html) (`.xml`),
>> [Exodus](https://nschloe.github.io/meshio/exodus.pdf) (`.e`, `.exo`),
>> [FLAC3D](https://www.itascacg.com/software/flac3d) (`.f3grid`),
>> [H5M](https://www.mcs.anl.gov/~fathom/moab-docs/h5mmain.html) (`.h5m`),
>> [Kratos/MDPA](https://github.com/KratosMultiphysics/Kratos/wiki/Input-data) (`.mdpa`),
>> [Medit](https://people.sc.fsu.edu/~jburkardt/data/medit/medit.html) (`.mesh`, `.meshb`),
>> [MED/Salome](https://docs.salome-platform.org/latest/dev/MEDCoupling/developer/med-file.html) (`.med`),
>> [Nastran](https://help.autodesk.com/view/NSTRN/2019/ENU/?guid=GUID-42B54ACB-FBE3-47CA-B8FE-475E7AD91A00) (bulk data, `.bdf`, `.fem`, `.nas`),
>> [Netgen](https://github.com/ngsolve/netgen) (`.vol`, `.vol.gz`),
>> [Neuroglancer precomputed format](https://github.com/google/neuroglancer/tree/master/src/neuroglancer/datasource/precomputed#mesh-representation-of-segmented-object-surfaces),
>> [Gmsh](https://gmsh.info/doc/texinfo/gmsh.html#File-formats) (format versions 2.2, 4.0, and 4.1, `.msh`),
>> [OBJ](https://en.wikipedia.org/wiki/Wavefront_.obj_file) (`.obj`),
>> [OFF](https://segeval.cs.princeton.edu/public/off_format.html) (`.off`),
>> [PERMAS](https://www.intes.de) (`.post`, `.post.gz`, `.dato`, `.dato.gz`),
>> [PLY](<https://en.wikipedia.org/wiki/PLY_(file_format)>) (`.ply`),
>> [STL](<https://en.wikipedia.org/wiki/STL_(file_format)>) (`.stl`),
>> [Tecplot .dat](http://paulbourke.net/dataformats/tp/),
>> [TetGen .node/.ele](https://wias-berlin.de/software/tetgen/fformats.html),
>> [SVG](https://www.w3.org/TR/SVG/) (2D output only) (`.svg`),
>> [SU2](https://su2code.github.io/docs_v7/Mesh-File/) (`.su2`),
>> [UGRID](https://www.simcenter.msstate.edu/software/documentation/ug_io/3d_grid_file_type_ugrid.html) (`.ugrid`),
>> [VTK](https://vtk.org/wp-content/uploads/2015/04/file-formats.pdf) (`.vtk`),
>> [VTU](https://vtk.org/Wiki/VTK_XML_Formats) (`.vtu`),
>> [WKT](https://en.wikipedia.org/wiki/Well-known_text_representation_of_geometry) ([TIN](https://en.wikipedia.org/wiki/Triangulated_irregular_network)) (`.wkt`),
>> [XDMF](https://xdmf.org/index.php/XDMF_Model_and_Format) (`.xdmf`, `.xmf`).

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [MIT] license,
""napari-meshio"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/GenevieveBuckley/napari-meshio/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: MIT License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/GenevieveBuckley/napari-meshio/issues', 'Documentation, https://github.com/GenevieveBuckley/napari-meshio#README.md', 'Source Code, https://github.com/GenevieveBuckley/napari-meshio', 'User Support, https://github.com/GenevieveBuckley/napari-meshio/issues']",napari-meshio.get_reader,napari-meshio.write_multiple,,napari-meshio.bunny,"['*.inp', '*.msh', '*.avs', '*.cgns', '*.xml', '*.e', '*.exo', '*.f3grid', '*.h5m', '*.mdpa', '*.mesh', '*.meshb', '*.med', '*.bdf', '*.fem', '*.nas', '*.vol', '*.vol.gz', '*.msh', '*.obj', '*.off', '*.post', '*.post.gz', '*.dato', '*.dato.gz', '*.ply', '*.stl', '*.dat', '*.node', '*.ele', '*.su2', '*.ugrid', '*.vtk', '*.vtu', '*.wkt', '*.xdmf', '*.xmf']",,"['.inp', '.msh', '.avs', '.cgns', '.xml', '.e', '.exo', '.f3grid', '.h5m', '.mdpa', '.mesh', '.meshb', '.med', '.bdf', '.fem', '.nas', '.vol', '.vol.gz', '.msh', '.obj', '.off', '.post', '.post.gz', '.dato', '.dato.gz', '.ply', '.stl', '.dat', '.node', '.ele', '.su2', '.ugrid', '.vtk', '.vtu', '.wkt', '.xdmf', '.xmf']",https://pypi.org/project/napari-meshio,https://github.com/GenevieveBuckley/napari-meshio,
206,napari METROID,0.0.5,2022-08-19,2023-06-18,napari-metroid,Marcelo Leomil Zoccoler,marcelo.zoccoler@tu-dresden.de,BSD-3-Clause,https://github.com/zoccoler/napari-metroid,This napari plugin creates several regions of interest of similar area over cells in a fluorescence video (2D+time). It then gets ROIs means over time and performs signal denoising: fixes photobleaching and separates signal from noise by means of blind source separation (with or without wavelet filtering).,"<3.9,>=3.7","['numpy', 'scikit-learn', 'scikit-image', 'statsmodels', 'scipy', 'matplotlib', 'napari-skimage-regionprops (>=0.3.1)']","# napari-metroid

[![License](https://img.shields.io/pypi/l/napari-metroid.svg?color=green)](https://github.com/zoccoler/napari-metroid/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-metroid.svg?color=green)](https://pypi.org/project/napari-metroid)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-metroid.svg?color=green)](https://python.org)
[![tests](https://github.com/zoccoler/napari-metroid/workflows/tests/badge.svg)](https://github.com/zoccoler/napari-metroid/actions)
[![codecov](https://codecov.io/gh/zoccoler/napari-metroid/branch/main/graph/badge.svg)](https://codecov.io/gh/zoccoler/napari-metroid)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-metroid)](https://napari-hub.org/plugins/napari-metroid)

This napari plugin is an adaptation of [metroid](https://github.com/zoccoler/metroid). It creates several regions of interest of similar area over cells in a fluorescence video (2D+time). It then gets ROIs means over time and performs signal denoising: fixes photobleaching and separates signal from noise by means of blind source separation (with or without wavelet filtering).

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/stable/index.html
-->

## A Picture (to boil down a thousand words)

Below is the graphical abstract of the Metroid software. This napari plugin works very similarly.

![](https://github.com/zoccoler/metroid/blob/master/Metroid_flowchart.png)

## Table of Contents

- [Quick Walktrough](#quick-walkthrough)
- [Installation](#installation)
- [Usage](#usage)
  - [Open Sample Data](#open-sample-data)
  - [Open Plugin Main Interface](#open-plugin-main-interface)
  - [Auto-generate Cell Mask](#auto-generate-cell-mask)
  - [Split Mask into ROIs](#split-mask-into-rois)
  - [Get ROI Means over Time](#get-roi-means-over-time)
  - [Remove Photobleaching](#remove-photobleaching)
  - [Filter Signals](#filter-signals)
  - [Save outputs](#save-outputs)
- [Contributing](#contributing)
- [Citing napari-metroid](#citing-napari-metroid)
- [License](#license)
- [Issues](#issues)

## Quick Walkthrough

Below is a full demonstration of using napari-metroid. It shows the following:
  * Open sample data;
  * Create cell mask;
  * Split mask into ROIs of similar area;
  * Get ROIs signals over time and plots two of them;
  * Remove photobleaching;
  * Remove noise:
    * Use ICA to decompose ROIs signals into independent components;
    * Plot 4 components;
    * Manually select the component of interest (source);
    * Perform inverse transformation with selected source;
        
![](https://github.com/zoccoler/napari-metroid/raw/main/figures/napari_metroid_demo.gif)

## Installation

Download and install [Anaconda](https://www.anaconda.com/products/individual) or [Miniconda](https://docs.conda.io/en/latest/miniconda.html#).

Create a new conda environment:

    conda create -n metroid-env python=3.8

Install napari, e.g. via pip:

    pip install ""napari[all]""

Install `napari-metroid` via [pip]:

    pip install napari-metroid

To install latest development version :

    pip install git+https://github.com/zoccoler/napari-metroid.git

## Usage
### Open Sample Data

This plugin comes with two sample videos:
- Cell1 Video Action Potential: 2D + time fluorescence video of a rat isolated cardiomyocyte labeled with a membrane potential dye upon which an external electrical field pulse is applied.
- Cell1 Video Electroporation: Same cell, but submitted to a strong external electrical field pulse.

You can open them under ""File -> Open Sample -> napari-metroid"", as shown below. Both videos are loaded from the [metroid main repository](https://github.com/zoccoler/metroid). To know more about the experimental conditions, please refer to the [original publication](https://doi.org/10.1186/s12859-020-03661-9).

![](https://github.com/zoccoler/napari-metroid/raw/main/figures/load_sample_data.gif)

### Open Plugin Main Interface

![](https://github.com/zoccoler/napari-metroid/raw/main/figures/open_plugin.gif)

### Auto-generate Cell Mask

Metroid can generate cell binary masks automatically by cumulative sum of images until any pixel saturation happens. It then applies Otsu thresholding and removes small objects.

![](https://github.com/zoccoler/napari-metroid/raw/main/figures/auto_create_mask.png)

### Split Mask into ROIs

By default, a cell mask is split into 32 regions of interest (ROIs) in a double-layer fashion: An outer layer of ROIs and an inner layer. 
The method is solely based on the shape of the cell mask and the main criteria is that ROIs must have similar areas. The number of ROIs in each layer can be editted. 

![](https://github.com/zoccoler/napari-metroid/raw/main/figures/mess.png)

### Get ROI Means over Time

The 'Get Signals' button serves to collect each ROI mean fluorescence over time and enable plotting. There, you can optionally provide the frame rate so that the time axis is properly displayed.
Double click over a ROI to have its signal plotted. Hold the 'ALT' key to plot multiple signals together.

![](https://github.com/zoccoler/napari-metroid/raw/main/figures/get_signals.gif)

### Remove Photobleaching

Metroid removes photobleaching by curve fitting over time periods that lack the cellular signal (which can be an action potential or an electroporation signal). That is why the 'Transitory' parameter is important. Action potentials are transitory signals whereas electroporation (at least for the duration of this experiment) are not, and the algorithm must be informed about that for proper trend removal.

![](https://github.com/zoccoler/napari-metroid/raw/main/figures/remov_photob.gif)

### Filter Signals

Cellular signals are filtered by separating signal components with either PCA or ICA (plus optional wavelet filtering). It then chooses one (or several) components and it applies the inverse transform using only the selected components. Metroid can do this component/source selection automatically based on estimations of signal power. Instead, we show below the manual selection procedure, where 4 components are plotted and the user selects one of them.

![](https://github.com/zoccoler/napari-metroid/raw/main/figures/bssd.gif)

### Save Outputs

Raw, corrected and filtered signals, as well as time and components, are arranged in a table with values for each time point. The table is displayed as a widget after each Run button click. Estimated signal-to-noise (SNR) in dB for each label/ROI are also provided (in this case, each line corresponds to a ROI, not a time point).
The user can save these data by clicking on the buttons ""Copy to clipboard"" or ""Save as csv..."".

![](https://github.com/zoccoler/napari-metroid/raw/main/figures/table_widget.png)

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## Citing napari-metroid

If you use this plugin in your research, please be kind to cite the original paper below:

Zoccoler, M., de Oliveira, P.X. METROID: an automated method for robust quantification of subcellular fluorescence events at low SNR. BMC Bioinformatics 21, 332 (2020). https://doi.org/10.1186/s12859-020-03661-9

## License

Distributed under the terms of the [BSD-3] license,
""napari-metroid"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/zoccoler/napari-metroid/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/


","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/zoccoler/napari-metroid/issues', 'Documentation, https://github.com/zoccoler/napari-metroid#README.md', 'Source Code, https://github.com/zoccoler/napari-metroid', 'User Support, https://github.com/zoccoler/napari-metroid/issues']",,napari-metroid.write_multiple,napari-metroid.make_qwidget,napari-metroid.make_cell1_AP1_data,,,['.npy'],https://pypi.org/project/napari-metroid,https://github.com/zoccoler/napari-metroid,
207,napari-micromanager,0.1.0,2022-02-14,2023-10-17,napari-micromanager,"Federico Gasparoli, Talley Lambert","Federico Gasparoli <federico.gasparoli@gmail.com>, Talley Lambert <talley.lambert@gmail.com>",BSD 3-Clause,https://github.com/tlambert03/napari-micromanager,Micro-Manager GUI interface in napari.,>=3.8,"['fonticon-materialdesignicons6', 'napari>=0.4.13', 'pymmcore-plus>=0.9.3', 'pymmcore-widgets>=0.7.0rc1', 'superqt>=0.5.1', 'tifffile', 'useq-schema>=0.4.1', 'zarr', ""isort; extra == 'dev'"", ""mda-simulator; extra == 'dev'"", ""mypy; extra == 'dev'"", ""pre-commit; extra == 'dev'"", ""ruff; extra == 'dev'"", ""pyqt5; extra == 'pyqt5'"", ""pyqt6; extra == 'pyqt6'"", ""pyside2; extra == 'pyside2'"", ""pyside6; extra == 'pyside6'"", ""pytest; extra == 'test'"", ""pytest-cov; extra == 'test'"", ""pytest-qt; extra == 'test'""]","# napari-micromanager

[![License](https://img.shields.io/pypi/l/napari-micromanager.svg?color=green)](https://github.com/napari/napari-micromanager/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-micromanager.svg?color=green)](https://pypi.org/project/napari-micromanager)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-micromanager.svg?color=green)](https://python.org)
[![Tests](https://github.com/pymmcore-plus/napari-micromanager/actions/workflows/test.yml/badge.svg)](https://github.com/pymmcore-plus/napari-micromanager/actions/workflows/test.yml)
[![codecov](https://codecov.io/gh/pymmcore-plus/napari-micromanager/branch/main/graph/badge.svg?token=tf6lYDWV1s)](https://codecov.io/gh/pymmcore-plus/napari-micromanager)


GUI interface between napari and micromanager powered by [pymmcore-plus](https://pymmcore-plus.github.io/pymmcore-plus/) and [pymmcore-widgets](https://pymmcore-plus.github.io/pymmcore-widgets/)

🚧 Experimental!  Work in progress!  Here be 🐲 🚧

----------------------------------
<img width=""1797"" alt=""mm"" src=""https://user-images.githubusercontent.com/1609449/138457506-787b7bec-7f30-4d92-b5cf-6e218c87225a.png"">


## Installation

You can install `napari-micromanager` via [pip]:

    pip install napari-micromanager

You will also need a Qt backend such as PySide2/6, or PyQt5/6.  If you've previously installed napari
into this environment with `pip install napari[all]`, then you will likely already have it. If not,
you will also need to install a Qt backend of your choice:

    pip install pyqt5  # or any of {pyqt5, pyqt6, pyside2, pyside6}

### Getting micromanager adapters:

The easiest way to get the micromanager adapters is to use:

```
mmcore install
```

this will install micromanager to the pymmcore_plus folder in your site-package; use this to see where:

```
python -c ""from pymmcore_plus import find_micromanager; print(find_micromanager())""
```

alternatively, you can direct pymmcore_plus to your own micromanager installation with the `MICROMANAGER_PATH`
environment variable:

```
export MICROMANAGER_PATH='/path/to/Micro-Manager-...'
```

## Contributing

Contributions are very welcome.

### Launching napari with plugin
You can launch napari and automatically load this plugin using the `launch-dev.py` script:

```bash
python launch-dev.py
```

Alternatively you can run:

```bash
napari -w napari-micromanager
```

## License

Distributed under the terms of the [BSD-3] license,
""napari-micromanager"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/pymmcore-plus/napari-micromanager/issues
[napari]: https://github.com/napari/napari
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 3 - Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'Intended Audience :: Science/Research', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Topic :: System :: Hardware', 'Topic :: System :: Hardware :: Hardware Drivers', 'Topic :: Utilities']","['Source, https://github.com/pymmcore-plus/napari-micromanager', 'Tracker, https://github.com/pymmcore-plus/napari-micromanager/issues']",,,napari-micromanager.MainWindow,,,,,https://pypi.org/project/napari-micromanager,https://github.com/tlambert03/napari-micromanager,
208,napari-microscope,0.0.3,2022-02-23,2023-06-18,napari-microscope,David Miguel Susano Pinto,david.pinto@bioch.ox.ac.uk,GPL-3.0-or-later,https://pypi.org/project/napari-microscope/,Napari plugin for Microscope.,>=3.6,"['Pyro4', 'microscope', 'napari-plugin-engine']","Microscope control plugin for Napari via Python Microscope.

Current development stage is whatever comes before alpha and ""proof of
concept"".

To test
-------

I haven't had access to real hardware yet, so this has all been
developed with simulated devices.

1. Start the device server with simulated devices.

    a. Create a device server configuration file like so::

        import microscope
        from microscope.device_server import device
        from microscope.simulators import (
            SimulatedCamera,
            SimulatedFilterWheel,
            SimulatedLightSource,
            SimulatedStage,
        )

        DEVICES = [
            device(SimulatedCamera, ""localhost"", 8000,),
            device(SimulatedLightSource, ""localhost"", 8001),
            device(SimulatedFilterWheel, ""localhost"", 8002,
                   {""positions"": 6}),
            device(SimulatedStage, ""localhost"", 8003,
                   {""limits"": {""X"": microscope.AxisLimits(0, 25000),
                               ""Y"": microscope.AxisLimits(0, 12000)}}),
        ]

    b. Start the device server (ensure port 8000-8003 are unused)::

        $ device-server path-to-microscope-config.py

2. Start napari

3. Plugins > Add Dock Widget > microscope: MicroscopeWidget

4. Connect to the camera:

    a. On the new widget, click on the ""Add device"" button.

    b. Enter the camera URI `PYRO:SimulatedCamera@localhost:8000`

5. Tick the `Enabled` box to enable the camera and then press the
""Snap"" button.

6. A random values image will appear displayed on the napari viewer.
Keep pressing the ""Snap"" button to get new images.  The top left
corner of the image is the simulated image number.

7. Connect to the other simulated devices.  Their URIs are:

    a. PYRO:SimulatedLightSource@localhost:8001
    b. PYRO:SimulatedFilterWheel@localhost:8002
    c. PYRO:SimulatedStage@localhost:8003

8. Changing the other simulated devices, doesn't really do much (but
does change state of the devices, as can be seen in the logs)


Test with stage aware camera
----------------------------

This is pretty much the same as before but one can use a large RGB
TIFF (histology samples are perfect) to simulate a camera that returns
subsections of the image file based on the simulated stage position.

For quick example, try::

    wget https://zenodo.org/record/1445489/files/B0002.tif

And use the following device server configuration file::

    from microscope.device_server import device
    from microscope.simulators.stage_aware_camera import simulated_setup_from_image

    DEVICES = [
        device(simulated_setup_from_image, ""localhost"", 8000,
               conf={""filepath"": ""B0002.tif""}),
    ]

The URI for the devices will be::

    PYRO:camera@localhost:8000
    PYRO:filterwheel@localhost:8000
    PYRO:stage@localhost:8000

Changing the filterwheel changes which channel from the image is
returned.  Changing the stage coordinates changes the image that is
returned (but beware of the corners, pixels outside the image size are
not handled yet and will give an error).
","['Development Status :: 3 - Alpha', 'Environment :: Plugins', 'Framework :: napari ', 'Intended Audience :: Science/Research', 'Operating System :: OS Independent', 'Topic :: Scientific/Engineering']",,,,napari-microscope.MicroscopeWidget,,,,,https://pypi.org/project/napari-microscope/,,
209,Microtubule Analyzer,0.0.1a7,2023-11-18,2023-11-22,napari-microtubule-analyzer,Daniel Krentzel,dkrentzel@pm.me,MIT,https://pypi.org/project/napari-microtubule-analyzer,A plugin to analyze microtubule organization,>=3.8,"['setuptools', 'packaging', 'numpy', 'magicgui', 'qtpy', 'opencv-python', 'matplotlib', 'scikit-image', 'tqdm', 'tifffile', 'scipy', 'pyefd', 'pyqtgraph', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-microtubule-analyzer

[![License MIT](https://img.shields.io/pypi/l/napari-microtubule-analyzer.svg?color=green)](https://github.com/krentzd/napari-microtubule-analyzer/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-microtubule-analyzer.svg?color=green)](https://pypi.org/project/napari-microtubule-analyzer)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-microtubule-analyzer.svg?color=green)](https://python.org)
[![tests](https://github.com/krentzd/napari-microtubule-analyzer/workflows/tests/badge.svg)](https://github.com/krentzd/napari-microtubule-analyzer/actions)
[![codecov](https://codecov.io/gh/krentzd/napari-microtubule-analyzer/branch/main/graph/badge.svg)](https://codecov.io/gh/krentzd/napari-microtubule-analyzer)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-microtubule-analyzer)](https://napari-hub.org/plugins/napari-microtubule-analyzer)

A plugin to analyze microtubule organization 

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-microtubule-analyzer` via [pip]:

    pip install napari-microtubule-analyzer



To install latest development version :

    pip install git+https://github.com/krentzd/napari-microtubule-analyzer.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [MIT] license,
""napari-microtubule-analyzer"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/krentzd/napari-microtubule-analyzer/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: MIT License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/krentzd/napari-microtubule-analyzer/issues', 'Documentation, https://github.com/krentzd/napari-microtubule-analyzer#README.md', 'Source Code, https://github.com/krentzd/napari-microtubule-analyzer', 'User Support, https://github.com/krentzd/napari-microtubule-analyzer/issues']",napari-microtubule-analyzer.get_reader,,napari-microtubule-analyzer.degree_of_radiality,napari-microtubule-analyzer.sample_data,"['*.tif', '*.tiff']",,,https://pypi.org/project/napari-microtubule-analyzer,,
210,napari-mm3,0.0.14,,,napari-mm3,"Gursharan Ahir, Michael Sandler, Ryan Thiermann",ryan.thiermann@gmail.com,BSD-3-Clause,,a plugin for mother machine image analysis,>=3.7,"['napari-plugin-engine (>=0.1.4)', 'numpy', 'h5py', 'tifffile (==2021.11.2)', 'scikit-learn', 'scikit-image', 'tensorflow', 'nd2reader', 'seaborn', 'elasticdeform']","# napari-mm3

[![License](https://img.shields.io/pypi/l/napari-mm3.svg?color=green)](https://github.com/ahirsharan/napari-mm3/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-mm3.svg?color=green)](https://pypi.org/project/napari-mm3)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-mm3.svg?color=green)](https://python.org)
[![tests](https://github.com/ahirsharan/napari-mm3/workflows/tests/badge.svg)](https://github.com/ahirsharan/napari-mm3/actions)
[![codecov](https://codecov.io/gh/ahirsharan/napari-mm3/branch/main/graph/badge.svg)](https://codecov.io/gh/ahirsharan/napari-mm3)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-mm3)](https://napari-hub.org/plugins/napari-mm3)

A plugin for mother machine image analysis by the [Jun Lab](https://jun.ucsd.edu/).

Reference:
[Tools and methods for high-throughput single-cell imaging with the mother machine. Ryan Thiermann, Michael Sandler, Gursharan Ahir, John T. Sauls, Jeremy W. Schroeder, Steven D. Brown, Guillaume Le Treut, Fangwei Si, Dongyang Li, Jue D. Wang, Suckjoon Jun. bioRxiv 2023.03.27.534286](https://www.biorxiv.org/content/10.1101/2023.03.27.534286v2)

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/stable/index.html
-->


https://github.com/junlabucsd/napari-mm3/assets/40699438/1b3e6121-f5e1-475f-aca3-c6ed1b5bab3a



## Installation

We describe installation with mamba, a faster version of conda which we recommend. Installation with conda is the exact same, except replace `mamba` with `conda` Run the following command:

```
mamba create -n napari-mm3 -c conda-forge conda-build tensorflow napari
``` 
Now, you need to install our code (please let us know if this causes problems -- it has been a pain point in the past). To do so, clone the repository:

```
git clone https://github.com/junlabucsd/napari-mm3.git
```

Then, run the following commands from within your conda environment:
```
cd napari-mm3
pip install -e .
```
This supplies you with the latest, most recent version of our code.

If you would like to have a more stable version, simply run `pip install napari-mm3`. In general, we recommend going off of the github version.

napari-MM3 can use the [python-bioformats](https://pypi.org/project/python-bioformats/) library to import various image file formats. It can be installed with pip:
```
pip install python-bioformats
```
If your raw images are in the .nd2 format, they will be read in with the nd2reader package. In this case, Bio-Formats is not required.

NOTES:
Not running the conda command above and trying to install things in a different way may lead to difficult issues with PyQt5. We recommend following the above commands to simplify the situation.
Using `pip -e .` instead of `mamba develop .` is a deliberate choice, the former did not seem to register the plugin with napari.

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## Usage guide

**Brief video introduction:** available [here](https://youtu.be/7MCiGTg6mq4)

### a. Preprocessing

* [TIFFConverter](https://github.com/junlabucsd/napari-mm3/blob/main/docs/tiffconvert-widget.md) -- Turn your nd2 microscopy data, or other format via bioformats, into TIFFs. If your data is already exported as individual TIFF files, skip to the [Compile](https://github.com/junlabucsd/napari-mm3/blob/main/docs/compile-widget.md) widget. Take note of the [input image guidelines](https://github.com/junlabucsd/napari-mm3/blob/main/docs/Input-images-guidelines.md).

* [Compile](https://github.com/junlabucsd/napari-mm3/blob/main/docs/compile-widget.md) -- Locate traps, separate their timelapses into their own TIFFs, and return metadata.

* [PickChannels](https://github.com/junlabucsd/napari-mm3/blob/main/docs/pickchannels-widget.md) -- User guided selection of empty and full traps.

### b. Segmentation

___With Otsu's method:___

* [Subtract](https://github.com/junlabucsd/napari-mm3/blob/main/docs/subtract-widget.md) -- Remove (via subtraction) empty traps from the background of traps that contain cells; run this on the phase contrast channel.

* [SegmentOtsu](https://github.com/junlabucsd/napari-mm3/blob/main/docs/segmentotsu-widget.md) -- Use Otsu segmentation to segment cells.

___With U-Net:___

* [Annotate](https://github.com/junlabucsd/napari-mm3/blob/main/docs/annotate-widget.md) -- annotate images for ML (U-Net or similar) training purposes.

* [Train U-Net](https://github.com/junlabucsd/napari-mm3/blob/main/docs/trainunet-widget.md) -- Train a U-Net model for cell segmentation.

* [SegmentUnet](https://github.com/junlabucsd/napari-mm3/blob/main/docs/segmentunet-widget.md) -- Run U-Net segmentation.

### c. Tracking

* [Track](https://github.com/junlabucsd/napari-mm3/blob/main/docs/track-widget.md) -- Acquire individual cell properties and track lineages.

### d. Fluorescence data analysis

* [Subtract](https://github.com/junlabucsd/napari-mm3/blob/main/docs/subtract-widget.md) -- Remove (via subtraction) empty traps from the background of traps that contain cells. This time, run this on your fluorescence channels.

* [Colors](https://github.com/junlabucsd/napari-mm3/blob/main/docs/colors-widget.md) -- Calculate fluorescence information.

### e. Focus tracking

* [Foci](https://github.com/junlabucsd/napari-mm3/blob/main/docs/foci-widget.md) -- We use this to track `foci` (bright fluorescent spots) inside of cells.

### f. Extracting data and plotting

* The notebook [here](https://github.com/junlabucsd/napari-mm3/blob/main/notebooks/napari_mm3_analysis_template.ipynb) demonstrates how to extract, filter and visualize the lineage data output by the [Track](https://github.com/junlabucsd/napari-mm3/blob/main/docs/track-widget.md) widget.


### g. Outputs, inputs, and file structure
Finally, to better understand the data formats, you may wish to refer to the following documents:

* [Input image guidelines](https://github.com/junlabucsd/napari-mm3/blob/main/docs/Input-images-guidelines.md)

* [File structure](https://github.com/junlabucsd/napari-mm3/blob/main/docs/file-structure.md)

* [Output data structure](https://github.com/junlabucsd/napari-mm3/blob/main/docs/Cell-class-docs.md)

## License

Distributed under the terms of the [BSD-3] license,
""napari-mm3"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/junlabucsd/napari-mm3/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/junlabucsd/napari-mm3/issues', 'Documentation, https://github.com/junlabucsd/napari-mm3#README.md', 'Source Code, https://github.com/junlabucsd/napari-mm3', 'User Support, https://github.com/junlabucsd/napari-mm3/issues']",,,napari-mm3.TIFFConverter,,,,,https://pypi.org/project/napari-mm3,,
211,napari molecule reader,0.1.2,2022-01-31,2023-06-18,napari-molecule-reader,Lorenzo Gaifas,brisvag@gmail.com,BSD-3-Clause,https://github.com/brisvag/napari-molecule-reader,A napari plugin that read molecular structure files.,>=3.7,"['numpy', 'pandas', 'scipy', 'atomium']","# napari-molecule-reader

[![License](https://img.shields.io/pypi/l/napari-molecule-reader.svg?color=green)](https://github.com/brisvag/napari-molecule-reader/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-molecule-reader.svg?color=green)](https://pypi.org/project/napari-molecule-reader)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-molecule-reader.svg?color=green)](https://python.org)
[![tests](https://github.com/brisvag/napari-molecule-reader/workflows/tests/badge.svg)](https://github.com/brisvag/napari-molecule-reader/actions)
[![codecov](https://codecov.io/gh/brisvag/napari-molecule-reader/branch/main/graph/badge.svg)](https://codecov.io/gh/brisvag/napari-molecule-reader)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-molecule-reader)](https://napari-hub.org/plugins/napari-molecule-reader)

A napari plugin that read molecular structure files. It reads PDB and MMCIF files using [`atomium`](https://github.com/samirelanduk/atomium), expanding molecular assemblies to a full visualization. Data is loaded into napari as `Points` for ball representation and `Vectors` for stick representation. If multiple models or assemblies are detected, they will be loaded as separate objects.

https://user-images.githubusercontent.com/23482191/150109390-bd7fb3b4-79b4-43da-aafc-20921714df25.mp4

TODO list:
- [] handle alternate locations (i.e: different conformations in the same pdb model)

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/stable/index.html
-->

## Installation

You can install `napari-molecule-reader` via [pip]:

    pip install napari-molecule-reader



To install latest development version :

    pip install git+https://github.com/brisvag/napari-molecule-reader.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-molecule-reader"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/brisvag/napari-molecule-reader/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/


","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/brisvag/napari-molecule-reader/issues', 'Documentation, https://github.com/brisvag/napari-molecule-reader#README.md', 'Source Code, https://github.com/brisvag/napari-molecule-reader', 'User Support, https://github.com/brisvag/napari-molecule-reader/issues']",napari-molecule-reader.get_reader,,,,"['*.pdb', '*.cif']",,,https://pypi.org/project/napari-molecule-reader,https://github.com/brisvag/napari-molecule-reader,
212,napari-morphodynamics,0.1.2,2023-12-09,2023-12-09,napari-morphodynamics,Guillaume Witz,guillaume.witz@unibe.ch,BSD-3-Clause,https://pypi.org/project/napari-morphodynamics,Interface to run the morphodynamics package.,>=3.9,"['morphodynamics', 'napari-convpaint', 'napari-guitils', 'napari-matplotlib', ""cellpose ; extra == 'cellpose'""]","# napari-morphodynamics

[![License](https://img.shields.io/pypi/l/napari-morphodynamics.svg?color=green)](https://github.com/guiwitz/napari-morphodynamics/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-morphodynamics.svg?color=green)](https://pypi.org/project/napari-morphodynamics)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-morphodynamics.svg?color=green)](https://python.org)
[![tests](https://github.com/guiwitz/napari-morphodynamics/workflows/tests/badge.svg)](https://github.com/guiwitz/napari-morphodynamics/actions)
[![codecov](https://codecov.io/gh/guiwitz/napari-morphodynamics/branch/main/graph/badge.svg)](https://codecov.io/gh/guiwitz/napari-morphodynamics)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-morphodynamics)](https://napari-hub.org/plugins/napari-morphodynamics)

This plugin offers an interface for the [Morphodynamics](https://github.com/guiwitz/MorphoDynamics) package which allows to study the shape and intra-cellular dynamics of cells imaged as time-lapses by fluorescence microscopy. The plugin offers a single place to perfrom segmentation, windowing (partition cells into small regions of interests that are tracked over time) and results visualization. The software depends on [napari-convpaint](https://github.com/guiwitz/napari-convpaint) a pixel-classifier and/or on [cellpose](https://cellpose.readthedocs.io/en/latest/index.html) for segmentation. 

## Installation

You can install the plugin via [pip] with:

    pip install napari-morphodynamics

To install latest development version :

    pip install git+https://github.com/guiwitz/napari-morphodynamics.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-morphodynamics"" is free and open source software

## Authors

This plugin has been developed by Guillaume Witz and Ana Stojiljkovic at the Data Science Lab, University of Bern, in collaboration with Lucien Hinderling and Olivier Pertz from the Pertz Lab, University of Bern. Development has been partially funded by a [Chan Zuckerberg Initiative grant](https://chanzuckerberg.com/science/programs-resources/imaging/napari/napari-morphodynamics-a-plugin-to-quantify-cellular-dynamics/).

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/guiwitz/napari-morphodynamics/issues

[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/guiwitz/napari-morphodynamics/issues', 'Documentation, https://github.com/guiwitz/napari-morphodynamics#README.md', 'Source Code, https://github.com/guiwitz/napari-morphodynamics', 'User Support, https://github.com/guiwitz/napari-morphodynamics/issues']",,,napari-morphodynamics.make_qwidget,,,,,https://pypi.org/project/napari-morphodynamics,,
213,napari-mouse-controls,0.1.3,2022-02-04,2023-06-18,napari-mouse-controls,Robert Haase,robert.haase@tu-dresden.de,BSD-3-Clause,https://github.com/haesleinhuepf/napari-mouse-controls,Control napari using a touch screen,>=3.7,"['napari-plugin-engine (>=0.1.4)', 'numpy', 'napari', 'napari-tools-menu']","# napari-mouse-controls

[![License](https://img.shields.io/pypi/l/napari-mouse-controls.svg?color=green)](https://github.com/haesleinhuepf/napari-mouse-controls/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-mouse-controls.svg?color=green)](https://pypi.org/project/napari-mouse-controls)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-mouse-controls.svg?color=green)](https://python.org)
[![tests](https://github.com/haesleinhuepf/napari-mouse-controls/workflows/tests/badge.svg)](https://github.com/haesleinhuepf/napari-mouse-controls/actions)
[![codecov](https://codecov.io/gh/haesleinhuepf/napari-mouse-controls/branch/main/graph/badge.svg)](https://codecov.io/gh/haesleinhuepf/napari-mouse-controls)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-mouse-controls)](https://napari-hub.org/plugins/napari-mouse-controls)

Control zoom, slicing and contrast windowing with mouse and touch screen

----------------------------------

## Usage

You find the mouse control panel in the menu `Tools > Utilities > Mouse controls`

### Zoom

After clicking the Zoom button ![](https://github.com/haesleinhuepf/napari-mouse-controls/raw/main/src/napari_mouse_controls/icons/Zoom.png), you can click in the napari canvas and move the mouse up and down to zoom in and out.

![](https://github.com/haesleinhuepf/napari-mouse-controls/raw/main/docs/zoom.gif)

### Slicing

After clicking the Slicing button ![](https://github.com/haesleinhuepf/napari-mouse-controls/raw/main/src/napari_mouse_controls/icons/Slicing.png), you can control the currently displayed slice by moving the mouse.
By moving the mouse up and down, you control the currently selected Z-plane.
By moving the mouse left and right, you control the currently seleted time point.

![](https://github.com/haesleinhuepf/napari-mouse-controls/raw/main/docs/slicing.gif)

### Windowing

After clicking the Windowing button ![](https://github.com/haesleinhuepf/napari-mouse-controls/raw/main/src/napari_mouse_controls/icons/Windowing.png), you can modify the brightness and contrast by moving the mouse. 
By moving the mouse up and down, you control window width of the range of displayed grey values (max - min).
By moving the mouse left and right, you control the center of the grey value window. 

![](https://github.com/haesleinhuepf/napari-mouse-controls/raw/main/docs/windowing.gif)

### Normal / default mode

Click the Default button ![](https://github.com/haesleinhuepf/napari-mouse-controls/raw/main/src/napari_mouse_controls/icons/Default.png)
to return to napari's normal mode.


This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.


## Installation

You can install `napari-mouse-controls` via [pip]:

    pip install napari-mouse-controls

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-mouse-controls"" is free and open source software

## Issues

If you encounter any problems, please create a thread on [image.sc] along with a detailed description and tag [@haesleinhuepf].

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/haesleinhuepf/napari-mouse-controls/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
[image.sc]: https://image.sc

[@haesleinhuepf]: https://twitter.com/haesleinhuepf


","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/haesleinhuepf/napari-mouse-control/issues', 'Documentation, https://github.com/haesleinhuepf/napari-mouse-controls#README.md', 'Source Code, https://github.com/haesleinhuepf/napari-mouse-controls', 'User Support, https://github.com/haesleinhuepf/napari-mouse-controls/issues']",,,napari-mouse-controls.MouseControls,,,,,https://pypi.org/project/napari-mouse-controls,https://github.com/haesleinhuepf/napari-mouse-controls,
214,napari-mrcfile-handler,0.0.6,2022-02-11,2023-06-18,napari-mrcfile-handler,Philipp Schoennenbeck,p.schoennenbeck@fz-juelich.de,BSD-3-Clause,https://github.com/Croxa/napari-mrcfile_handler,"A simple plugin to read, write and adjust mrcfiles in napari.",>=3.7,"['napari-plugin-engine (>=0.1.4)', 'numpy', 'mrcfile']","# napari-mrcfile_handler

[![License](https://img.shields.io/pypi/l/napari-mrcfile_handler.svg?color=green)](https://github.com/Croxa/napari-mrcfile_handler/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-mrcfile_handler.svg?color=green)](https://pypi.org/project/napari-mrcfile_handler)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-mrcfile_handler.svg?color=green)](https://python.org)
[![tests](https://github.com/Croxa/napari-mrcfile_handler/workflows/tests/badge.svg)](https://github.com/Croxa/napari-mrcfile_handler/actions)
[![codecov](https://codecov.io/gh/Croxa/napari-mrcfile_handler/branch/master/graph/badge.svg)](https://codecov.io/gh/Croxa/napari-mrcfile_handler)

A simple plugin to read, write and adjust mrcfiles in napari.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/docs/plugins/index.html
-->

## Installation

You can install `napari-mrcfile_handler` via [pip]:

    pip install napari-mrcfile_handler

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-mrcfile_handler"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/Croxa/napari-mrcfile_handler/issues
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/


","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/Croxa/napari-mrcfile_handler/issues', 'Documentation, https://github.com/Croxa/napari-mrcfile_handler#README.md', 'Source Code, https://github.com/Croxa/napari-mrcfile_handler', 'User Support, https://github.com/Croxa/napari-mrcfile_handler/issues']",napari-mrcfile-handler.napari_get_reader,napari-mrcfile-handler.napari_write_image,napari-mrcfile-handler.PixelSpacing,,['*'],,,https://pypi.org/project/napari-mrcfile-handler,https://github.com/Croxa/napari-mrcfile_handler,
215,napari-mrcfile-reader,0.2.0,2022-01-31,2023-07-26,napari-mrcfile-reader,Alister Burt,alisterburt@gmail.com,BSD-3-Clause,https://github.com/alisterburt/napari-mrcfile-reader,Read MRC2014 files in napari using mrcfile.,>=3.8,"['numpy', 'mrcfile', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'""]","# napari-mrcfile-reader

[![License](https://img.shields.io/pypi/l/napari-mrcfile-reader.svg?color=green)](https://github.com/alisterburt/napari-mrcfile-reader/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-mrcfile-reader.svg?color=green)](https://pypi.org/project/napari-mrcfile-reader)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-mrcfile-reader.svg?color=green)](https://python.org)
[![tests](https://github.com/alisterburt/napari-mrcfile-reader/workflows/tests/badge.svg)](https://github.com/alisterburt/napari-mrcfile-reader/actions)
[![codecov](https://codecov.io/gh/alisterburt/napari-mrcfile-reader/branch/master/graph/badge.svg)](https://codecov.io/gh/alisterburt/napari-mrcfile-reader)

Read MRC format image files into napari using the [mrcfile] package from [CCP-EM]

----------------------------------
![example usage](example.gif)
----------------------------------

This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.


## Installation

You can install `napari-mrcfile-reader` via [pip]:

    pip install napari-mrcfile-reader

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-mrcfile-reader"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.


[CCP-EM]: https://www.ccpem.ac.uk/
[mrcfile]: https://github.com/ccpem/mrcfile
[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/alisterburt/napari-mrcfile-reader/issues
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/alisterburt/napari-mrcfile-reader/issues', 'Documentation, https://github.com/alisterburt/napari-mrcfile-reader#README.md', 'Source Code, https://github.com/alisterburt/napari-mrcfile-reader', 'User Support, https://github.com/alisterburt/napari-mrcfile-reader/issues']",napari-mrcfile-reader.get_reader,,,,"['*.mrc', '*.mrcs', '*.map', '*.st', '*.rec', '*.preali', '*.ali']",,,https://pypi.org/project/napari-mrcfile-reader,https://github.com/alisterburt/napari-mrcfile-reader,
216,napari-multitask,0.0.2,2022-02-24,2023-06-18,napari-multitask,Hanjin Liu,liuhanjin-sc@g.ecc.u-tokyo.ac.jp,BSD 3-Clause,https://pypi.org/project/napari-multitask/,Multitasking in napari,>=3.8,['magic-class (>=0.5.11)'],"# napari-multitask

Multitasking on napari.

![](https://github.com/hanjinliu/napari-multitask/raw/main/Figs/output.gif)

Layers and opened dock widgets are stored in the task panels below. Switch your tasks at any time.

# Installation

```
pip install napari-multitask
```


","['Framework :: napari', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9']",,,,napari-multitask.TaskView,,,,,https://pypi.org/project/napari-multitask/,,
217,Napari Mzarr,0.0.3,2023-10-23,2023-10-23,napari-mzarr,Karol Gotkowski,karol.gotkowski@dkfz.de,Apache-2.0,https://pypi.org/project/napari-mzarr,A reader and writer plugin for the Mzarr image format.,>=3.8,"['numpy', 'zarr', 'numcodecs', 'imagecodecs ==2023.1.23', 'dask', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'""]","# napari-mzarr

[![License Apache Software License 2.0](https://img.shields.io/pypi/l/napari-mzarr.svg?color=green)](https://github.com/Karol-G/napari-mzarr/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-mzarr.svg?color=green)](https://pypi.org/project/napari-mzarr)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-mzarr.svg?color=green)](https://python.org)
[![tests](https://github.com/Karol-G/napari-mzarr/workflows/tests/badge.svg)](https://github.com/Karol-G/napari-mzarr/actions)
[![codecov](https://codecov.io/gh/Karol-G/napari-mzarr/branch/main/graph/badge.svg)](https://codecov.io/gh/Karol-G/napari-mzarr)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-mzarr)](https://napari-hub.org/plugins/napari-mzarr)

A reader and writer plugin for the Mzarr image format.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-mzarr` via [pip]:

    pip install napari-mzarr




## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [Apache Software License 2.0] license,
""napari-mzarr"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: Apache Software License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']",,napari-mzarr.get_reader,napari-mzarr.write_multiple,,,"['*.mzarr', '*.mzz']",,['.mzarr'],https://pypi.org/project/napari-mzarr,,
218,napari n2v,0.1.1,2022-12-30,2023-09-06,napari-n2v,"Tom Burke, Joran Deschamps",joran.deschamps@fht.org,BSD-3-Clause,https://github.com/juglab/napari-n2v,A self-supervised denoising algorithm now usable by all in napari.,>=3.8,"['scikit-image', 'bioimageio.core', 'n2v >=0.3.2', 'napari-time-slicer >=0.4.9', 'napari', 'qtpy', 'pyqtgraph', 'tensorflow >=2.10.0 ; platform_system != ""Darwin"" or platform_machine != ""arm64""', 'tensorflow-macos ; platform_system == ""Darwin"" and platform_machine == ""arm64""', 'tensorflow-metal ; platform_system == ""Darwin"" and platform_machine == ""arm64""', 'numpy <1.24.0 ; python_version < ""3.9""', 'numpy ; python_version >= ""3.9""', ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-n2v

[![License](https://img.shields.io/pypi/l/napari-n2v.svg?color=green)](https://github.com/juglab/napari-n2v/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-n2v.svg?color=green)](https://pypi.org/project/napari-n2v)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-n2v.svg?color=green)](https://python.org)
[![tests](https://github.com/juglab/napari-n2v/workflows/build/badge.svg)](https://github.com/juglab/napari-n2v/actions)
[![codecov](https://codecov.io/gh/juglab/napari-n2v/branch/main/graph/badge.svg)](https://codecov.io/gh/juglab/napari-n2v)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-n2v)](https://napari-hub.org/plugins/napari-n2v)

A self-supervised denoising algorithm now usable by all in napari.

<img src=""https://raw.githubusercontent.com/juglab/napari-n2v/master/docs/images/noisy_denoised.png"" width=""800"" />
----------------------------------

## Installation

Check out the [documentation](https://juglab.github.io/napari-n2v/installation.html) for more detailed installation 
instructions. 

You can then start the napari plugin by clicking on ""Plugins > napari_n2v > Training"",
or run the plugin directly from a [script](scripts/start_plugin.py).



## Quick demo

You can try out a demo by loading the `N2V Demo prediction` plugin and directly clicking on `Predict`. This model was trained using the [N2V2 example](https://juglab.github.io/napari-n2v/examples.html).


<img src=""https://raw.githubusercontent.com/juglab/napari-n2v/master/docs/images/demo.gif"" width=""800"" />


## Documentation

Documentation is available on the [project website](https://juglab.github.io/napari-n2v/).


## Contributing and feedback

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request. You can also 
help us improve by [filing an issue] along with a detailed description or contact us
through the [image.sc](https://forum.image.sc/) forum (tag @jdeschamps).


## Citations

### N2V

Alexander Krull, Tim-Oliver Buchholz, and Florian Jug. ""[Noise2void-learning denoising from single noisy images.](https://ieeexplore.ieee.org/document/8954066)"" 
*Proceedings of the IEEE/CVF conference on computer vision and pattern recognition*. 2019.

### structN2V

Coleman Broaddus, et al. ""[Removing structured noise with self-supervised blind-spot networks.](https://ieeexplore.ieee.org/document/9098336)"" *2020 IEEE 17th 
International Symposium on Biomedical Imaging (ISBI)*. IEEE, 2020.

### N2V2

Eva Hoeck, Tim-Oliver Buchholz, et al. ""[N2V2 - Fixing Noise2Void Checkerboard Artifacts with Modified Sampling Strategies and a Tweaked Network Architecture](https://arxiv.org/abs/2211.08512)"", arXiv (2022). 

## Acknowledgements

This plugin was developed thanks to the support of the Silicon Valley Community Foundation (SCVF) and the 
Chan-Zuckerberg Initiative (CZI) with the napari Plugin Accelerator grant _2021-240383_.


Distributed under the terms of the [BSD-3] license,
""napari-n2v"" is a free and open source software.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[filing an issue]: https://github.com/juglab/napari-n2v/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Framework :: napari', 'Development Status :: 4 - Beta', 'Intended Audience :: Science/Research', 'Topic :: Scientific/Engineering :: Image Processing', 'Topic :: Scientific/Engineering :: Information Analysis', 'Programming Language :: Python', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/juglab/napari-n2v/issues', 'Documentation, https://juglab.github.io/napari-n2v/', 'Source Code, https://github.com/juglab/napari-n2v', 'User Support, https://github.com/juglab/napari-n2v/issues']",,,napari-n2v.make_n2v_trainwidget,napari-n2v.data_2D,,,,https://pypi.org/project/napari-n2v,https://github.com/juglab/napari-n2v,
219,napari NanoPyx,0.1.4,,,napari-nanopyx,"Ricardo Henriques, Bruno Saraiva, Inês Cunha, António Brito",bruno.msaraiva2@gmail.com,LGPL-3.0-only,,"napari plugin of Nanoscopy Python library (NanoPyx, the successor to NanoJ) - focused on light microscopy and super-resolution imaging",>=3.9,"['napari', 'nanopyx >=0.3.1', 'scikit-image', 'magicgui', ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'""]","# napari-nanopyx

<img src=""https://github.com/HenriquesLab/NanoPyx/blob/main/.github/logo.png"" align=""right"" width=""230""/>

[![License](https://img.shields.io/github/license/HenriquesLab/NanoPyx?color=Green)](https://github.com/HenriquesLab/NanoPyx/blob/main/LICENSE.txt)
[![PyPI](https://img.shields.io/pypi/v/napari-nanopyx.svg?color=green)](https://pypi.org/project/napari-nanopyx)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-nanopyx.svg?color=green)](https://python.org)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-nanopyx)](https://napari-hub.org/plugins/napari-nanopyx)
[![Docs](https://img.shields.io/badge/documentation-link-blueviolet)](https://github.com/HenriquesLab/napari-NanoPyx/wiki/3.-Methods)
[![Wiki](https://img.shields.io/badge/wiki-click_me-blue)](https://github.com/HenriquesLab/napari-NanoPyx/wiki)

napari plugin of [NanoPyx](https://github.com/HenriquesLab/NanoPyx) (the successor to NanoJ) - focused on light microscopy and super-resolution imaging.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

## What is the NanoPyx 🔬 Library?

NanoPyx is a library specialized in the analysis of light microscopy and super-resolution data.
It is a successor to [NanoJ](https://github.com/HenriquesLab/NanoJ-Core), which is a Java library for the analysis of super-resolution microscopy data.

NanoPyx focuses on performance, by heavily exploiting cython aided multiprocessing and simplicity. It implements methods for the bioimage analysis field, with a special emphasis on those developed by the [Henriques Laboratory](https://henriqueslab.github.io/).
It will be distributed as a Python Library and also as [Codeless Jupyter Notebooks](https://github.com/HenriquesLab/NanoPyx#codeless-jupyter-notebooks-available), that can be run locally or on Google Colab, and as a [napari plugin](https://github.com/HenriquesLab/napari-NanoPyx).

You can read more about NanoPyx in our [preprint](https://www.biorxiv.org/content/10.1101/2023.08.13.553080v1).

Currently it implements the following approaches:
- A reimplementation of the NanoJ image registration, SRRF and Super Resolution metrics
- eSRRF
- Non-local means denoising
- More to come soon™

if you found this work useful, please cite: [preprint](https://www.biorxiv.org/content/10.1101/2023.08.13.553080v1) and  [![DOI](https://zenodo.org/badge/505388398.svg)](https://zenodo.org/badge/latestdoi/505388398)

## Installation

You can install `napari-nanopyx` via [pip]:

    pip install napari-nanopyx

## User Documentation

You can find installation and usage instructions in the [wiki](https://github.com/HenriquesLab/napari-NanoPyx/wiki).

## Contributing

Contributions are very welcome.
Please read our [Contribution Guidelines](https://github.com/HenriquesLab/NanoPyx/blob/main/CONTRIBUTING.md) to know how to proceed.

## License

Distributed under the terms of the [CC-By v4.0] license,
""napari-nanopyx"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[CC-By v4.0]: https://creativecommons.org/licenses/by/4.0/
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/

## Citing

If you found this work useful, please cite: [preprint](https://www.biorxiv.org/content/10.1101/2023.08.13.553080v1) and  [![DOI](https://zenodo.org/badge/505388398.svg)](https://zenodo.org/badge/latestdoi/505388398)
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: GNU Lesser General Public License v3 (LGPLv3)', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Topic :: Software Development :: Testing']","['Bug Tracker, https://github.com/HenriquesLab/napari-NanoPyx/issues', 'Documentation, https://github.com/HenriquesLab/napari-NanoPyx/wiki', 'Source Code, https://github.com/HenriquesLab/napari-NanoPyx', 'User Support, https://github.com/HenriquesLab/napari-NanoPyx/issues']",,,napari-nanopyx.benchmark,,,,,https://pypi.org/project/napari-nanopyx,,
220,Napari Napari,0.0.1,2023-08-01,2023-08-01,napari-napari,Jordao Bragantini,jordao.bragantini@gmail.com,BSD-3-Clause,https://github.com/jookuma/napari-napari,A napari viewer of the napari viewer,>=3.8,"['numpy', 'magicgui', 'qtpy', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# [napari-napari](https://github.com/jookuma/napari-napari)

[![License BSD-3](https://img.shields.io/pypi/l/napari-napari.svg?color=green)](https://github.com/jookuma/napari-napari/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-napari.svg?color=green)](https://pypi.org/project/napari-napari)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-napari.svg?color=green)](https://python.org)
[![tests](https://github.com/jookuma/napari-napari/workflows/tests/badge.svg)](https://github.com/jookuma/napari-napari/actions)
[![codecov](https://codecov.io/gh/jookuma/napari-napari/branch/main/graph/badge.svg)](https://codecov.io/gh/jookuma/napari-napari)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-napari)](https://napari-hub.org/plugins/napari-napari)

A viewer of the napari viewer.

https://user-images.githubusercontent.com/21022743/233817006-67ab4165-0b9a-46aa-9731-5964448252de.mp4

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-napari` via [pip]:

    pip install napari-napari



To install latest development version :

    pip install git+https://github.com/jookuma/napari-napari.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-napari"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/jookuma/napari-napari/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/jookuma/napari-napari/issues', 'Documentation, https://github.com/jookuma/napari-napari#README.md', 'Source Code, https://github.com/jookuma/napari-napari', 'User Support, https://github.com/jookuma/napari-napari/issues']",,,napari-napari.napari,,,,,https://pypi.org/project/napari-napari,https://github.com/jookuma/napari-napari,
221,NASA sample images,0.0.5,2022-08-18,2023-06-18,napari-nasa-samples,Loic A. Royer,royerloic@gmail.com,MPL-2.0,https://github.com/royerloic/napari-nasa-samples,This napari plugin provides sample datasets from NASA.,>=3.8,"['numpy', 'requests', 'pillow', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'""]","# napari-nasa-samples

[![License Mozilla Public License 2.0](https://img.shields.io/pypi/l/napari-nasa-samples.svg?color=green)](https://github.com/royerlab/napari-nasa-samples/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-nasa-samples.svg?color=green)](https://pypi.org/project/napari-nasa-samples)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-nasa-samples.svg?color=green)](https://python.org)
[![tests](https://github.com/royerloic/napari-nasa-samples/workflows/tests/badge.svg)](https://github.com/royerlab/napari-nasa-samples/actions)
[![codecov](https://codecov.io/gh/royerloic/napari-nasa-samples/branch/main/graph/badge.svg)](https://codecov.io/gh/royerlab/napari-nasa-samples)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-nasa-samples)](https://napari-hub.org/plugins/napari-nasa-samples)

This napari plugin written [by Loic A. Royer](https://twitter.com/loicaroyer) provides sample datasets from NASA.
In particular, you can access directly from napari the recently released images for the [James Webb Space Telescope](https://webb.nasa.gov/), as well as
some of the classic and most beautiful images obtained by the venerable and still strong [Hubble Space Telescope](https://hubblesite.org/). 
More images will be added over time.

Thanks to (NASA)[https://www.nasa.gov/] for releasing these incredible images!

![](https://github.com/royerloic/napari-nasa-samples/raw/main/docs/images/teaser.gif)

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/index.html
-->

## Installation

You can install `napari-nasa-samples` via [pip]:

    pip install napari-nasa-samples



To install latest development version :

    pip install git+https://github.com/royerloic/napari-nasa-samples.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [Mozilla Public License 2.0] license,
""napari-nasa-samples"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/royerlab/napari-nasa-samples/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: Mozilla Public License 2.0 (MPL 2.0)', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/royerloic/napari-nasa-samples/issues', 'Documentation, https://github.com/royerloic/napari-nasa-samples#README.md', 'Source Code, https://github.com/royerloic/napari-nasa-samples', 'User Support, https://github.com/royerloic/napari-nasa-samples/issues']",,,,napari-nasa-samples.messier_101,,,,https://pypi.org/project/napari-nasa-samples,https://github.com/royerloic/napari-nasa-samples,
222,Annotation Toolbox,0.2.3,2022-07-11,2023-06-18,napari-nD-annotator,"David Bauer, Jozsef Molnar, Dominik Hirling",dbauer@brc.hu,BSD-3-Clause,https://github.com/bauerdavid/napari-nD-annotator,A toolbox for annotating objects one by one in nD,>=3.8,"['numpy', 'magicgui', 'qtpy', 'opencv-python', 'matplotlib', 'napari >=0.4.11', 'scikit-image >=0.19', 'SimpleITK', ""napari-bbox ; extra == 'all'"", ""minimal-surface ; extra == 'all'"", ""napari-bbox ; extra == 'bbox'"", ""minimal-surface ; extra == 'ms'"", ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'"", ""numpy ; extra == 'testing'""]","# napari-nD-annotator

[![License BSD-3](https://img.shields.io/pypi/l/napari-nD-annotator.svg?color=green)](https://github.com/bauerdavid/napari-nD-annotator/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-nD-annotator.svg?color=green)](https://pypi.org/project/napari-nD-annotator)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-nD-annotator.svg?color=green)](https://python.org)
[![tests](https://github.com/bauerdavid/napari-nD-annotator/workflows/tests/badge.svg)](https://github.com/bauerdavid/napari-nD-annotator/actions)
[![codecov](https://codecov.io/gh/bauerdavid/napari-nD-annotator/branch/main/graph/badge.svg)](https://codecov.io/gh/bauerdavid/napari-nD-annotator)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-nD-annotator)](https://napari-hub.org/plugins/napari-nD-annotator)

**A toolbox for annotating objects one by one in nD.**

This plugin contains some tools to make 2D/3D (and technically any dimensional) annotation easier.
Main features:
 * auto-filling labels
 * label slice interpolation (geometric mean, RPSV representation)
 * minimal contour segmentation

If the <code>[napari-bbox]</code> plugin is also installed (see [Installation](#installation)), you can also
 * list objects annotated with bounding boxes 
 * visualize selected objects from different projections

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/index.html
-->

## Installation

You can install `napari-nD-annotator` via [pip]:

    pip install napari-nD-annotator

The plugin is also available in [napari-hub], to install it directly from napari, please refer to
[plugin installation instructions] at the official [napari] website.


### Optional packages
There are some functionalities which require additional Python packages.

#### Bounding boxes
The bounding box and object list functionality requires the <code>[napari-bbox]</code> Python package.
If you want to use these features, install <code>[napari-bbox]</code> separately either using [pip] or directly from napari.
You can also install it together with this plugin:
```
pip install napari-nD-annotator[bbox]
```
> [!WARNING]
> The <code>[napari-bbox]</code> plugin currently works only with `napari<=0.4.17`. Do not install it with newer versions.

#### Minimal surface
To use the minimal surface method, you will need the <code>[minimal-surface]</code> Python package as well. Please install it using [pip]:

Separately:
```
pip install minimal-surface
```

Or bundled with the plugin:
```
pip install napari-nD-annotator[ms]
```
> [!WARNING]
> The <code>[minimal-surface]</code> package is only available for Windows at the time. We are actively working on bringing it to Linux and Mac systems as well.

#

If you would like to install all optional packages, use
```
pip install napari-nD-annotator[all]
```
###
If any problems occur during installation or while using the plugin, please [file an issue].

## Usage
You can start napari with the plugin's widgets already opened as:

    napari -w napari-nD-annotator ""Object List"" ""Annotation Toolbox""


### Bounding boxes
The main idea is to create bounding boxes around objects we want to annotate, crop them, and annotate them one by one. This has mainly two advantages when visualizing in 3D:

1. We don't have to load the whole data into memory
2. The surrounding objects won't occlude the annotated ones, making it easier to check the annotation.

Bounding boxes can be created from the `Object list` widget. The dimensionality of the bounding box layer will be determined from the image layer. As bounding boxes are created, a small thumbnail will be displayed.

The proposed pipeline goes as follows:

 1. Create a bounding box layer
 2. Select data parts using the bounding boxes
 3. Select an object from the object list
 4. Annotate the object
 5. Repeat from 3.

### Slice interpolation
The `Interpolation` tab contains tools for estimating missing annotation slices from existing ones. There are multiple options:
 * Geometric: the interpolation will be determined by calculating the average of the corresponding contour points.
 * RPSV: A more sophisticated average contour calculation, see the preprint [here](https://arxiv.org/pdf/1901.02823.pdf).
 * Distance-based: a signed distance transform is applied to the annotations. The missing slices will be filled in using their 
weighted sum.

> **Note**: Geometric and RPSV interpolation works only when there's a single connected mask on each slice. If you want to 
> interpolate disjoint objects (*e.g.* dividing cells), use distance based interpolation instead.

> **Note**: Distance-based interpolation might give bad results if some masks are too far away from each other on the same slice
> and there's a big offset compared to the other slice used in the interpolation. If you get unsatisfactory results, try
> annotating more slices (skip less frames).

https://user-images.githubusercontent.com/36735863/188876826-1771acee-93ba-4905-982e-bfb459329659.mp4

### Minimal contour
This plugin can estimate a minimal contour, which is calculated from a point set on the edges of the object, which are provided by the user. This contour will follow some kind of image feature (pixels with high gradient or high/low intensity).
Features:
 * With a single click a new point can be added to the set. This will also extend the contour with the curve shown in red
 * A double click will close the curve by adding both the red and gray curves to the minimal contour
 * When holding `Shift`, the gray and red highlight will be swapped, so the other curve can be added to the contour
 * With the `Ctrl` button down a straight line can be added instead of the minimal path
 * If the anchor points were misplaced, the last point can be removed by right-clicking, or the whole point set can be cleared by pressing `Esc`
 * The `Param` value at the widget will decide, how strongly should the contour follow edges on the image. Higher value means higher sensitivity to image data, while a lower value will be closer to straight lines.
 * Different features can be used, like image gradient or pixel intensities, and also user-defined features (using Python)
   * the image is accessed as the `image` variable, and the features should be stored in the `features` variable in the small code editor widget

This functionality can be used by selecting the `Minimal Contour` tab in the `Annotation Toolbox` widget, which will create a new layer called `Anchors`.

> **Warning**: Do not remove the `Anchors` layer!

> **Warning**: Some utility layers appear in the layer list when using the plugin. These are marked with a lock (:lock:) symbol.
> __Do not remove them or modify their data, as this will most probably break the plugin!__ However, you can change their appearance,
> *e.g.* their color settings.

#### Intensity-based:

https://user-images.githubusercontent.com/36735863/191023482-0dfafb5c-003a-47f6-a21b-8582a4e3930f.mp4

#### Gradient-based:

https://user-images.githubusercontent.com/36735863/191024941-f20f63a0-8281-47d2-be22-d1ec34fe1f5d.mp4

#### Custom feature:

https://user-images.githubusercontent.com/36735863/191025028-3f807bd2-1f2e-40d2-800b-48af820a7dbe.mp4

### Shortcuts

| Action                                        | Mouse               | Keyboard       |
|-----------------------------------------------|---------------------|----------------|
| Increment selected label                      | `Shift + Wheel ⬆️`  | `E`            |
| Decrement selected label                      | `Shift + Wheel ⬇️`  | `Q`            |
| Previous slice                                | `Ctrl + Wheel ⬆️`\* | `A`            |
| Next slice                                    | `Ctrl + Wheel ⬇️`\* | `D`            |
| Increase paint brush size of labels layer     | `Alt + Wheel ⬆️`    | `W`            |
| Decrease paint brush size of labels layer     | `Alt + Wheel ⬇️`    | `S`            |
| Interpolate                                   | -                   | `Ctrl+I`       |
| Change between 'Anchors' and the labels layer | -                   | `Ctrl+Tab`     |
| Jump to layer `#i`                            | -                   | `Ctrl+'i'`\*\* |

> *Built-in functionality of [napari]
> 
> **`i`: 0-9

> **Note**: you can check the list of available shortcuts by clicking the `?` button in the bottom right corner of the main widget.

## License

Distributed under the terms of the [BSD-3] license,
""napari-nD-annotator"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[napari-hub]: https://napari-hub.org/
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
[plugin installation instructions]: https://napari.org/plugins/find_and_install_plugin.html
[file an issue]: https://github.com/bauerdavid/napari-nD-annotator/issues/new/choose
[napari-bbox]: https://github.com/bauerdavid/napari-bbox
[minimal-surface]: https://pypi.org/project/minimal-surface
","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: C', 'Programming Language :: Cython', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Programming Language :: Python :: Implementation :: CPython', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/bauerdavid/napari-nD-annotator/issues', 'Documentation, https://github.com/bauerdavid/napari-nD-annotator/blob/main/README.md', 'Source Code, https://github.com/bauerdavid/napari-nD-annotator', 'User Support, https://github.com/bauerdavid/napari-nD-annotator/issues']",,,napari-nD-annotator.annotator_widget,,,,,https://pypi.org/project/napari-nD-annotator,https://github.com/bauerdavid/napari-nD-annotator,
223,napari-nd-cropper,0.1.3,2022-03-06,2023-06-18,napari-nd-cropper,"Marc Boucsein, Robin Koch",,BSD-3-Clause,https://github.com/MBPhys/napari-nd-cropper,A napari plugin in order to crop nd-images via different modes,>=3.9,"['napari-plugin-engine (>=0.1.4)', 'numpy', 'napari-tools-menu', 'qtpy', 'superqt', 'magicgui']","# napari-nd-cropper

[![License](https://img.shields.io/pypi/l/napari-medical-image-formats.svg?color=green)](https://github.com/MBPhys/napari-nd-cropper/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-nd-cropper.svg?color=green)](https://pypi.org/project/napari-nd-cropper)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-nd-cropper.svg?color=green)](https://python.org)


A napari plugin in order to crop nd-images via different modes:

- Cropping via Drag&Drop interaction box (available for napari releases > 0.4.12)
- Cropping of double-clicked regions based on predefined size (Integer or Tuple of integer) 
- Cropping based on view 
- Cropping via Sliders 


----------------------------------

## Installation

You can install `napari-nd-cropper` via [pip]:

    pip install napari-nd-cropper

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-nd-cropper"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/MBPhys/napari-nd-cropper/issues
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/


","['Development Status :: 3 - Alpha', 'Intended Audience :: Science/Research', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/MBPhys/napari-nd-cropper/issues', 'Documentation, https://github.com/MBPhys/napari-nd-cropper', 'Source Code, https://github.com/MBPhys/napari-nd-cropper', 'User Support, https://github.com/MBPhys/napari-nd-cropper/issues']",,,napari-nd-cropper.nd_Cropper,,,,,https://pypi.org/project/napari-nd-cropper,https://github.com/MBPhys/napari-nd-cropper,
224,napari nd2 folder viewer,0.0.13,2022-08-18,2023-06-18,napari-nd2-folder-viewer,Niklas Netter,niknett@gmail.com,BSD-3-Clause,https://github.com/gatoniel/napari-nd2-folder-viewer,Look through separate nd2 files in one viewer.,>=3.8,"['numpy', 'magicgui', 'qtpy', 'pyyaml', 'marshmallow', 'desert', 'nd2 (>=0.4.3)', 'dask', 'pandas', 'openpyxl', 'julian', 'napari-animation', 'scikit-learn', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-nd2-folder-viewer

[![License BSD-3](https://img.shields.io/pypi/l/napari-nd2-folder-viewer.svg?color=green)](https://github.com/gatoniel/napari-nd2-folder-viewer/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-nd2-folder-viewer.svg?color=green)](https://pypi.org/project/napari-nd2-folder-viewer)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-nd2-folder-viewer.svg?color=green)](https://python.org)
[![tests](https://github.com/gatoniel/napari-nd2-folder-viewer/workflows/tests/badge.svg)](https://github.com/gatoniel/napari-nd2-folder-viewer/actions)
[![codecov](https://codecov.io/gh/gatoniel/napari-nd2-folder-viewer/branch/main/graph/badge.svg)](https://codecov.io/gh/gatoniel/napari-nd2-folder-viewer)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-nd2-folder-viewer)](https://napari-hub.org/plugins/napari-nd2-folder-viewer)

Look through separate nd2 files in one viewer.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-nd2-folder-viewer` via [pip]:

    pip install napari-nd2-folder-viewer



To install latest development version :

    pip install git+https://github.com/gatoniel/napari-nd2-folder-viewer.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-nd2-folder-viewer"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/gatoniel/napari-nd2-folder-viewer/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/gatoniel/napari-nd2-folder-viewer/issues', 'Documentation, https://github.com/gatoniel/napari-nd2-folder-viewer#README.md', 'Source Code, https://github.com/gatoniel/napari-nd2-folder-viewer', 'User Support, https://github.com/gatoniel/napari-nd2-folder-viewer/issues']",,,napari-nd2-folder-viewer.make_qwidget,,,,,https://pypi.org/project/napari-nd2-folder-viewer,https://github.com/gatoniel/napari-nd2-folder-viewer,
225,neuralDev,0.6.5,2023-03-30,2023-11-07,napari-ndev,Tim Monko,timmonko@gmail.com,BSD-3-Clause,https://github.com/TimMonko/napari-ndev,A collection of widgets to process images from start to finish--focused on neural development.,>=3.8,"['numpy', 'magicgui', 'qtpy', 'aicsimageio', 'napari', 'apoc', 'pyclesperanto-prototype', 'dask', 'napari-workflows', 'seaborn', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-ndev

[![License BSD-3](https://img.shields.io/pypi/l/napari-ndev.svg?color=green)](https://github.com/TimMonko/napari-ndev/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-ndev.svg?color=green)](https://pypi.org/project/napari-ndev)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-ndev.svg?color=green)](https://python.org)
[![tests](https://github.com/TimMonko/napari-ndev/workflows/tests/badge.svg)](https://github.com/TimMonko/napari-ndev/actions)
[![codecov](https://codecov.io/gh/TimMonko/napari-ndev/branch/main/graph/badge.svg)](https://codecov.io/gh/TimMonko/napari-ndev)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-ndev)](https://napari-hub.org/plugins/napari-ndev)

A collection of widgets intended to serve any person seeking to process microscopy images from start to finish. The wide breadth of this plugin's scope is only made possible by the amazing libraries and plugins from the napari community, especially Robert Haase. Currently, the plugin supports the following goals:

1. **Image-utilities:** Allows opening image files (using aics-imageio) and displaying in napari. Also reads metadata and allows customization prior to saving images and labels layers. Allows concatenation of image files and image layers for saving new images. Speeds up annotation by saving corresponding images and labels in designated folders. Also allows saving of shapes layers as labels in case shapes are being used as a region of interest.
2. **Batch-workflow:** Batch pre-processing/processing images using [napari-workflows].
3. **Batch-APOC:** Utilizes the excellent accelerated-pixel-and-object-classification ([apoc]) in a similar fashion to [napari-apoc], but intended for batch training and prediction with a napari widget instead of scripting.
4. **Rescale-by:** Rescale any napari layer (image, label, shape) by a set amount, which can be inherited from a different image layer's metadata.

----------------------------------

![Plugin-Abstract](/Plugin-Abstract.png)


This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-ndev` via [pip]:

    pip install napari-ndev

----------------------------------

## Further Info

### 1. Image Utilities
A quick and easy way to save annotations (a napari labels layer) and corresponding images to corresponding folders. *Requires* that images are opened with [napari-aicsimageio]--which can be as simple as drag and drop opening by setting the appropriate default reader for each file type in Preferences -> Plugins--in order to utilize the metadata present for saving the image-label pairs. (See Note about AICSImageIO)

Quick uniform adjustments to a folder of images, saving the output. Currently supports selecting channels, slicing Z, cropping/downsampling in XY, and doing a max projection of the sliced/cropped image data. To be added: alternative projection types, slicing in T, and compatability with non TCZYX images (but this is not a priority since [aicsimageio] currently always extracts images as TCZYX even if a dim is only length 1.

### 2. Batch-workflow
Batch pre-processing/processing images using [napari-workflows].  Images are processed outside the napari-viewer using [aicsimageio] as both reader and writer. Prior to passing the images to napari-workflows, the user selects the correct images as the roots (inputs) and thus napari-workflows matches the processing to create the outputs. The advantage of using napari-workflows for batch processing is that it provides an incredibly flexible processing interface without writing a novel widget for small changes to processing steps like specific filters, segmentation, or measurements. Currently only intended for use with images as inputs and images as outputs from napari-workflows, though there is future potential to have other outputs possible, such as .csv measurement arrays.

### 3. Batch-training/prediction
Utilizes the excellent accelerated-pixel-and-object-classification ([apoc]) in a similar fashion to [napari-apoc], but intended for batch training and prediction with a napari widget instead of scripting. Recognizes pre established feature set, and custom feature sets (a string of filters and radii) can be genereated with a corresponding widget.

### A Note about AICSImageIO
[AICSImageIO] is a convenient, multi-format file reader which also has the complimentary [napari-aicsimageio] reader plugin. By default, napari-aicsimageio installs all reader dependencies. Because napari-aicsimageio is not technically required for this plugin to work (you could build your own metadata for the annotation-saver) and just napari-aicsimage is required, the former is not an install requirement. This is to avoid using the GPL liscence and to stick with BSD-3. However, you should install napari-aicsimageio if you want the smoothest operation of the annotation-saver.

----------------------------------

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-ndev"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/

[napari-workflows]: https://github.com/haesleinhuepf/napari-workflows
[apoc]: https://github.com/haesleinhuepf/apoc
[napari-apoc]: https://github.com/haesleinhuepf/napari-accelerated-pixel-and-object-classification
[napari-aicsimageio]: https://github.com/AllenCellModeling/napari-aicsimageio
[AICSImageIO]: https://allencellmodeling.github.io/aicsimageio/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/TimMonko/napari-ndev/issues', 'Documentation, https://github.com/TimMonko/napari-ndev#README.md', 'Source Code, https://github.com/TimMonko/napari-ndev', 'User Support, https://github.com/TimMonko/napari-ndev/issues']",,,napari-ndev.make_utilities_container,,,,,https://pypi.org/project/napari-ndev,https://github.com/TimMonko/napari-ndev,
226,napari-ndtiffs,0.2.1,2022-01-27,2023-06-18,napari-ndtiffs,Talley Lambert,Talley Lambert <talley.lambert@gmail.com>,BSD-3-Clause,https://github.com/tlambert03/napari-ndtiffs,napari plugin for nd tiff folders with OpenCl deskew,>=3.8,"['dask[array]', 'napari-plugin-engine>=0.1.4', 'numpy', 'python-dateutil', 'scipy', 'tifffile', ""black; extra == 'dev'"", ""ipython; extra == 'dev'"", ""mypy; extra == 'dev'"", ""pdbpp; extra == 'dev'"", ""rich; extra == 'dev'"", ""ruff; extra == 'dev'"", ""pyopencl; extra == 'opencl'"", ""pyopencl; extra == 'test'"", ""pytest; extra == 'test'"", ""pytest-cov; extra == 'test'""]","# napari-ndtiffs

[![License](https://img.shields.io/pypi/l/napari-ndtiffs.svg?color=green)](https://raw.githubusercontent.com/tlambert03/napari-ndtiffs/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-ndtiffs.svg?color=green)](https://pypi.org/project/napari-ndtiffs)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-ndtiffs.svg?color=green)](https://python.org)
[![tests](https://github.com/tlambert03/napari-ndtiffs/workflows/tests/badge.svg)](https://github.com/tlambert03/napari-ndtiffs/actions)
[![codecov](https://codecov.io/gh/tlambert03/napari-ndtiffs/branch/main/graph/badge.svg)](https://codecov.io/gh/tlambert03/napari-ndtiffs)

napari plugin for nd tiff folders with optional CUDA or OpenCL-based deskewing.

Built-in support for folders of (skewed) lattice light sheet tiffs.

![napari-ndtiffs demo](https://github.com/tlambert03/napari-ndtiffs/raw/main/demo.gif)

----------------------------------

*This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.*

## Features

- Drag and drop a folder of tiffs onto napari window to view easily 
  - (currently designed to detect  lattice light sheet tiffs, but easily
    adjustable)
- If lattice `Settings.txt` file is found, will deskew automatically (only if
  necessary)
- Lazily loads dataset on demand.  quickly load preview your data.
- Handles `.zip` archives as well!  Just directly compress your tiff folder,
  then drop it into napari.
- All OpenCL deskewing, works on GPU as well as CPU, falls back to scipy if
  [PyOpenCL] is unavailable.
- CuPy-based deskewing will work for cards with NVIDIA GPUs that support CUDA.
  CuPy 8.x releases should work, although CuPy >= 9 is recommended. If [CuPy]
  is unavailable, the [PyOpenCL] implementation is used instead.

It would not be hard to support arbitrary filenaming patterns!  If you have a
folder of tiffs with a consistent naming scheme and would like to take advantage
of this plugin, feel free to open an issue!

## Installation

You can install `napari-ndtiffs` via [pip]:

```shell
pip install napari-ndtiffs
```

To also install PyOpenCL (for faster deskewing):

```shell
pip install napari-ndtiffs[opencl]
```

On NVIDIA GPUs with CUDA support, the [CuPy] implementation may be faster than
[PyOpenCL]. CuPy also has experimental support for AMD GPUs via HIP/ROCm. See
the CuPy [installation instructions](https://docs.cupy.dev/en/stable/install.html)


## Usage

In most cases, just drop your folder onto napari, or use `viewer.open(""path"")`

### Overriding parameters

You can control things like voxel size and deskewing angle as follows:

```python
from napari_ndtiffs import parameter_override
import napari

viewer = napari.Viewer()
with parameter_override(angle=45, name=""my image""):
    viewer.open(""path/to/folder"", plugin=""ndtiffs"")
```

Valid keys for `parameter_override` include:

- **dx**: (`float`) the pixel size, in microns
- **dz**: (`float`)the z step size, in microns
- **deskew**: (`bool`) whether or not to deskew, (by default, will deskew if angle > 0, or if a lattice metadata file is detected that requires deskewing) 
- **angle**: (`float`) the angle of the light sheet relative to the coverslip
- **padval**: (`float`) the value with which to pad the image edges when deskewing (default is 0)
- **contrast_limits**: (`2-tuple of int`) (min, max) contrast_limits to use when viewing the image
- **name**: (`str`) an optional name for the image

### Sample data

Try it out with test data: [download sample data](https://www.dropbox.com/s/up4ywrn2sckjunc/lls_mitosis.zip?dl=1)

You can unzip if you like, or just drag the zip file onto the napari window.

Or, from command line, use:

```bash
napari path/to/lls_mitosis.zip
```

## Debugging

To monitor file io and deskew activity, enter the following in the napari console:

```python
import logging
logging.getLogger('napari_ndtiffs').setLevel('DEBUG')
```


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-ndtiffs"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/tlambert03/napari-ndtiffs/issues
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
[PyOpenCL]: https://documen.tician.de/pyopencl/
[CuPy]: https://docs.cupy.dev/
","['Development Status :: 3 - Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10']","['Bug Tracker, https://github.com/tlambert03/napari-ndtiffs/issues', 'Documentation, https://github.com/tlambert03/napari-ndtiffs#README.md', 'Source Code, https://github.com/tlambert03/napari-ndtiffs', 'User Support, https://github.com/tlambert03/napari-ndtiffs/issues']",napari-ndtiffs.get_reader,,,,['*'],,,https://pypi.org/project/napari-ndtiffs,https://github.com/tlambert03/napari-ndtiffs,
227,Napari NiBabel,0.1.0,2023-04-11,2023-06-18,napari-nibabel,Ashley Anderson,aandersoniii@chanzuckerberg.com,MIT,https://pypi.org/project/napari-nibabel/,Read access to some common neuroimaging file formats,>=3.8,"['numpy', 'nibabel[dicom,dicomfs,spm]', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'""]","# napari-nibabel

[![License MIT](https://img.shields.io/pypi/l/napari-nibabel.svg?color=green)](https://github.com/aganders3/napari-nibabel/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-nibabel.svg?color=green)](https://pypi.org/project/napari-nibabel)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-nibabel.svg?color=green)](https://python.org)
[![tests](https://github.com/aganders3/napari-nibabel/workflows/tests/badge.svg)](https://github.com/aganders3/napari-nibabel/actions)
[![codecov](https://codecov.io/gh/aganders3/napari-nibabel/branch/main/graph/badge.svg)](https://codecov.io/gh/aganders3/napari-nibabel)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-nibabel)](https://napari-hub.org/plugins/napari-nibabel)

Read access to some common neuroimaging file formats, thanks to the
[NiBabel](https://nipy.org/nibabel/) and [pydicom](https://pydicom.github.io/)
libraries.

Also check out [napari-medical-image-formats](https://www.napari-hub.org/plugins/napari-medical-image-formats)!

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.


## Installation

You can install `napari-nibabel` via [pip]:

    pip install napari-nibabel


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [MIT] license,
""napari-nibabel"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: MIT License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']",,napari-nibabel.get_reader,,,,"['*.par', '*.hdr', '*.nii', '*.nii.gz', '*.gii', '*.dcm']",,,https://pypi.org/project/napari-nibabel/,,
228,napari-nifti,0.0.12,2023-04-19,2023-07-26,napari-nifti,Karol Gotkowski,karol.gotkowski@dkfz.de,Apache-2.0,https://github.com/MIC-DKFZ/napari-nifti,A napari plugin for reading and writing NIFTI files that have the extension .nii or .nii.gz.,>=3.8,"['numpy', 'SimpleITK', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'""]","# napari-nifti

[![License Apache Software License 2.0](https://img.shields.io/pypi/l/napari-nifti.svg?color=green)](https://github.com/MIC-DKFZ/napari-nifti/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-nifti.svg?color=green)](https://pypi.org/project/napari-nifti)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-nifti.svg?color=green)](https://python.org)
[![tests](https://github.com/MIC-DKFZ/napari-nifti/workflows/tests/badge.svg)](https://github.com/MIC-DKFZ/napari-nifti/actions)
[![codecov](https://codecov.io/gh/MIC-DKFZ/napari-nifti/branch/main/graph/badge.svg)](https://codecov.io/gh/MIC-DKFZ/napari-nifti)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-nifti)](https://napari-hub.org/plugins/napari-nifti)

A napari plugin for reading and writing NIFTI files that have the extension .nii or .nii.gz.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-nifti` via [pip]:

    pip install napari-nifti



To install latest development version :

    pip install git+https://github.com/MIC-DKFZ/napari-nifti.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [Apache Software License 2.0] license,
""napari-nifti"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/MIC-DKFZ/napari-nifti/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/

# Acknowledgements
<img src=""HI_Logo.png"" height=""100px"" />

<img src=""dkfz_logo.png"" height=""100px"" />

napari-nifti is developed and maintained by the Applied Computer Vision Lab (ACVL) of [Helmholtz Imaging](http://helmholtz-imaging.de) 
and the [Division of Medical Image Computing](https://www.dkfz.de/en/mic/index.php) at the 
[German Cancer Research Center (DKFZ)](https://www.dkfz.de/en/index.html).
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: Apache Software License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/MIC-DKFZ/napari-nifti/issues', 'Documentation, https://github.com/MIC-DKFZ/napari-nifti#README.md', 'Source Code, https://github.com/MIC-DKFZ/napari-nifti', 'User Support, https://github.com/MIC-DKFZ/napari-nifti/issues']",napari-nifti.get_reader,napari-nifti.write_single_image,,,"['*.nii', '*.nii.gz']","['.nii', '.nii.gz']","['.nii', '.nii.gz']",https://pypi.org/project/napari-nifti,https://github.com/MIC-DKFZ/napari-nifti,
229,napari-nikon-nd2,0.1.3,2022-02-07,2023-06-18,napari-nikon-nd2,Chris Wood,cwood1967@gmail.com,Apache Software License 2.0,https://github.com/cwood1967/napari-nikon-nd2,Opens Nikon ND2 files into napari.,>=3.6,"['napari-plugin-engine (>=0.1.4)', 'numpy', 'nd2reader']","# napari-nikon-nd2

[![License](https://img.shields.io/pypi/l/napari-nikon-nd2.svg?color=green)](https://github.com/cwood1967/napari-nikon-nd2/blob/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-nikon-nd2.svg?color=green)](https://pypi.org/project/napari-nikon-nd2)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-nikon-nd2.svg?color=green)](https://python.org)
[![tests](https://github.com/cwood1967/napari-nikon-nd2/workflows/tests/badge.svg)](https://github.com/cwood1967/napari-nikon-nd2/actions)
[![codecov](https://codecov.io/gh/cwood1967/napari-nikon-nd2/branch/main/graph/badge.svg)](https://codecov.io/gh/cwood1967/napari-nikon-nd2)

Opens Nikon ND2 files into napari. This plugin uses the [nd2reader] and [pims] python packages. 

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/docs/plugins/index.html
-->

## Installation

You can install `napari-nikon-nd2` via [pip]:

    pip install napari-nikon-nd2

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [Apache Software License 2.0] license,
""napari-nikon-nd2"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

## Credits

This [napari] plugin was created using [Napari Delta Vision Reader] and
the [Allen Institute IO] plugin as examples.


[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/cwood1967/napari-nikon-nd2/issues
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
[nd2reader]: https://github.com/rbnvrw/nd2reader
[pims]: https://github.com/soft-matter/pims
[Allen Institute IO]: https://github.com/AllenCellModeling/napari-aicsimageio
[Napari Delta Vision Reader]: https://github.com/tlambert03/napari-dv

","['Development Status :: 4 - Beta', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: Apache Software License']",,napari-nikon-nd2.napari_get_reader,,,,['*'],,,https://pypi.org/project/napari-nikon-nd2,https://github.com/cwood1967/napari-nikon-nd2,
230,napari NLM,0.0.4,2023-07-13,2023-07-13,napari-nlm,Martin Weigert,marweigert@gmail.com,BSD-3-Clause,https://github.com/maweigert/napari-nlm,NLM (non local means) denoising,>=3.8,"['numpy', 'magicgui', 'qtpy', 'pyopencl (==2022.1.5)', 'gputools', 'scikit-image', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-nlm

[![License BSD-3](https://img.shields.io/pypi/l/napari-nlm.svg)](https://github.com/maweigert/napari-nlm/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-nlm.svg)](https://pypi.org/project/napari-nlm)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-nlm.svg)](https://python.org)
[![tests](https://github.com/maweigert/napari-nlm/workflows/tests/badge.svg)](https://github.com/maweigert/napari-nlm/actions)
[![codecov](https://codecov.io/gh/maweigert/napari-nlm/branch/main/graph/badge.svg)](https://codecov.io/gh/maweigert/napari-nlm)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-nlm)](https://napari-hub.org/plugins/napari-nlm)

----------------------------------


GPU accelerated non local means (NLM) denoising plugin for napari (WIP)

* currently only supports single-channel 2D or 3D images
* requires a OpenCL capable GPU

![Screenshot](images/screenshot.jpg)


## Installation

You can install `napari-nlm` via [pip]:

    pip install napari-nlm

## Usage

1. Open example image `Open Sample > napari-nlm: noisy bricks`
2. Adjust parameters 
   * `sigma`: denoising strength (the larger sigma, the greater the smoothing)
   * `patch_radius`: size of local patches, 2 or 3 is a good default
   * `search_radius`: size of search area around each pixel to find similar patches, 7-11 is a good default
3. Denoise by pressing `run`


## License

Distributed under the terms of the [BSD-3] license,
""napari-nlm"" is free and open source software
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/maweigert/napari-nlm/issues', 'Documentation, https://github.com/maweigert/napari-nlm#README.md', 'Source Code, https://github.com/maweigert/napari-nlm', 'User Support, https://github.com/maweigert/napari-nlm/issues']",,,napari-nlm.denoise_nlm,napari-nlm.make_sample_data_2d,,,,https://pypi.org/project/napari-nlm,https://github.com/maweigert/napari-nlm,
231,Napari nucleAIzer plugin,0.2.5,,,napari-nucleaizer,Ervin Tasnadi,tasnadi.ervin@brc.hu,BSD-3,,A GUI interface for training and prediction using the nucleAIzer nuclei detection method.,>=3.8,"['napari', 'qtpy', 'jsonpickle', 'numpy', 'scikit-image', 'imageio', 'nucleaizer-backend']","# napari_nucleaizer

[![License](https://img.shields.io/pypi/l/napari-nucleaizer.svg?color=green)](https://github.com/etasnadi/napari-nucleaizer/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-nucleaizer.svg?color=green)](https://pypi.org/project/napari-nucleaizer)
[![Python package](https://github.com/etasnadi/napari_nucleaizer/actions/workflows/test_and_deploy.yml/badge.svg)](https://github.com/etasnadi/napari_nucleaizer/actions/workflows/test_and_deploy.yml)
[![codecov](https://codecov.io/gh/etasnadi/napari_nucleaizer/branch/master/graph/badge.svg?token=5XC36PA6OQ)](https://codecov.io/gh/etasnadi/napari_nucleaizer)
[![Documentation Status](https://readthedocs.org/projects/napari-nucleaizer-docs/badge/?version=latest)](https://napari-nucleaizer-docs.readthedocs.io/en/latest/?badge=latest)

<!--
[![Python Version](https://img.shields.io/pypi/pyversions/napari-nucleaizer.svg?color=green)](https://python.org)
[![tests](https://github.com/etasnadi/napari_nucleaizer/workflows/tests/badge.svg)](https://github.com/etasnadi/napari-nucleaizer/actions)
[![codecov](https://codecov.io/gh/etasnadi/napari-nucleaizer/branch/master/graph/badge.svg)](https://codecov.io/gh/etasnadi/napari-nucleaizer)
-->

GUI for the nucleaAIzer method in Napari.

![Plugin interface in napari.](https://github.com/etasnadi/napari_nucleaizer/blob/main/napari_screenshot.png?raw=true)

## Overview

This is a napari plugin to execute the nucleaizer nuclei segmentation algorithm.

### Main functionalities

Using this plugin will be able to

1. Load your image into Napar, then outline the nuclei.
2. Specify an image folder containing lots of images and an output folder, and automatically segment all of the images in the input folder.
3. If you are not satisfied with the results, you can train your own model:
    1. You can use our pretrained models and fine tune them on your data.
    2. You can skip the nucleaizer pipeline and train only on your data.


### Supported image types

We have several pretrained models for the following image modelities:
* fluorescent microscopy images
* IHC stained images
* brightfield microscopy images,

among others. For the detailed descriptions of our models, see: https://zenodo.org/record/6800341.

### How it works?

For the description of the algorithm, see our paper: ""Hollandi et al.: nucleAIzer: A Parameter-free Deep Learning Framework for Nucleus Segmentation Using Image Style Transfer, Cell Systems, 2020. https://doi.org/10.1016/j.cels.2020.04.003""

The original code (https://github.com/spreka/biomagdsb) is partially transformed into a python package (nucleaizer_backend) to actually perform the operations. See the project page of the backend at: https://github.com/etasnadi/nucleaizer_backend.

If you wish to use the web interface, check: http://nucleaizer.org.

![All functionalities.](https://github.com/etasnadi/napari_nucleaizer/blob/main/nucleaizer_screenshot.png?raw=true)

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/docs/plugins/index.html
-->

## Install

1. Create an environment (recommended).

2. Install napari: `pip install ""napari[pyqt5]""`. Other methods: https://napari.org/tutorials/fundamentals/installation.html

3. Install the plugin into napari:

    * User mode from [PyPI](https://pypi.org/project/napari-nucleaizer/): start Napari (command line: `napari`) and select he **Install/Uninstall Plugins...** under the **Plugins** menu. In the popup, filter for `napari-nucleaizer`.

    * Developer mode: clone this project and use `pythhon3 -m pip install -e <path>` to install the project locally **into the same evnrionment as napari**. It has the advantage that you will have the latest version.
## Run

1. Start Napari by calling `napari` from the command line.
2. Then, activate the plugin in the `Plugins` menu. If you successfully installed the plugin, you have to see something like this:

![Plugin interface in napari.](https://github.com/etasnadi/napari_nucleaizer/blob/main/napari_plugin_launch.png?raw=true)

## Further help

See the [documentation](https://napari-nucleaizer-docs.readthedocs.io/en/latest/index.html) (work in progress).

## Issues

Use the github issue tracker if you experinece unexpected behaviour.

## Contact

You can contact me in [e-mail](mailto:tasnadi.ervin@MY-INSTITUTE) where MY-INSTITUTE is `brc.hu`.
","['Development Status :: 3 - Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/etasnadi/napari_nucleaizer/issues', 'Documentation, https://napari-nucleaizer-docs.readthedocs.io/en/latest/index.html', 'Source Code, https://github.com/etasnadi/napari_nucleaizer', 'User Support, https://github.com/etasnadi/napari_nucleaizer/issues']",,,napari-nucleaizer.launch,,,,,https://pypi.org/project/napari-nucleaizer,,
232,napari-nyxus,0.1.3,,,napari-nyxus,Jesse McKinzie,Jesse.McKinzie@axleinfo.com,,,A napari plugin for calculating features from intensity-label image data,,"['napari', 'pandas', 'numpy', 'nyxus >=0.5.0', 'imagecodecs', 'magicgui', 'napari-workflows', 'qtpy', 'superqt', 'napari-skimage-regionprops >=0.10.1']","# Nyxus Napari

Nyxus Napari is a Napari plugin for running feature calculations on image-segmentation image pairs, using the
Nyxus application to compute features. Nyxus is a feature-rich, highly optimized, Python/C++ application capable 
of analyzing images of arbitrary size and assembling complex regions of interest (ROIs) split across multiple image tiles and files. 

For more information on Nyxus, see https://github.com/PolusAI/nyxus.
 
# Installation 

To install Napari, it is recommended to first create a separate Conda environment. 

```
conda create -y -n napari-env -c conda-forge python=3.9
conda activate napari-env
```

After creating the Conda environment,
install Napari using pip

```
python -m pip install ""napari[all]""
python -m pip install ""napari[all]"" --upgrade
```

or using conda

```
conda install -c conda-forge napari
conda update napari
```

Next, Nyxus must be installed. Note that the version of Nyxus must be greater than or equal to `0.50` to run the Napari plugin.

`pip install nyxus`

or build from source using the instructions at https://github.com/PolusAI/nyxus#building-from-source using the conda build for the
python API.

After installing Napari and Nyxus, the Nyxus Napari plugin can be installed by cloning this repo and then building the plugin from the source. 
An example of this process is provided below.

```
git clone https://github.com/PolusAI/napari-nyxus.git
cd napari_nyxus
pip install -e .
```

Napari can then be ran by running 

```
napari
````

# Use
After installing the plugin, start Napari by running the command `napari` from the command line. Once the Napari 
GUI is loaded, the Nyxus plugin can be loaded from the `Plugins` menu in the toolbar by going to Plugins -> nyxus-napari.

![](https://github.com/PolusAI/napari-nyxus/raw/main/docs/source/img/plugin_menu.png)

A widget will appear in the Napari viewer to run Nyxus.

![](https://github.com/PolusAI/napari-nyxus/raw/main/docs/source/img/nyxus_loaded.png)

As shown by the example above, Nyxus will take in Intensity and Segmentation images. These parameters can either be a stack
of images or a single image pair. To load an image pair, use File -> Open File(s)... and select the images to load.

![](https://github.com/PolusAI/napari-nyxus/raw/main/docs/source/img/open_image.png)


Note that this method can also be used to open a stack of image, by using File -> Open Folder... instead of images. 

If the segmentation is loaded as an Image type in the napari viewer, it must first be converted to the Labels type. The image can converted as shown below.

![](https://github.com/PolusAI/napari-nyxus/raw/main/docs/source/img/convert_to_labels.png)

The loaded files can then be selected with the Intensity and Segmentation drop down menus. Other parameters can also be changed,
such as which features to calculate. For more information on the available features, see https://nyxus.readthedocs.io/en/latest/featurelist.html.

![](https://github.com/PolusAI/napari-nyxus/raw/main/docs/source/img/setup_calculation.png)

After running Nyxus, the feature calculations will also appear in the Napari viewer.

![](https://github.com/PolusAI/napari-nyxus/raw/main/docs/source/img/feature_results.png)

The Nyxus Napari plugin provides functionality to interact with the table containing the feature calculations. First, click on the segmentation image and then select `show selected` in the layer controls. 


Then, if a value is clicked in the `label` column of the table, the respective ROI will be highlighted in the segmentation image in the viewer.

![](https://github.com/PolusAI/napari-nyxus/raw/main/docs/source/img/click_label.png)

To select the ROI and have it added to a separate Labels image, the label in the table can be double clicked. Each double clicked label will be added to the same Labels image as show below. To unselect, the ROI, double click its respective label again.

![](https://github.com/PolusAI/napari-nyxus/raw/main/docs/source/img/double_click_label.png)

This feature can also be used in the opposite way, i.e. if an ROI is clicked in the segmentation image, the respective row in the 
feature table will be highlighted.

If one of the column headers are double clicked, a colormap will be generated in the Napari viewer showing the values of the features in the clicked
column. For example, if `Intensity` features are calculated, the `INTEGRATED_INTENSITY` column can be clicked and the colormap will appear.

![](https://github.com/PolusAI/napari-nyxus/raw/main/docs/source/img/feature_colormap.png)

Once the colormap is loaded, a slider will appear in the window with the minimum value being the minimum value of the feature colormap and the 
maximum value of the slider is the maximum value of the colormap. By adjusting the ranges in the slider, a new label image will appear in the viewer
that contains the ROIs who's features values fall within the slider values.

![](https://github.com/PolusAI/napari-nyxus/raw/main/docs/source/img/slider_feature.png)

The new labels resulting from the range slider selector can then be used to run Nyxus on by using the labels image as the `Segmentation` parameter.

![](docs/source/img/run_on_colormap_labels.png)

# Limitations

While Nyxus Napari provides batched processing for large sets of images where each individual image will fit into RAM, 
it does not provide functionality to handle large single images that do not fit into RAM or that are larger than the 
limitations of Napari. For large images, it is recommended to install the Python or CLI version of Nyxus. 
For more information, see https://github.com/PolusAI/nyxus. 
",['Framework :: napari'],,,,napari-nyxus.nyxus_widget,,,,,https://pypi.org/project/napari-nyxus,,
233,obj file reader,1.0.0,2023-04-12,2023-06-18,napari-obj,Léo Guignard,leo.guignard@univ-amu.fr,MIT,https://github.com/guignardlab/napari-obj,A plugin to read .obj files,>=3.8,"['numpy', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'""]","# napari-obj

<!-- [![License MIT](https://img.shields.io/pypi/l/napari-obj.svg?color=green)](https://github.com/guignardlab/napari-obj/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-obj.svg?color=green)](https://pypi.org/project/napari-obj)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-obj.svg?color=green)](https://python.org)
[![tests](https://github.com/guignardlab/napari-obj/workflows/tests/badge.svg)](https://github.com/guignardlab/napari-obj/actions)
[![codecov](https://codecov.io/gh/guignardlab/napari-obj/branch/main/graph/badge.svg)](https://codecov.io/gh/guignardlab/napari-obj)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-obj)](https://napari-hub.org/plugins/napari-obj) -->

A plugin to read .obj files

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-obj` via [pip]:

    pip install napari-obj

To install latest development version :

    pip install git+https://github.com/guignardlab/napari-obj.git

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [MIT] license,
""napari-obj"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/guignardlab/napari-obj/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 4 - Beta', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: MIT License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/guignardlab/napari-obj/issues', 'Documentation, https://github.com/guignardlab/napari-obj#README.md', 'Source Code, https://github.com/guignardlab/napari-obj', 'User Support, https://github.com/guignardlab/napari-obj/issues']",napari-obj.get_reader,,,,['*.obj'],,,https://pypi.org/project/napari-obj,https://github.com/guignardlab/napari-obj,
234,napari OMAAS,0.1.3,2022-08-18,2023-11-07,napari-omaas,Ruben Lopez,rjlopez2@gmail.com,BSD-3-Clause,https://github.com/rjlopez2/napari-omaas,napari-OMAAS stands for Optical Mapping Acquisition and Analysis Software,>=3.8,"['numpy', 'magicgui', 'qtpy', 'pyqtgraph', 'napari-macrokit', 'napari-sif-reader', 'napari-matplotlib', 'napari-mat-file-reader', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-omaas

[![License BSD-3](https://img.shields.io/pypi/l/napari-omaas.svg?color=green)](https://github.com/rjlopez2/napari-omaas/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-omaas.svg?color=green)](https://pypi.org/project/napari-omaas)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-omaas.svg?color=green)](https://python.org)
[![tests](https://github.com/rjlopez2/napari-omaas/workflows/tests/badge.svg)](https://github.com/rjlopez2/napari-omaas/actions)
[![codecov](https://codecov.io/gh/rjlopez2/napari-omaas/branch/main/graph/badge.svg)](https://codecov.io/gh/rjlopez2/napari-omaas)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-omaas)](https://napari-hub.org/plugins/napari-omaas)

**napari-OMAAS stands for Optical Mapping Acquisition and Analysis Software for panoramic heart imaging**

This plugin intends to be an analysis and acquisition tool for optical mapping in potentiometric (V<sub>m</sub>) or calcium (Ca<sup>2+</sup>) fluorescence signals obtained from panoramic imaging of intact hearts.

This plugin is in a very early developmental/experimental stage so expect very braking changes at anytime. At the momment supports reading images in .sif format from Andor Technologies powered by the [sif_parser] python module.

## Usage

This plugin can read images generated with Andor Technologies cameras. It has been currently tested on Zyla cameras. Just drag and drop an image to the napari GUI, and the image will display. Alternatively, you can programmatically load/read the image within a notebook.
    
    import napari
    
    file = ""path/to/my/file/my_image.sif""

    viewer = napari.Viewer()
    viewer.open(path=file, plugin=""napari-omaas"", name = ""my_image"")

to display the metadata use the standard call to the corresponding layer:

    viewer.layers['my_image'].metadata

In addition to opening this specific image format (.sif), it allows the users to perform some basic operations and visualization on images, such as normalization, temporal/spatial filters, motion tracking/compenstaion, plot profile, etc.
## Examples

The following example ilustrate how to perform normalization (pixelwise) on a time serie image and plot its 2d profile along the t dimension withing the average data from the ROI selected.

![](https://github.com/rjlopez2/napari-omaas/blob/documentation/example_imgs/Oct-31-2023%2016-45-55_plot_profile.gif?raw=true)


The next example shows how to compute action potetnial duration in the same image stack.

![](https://github.com/rjlopez2/napari-omaas/blob/documentation/example_imgs/Oct-31-2023%2016-49-02_APD_analysis.gif?raw=true)



## Roadmap

This plugin is composed of two major components: **analysis** and **acquisition**.

Bellow is a list of some features this pluggin aims to do.

### Analysis Features
    
- [x] Read sif files from Andor Technologies.
- [x] Display time profile of ROIs on image sequences.
- [x] Normalize images.
    - [x] Perform peak analysis of action potential / Calcium traces.
    - [x] Add motion correction.
    - [x] APD analysis.
    - [ ] Create activation maps.
    - [ ] Segment images and align heart ROIs.
- [x] Export results and analysis log.

### Acquisition Features

- [ ] Control Zyla camera for the acquisition of data
    - [ ] test using the PYME module
- [ ] Real-time analysis(?)

    

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

Also review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-omaas` via [pip]:

    pip install napari-omaas



To install the latest development version (recommended) :

    pip install git+https://github.com/rjlopez2/napari-omaas.git


## Contributing

Contributions are very welcome. Run tests with [tox], ensuring
the coverage remains the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-omaas"" is free and open source software.

## Issues

If you encounter any problems, please [file an issue] and a  detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/rjlopez2/napari-omaas/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
[sif_parser]: https://pypi.org/project/sif-parser/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/rjlopez2/napari-omaas/issues', 'Documentation, https://github.com/rjlopez2/napari-omaas#README.md', 'Source Code, https://github.com/rjlopez2/napari-omaas', 'User Support, https://github.com/rjlopez2/napari-omaas/issues']",,napari-omaas.write_multiple,napari-omaas.make_qwidget,napari-omaas.make_sample_data,,,['.npy'],https://pypi.org/project/napari-omaas,https://github.com/rjlopez2/napari-omaas,
235,napari-ome-zarr,0.5.2,2022-02-02,2023-06-18,napari-ome-zarr,OME Team,ome-team@openmicroscopy.org,BSD-3,https://github.com/ome/napari-ome-zarr,A reader for zarr backed OME-NGFF images.,>=3.7,"['ome-zarr (>=0.3.0)', 'numpy', 'vispy', 'napari (>=0.4.13)']","# napari-ome-zarr

[![License](https://img.shields.io/pypi/l/napari-ome-zarr.svg?color=green)](https://github.com/ome/napari-ome-zarr/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-ome-zarr.svg?color=green)](https://pypi.org/project/napari-ome-zarr)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-ome-zarr.svg?color=green)](https://python.org)
[![tests](https://github.com/ome/napari-ome-zarr/workflows/tests/badge.svg)](https://github.com/ome/napari-ome-zarr/actions)
[![codecov](https://codecov.io/gh/ome/napari-ome-zarr/branch/master/graph/badge.svg)](https://codecov.io/gh/ome/napari-ome-zarr)
[![pre-commit.ci status](https://results.pre-commit.ci/badge/github/ome/napari-ome-zarr/main.svg)](https://results.pre-commit.ci/latest/github/ome/napari-ome-zarr/main)


A reader for zarr backed OME-NGFF images.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/docs/plugins/index.html
-->

## Installation

You can install `napari-ome-zarr` via [pip]:

    pip install napari-ome-zarr

## Usage

Napari will use `ome-zarr` to open images that the plugin recognises as ome-zarr.
The image metadata from OMERO will be used to set channel names and rendering settings
in napari::

    $ napari ""https://uk1s3.embassy.ebi.ac.uk/idr/zarr/v0.3/9836842.zarr/""


    # Also works with local files
    $ napari 6001240.zarr

OR in python::

    import napari

    viewer = napari.Viewer()
    viewer.open('https://uk1s3.embassy.ebi.ac.uk/idr/zarr/v0.3/9836842.zarr/')

    napari.run()

If single zarray is passed to the plugin, it will be opened without the use of
the metadata::

    $ napari '/tmp/6001240.zarr/0'

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-ome-zarr"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/ome/napari-ome-zarr/issues
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 4 - Beta', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/ome/napari-ome-zarr/issues', 'Documentation, https://github.com/ome/napari-ome-zarr#README.md', 'Source Code, https://github.com/ome/napari-ome-zarr', 'User Support, https://github.com/ome/napari-ome-zarr/issues', 'Twitter, https://twitter.com/openmicroscopy']",napari-ome-zarr.get_reader,,,,"['*.zarr', '*.zarr*']",,,https://pypi.org/project/napari-ome-zarr,https://github.com/ome/napari-ome-zarr,
236,napari-omero,0.2.1,2022-04-01,2023-06-18,napari-omero,Will Moore,Talley Lambert <talley.lambert@gmail.com>,GPL-2.0-or-later,https://github.com/tlambert03/napari-omero,napari/OMERO interoperability,>=3.7,"[""importlib-metadata; python_version < '3.8'"", 'napari>=0.4.13', 'omero-py', 'omero-rois', ""napari[all]; extra == 'all'"", ""black; extra == 'dev'"", ""ipython; extra == 'dev'"", ""mypy; extra == 'dev'"", ""pdbpp; extra == 'dev'"", ""rich; extra == 'dev'"", ""ruff; extra == 'dev'"", ""pytest; extra == 'test'"", ""pytest-cov; extra == 'test'"", ""pytest-qt; extra == 'test'"", ""pytest-regressions; extra == 'test'"", ""pywin32; sys_platform == 'win32' and extra == 'test'""]","# napari-omero

[![License](https://img.shields.io/pypi/l/napari-omero.svg?color=green)](https://github.com/tlambert03/napari-omero/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-omero.svg?color=green)](https://pypi.org/project/napari-omero)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-omero.svg?color=green)](https://python.org)
[![CI](https://github.com/tlambert03/napari-omero/actions/workflows/ci.yml/badge.svg)](https://github.com/tlambert03/napari-omero/actions/workflows/ci.yml)
[![codecov](https://codecov.io/gh/tlambert03/napari-omero/branch/main/graph/badge.svg)](https://codecov.io/gh/tlambert03/napari-omero)
[![conda-forge](https://img.shields.io/conda/vn/conda-forge/napari-omero)](https://anaconda.org/conda-forge/napari-omero)

This package provides interoperability between the
[OMERO](https://www.openmicroscopy.org/omero/) image management platform, and
[napari](https://github.com/napari/napari): a fast, multi-dimensional image
viewer for python.

It provides a GUI interface for browsing an OMERO instance from within napari,
as well as command line interface extensions for both OMERO and napari CLIs.

![demo](https://github.com/tlambert03/napari-omero/blob/master/demo.gif?raw=true)

## Features

- GUI interface to browse remote OMERO data, with thumbnail previews.
- Loads remote nD images from an OMERO server into napari
- Planes are loading on demand as sliders are moved (""lazy loading"").
- session management (login memory)
- OMERO rendering settings (contrast limits, colormaps, active channels, current
  Z/T position) are applied in napari

### as a napari dock widget

To launch napari with the OMERO browser added, [install](#installation) this
package and run:

```bash
napari-omero
```

The OMERO browser widget can also be manually added to the napari viewer:

```python
import napari

viewer = napari.Viewer()
viewer.window.add_plugin_dock_widget('napari-omero')

napari.run()
```

### as a napari plugin

This package provides a napari reader plugin that accepts OMERO resources as
""proxy strings"" (e.g. `omero://Image:<ID>`) or as [OMERO webclient
URLS](https://help.openmicroscopy.org/urls-to-data.html).

```python
viewer = napari.Viewer()

# omero object identifier string
viewer.open(""omero://Image:1"")

# or URLS: https://help.openmicroscopy.org/urls-to-data.html
viewer.open(""http://yourdomain.example.org/omero/webclient/?show=image-314"")
```

these will also work on the napari command line interface, e.g.:

```bash
napari omero://Image:1
# or
napari http://yourdomain.example.org/omero/webclient/?show=image-314
```

### as an OMERO CLI plugin

This package also serves as a plugin to the OMERO CLI

```bash
omero napari view Image:1
```

- ROIs created in napari can be saved back to OMERO via a ""Save ROIs"" button.
- napari viewer console has BlitzGateway 'conn' and 'omero_image' in context.

## installation

Requires python 3.7 - 3.10.

### from conda

It's easiest to install `omero-py` from conda, so the recommended procedure
is to install everything from conda, using the `conda-forge` channel

```python
conda install -c conda-forge napari-omero
```

### from pip

`napari-omero` itself can be installed from pip, but you will still need
`omero-py`

```sh
conda create -n omero -c conda-forge python=3.9 omero-py
conda activate omero
pip install napari-omero[all]  # the [all] here is the same as `napari[all]`
```

## issues

| ❗  | This is alpha software & some things will be broken or sub-optimal!  |
| --- | -------------------------------------------------------------------- |

- experimental & definitely still buggy!  [Bug
  reports](https://github.com/tlambert03/napari-omero/issues/new) are welcome!
- remote loading can be very slow still... though this is not strictly an issue
  of this plugin.  Datasets are wrapped as delayed dask stacks, and remote data
  fetching time can be significant.  Plans for [asynchronous
  rendering](https://napari.org/guides/stable/rendering.html) in
  napari and
  [tiled loading from OMERO](https://github.com/tlambert03/napari-omero/pull/1)
  may eventually improve the subjective performance... but remote data loading
  will likely always be a limitation here.
  To try asyncronous loading, start the program with `NAPARI_ASYNC=1 napari-omero`.

## contributing

Contributions are welcome!  To get setup with a development environment:

```bash
# clone this repo:
git clone https://github.com/tlambert03/napari-omero.git
# change into the new directory
cd napari-omero
# create conda environment
conda env create -f environment.yml
# activate the new env
conda activate napari-omero

# install in editable mode
pip install -e .
```

To maintain good code quality, this repo uses
[flake8](https://gitlab.com/pycqa/flake8),
[mypy](https://github.com/python/mypy), and
[black](https://github.com/psf/black).  To enforce code quality when you commit
code, you can install pre-commit

```bash
# install pre-commit which will run code checks prior to commits
pre-commit install
```

The original OMERO data loader and CLI extension was created by [Will
Moore](https://github.com/will-moore).

The napari reader plugin and GUI browser was created by [Talley
Lambert](https://github.com/tlambert03/)
","['Development Status :: 3 - Alpha', 'Environment :: X11 Applications :: Qt', 'Framework :: napari', 'Intended Audience :: Developers', 'Intended Audience :: Education', 'Intended Audience :: End Users/Desktop', 'Intended Audience :: Science/Research', 'License :: OSI Approved :: GNU General Public License v2 or later (GPLv2+)', 'Natural Language :: English', 'Operating System :: OS Independent', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Topic :: Scientific/Engineering', 'Topic :: Scientific/Engineering :: Bio-Informatics', 'Topic :: Scientific/Engineering :: Information Analysis', 'Topic :: Scientific/Engineering :: Visualization', 'Topic :: Software Development :: Libraries :: Python Modules', 'Topic :: Utilities']","['homepage, https://github.com/tlambert03/napari-omero', 'repository, https://github.com/tlambert03/napari-omero']",napari-omero.get_reader,,napari-omero.widget,,['omero://*'],,,https://pypi.org/project/napari-omero,https://github.com/tlambert03/napari-omero,
237,OpenFIBSEM Napari,0.1.5,,,napari-openfibsem,Patrick Cleeve,patrick.cleeve@monash.edu,MIT,,OpenFIBSEM Applications,>=3.9,"['fibsem >=0.3.2a1', 'autolamella >=0.3.2a1', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-openfibsem

[![License MIT](https://img.shields.io/pypi/l/napari-openfibsem.svg?color=green)](https://github.com/DeMarcoLab/napari-openfibsem/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-openfibsem.svg?color=green)](https://pypi.org/project/napari-openfibsem)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-openfibsem.svg?color=green)](https://python.org)
[![tests](https://github.com/DeMarcoLab/napari-openfibsem/workflows/tests/badge.svg)](https://github.com/DeMarcoLab/napari-openfibsem/actions)
[![codecov](https://codecov.io/gh/DeMarcoLab/napari-openfibsem/branch/main/graph/badge.svg)](https://codecov.io/gh/DeMarcoLab/napari-openfibsem)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-openfibsem)](https://napari-hub.org/plugins/napari-openfibsem)

OpenFIBSEM Applications

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-openfibsem` via [pip]:

    pip install napari-openfibsem



To install latest development version :

    pip install git+https://github.com/DeMarcoLab/napari-openfibsem.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [MIT] license,
""napari-openfibsem"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/DeMarcoLab/napari-openfibsem/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: MIT License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/DeMarcoLab/napari-openfibsem/issues', 'Documentation, https://github.com/DeMarcoLab/napari-openfibsem#README.md', 'Source Code, https://github.com/DeMarcoLab/napari-openfibsem', 'User Support, https://github.com/DeMarcoLab/napari-openfibsem/issues']",,,napari-openfibsem.fibsem,,,,,https://pypi.org/project/napari-openfibsem,,
238,napari OrganoidCounter,0.2.3,2023-10-29,2023-11-22,napari-organoid-counter,christinab12,christina.bukas@helmholtz-muenchen.de,MIT,https://pypi.org/project/napari-organoid-counter,A plugin to automatically count lung organoids,"<3.11,>=3.8","['napari[all] >=0.4.17', 'napari-aicsimageio >=0.7.2', 'torch >=1.13.1', 'torchvision >=0.14.1', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# Napari Organoid Counter - Version 0.2 is out! 

![stability-stable](https://img.shields.io/badge/stability-stable-green.svg)
[![DOI](https://zenodo.org/badge/476715320.svg)](https://zenodo.org/badge/latestdoi/476715320)
[![License](https://img.shields.io/pypi/l/napari-organoid-counter.svg?color=green)](https://github.com/HelmholtzAI-Consultants-Munich/napari-organoid-counter/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-organoid-counter.svg?color=green)](https://pypi.org/project/napari-organoid-counter)
[![Python Version](https://img.shields.io/badge/python-3.8%20%7C%203.9%20%7C%203.10-blue)](https://python.org)
[![tests](https://github.com/HelmholtzAI-Consultants-Munich/napari-organoid-counter/workflows/tests/badge.svg)](https://github.com/HelmholtzAI-Consultants-Munich/napari-organoid-counter/actions)
[![codecov](https://codecov.io/gh/HelmholtzAI-Consultants-Munich/napari-organoid-counter/branch/main/graph/badge.svg)](https://codecov.io/gh/HelmholtzAI-Consultants-Munich/napari-organoid-counter)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-organoid-counter)](https://napari-hub.org/plugins/napari-organoid-counter)

A napari plugin to automatically count lung organoids from microscopy imaging data. *Note that this plugin only supports single channel grayscale images.*

![Alt Text](https://github.com/HelmholtzAI-Consultants-Munich/napari-organoid-counter/blob/main/readme-content/demo-plugin-v2.gif)

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.


## Installation

You can install `napari-organoid-counter` via [pip]:

    pip install napari-organoid-counter


To install latest development version :

    pip install git+https://github.com/HelmholtzAI-Consultants-Munich/napari-organoid-counter.git
    
    
For the dev branch you can clone this repo and install with:

    pip install -e .  

For installing on a Windows machine via napari, follow the instuctions [here](https://github.com/HelmholtzAI-Consultants-Munich/napari-organoid-counter/blob/main/readme-content/How%20to%20install%20on%20a%20Windows%20machine.pdf).

## What's new in v2?
Checkout our *What's New in v2* [here](https://github.com/HelmholtzAI-Consultants-Munich/napari-organoid-counter/blob/main/.napari/DESCRIPTION.md#whats-new-in-v2).

## How to use?
After installing, you can start napari (either by typing ```napari``` in your terminal or by launching the application) and select the plugin from the drop down menu.

For more information on this plugin, its' intended audience, as well as Quickstart guide go to our [Quickstart guide](https://github.com/HelmholtzAI-Consultants-Munich/napari-organoid-counter/blob/main/.napari/DESCRIPTION.md#quickstart).

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [MIT] license,
""napari-organoid-counter"" is free and open source software

## Dependencies


```napari-organoid-counter``` uses the ```napari-aicsimageio```<sup>[1]</sup> <sup>[2]</sup> plugin for reading and processing CZI images.

[1] Eva Maxfield Brown, Dan Toloudis, Jamie Sherman, Madison Swain-Bowden, Talley Lambert, AICSImageIO Contributors (2021). AICSImageIO: Image Reading, Metadata Conversion, and Image Writing for Microscopy Images in Pure Python [Computer software]. GitHub. https://github.com/AllenCellModeling/aicsimageio

[2] Eva Maxfield Brown, Talley Lambert, Peter Sobolewski, Napari-AICSImageIO Contributors (2021). Napari-AICSImageIO: Image Reading in Napari using AICSImageIO [Computer software]. GitHub. https://github.com/AllenCellModeling/napari-aicsimageio

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/HelmholtzAI-Consultants-Munich/napari-organoid-counter/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/

## Citing

If you use this plugin for your work, please cite it using the following:

> Christina Bukas, Harshavardhan Subramanian, & Marie Piraud. (2023). HelmholtzAI-Consultants-Munich/napari-organoid-counter: v0.2.0 (v0.2.0). Zenodo. https://doi.org/10.5281/zenodo.7859571
> 
bibtex:
```
@software{christina_bukas_2022_6457904,
  author       = {Christina Bukas, Harshavardhan Subramanian, & Marie Piraud},
  title        = {{HelmholtzAI-Consultants-Munich/napari-organoid- 
                   counter: second release of the napari plugin for lung
                   organoid counting}},
  month        = apr,
  year         = 2023,
  publisher    = {Zenodo},
  version      = {v0.2.0},
  doi          = {10.5281/zenodo.7859571},
  url          = {https://doi.org/10.5281/zenodo.7859571}
}
```

","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Operating System :: OS Independent', 'License :: OSI Approved :: MIT License']","['Bug Tracker, https://github.com/HelmholtzAI-Consultants-Munich/napari-organoid-counter/issues', 'Documentation, https://github.com/HelmholtzAI-Consultants-Munich/napari-organoid-counter#README.md', 'Source Code, https://github.com/HelmholtzAI-Consultants-Munich/napari-organoid-counter', 'User Support, https://github.com/HelmholtzAI-Consultants-Munich/napari-organoid-counter/issues']",napari-organoid-counter.get_reader,,napari-organoid-counter.OrganoidCounterWidget,,['*.json'],,,https://pypi.org/project/napari-organoid-counter,,
239,Napari Orientationpy,0.0.7,,,napari-orientationpy,Mallory Wittwer,mallory.wittwer@epfl.ch,BSD-3-Clause,,Napari plugin for the Orientationpy project.,>=3.8,"['numpy', 'magicgui', 'qtpy', 'napari[all] >=0.4.16', 'orientationpy', 'seaborn', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","![EPFL Center for Imaging logo](https://imaging.epfl.ch/resources/logo-for-gitlab.svg)
# napari-orientationpy

Analyze orientations in 2D, 3D, and RGB images in Napari. This plugin is based on the [Orientationpy](https://gitlab.com/epfl-center-for-imaging/orientationpy/) project.

<p align=""center"">
    <img src=""assets/ori_color-1.gif"" height=""400"">
</p>

## Installation

You can install `napari-orientationpy` via [pip]:

    pip install napari-orientationpy

## Usage
To get started, open an image in the Napari viewer and start `napari-orientationpy` from the `Plugins` menu:

```
Plugins > Napari Orientationpy > Orientation measurement
```

1. **Select the structural scale parameter `sigma`**. This value control represents the scale at which the image gradients are computed. Try different values of `sigma` to understand what works best for your images. A reasonable guess would be the order in size, in pixels, of the structures that you are interested in. For example, if you are imaging fibers that appear to be about 4 pixels wide, try to set a value of *sigma=4*.

<p align=""center"">
    <img src=""assets/sigmas.png"" height=""230"">
</p>

2. **If you are analyzing a 3D image, select `fiber` or `membrane` mode**. In `fiber` mode, the orientation normals follow fibrous structures. In `membrane` mode, the orientations are normal to the surface of membranous structures.

3. **Decide which outputs you'd like to visualize.**
  - The `color-coded orientation` is a pixel-wise representation of 3D orientations as colors (similar colors = similar orientations).
  - The `orientation vectors` get rendered in a `Vectors` layer in Napari. They are sampled on a regular grid defined by the `Spacing (X)`, `Spacing (Y)` and `Spacing (Z)` values (for 2D images, the `Z` value is ignored). The length of the vectors can be rescaled based on the `energy` value of the orientation computation.
  - You can also output the local `orientation gradient` (misorientation).

4. **Compute orientation**. This button will trigger the orientation computation **only when necessary** (i.e. when the value of `sigma`, the `mode` or the `image` have changed). If you only adjust the `orientation vectors` parameters, clicking the compute button will update the results very fast.
5. **Save orientation (CSV)**. This will save the orientation measurements as a CSV table with columns `X`, `Y`, `Z`, `theta`, `phi`, `energy`, and `coherency` for all the pixels in the image. 

### Plotting the 3D orientation distribution

If you have computed **orientation vectors** for a 3D image, you can plot their spatial distribution as a `stereographic projection` along the `X`, `Y` or `Z` direction directly in Napari. Select the widget from:

```
Plugins > Napari Orientationpy > Orientation distribution (3D)
```
<p align=""center"">
    <img src=""assets/fibers_dist.png"" height=""400"">
</p>

## Sample images

We provide a few sample images to test our plugin. Open them from:

```
File > Open Sample > Napari Orientationpy
```

## Contributing

Contributions are very welcome. Please get in touch if you'd like to be involved in improving or extending the package.

## License

Distributed under the terms of the [BSD-3] license,
""napari-orientationpy"" is free and open source software

## Issues

If you encounter any problems, please file an issue along with a detailed description.

----------------------------------

[napari]: https://github.com/napari/napari
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[pip]: https://pypi.org/project/pip/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']",,,,napari-orientationpy.pixels,,,,,https://pypi.org/project/napari-orientationpy,,
240,napari-owncloud,0.1.2,2023-04-21,2023-06-18,napari-owncloud,Robert Haase,robert.haase@tu-dresden.de,BSD-3-Clause,https://github.com/haesleinhuepf/napari-owncloud,Browse folders and images in owncloud / nextcloud servers and open them using just a double-click!,>=3.8,"['napari-plugin-engine (>=0.1.4)', 'numpy', 'napari-tools-menu', 'pyocclient']","# napari-owncloud

[![License](https://img.shields.io/pypi/l/napari-owncloud.svg?color=green)](https://github.com/haesleinhuepf/napari-owncloud/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-owncloud.svg?color=green)](https://pypi.org/project/napari-owncloud)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-owncloud.svg?color=green)](https://python.org)
[![tests](https://github.com/haesleinhuepf/napari-owncloud/workflows/tests/badge.svg)](https://github.com/haesleinhuepf/napari-owncloud/actions)
[![codecov](https://codecov.io/gh/haesleinhuepf/napari-owncloud/branch/master/graph/badge.svg)](https://codecov.io/gh/haesleinhuepf/napari-owncloud)

## Usage

Browse folders and images in [owncloud](https://owncloud.com/) / [nextcloud](https://nextcloud.com/) servers and open them using just a double-click! 

Login to an owncloud or nextcloud server by clicking the menu `Tools > Utilities > Browse owncloud / nextcloud storage`

![](https://github.com/haesleinhuepf/napari-owncloud/raw/main/docs/login.png)

You can then navigate through folders by double-clicking `folder/` items in the list.
You can also open images by double-clicking them. Alternatively, use the arrow-up and arrow-down key to navigate the list and hit ENTER to open an image or folder.

![](https://github.com/haesleinhuepf/napari-owncloud/raw/main/docs/browse.png)

Store images in your cloud storage using the button `Save / upload current layer`. Note: Currently, only single selected layers can be saved.

![](https://github.com/haesleinhuepf/napari-owncloud/raw/main/docs/upload.png)

[Demo](https://github.com/haesleinhuepf/napari-owncloud/raw/main/docs/demo.mp4)

![](https://github.com/haesleinhuepf/napari-owncloud/raw/main/docs/demo.gif)

## Installation

You can install `napari-owncloud` via [pip]:

    pip install napari-owncloud

## Related plugins

There are other napari plugins that allow you browsing local and online image storage
* [napari-omero](https://www.napari-hub.org/plugins/napari-omero)
* [napari-folder-browser](https://www.napari-hub.org/plugins/napari-folder-browser)

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-owncloud"" is free and open source software

## Issues

If you encounter any problems, please create a thread on [image.sc] along with a detailed description and tag [@haesleinhuepf].

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/haesleinhuepf/napari-owncloud/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
[image.sc]: https://image.sc
[@haesleinhuepf]: https://twitter.com/haesleinhuepf

","['Development Status :: 3 - Alpha', 'Intended Audience :: Science/Research', 'Framework :: napari', 'Topic :: Scientific/Engineering :: Image Processing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/haesleinhuepf/napari-owncloud/issues', 'Documentation, https://github.com/haesleinhuepf/napari-owncloud#README.md', 'Source Code, https://github.com/haesleinhuepf/napari-owncloud', 'User Support, https://github.com/haesleinhuepf/napari-owncloud/issues']",,,napari-owncloud.OwncloudBrowser,,,,,https://pypi.org/project/napari-owncloud,https://github.com/haesleinhuepf/napari-owncloud,
241,Napari Parallel,0.0.2,2023-10-29,2023-11-07,napari-parallel,"Artem Tomilo, Nafisa Anjum, Himanshu Kaloni",artem.tomilo@mailbox.tu-dresden.de,BSD-3-Clause,https://pypi.org/project/napari-parallel,Plugin to process images in parallel using several computers,>=3.8,"['numpy', 'magicgui', 'qtpy', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-parallel

This plugin is used for parallel computing of image processing using the code
generation capabilities of the `napari-assistant` plugin and the distributed
computing library `dask`.

[![License BSD-3](https://img.shields.io/pypi/l/napari-parallel.svg?color=green)](https://github.com/bridgeArchitect/napari-parallel/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-parallel.svg?color=green)](https://pypi.org/project/napari-parallel)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-parallel.svg?color=green)](https://python.org)
[![tests](https://github.com/bridgeArchitect/napari-parallel/workflows/tests/badge.svg)](https://github.com/bridgeArchitect/napari-parallel/actions)
[![codecov](https://codecov.io/gh/bridgeArchitect/napari-parallel/branch/main/graph/badge.svg)](https://codecov.io/gh/bridgeArchitect/napari-parallel)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-parallel)](https://napari-hub.org/plugins/napari-parallel)

Plugin to process images in parallel using several computers

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-parallel` via [pip]:

    pip install napari-parallel


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-parallel"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']",,napari-parallel.get_reader,napari-parallel.write_multiple,napari-parallel.make_qwidget,napari-parallel.make_sample_data,['*.npy'],,['.npy'],https://pypi.org/project/napari-parallel,,
242,napari patch creator,0.1.4,2023-04-13,2023-06-18,napari-patchcreator,Tom Burke,burke@mpi-cbg.de,BSD-3-Clause,https://github.com/juglab/napari-patchcreator,A simple plugin to use with napari,>=3.8,"['numpy', 'napari', 'napari-plugin-engine (>=0.1.4)', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-patchcreator

[![License BSD-3](https://img.shields.io/pypi/l/napari-patchcreator.svg?color=green)](https://github.com/juglab/napari-patchcreator/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-patchcreator.svg?color=green)](https://pypi.org/project/napari-patchcreator)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-patchcreator.svg?color=green)](https://python.org)
[![tests](https://github.com/juglab/napari-patchcreator/workflows/tests/badge.svg)](https://github.com/juglab/napari-patchcreator/actions)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-patchcreator)](https://napari-hub.org/plugins/napari-patchcreator)

A simple plugin to create quadratic patches from images through selection and clicking with the left mouse button.
The patches can then be exported to a folder of your own choosing.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-patchcreator` via [pip]:

    pip install napari-patchcreator



To install latest development version :

    pip install git+https://github.com/juglab/napari-patchcreator.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-patchcreator"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/juglab/napari-patchcreator/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 5 - Production/Stable', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/juglab/napari-patchcreator/issues', 'Documentation, https://github.com/juglab/napari-patchcreator#README.md', 'Source Code, https://github.com/juglab/napari-patchcreator', 'User Support, https://github.com/juglab/napari-patchcreator/issues']",,,napari-patchcreator.make_patch_widget,,,,,https://pypi.org/project/napari-patchcreator,https://github.com/juglab/napari-patchcreator,
243,napari-pdf-reader,0.0.1a3,2022-02-17,2023-06-18,napari-pdf-reader,Daniel Krentzel,dkrentzel@pm.me,MIT,https://github.com/krentzd/napari-pdf-reader,Reader for PDF files,>=3.7,"['napari-plugin-engine (>=0.1.4)', 'numpy', 'pillow', 'pdf2image']","# PDF reader for napari
Reads PDF files into napari


","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: MIT License']","['Bug Tracker, https://github.com/krentzd/napari-pdf-reader/issues', 'Documentation, https://github.com/krentzd/napari-pdf-reader#README.md', 'Source Code, https://github.com/krentzd/napari-pdf-reader', 'User Support, https://github.com/krentzd/napari-pdf-reader/issues']",napari-pdf-reader.napari_get_reader,,,,['*'],,,https://pypi.org/project/napari-pdf-reader,https://github.com/krentzd/napari-pdf-reader,
244,PDS reader plugin for Napari,0.0.1,2022-08-19,2023-06-18,napari-pdr-reader,Dr. Andrew Annex,ama6fy@virginia.edu,BSD-3-Clause,https://github.com/AndrewAnnex/napari-pdr-reader,A reader plugin for Napari for PDS data powered by the PDR library,>=3.9,"['astropy', 'dustgoggles', 'napari', 'numpy', 'pandas', 'pdr', 'pds4-tools', 'pillow', 'pvl', ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""tox ; extra == 'testing'""]","# napari-pdr-reader

[![License BSD-3](https://img.shields.io/pypi/l/napari-pdr-reader.svg?color=green)](https://github.com/AndrewAnnex/napari-pdr-reader/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-pdr-reader.svg?color=green)](https://pypi.org/project/napari-pdr-reader)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-pdr-reader.svg?color=green)](https://python.org)
[![tests](https://github.com/AndrewAnnex/napari-pdr-reader/workflows/tests/badge.svg)](https://github.com/AndrewAnnex/napari-pdr-reader/actions)
[![codecov](https://codecov.io/gh/AndrewAnnex/napari-pdr-reader/branch/main/graph/badge.svg)](https://codecov.io/gh/AndrewAnnex/napari-pdr-reader)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-pdr-reader)](https://napari-hub.org/plugins/napari-pdr-reader)

A reader plugin for Napari for PDS data powered by the PDR library

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/index.html
-->

## Installation

You can install `napari-pdr-reader` via [pip]:

    pip install napari-pdr-reader



To install latest development version :

    pip install git+https://github.com/AndrewAnnex/napari-pdr-reader.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-pdr-reader"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/AndrewAnnex/napari-pdr-reader/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/AndrewAnnex/napari-pdr-reader/issues', 'Documentation, https://github.com/AndrewAnnex/napari-pdr-reader#README.md', 'Source Code, https://github.com/AndrewAnnex/napari-pdr-reader', 'User Support, https://github.com/AndrewAnnex/napari-pdr-reader/issues']",napari-pdr-reader.get_reader,,,napari-pdr-reader.get_m2020_data,"['*.fits', '*.FITS', '*.lbl', '*.img', '*.LBL', '*.IMG']",,,https://pypi.org/project/napari-pdr-reader,https://github.com/AndrewAnnex/napari-pdr-reader,
245,napari-PHILOW,0.1.1,2022-08-18,2024-04-03,napari-PHILOW,Hiroki Kawai,h.kawai888@gmail.com,GPLv3,https://github.com/neurobiology-ut/PHILOW,PHILOW is an interactive deep learning-based platform for 3D datasets,>=3.8,"['numpy', 'scikit-image', 'dask-image', 'opencv-python', 'matplotlib', 'pandas', 'torch', 'torchvision', 'segmentation-models-pytorch', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-PHILOW

[![License](https://img.shields.io/pypi/l/napari-PHILOW.svg?color=green)](https://github.com/neurobiology-ut/PHILOW/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-PHILOW.svg?color=green)](https://pypi.org/project/napari-PHILOW)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-PHILOW.svg?color=green)](https://python.org)
[![tests](https://github.com/neurobiology-ut/napari-PHILOW/workflows/tests/badge.svg)](https://github.com/neurobiology-ut/PHILOW/actions)
[![codecov](https://codecov.io/gh/neurobiology-ut/napari-PHILOW/branch/main/graph/badge.svg)](https://codecov.io/gh/neurobiology-ut/PHILOW)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-PHILOW)](https://napari-hub.org/plugins/napari-PHILOW)

# PHILOW <br>
***P***ython-based platform for ***h***uman-***i***n-the-***lo***op (HITL)  ***w***orkflow (PHILOW) <br>

PHILOW is an interactive deep learning-based platform for 3D datasets implemented on top of [napari](https://github.com/napari/napari)

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/stable/index.html
-->

## Installation

Install napari and Pytorch first.   
See [napari] and [Pytorch](https://pytorch.org/) for more information.

You can install `napari-PHILOW` via [pip]:

    pip install napari-PHILOW
    
or clone this repository   
then
```angular2
cd PHILOW
pip install -e .
```
    

## Usage

Launch napari 

```angular2
napari
```


#### load dataset


1) Plugins > napari-PHILOW > Annotation Mode

2) Select original dir : all slices must be in separate 8bit PNG and must be sequentially numbered (e.g. 000.png, 001.png ...)

3) Select mask dir : To resume from the middle of the annotation, specify here the name of the directory containing the mask image. The directory must contain the same number of files with the same name as the original image.   
 If you are starting a completely new annotation, you do not need to specify a directory. The directory for mask is automatically created and blank images are generated and stored.

4) Enter a name for the label or model you want to create (e.g. mito, cristae, ...)   
This name will be used as the directory name of the newly created mask dir if no mask dir is specified, 
and as the name of the csv file for training dataset management.

5) Check if you want to create new dataset (new model)
When checked, if there is already a csv file for training dataset management, a new csv file with one sequential number will be generated.

6) Start tracing


#### create labels
Create a label with the brush function.
more information → https://napari.org/tutorials/fundamentals/labels.html

#### Orthogonal view
If you want to see orthogonal view, click on the location you want to see while holding down the Shift button.    
The image from xy, yz, and zx will be displayed on the right side of the screen.

#### Low confident layer
If you are in the second iteration and you are loading the prediction results, you will see a low confidence layer.    
This shows the area where the confidence of the prediction result is low.    
Use this as a reference for correction.   

#### Small object layer
We provide a small object layer to find small painted areas.   
This is a layer for displaying small objects.   
The slider widget on the left allows you to change the maximum object size to be displayed.   

#### save labels
If you want to save your label, click the ""save"" button on the bottom right.

#### select training dataset
We are providing a way to manage the dataset for use in training.   
If you want to use the currently displayed slice as your training data, click the 'Not Checked' button near the center left to display 'Checked'.


### Train and pred with your gpu machine
#### Train
To train on your GPU machine (or with CPU), 

1) Plugins > napari-PHILOW > Trainer
   
2) Select original dir : all slices must be in separate 8bit PNG and must be sequentially numbered (e.g. 000.png, 001.png ...)   
   
3) Select labels dir : all label images should be named same as original images and contains data management csv file   
   
4) Select dir for save trained model   
   
5) Click on the ""start training"" button   

6) Dice score and dice loss are displayed. For more detail, check the command line for the progress of training. If you want to stop in the middle, click stop button.   
   
#### Predict
To predict labels on your machine,  

1) Plugins > napari-PHILOW > Predicter
   
2) Select original dir : all slices must be in separate 8bit PNG and must be sequentially numbered (e.g. 000.png, 001.png ...)   
   
3) (Optional) Select labels dir if you want to keep labels witch were used on training, and data management csv file   
   
4) Select model dir contains hdf5 file   
   
5) Select output dir for predicted labels   

6) Uncheck the box if you DO NOT want to use TAP (Three-Axis-Prediction)   
   
7) Click on the ""predict"" button  

8) Check the command line for the progress of prediction. If you want to stop in the middle, use ctrl+C.   

9) You can start the next round of annotation by selecting the merged_prediction directory as the mask dir in Annotation mode.

### Train and predict with Google Colab   
If you don't have a GPU machine, you can use Google Colab to perform GPU-based training and prediction for free.    

1) Open [train and predict notebook](https://github.com/neurobiology-ut/PHILOW/blob/develop/notebooks/train_and_pred_using_PHILOW.ipynb) and click ""Open in Colab"" button

2) You can upload your own dataset to train and predict, or try it on demo data   


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [GNU GPL v3.0] license,
""napari-PHILOW"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

# Authors <br>

Shogo Suga <br>
Hiroki Kawai <br>
<a href=""http://park.itc.u-tokyo.ac.jp/Hirabayashi/WordPress/"">Yusuke Hirabayashi</a> 


# How to Cite <br>
Shogo Suga, Koki Nakamura, Yu Nakanishi, Bruno M Humbel, Hiroki Kawai, Yusuke Hirabayashi, An interactive deep learning-based approach reveals mitochondrial cristae topologies. PLoS Biol 21(8): e3002246.
<a href=""https://doi.org/10.1371/journal.pbio.3002246"">https://doi.org/10.1371/journal.pbio.3002246</a>


```
@article {Suga_Nakamura_Nakanishi_Humbel_Kawai_Hirabayashi_2023,
	title={An interactive deep learning-based approach reveals mitochondrial cristae topologies},
	volume={21},
	ISSN={1545-7885},
	DOI={10.1371/journal.pbio.3002246},
	number={8},
	journal={PLOS Biology},
	publisher={Public Library of Science},
	author={Suga, Shogo and Nakamura, Koki and Nakanishi, Yu and Humbel, Bruno M. and Kawai, Hiroki and Hirabayashi, Yusuke},
	year={2023},
	month={Aug},
	pages={e3002246},
	language={en}
}
```

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'License :: OSI Approved :: GNU General Public License v3 (GPLv3)', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/neurobiology-ut/PHILOW/issues', 'Documentation, https://github.com/neurobiology-ut/PHILOW#README.md', 'Source Code, https://github.com/neurobiology-ut/PHILOW', 'User Support, https://github.com/neurobiology-ut/PHILOW/issues']",,,napari-PHILOW.AnnotationMode,,,,,https://pypi.org/project/napari-PHILOW,https://github.com/neurobiology-ut/PHILOW,
246,napari-PICASSO,0.3.0,2022-07-07,2023-06-18,napari-PICASSO,Kunal Pandit,kpandit@nygenome.org,GPL-3.0-only,https://github.com/nygctech/PICASSO,Blind fluorescence unmixing,>=3.8,"['numpy', 'magicgui', 'qtpy', 'dask', 'psutil', ""tox ; extra == 'testing'"", ""napari[all] ; extra == 'testing'"", ""torch ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""xarray ; extra == 'testing'""]","# napari-PICASSO

[![License](https://img.shields.io/pypi/l/napari-curtain.svg?color=green)](https://github.com/nygctech/PICASSO/blob/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-PICASSO.svg?color=green)](https://pypi.org/project/napari-PICASSO)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-PICASSO.svg?color=green)](https://python.org)
[![tests](https://github.com/nygctech/PICASSO/actions/workflows/test_and_deploy.yml/badge.svg?event=push)](https://github.com/nygctech/PICASSO/actions/workflows/test_and_deploy.yml)
[![codecov](https://codecov.io/gh/nygctech/napari-PICASSO/branch/main/graph/badge.svg)](https://codecov.io/gh/nygctech/napari-PICASSO)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-PICASSO)](https://napari-hub.org/plugins/napari-PICASSO)

Unmix spectral spillover

![](https://user-images.githubusercontent.com/72306584/176486552-50e1bca9-65fd-4466-8c92-a114e48d2278.gif)

## Automatic Usage

You can find the `PICASSO` plugin in the menu `Plugins > napari-PICASSO: PICASSO`. Select sink images that have spectral spillover from corresponding source images, then click run to optimise the mixing parameters with PICASSO. 

## Manual Usage

![](https://user-images.githubusercontent.com/72306584/176505151-572bd762-abe6-47b1-9821-4f3aaa4704c9.gif)

Select the manual button in options pop up window. Then select sink images that have spectral spillover from corresponding source images. In the source images window, sliders for each $source$ control the mixing spillover, $m$ (top), and background, $b$ (bottom, optional).

## Mixing model

$$ sink = \sum_{i} m_i(source - b_i) $$

## Installation

You can install `napari-PICASSO` via [pip]:

    pip install napari-PICASSO

## Details

napari-PICASSO is a napari widget to blindly unmix fluorescence images of known members using PICASSO<sup>1</sup>. 

For example, if 2 fluorophores with overlapping spectra are imaged, spillover fluorescesce from a channel into an adjacent channel could be removed if you know which channel is the source of the spillover fluorescence and which channel is the sink of the spillover fluorescence. 

PICASSO is an algorithm to remove spillover fluorescence by minimizing the mutual information between sink and source images. The original algorithm described by Seo et al, minimized the mutual information between pairs of sink and source images using a Nelson-Mead simplex algorithm and computing the mutual information outright with custom written MATLAB code<sup>1</sup>. The napari plugin uses a neural net to estimate and minimize the mutual information (MINE<sup>2</sup>) between pairs of sink and source images using stochastic gradient descent with GPU acceleration.

## References

1. Seo, J. et al. PICASSO allows ultra-multiplexed fluorescence imaging of spatially overlapping proteins without reference spectra measurements. Nat Commun 13, 2475 (2022).
2. Belghazi, M. I. et al. MINE: Mutual Information Neural Estimation. arXiv:1801.04062 [cs, stat] (2018).


[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 4 - Beta', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Operating System :: OS Independent', 'License :: OSI Approved :: GNU General Public License v3 (GPLv3)']","['Bug Tracker, https://github.com/nygctech/PICASSO/issues']",,,napari-PICASSO.PicassoWidget,,,,,https://pypi.org/project/napari-PICASSO,https://github.com/nygctech/PICASSO,
247,Pixel correction,0.1.4,,,napari-pixel-correction,Herearii Metuarea,herearii.metuarea@gmail.com,BSD-3-Clause,,Plugin to correct manually pixel wrongly predicted on image by annotation,>=3.8,"['numpy', 'magicgui', 'qtpy', 'scikit-image', 'napari', 'matplotlib', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-pixel-correction

[![License BSD-3](https://img.shields.io/pypi/l/napari-pixel-correction.svg?color=green)](https://github.com/hereariim/napari-pixel-correction/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-pixel-correction.svg?color=green)](https://pypi.org/project/napari-pixel-correction)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-pixel-correction.svg?color=green)](https://python.org)
[![tests](https://github.com/hereariim/napari-pixel-correction/workflows/tests/badge.svg)](https://github.com/hereariim/napari-pixel-correction/actions)
[![codecov](https://codecov.io/gh/hereariim/napari-pixel-correction/branch/main/graph/badge.svg)](https://codecov.io/gh/hereariim/napari-pixel-correction)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-pixel-correction)](https://napari-hub.org/plugins/napari-pixel-correction)

Plugin to correct manually pixel wrongly predicted on image by annotation

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

This plugin allows you to manually correct the images of the apple tree flowers by annotation. Below, a piece of an image shows the predicted pixels (in brown). A pixel in brown is assigned to the flower class. We can see that the brown colour does not necessarily cover a flower in this image.

![Capture d’écran 2022-09-21 152404](https://user-images.githubusercontent.com/93375163/191530483-5ce230af-e34c-4fd5-ab91-1d611fd774d1.png)

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-pixel-correction` via [pip]:

    pip install napari-pixel-correction



To install latest development version :

    pip install git+https://github.com/hereariim/napari-pixel-correction.git

## How does it work

First, you need a compressed file (in .zip format) were you have all your images. For a compressed file named as `input.zip`, the compressed file should be built like :

```
.
└── input.zip
    └── repository
        ├── image
        │   ├── im_1.JPG
        │   ├── im_2.JPG  
        │   ├── im_3.JPG
        │   ...
        │   └── im_n.JPG
        │
        └── mask
            ├── im_1_mask.JPG
            ├── im_2_mask.JPG
            ├── im_3_mask.JPG
            ...
            └── im_n_mask.JPG
```
In repository, each image folder should have two elements : image in RGB and the segmented mask in binary image (where no-flower class is 0 and flower class is 255)

![napari-tutorial_simple](https://user-images.githubusercontent.com/93375163/191527225-47ba8667-e3bd-467b-b5f3-f8f7d97617a5.gif)

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-pixel-correction"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/hereariim/napari-pixel-correction/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Software Development :: Testing']","['Bug Tracker, https://github.com/hereariim/napari-pixel-correction/issues', 'Documentation, https://github.com/hereariim/napari-pixel-correction#README.md', 'Source Code, https://github.com/hereariim/napari-pixel-correction', 'User Support, https://github.com/hereariim/napari-pixel-correction/issues']",napari-pixel-correction.get_reader,napari-pixel-correction.write_multiple,napari-pixel-correction.load,,['*.npy'],,['.npy'],https://pypi.org/project/napari-pixel-correction,,
248,Napari PixSeq,1.0.0,,,napari-PixSeq,Piers Turner,piers.turner@physics.ox.ac.uk,MIT,,A Napari plugin for extracting time series traces from Single Molecule Localisation Microsocpy (SMLM) data.,>=3.8,"['napari[all]', 'numpy', 'magicgui', 'qtpy', 'scipy', 'pyqtgraph', 'picassosr', 'pandas', 'matplotlib', 'opencv-python', 'tqdm', 'originpro', 'pyqt5-tools', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-PixSeq

[![License MIT](https://img.shields.io/pypi/l/napari-GapSeq2.svg?color=green)](https://github.com/piedrro/napari-PixSeq/blob/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-GapSeq2.svg?color=green)](https://pypi.org/project/napari-PixSeq)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-GapSeq2.svg?color=green)](https://python.org)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-GapSeq2)](https://napari-hub.org/plugins/napari-PixSeq)

A **Napari** plugin for extracting time series traces from **Single Molecule Localisation Microsocpy** (SMLM) data.

Napari-PixSeq uses **Picasso** (picassosr) as a backend and includes features for **aligning** image channels/datasets, **undrifting** images, **detecting/fitting** localisations and extracting **traces**, and supports both **ALEX** and **FRET** data. Traces can be exported in different formats for downstream analysis.

This is still undergoing development, so some features may not work as expected.

This was built by Dr Piers Turner from the Kapanidis Lab, University of Oxford.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-GapSeq2` via [GitHub]:

    conda create –-name napari-pixseq python==3.9
    conda activate napari-pixseq
    conda install -c anaconda git
    conda update --all

    pip install git+https://github.com/piedrro/napari-PixSeq.git

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [MIT] license,
""napari-PixSeq"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/piedrro/napari-GapSeq2/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: MIT License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/piedrro/napari-PixSeq/issues', 'Documentation, https://github.com/piedrro/napari-PixSeq#README.md', 'Source Code, https://github.com/piedrro/napari-PixSeq', 'User Support, https://github.com/piedrro/napari-PixSeq/issues']",,,napari-PixSeq.make_qwidget,,,,,https://pypi.org/project/napari-PixSeq,,
249,napari-plot,0.1.5,2022-02-04,2023-06-18,napari-plot,Lukasz G. Migas,lukas.migas@yahoo.com,BSD-3,https://github.com/lukasz-migas/napari-1d,Plugin providing support for 1d plotting in napari.,>=3.7,"['napari-plugin-engine (>=0.1.4)', 'numpy', 'qtpy', 'qtawesome', 'napari (<0.4.15,>=0.4.13)', 'matplotlib', 'vispy (>=0.9.6)', ""PySide2 (!=5.15.0,>=5.13.2) ; extra == 'all'"", ""pre-commit (>=2.9.0) ; extra == 'dev'"", ""black (==22.1.0) ; extra == 'dev'"", ""flake8 (==4.0.1) ; extra == 'dev'"", ""PySide2 (!=5.15.0,>=5.13.2) ; extra == 'dev'"", ""pytest ; extra == 'dev'"", ""pytest-qt ; extra == 'dev'"", ""scikit-image ; extra == 'dev'"", ""PyQt5 (!=5.15.0,>=5.12.3) ; extra == 'pyqt'"", ""PyQt5 (!=5.15.0,>=5.12.3) ; extra == 'pyqt5'"", ""PySide2 (!=5.15.0,>=5.13.2) ; extra == 'pyside'"", ""PySide2 (!=5.15.0,>=5.13.2) ; extra == 'pyside2'"", ""PyQt5 (!=5.15.0,>=5.12.3) ; extra == 'qt'"", ""pytest ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""scikit-image ; extra == 'testing'""]","# napari-plot

[![License](https://img.shields.io/pypi/l/napari-plot.svg?color=green)](https://github.com/lukasz-migas/napari-1d/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-plot.svg?color=green)](https://pypi.org/project/napari-plot)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-plot.svg?color=green)](https://python.org)
[![tests](https://github.com/lukasz-migas/napari-1d/workflows/tests/badge.svg)](https://github.com/lukasz-migas/napari-1d/actions)
[![codecov](https://codecov.io/gh/lukasz-migas/napari-1d/branch/main/graph/badge.svg)](https://codecov.io/gh/lukasz-migas/napari-1d)

Plugin providing support for 1d plotting in napari.

This plugin is in very early stages of development and many things are still in a state of disarray. New features and bug fixes
will be coming over the coming months. 

## Note

`napari-plot` provides several custom icons and stylesheets to take advantage of the `Qt` backend. Since it would be a bit busy to add multiple layer lists,
I opted to include a toolbar that quickly pulls the layer list whenever requested. Simple use the toolbar to access several commonly accessed elements.

## Usage

You can use `napari-plot` alongside `napari` where it is embedded as a dock widget. If using this option, controls are relegated to toolbar
where you can adjust layer properties like you would do in `napari`.

![embedded](https://github.com/lukasz-migas/napari-1d/blob/main/misc/embedded.png)

Or as a standalone app where only one-dimensional plotting is enabled. In this mode, controls take central stage and reflect `napari's` own
behaviour where layer controls are embedded in the main application.

![live-view](https://github.com/lukasz-migas/napari-1d/blob/main/misc/napariplot-live-line.gif)

## Roadmap:

This is only provisional list of features that I would like to see implemented. It barely scratches the surface of what plotting tool should cover so as soon as the basics are covered,
focus will be put towards adding more exotic features. If there are features that you certainly wish to be included,
please modify the list below or create a [new issue](https://github.com/lukasz-migas/napari-1d/issues/new)

- [ ] Support for new layer types. Layers are based on `napari's` `Layer`, albeit in a two-dimensional setting. Supported and planned layers:
  - [x] Line Layer - simple line plot.
  - [x] Scatter Layer - scatter plot (similar to `napari's Points` layer).
  - [x] Centroids/Segments Layer - horizontal or vertical line segments.
  - [x] InfLine Layer - infinite horizontal or vertical lines that span over very broad range. Useful for defining regions of interest.
  - [x] Region Layer - infinite horizontal or vertical rectangular boxes that span over very broad range. Useful for defining regions of interest.
  - [x] Shapes Layer - `napari's` own `Shapes` layer
  - [x] Points Layer - `napari's` own `Points` layer
  - [x] Multi-line Layer - more efficient implementation of `Line` layer when multiple lines are necessary.
  - [ ] Bar - horizontal and vertical barchart (TODO)
- [x] Proper interactivity of each layer type (e.g. moving `Region` or `InfLine`, adding points, etc...)
- [x] Intuitive interactivity. `napari-plot` will provide excellent level of interactivity with the plotted data. We plan to support several types of `Tools` that permit efficient interrogation of the data. We currently provide several `zoom` and `select` tools and hope to add few extras in the future.
  - [x] Box-zoom - standard zooming rectangle. Simply `left-mouse + drag/release` in the canvas on region of interest
  - [x] Horizontal span - zoom-in only in the y-axis by `Ctrl + left-mouse + drag/release` in the canvas.
  - [x] Vertical span - span-in only in the x-axis by `Shift + left-mouse + drag/release` in the canvas.
  - [x] Rectangle select - rectangle tool allowing sub-selection of data in the canvas. Similar to the `Box-zoom` but without the zooming part.
  - [x] Polygon select - polygon tool allowing sub-selection of data in the canvas.
  - [x] Lasso select - lasso tool allowing sub-selection of data in the canvas.
- [ ] Interactive plot legend
- [ ] Customizable axis visuals.
  - [x] Plot axis enabling customization of tick/label size and color
  - [ ] Support for non-linear scale
- [ ] Add convenient plotting interface:
  - [ ] Add `.plot` functionality
  - [ ] Add `.scatter` functionality
  - [ ] Add `.hbar` and `.vbar` functionality
  - [ ] Add `.imshow` functionality

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/docs/plugins/index.html
-->

## Installation

You can install `napari-plot` directly from PyPI via:

```python
pip install napari-plot
```

or from the git repo:

```python
git clone https://github.com/lukasz-migas/napari-1d.git
cd napari-1d
pip install -e '.[all]'
```

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-plot"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/lukasz-migas/napari-1d/issues
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/


","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/lukasz-migas/napari-1d/issues', 'Documentation, https://github.com/lukasz-migas/napari-1d#README.md', 'Source Code, https://github.com/lukasz-migas/napari-1d', 'User Support, https://github.com/lukasz-migas/napari-1d/issues']",,,napari-plot.NapariPlotWidget,,,,,https://pypi.org/project/napari-plot,https://github.com/lukasz-migas/napari-1d,
250,napari-plot-profile,0.2.2,2022-02-05,2023-06-18,napari-plot-profile,"Robert Haase, Marcelo Leomil Zoccoler",robert.haase@tu-dresden.de,BSD-3-Clause,https://github.com/haesleinhuepf/napari-plot-profile,Plot intensity along a line and create topographical views in napari,>=3.7,"['napari-plugin-engine (>=0.1.4)', 'numpy', 'pyqtgraph', 'napari', 'napari-tools-menu', 'napari-skimage-regionprops (>=0.2.4)', 'imageio (!=2.22.1)']","# napari-plot-profile (npp)

[![License](https://img.shields.io/pypi/l/napari-plot-profile.svg?color=green)](https://github.com/haesleinhuepf/napari-plot-profile/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-plot-profile.svg?color=green)](https://pypi.org/project/napari-plot-profile)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-plot-profile.svg?color=green)](https://python.org)
[![tests](https://github.com/haesleinhuepf/napari-plot-profile/workflows/tests/badge.svg)](https://github.com/haesleinhuepf/napari-plot-profile/actions)
[![codecov](https://codecov.io/gh/haesleinhuepf/napari-plot-profile/branch/master/graph/badge.svg)](https://codecov.io/gh/haesleinhuepf/napari-plot-profile)
[![Development Status](https://img.shields.io/pypi/status/napari-plot-profile.svg)](https://en.wikipedia.org/wiki/Software_release_life_cycle#Alpha)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-plot-profile)](https://napari-hub.org/plugins/napari-plot-profile)

## Plot a Line Profile

Plot intensities along a line in [napari].

![img.png](https://github.com/haesleinhuepf/napari-plot-profile/raw/main/docs/napari-plot-profile-screencast.gif)

* Open some images in [napari].
  
* Add a shapes layer.

![img.png](https://github.com/haesleinhuepf/napari-plot-profile/raw/main/docs/add_shapes_layer_screenshot.png)
  
* Activate the line drawing tool or the path tool and draw a line.

![img.png](https://github.com/haesleinhuepf/napari-plot-profile/raw/main/docs/draw_line_tool_screenshot.png)
  
* After drawing a line, click on the menu Plugins > Measurements (Plot Profile)
* If you modify the line, you may want to click the ""Refresh"" button to redraw the profile.

![img.png](https://github.com/haesleinhuepf/napari-plot-profile/raw/main/docs/redraw_screenshot.png)

To see how these steps can be done programmatically from python, check out the [demo notebook](https://github.com/haesleinhuepf/napari-plot-profile/blob/main/docs/demo.ipynb)

## Create a Topographical View

Create a 3D view of a 2D image by warping pixel intensities to heights. It can be displayed as a 3D image layer, a points cloud layer or a surface layer.

![](https://github.com/haesleinhuepf/napari-plot-profile/raw/main/docs/topographical_view_screencast.gif)

This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.

----------------------------------

## Installation

You can install `napari-plot-profile` via [pip]:

    pip install napari-plot-profile

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-plot-profile"" is free and open source software

## Issues

If you encounter any problems, please create a thread on [image.sc] along with a detailed description and tag [@haesleinhuepf].

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/haesleinhuepf/napari-plot-profile/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
[image.sc]: https://image.sc
[@haesleinhuepf]: https://twitter.com/haesleinhuepf
","['Development Status :: 3 - Alpha', 'Intended Audience :: Science/Research', 'Framework :: napari', 'Topic :: Scientific/Engineering :: Image Processing', 'Topic :: Scientific/Engineering :: Information Analysis', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/haesleinhuepf/napari-plot-profile/issues', 'Documentation, https://github.com/haesleinhuepf/napari-plot-profile#README.md', 'Source Code, https://github.com/haesleinhuepf/napari-plot-profile', 'User Support, https://github.com/haesleinhuepf/napari-plot-profile/issues']",,,napari-plot-profile.PlotProfile,,,,,https://pypi.org/project/napari-plot-profile,https://github.com/haesleinhuepf/napari-plot-profile,
251,napari-plugin-search,0.1.4,2022-02-04,2023-06-18,napari-plugin-search,Robert Haase,robert.haase@tu-dresden.de,BSD-3-Clause,https://github.com/haesleinhuepf/napari-plugin-search,Find napari plugins,>=3.7,"['napari-plugin-engine (>=0.1.4)', 'numpy', 'napari-tools-menu']","# napari-plugin-search

[![License](https://img.shields.io/pypi/l/napari-plugin-search.svg?color=green)](https://github.com/haesleinhuepf/napari-plugin-search/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-plugin-search.svg?color=green)](https://pypi.org/project/napari-plugin-search)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-plugin-search.svg?color=green)](https://python.org)
[![tests](https://github.com/haesleinhuepf/napari-plugin-search/workflows/tests/badge.svg)](https://github.com/haesleinhuepf/napari-plugin-search/actions)
[![codecov](https://codecov.io/gh/haesleinhuepf/napari-plugin-search/branch/master/graph/badge.svg)](https://codecov.io/gh/haesleinhuepf/napari-plugin-search)

Find napari plugins
![img.png](https://github.com/haesleinhuepf/napari-plugin-search/raw/main/docs/napari-plugin-search-screencast.gif)

## Usage
Enter the name of the plugin you are searching for and use the `up` and `down` arrow keys to navigate between them. 
Hit `Enter` to start a plugin.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.

## Installation

You can install `napari-plugin-search` via [pip]:

    pip install napari-plugin-search

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-plugin-search"" is free and open source software

## Issues

If you encounter any problems, please create a thread on [image.sc] along with a detailed description and tag [@haesleinhuepf].

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/haesleinhuepf/napari-plugin-search/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
[image.sc]: https://image.sc
[@haesleinhuepf]: https://twitter.com/haesleinhuepf
","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Scientific/Engineering :: Image Processing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/haesleinhuepf/napari-plugin-search/issues', 'Documentation, https://github.com/haesleinhuepf/napari-plugin-search#README.md', 'Source Code, https://github.com/haesleinhuepf/napari-plugin-search', 'User Support, https://github.com/haesleinhuepf/napari-plugin-search/issues']",,,napari-plugin-search.PluginSearch,,,,,https://pypi.org/project/napari-plugin-search,https://github.com/haesleinhuepf/napari-plugin-search,
252,Points2Regions,0.0.2,,,napari-points2regions,Jonas Windhager,jonas@windhager.io,MIT,,A napari plugin for Points2Regions,>=3.9,"['colorcet', 'magicgui', 'napari', 'numpy', 'pandas', 'points2regions >=0.0.4', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-points2regions

[![License MIT](https://img.shields.io/pypi/l/napari-points2regions.svg?color=green)](https://github.com/wahlby-lab/napari-points2regions/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-points2regions.svg?color=green)](https://pypi.org/project/napari-points2regions)
[![tests](https://github.com/wahlby-lab/napari-points2regions/workflows/tests/badge.svg)](https://github.com/wahlby-lab/napari-points2regions/actions)
[![codecov](https://codecov.io/gh/wahlby-lab/napari-points2regions/branch/main/graph/badge.svg)](https://codecov.io/gh/wahlby-lab/napari-points2regions)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-points2regions.svg?color=green)](https://python.org)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-points2regions)](https://napari-hub.org/plugins/napari-points2regions)

A napari plugin for Points2Regions

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-points2regions` via [pip]:

    pip install napari-points2regions



To install latest development version :

    pip install git+https://github.com/wahlby-lab/napari-points2regions.git


## Contributing

Contributions are very welcome.

## License

Distributed under the terms of the [MIT] license,
""napari-points2regions"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/wahlby-lab/napari-points2regions/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Framework :: napari', 'Intended Audience :: Science/Research', 'License :: OSI Approved :: MIT License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/wahlby-lab/napari-points2regions/issues', 'Documentation, https://github.com/wahlby-lab/napari-points2regions#README.md', 'Source Code, https://github.com/wahlby-lab/napari-points2regions', 'User Support, https://github.com/wahlby-lab/napari-points2regions/issues']",,,napari-points2regions.load_points,,,,,https://pypi.org/project/napari-points2regions,,
253,Projection of Points layers,0.0.2,2023-04-12,2023-06-18,napari-pointslayer-projection,Niklas Netter,niknett@gmail.com,BSD-3-Clause,https://github.com/gatoniel/napari-pointslayer-projection,This plugin creates a 2d projection of all your points.,>=3.8,"['numpy', 'magicgui', 'qtpy', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-pointslayer-projection

[![License BSD-3](https://img.shields.io/pypi/l/napari-pointslayer-projection.svg?color=green)](https://github.com/gatoniel/napari-pointslayer-projection/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-pointslayer-projection.svg?color=green)](https://pypi.org/project/napari-pointslayer-projection)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-pointslayer-projection.svg?color=green)](https://python.org)
[![tests](https://github.com/gatoniel/napari-pointslayer-projection/workflows/tests/badge.svg)](https://github.com/gatoniel/napari-pointslayer-projection/actions)
[![codecov](https://codecov.io/gh/gatoniel/napari-pointslayer-projection/branch/main/graph/badge.svg)](https://codecov.io/gh/gatoniel/napari-pointslayer-projection)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-pointslayer-projection)](https://napari-hub.org/plugins/napari-pointslayer-projection)

This plugin creates a 2d projection of all your points.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-pointslayer-projection` via [pip]:

    pip install napari-pointslayer-projection



To install latest development version :

    pip install git+https://github.com/gatoniel/napari-pointslayer-projection.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-pointslayer-projection"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/gatoniel/napari-pointslayer-projection/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/gatoniel/napari-pointslayer-projection/issues', 'Documentation, https://github.com/gatoniel/napari-pointslayer-projection#README.md', 'Source Code, https://github.com/gatoniel/napari-pointslayer-projection', 'User Support, https://github.com/gatoniel/napari-pointslayer-projection/issues']",,,napari-pointslayer-projection.make_func_widget,,,,,https://pypi.org/project/napari-pointslayer-projection,https://github.com/gatoniel/napari-pointslayer-projection,
254,Differentiable Potential Field Navigation,0.1.1,,,napari-potential-field-navigation,Robin CREMESE,robin.cremese@gmail.com,MPL-2.0,,A simple plugin for trajectories visualisations in napari for lung navigation in CTs scans,>=3.8,"['napari', 'numpy', 'magicgui', 'qtpy', 'scikit-image', 'napari-itk-io', 'taichi', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-potential-field-navigation

[![License Mozilla Public License 2.0](https://img.shields.io/pypi/l/napari-potential-field-navigation.svg?color=green)](https://github.com/rcremese/napari-potential-field-navigation/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-potential-field-navigation.svg?color=green)](https://pypi.org/project/napari-potential-field-navigation)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-potential-field-navigation.svg?color=green)](https://python.org)
[![tests](https://github.com/rcremese/napari-potential-field-navigation/workflows/tests/badge.svg)](https://github.com/rcremese/napari-potential-field-navigation/actions)
[![codecov](https://codecov.io/gh/rcremese/napari-potential-field-navigation/branch/main/graph/badge.svg)](https://codecov.io/gh/rcremese/napari-potential-field-navigation)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-potential-field-navigation)](https://napari-hub.org/plugins/napari-potential-field-navigation)

A simple plugin for trajectories visualisations in napari for lung navigation in CTs scans

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-potential-field-navigation` via [pip]:

    pip install napari-potential-field-navigation



To install latest development version :

    pip install git+https://github.com/rcremese/napari-potential-field-navigation.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [Mozilla Public License 2.0] license,
""napari-potential-field-navigation"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/rcremese/napari-potential-field-navigation/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: Mozilla Public License 2.0 (MPL 2.0)', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/rcremese/napari-potential-field-navigation/issues', 'Documentation, https://github.com/rcremese/napari-potential-field-navigation#README.md', 'Source Code, https://github.com/rcremese/napari-potential-field-navigation', 'User Support, https://github.com/rcremese/napari-potential-field-navigation/issues']",napari-potential-field-navigation.get_reader,napari-potential-field-navigation.write_multiple,napari-potential-field-navigation.make_diff_apf_widget,napari-potential-field-navigation.make_sample_data,['*.npy'],,['.npy'],https://pypi.org/project/napari-potential-field-navigation,,
255,Power Spectrum,0.0.6,2022-06-16,2023-06-18,napari-power-spectrum,Giorgia Tortora,giorgiatortora2@gmail.com,BSD-3-Clause,https://github.com/GiorgiaTortora/napari-power-spectrum,A simple plugin to get the power spectrum of frames of a stack image,>=3.8,"['numpy', 'magicgui', 'qtpy', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-power-spectrum

[![License](https://img.shields.io/pypi/l/napari-power-spectrum.svg?color=green)](https://github.com/GiorgiaTortora/napari-power-spectrum/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-power-spectrum.svg?color=green)](https://pypi.org/project/napari-power-spectrum)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-power-spectrum.svg?color=green)](https://python.org)
[![tests](https://github.com/GiorgiaTortora/napari-power-spectrum/workflows/tests/badge.svg)](https://github.com/GiorgiaTortora/napari-power-spectrum/actions)
[![codecov](https://codecov.io/gh/GiorgiaTortora/napari-power-spectrum/branch/main/graph/badge.svg)](https://codecov.io/gh/GiorgiaTortora/napari-power-spectrum)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-power-spectrum)](https://napari-hub.org/plugins/napari-power-spectrum)

A simple plugin to get the power spectrum of frames of a stack image

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/stable/index.html
-->

## Installation

You can install `napari-power-spectrum` via [pip]:

    pip install napari-power-spectrum



To install latest development version :

    pip install git+https://github.com/GiorgiaTortora/napari-power-spectrum.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-power-spectrum"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/GiorgiaTortora/napari-power-spectrum/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/


","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/GiorgiaTortora/napari-power-spectrum/issues', 'Documentation, https://github.com/GiorgiaTortora/napari-power-spectrum#README.md', 'Source Code, https://github.com/GiorgiaTortora/napari-power-spectrum', 'User Support, https://github.com/GiorgiaTortora/napari-power-spectrum/issues']",,,napari-power-spectrum.make_powerspectrum_widget,,,,,https://pypi.org/project/napari-power-spectrum,https://github.com/GiorgiaTortora/napari-power-spectrum,
256,napari-power-widgets,0.0.1,2022-11-27,2023-06-18,napari-power-widgets,Hanjin Liu,liuhanjin-sc@g.ecc.u-tokyo.ac.jp,BSD-3-Clause,https://github.com/hanjinliu/napari-power-widgets,Powerful widgets and type annotations for napari plugin widgets,>=3.8,"['numpy', 'pandas', 'typing-extensions', 'magicgui', 'napari', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-power-widgets

[![License BSD-3](https://img.shields.io/pypi/l/napari-power-widgets.svg?color=green)](https://github.com/hanjinliu/napari-power-widgets/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-power-widgets.svg?color=green)](https://pypi.org/project/napari-power-widgets)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-power-widgets.svg?color=green)](https://python.org)
[![tests](https://github.com/hanjinliu/napari-power-widgets/workflows/tests/badge.svg)](https://github.com/hanjinliu/napari-power-widgets/actions)
[![codecov](https://codecov.io/gh/hanjinliu/napari-power-widgets/branch/main/graph/badge.svg)](https://codecov.io/gh/hanjinliu/napari-power-widgets)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-power-widgets)](https://napari-hub.org/plugins/napari-power-widgets)

Powerful `magicgui` widgets and type annotations for general-purpose napari plugin development.

`napari-power-widgets` makes the full use of type-to-widget mapping strategy of `magicgui` to provide napari-specific types and value-widgets, which will be very useful to improve UI/UX of your napari plugins with simple codes.

Currently, `napari-power-widgets` does not provide any reader, writer or widget. It is supposed to be used programmatically.

### Examples

Some types/widgets and the possible usage are picked up here ([&rarr; check all](https://github.com/hanjinliu/napari-power-widgets/blob/main/src/napari_power_widgets/types.py)). If you have any neat ideas, please open an issue.

#### 1. `BoxSelection`

Alias of a four-float tuple for 2D selection. You can set the value by drawing a interaction box in the viewer.

*e. g. : image cropper, rectangular labeling etc.*

```python
@magicgui
def f(box: BoxSelection):
    print(box)
viewer.window.add_dock_widget(f)
```

![](images/BoxSelection.gif)

#### 2. `OneOfRectangles`

Alias of `np.ndarray` for one of rectangles in a `Shapes` layer.

*e. g. : image cropper, rectangular labeling etc.*

```python
@magicgui
def f(rect: OneOfRectangles):
    print(rect)
viewer.window.add_dock_widget(f)
```

![](images/OneOfRectangles.gif)

#### 3. `LineData`

Alias of `np.ndarray` for a line data. You can obtain the data by manually drawing a line in the viewer.

*e. g. : line profiling, kymograph etc.*

```python
@magicgui
def f(line: LineData):
    print(line)
viewer.window.add_dock_widget(f)
```

![](images/LineData.gif)

#### 4. `OneOfLabels`

Alias of boolean `np.ndarray` for a labeled region. You can choose ones by directly clicking the viewer.

*e. g. : image masking, feature measurement etc.*

```python
@magicgui
def f(label: OneOfLabels):
    pass
viewer.window.add_dock_widget(f)
```

![](images/OneOfLabels.gif)


#### 5. `ZRange`

Alias of a tuple of float that represents the limit of the third dimension. You can select the values by moving the dimension slider.

*e. g. : movie trimming, partial image projection etc.*

```python
@magicgui
def f(zrange: ZRange):
    print(zrange)
viewer.window.add_dock_widget(f)
```

![](images/ZRange.gif)

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-power-widgets` via [pip]:

    pip install napari-power-widgets



To install latest development version :

    pip install git+https://github.com/hanjinliu/napari-power-widgets.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-power-widgets"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/hanjinliu/napari-power-widgets/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/hanjinliu/napari-power-widgets/issues', 'Documentation, https://github.com/hanjinliu/napari-power-widgets#README.md', 'Source Code, https://github.com/hanjinliu/napari-power-widgets', 'User Support, https://github.com/hanjinliu/napari-power-widgets/issues']",,,,,,,,https://pypi.org/project/napari-power-widgets,https://github.com/hanjinliu/napari-power-widgets,
257,napari PRAM,0.1.3,2022-07-06,2023-06-18,napari-pram,Hieu Hoang,hthieu@illinois.edu,MIT,https://pypi.org/project/napari-pram/,plugin for PRAM data annotation and processing,>=3.7,"['numpy', 'magicgui', 'qtpy', 'opencv-python', 'scipy', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-pram

[![License](https://img.shields.io/pypi/l/napari-pram.svg?color=green)](https://github.com/hthieu166/napari-pram/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-pram.svg?color=green)](https://pypi.org/project/napari-pram)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-pram.svg?color=green)](https://python.org)
[![tests](https://github.com/hthieu166/napari-pram/workflows/tests/badge.svg)](https://github.com/hthieu166/napari-pram/actions)
[![codecov](https://codecov.io/gh/hthieu166/napari-pram/branch/main/graph/badge.svg)](https://codecov.io/gh/hthieu166/napari-pram)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-pram)](https://napari-hub.org/plugins/napari-pram)

Plugin for PRAM data annotation and processing.

![PRAM Demo](https://raw.githubusercontent.com/hthieu166/napari-pram/main/docs/figs/demo.jpg)

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/stable/index.html
-->

## Usage

### Open `napari-pram` toolbox:

On the toolbar, select ``[Plugins] > napari-pram: Open PRAM's toolbox``

### Load PRAM image and annotations:

Press <kbd>Command/Control</kbd> + <kbd>O</kbd>: 
- Select `*.json` files for annotations (from either [VGG Annotator](https://www.robots.ox.ac.uk/~vgg/software/via/) or `napari-pram`)
- Select `*.png` files for PRAM image

### Annotate
- Press <kbd>Annotate</kbd>
- Click the plus-in-circle icon on the top-left panel and start editing

### Run PRAM particles detector
- Select a proper threshold between 1 (ultra sensitive) - 10 (less sensitive)
- Press <kbd>Run Detector</kbd>

### Evaluate
- Press <kbd>Evaluate</kbd>
- Hide/Unhide true positive/ false postive/false negative layers

### Load new image
- Press <kbd>Clear All</kbd> to remove all layers

### Export to JSON
- Press <kbd>Save to File</kbd> to export all annotations, predictions from the algorithm to a JSON file
## Installation
Following this [tutorial](https://napari.org/tutorials/fundamentals/quick_start.html) to install `napari`. 

Alternatively, you can follow my instructions as follows:

You will need a python environment. I recommend [Conda](https://docs.conda.io/en/latest/miniconda.html). Create a new environment, for example:
    
    conda create --name napari-env python=3.7 pip 

Activate the new environment:

    conda activate napari-env 

Install [napari](https://napari.org/tutorials/fundamentals/installation) via [pip]:

    pip install napari[all]

Then you can finally install our plugin `napari-pram` via [pip]:

    pip install napari-pram

Alternatively, the plugin can be installed using napari-GUI

``[Plugins] > Install/Uninstall Plugins`` and search for `napari-pram`

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [MIT] license,
""napari-pram"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/


","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Operating System :: OS Independent', 'License :: OSI Approved :: MIT License']",,napari-pram.get_img_reader,napari-pram.write_multiple,napari-pram.open_panel,napari-pram.make_sample_data,['*.png'],,['.npy'],https://pypi.org/project/napari-pram/,,
258,napari-process-points-and-surfaces,0.5.0,2023-04-13,2023-06-18,napari-process-points-and-surfaces,"Robert Haase, Johannes Soltwedel",robert.haase@tu-dresden.de,BSD-3-Clause,https://github.com/haesleinhuepf/napari-process-points-and-surfaces,Process and analyze surfaces using open3d and vedo in napari,>=3.7,"['napari-plugin-engine (>=0.1.4)', 'numpy', 'napari', 'napari-tools-menu (>=0.1.14)', 'napari-time-slicer (>=0.4.5)', 'napari-workflows (>=0.2.3)', 'vedo (>=2022.4.1)', 'napari-skimage-regionprops (>=0.5.5)', 'pandas', 'imageio (!=2.22.1)', 'stackview (>=0.5.2)']","# napari-process-points-and-surfaces (nppas)

[![License](https://img.shields.io/pypi/l/napari-process-points-and-surfaces.svg?color=green)](https://github.com/haesleinhuepf/napari-process-points-and-surfaces/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-process-points-and-surfaces.svg?color=green)](https://pypi.org/project/napari-process-points-and-surfaces)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-process-points-and-surfaces.svg?color=green)](https://python.org)
[![tests](https://github.com/haesleinhuepf/napari-process-points-and-surfaces/workflows/tests/badge.svg)](https://github.com/haesleinhuepf/napari-process-points-and-surfaces/actions)
[![codecov](https://codecov.io/gh/haesleinhuepf/napari-process-points-and-surfaces/branch/master/graph/badge.svg)](https://codecov.io/gh/haesleinhuepf/napari-process-points-and-surfaces)
[![Development Status](https://img.shields.io/pypi/status/napari-process-points-and-surfaces.svg)](https://en.wikipedia.org/wiki/Software_release_life_cycle#Alpha)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-process-points-and-surfaces)](https://napari-hub.org/plugins/napari-process-points-and-surfaces)
[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.7654555.svg)](https://doi.org/10.5281/zenodo.7654555)

Process and analyze surfaces using [vedo](https://vedo.embl.es/) in [napari].

![img.png](https://github.com/haesleinhuepf/napari-process-points-and-surfaces/raw/main/docs/graphical_abstract.gif)
The nppas gastruloid example is derived from [AV Luque and JV Veenvliet (2023)](https://zenodo.org/record/7603081) which is licensed [CC-BY](https://creativecommons.org/licenses/by/4.0/legalcode) and can be downloaded from here: https://zenodo.org/record/7603081

## Usage

You find menus for surface generation, smoothing and analysis in the menu `Tools > Surfaces` and `Tools > Points`. 
For detailed explanation of the underlying algorithms, please refer to the [vedo](https://vedo.embl.es/) documentation.

For processing meshes in Python scripts, see the [demo notebook](https://github.com/haesleinhuepf/napari-process-points-and-surfaces/blob/main/docs/demo.ipynb). 
There you also learn how this screenshot is made:

![img.png](https://github.com/haesleinhuepf/napari-process-points-and-surfaces/raw/main/docs/screenshot5.png)

For performing quantitative measurements of surface in Python scripts, see the [demo notebook](https://github.com/haesleinhuepf/napari-process-points-and-surfaces/blob/main/docs/quality_measurements.ipynb). 
There you also learn how this screenshot is made:

![img.png](https://github.com/haesleinhuepf/napari-process-points-and-surfaces/raw/main/docs/screenshot6.png)

### Surface measurements and annotations

Using the menu `Tools > Measurement tables > Surface quality table (vedo, nppas)` you can derive quantiative measurements of
the vertices in a given surface layer. 

![img_1.png](https://github.com/haesleinhuepf/napari-process-points-and-surfaces/raw/main/docs/surface_measurements2.png)

To differentiate regions when analyzing those measurements it is recommended to use the menu `Tools > Surfaces > Annotate surface manually (nppas)`
after measurements have been made. This tool allows you to draw annotation label values on the surface. 
It is recommended to do activate a colorful colormap such as `hsv` before starting to draw annotations. 
Furthermore, set the maximum of the contrast limit range to the number of regions you want to annotate + 1.
Annotations can be drawn as freehand lines and circles.

![img.png](https://github.com/haesleinhuepf/napari-process-points-and-surfaces/raw/main/docs/surface_annotation2.png)

After measurements and annotations were done, you can save the annotation in the same measurement table using the menu
`Tools > Measurement tables > Surface quality/annotation to table (nppas)`

![img.png](https://github.com/haesleinhuepf/napari-process-points-and-surfaces/raw/main/docs/surface_annotation_in_table2.png)

For classifying surface vertices using machine learning, please refer to the [napari APOC](https://www.napari-hub.org/plugins/napari-accelerated-pixel-and-object-classification) documentation.

### Measurement visualization

To visualize measurements on the surface, just double-click on the table column headers.

![img.png](https://github.com/haesleinhuepf/napari-process-points-and-surfaces/raw/main/docs/quality_measurements.gif)

## Installation

You can install `napari-process-points-and-surfaces` via mamba/conda and pip:

```
mamba install vedo vtk libnetcdf=4.7.4 -c conda-forge
pip install napari-process-points-and-surfaces
```

### Troubleshooting: Open3d installation

Since version 0.4.0, `nppas` does no longer depend on [open3d](http://www.open3d.org/). 
Some deprecated functions still use Open3d though. 
Follow the installation instructions in the [open3d documentation](http://www.open3d.org/docs/release/getting_started.htm) to install it and keep using those functions.
Also consider updating code and no longer using these deprecated functions. 
See [release notes](https://github.com/haesleinhuepf/napari-process-points-and-surfaces/releases/tag/0.4.0) for details.

## See also

There are other napari plugins with similar / overlapping functionality
* [morphometrics](https://www.napari-hub.org/plugins/morphometrics)  
* [napari-accelerated-pixel-and-object-classification](https://www.napari-hub.org/plugins/napari-accelerated-pixel-and-object-classification)
* [napari-pymeshlab](https://www.napari-hub.org/plugins/napari-pymeshlab)
* [napari-pyclesperanto-assistant](https://www.napari-hub.org/plugins/napari-pyclesperanto-assistant)
* [napari-stress](https://www.napari-hub.org/plugins/napari-stress)

And there is software for doing similar things:
* [meshlab](https://www.meshlab.net/)
* [paraview](https://www.paraview.org/)

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-process-points-and-surfaces"" is free and open source software

## Acknowledgements

Some code snippets and example data were taken from the [vedo](https://vedo.embl.es/) and [open3d](http://www.open3d.org/) 
repositories and documentation. See [thirdparty licenses](https://github.com/haesleinhuepf/napari-process-points-and-surfaces/tree/main/licenses_third_party) for licensing details.
The Standford Bunny example dataset has been taken from [The Stanford 3D Scanning Repository](http://graphics.stanford.edu/data/3Dscanrep/).
The nppas gastruloid example is derived from [AV Luque and JV Veenvliet (2023)](https://zenodo.org/record/7603081) which is licensed [CC-BY](https://creativecommons.org/licenses/by/4.0/legalcode) and can be downloaded from here: https://zenodo.org/record/7603081

## Issues

If you encounter any problems, please create a thread on [image.sc] along with a detailed description and tag [@haesleinhuepf].

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/haesleinhuepf/napari-process-points-and-surfaces/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/

[image.sc]: https://image.sc
[@haesleinhuepf]: https://twitter.com/haesleinhuepf
","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Science/Research', 'Framework :: napari', 'Topic :: Scientific/Engineering :: Image Processing', 'Topic :: Scientific/Engineering :: Information Analysis', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/haesleinhuepf/napari-process-points-and-surfaces/issues', 'Documentation, https://github.com/haesleinhuepf/napari-process-points-and-surfaces#README.md', 'Source Code, https://github.com/haesleinhuepf/napari-process-points-and-surfaces', 'User Support, https://github.com/haesleinhuepf/napari-process-points-and-surfaces/issues']",,,napari-process-points-and-surfaces.SurfaceAnnotationWidget,napari-process-points-and-surfaces._vedo_stanford_bunny_layerdatatuple,,,,https://pypi.org/project/napari-process-points-and-surfaces,https://github.com/haesleinhuepf/napari-process-points-and-surfaces,
259,napari proofread brainbow,0.3.0,2023-04-11,2023-06-18,napari-proofread-brainbow,Seongbin Lim,seongbin.lim@polytechnique.edu,MIT,https://pypi.org/project/napari-proofread-brainbow/,proofreading Brainbow images with napari,>=3.8,"['numpy', 'magicgui', 'qtpy', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""pytest-xvfb ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""qtpy ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-proofread-brainbow

[![License](https://img.shields.io/pypi/l/napari-proofread-brainbow.svg?color=green)](https://github.com/sbinnee/napari-proofread-brainbow/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-proofread-brainbow.svg?color=green)](https://pypi.org/project/napari-proofread-brainbow)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-proofread-brainbow.svg?color=green)](https://python.org)
[![tests](https://github.com/sbinnee/napari-proofread-brainbow/workflows/tests/badge.svg)](https://github.com/sbinnee/napari-proofread-brainbow/actions)
[![codecov](https://codecov.io/gh/sbinnee/napari-proofread-brainbow/branch/main/graph/badge.svg)](https://codecov.io/gh/sbinnee/napari-proofread-brainbow)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-proofread-brainbow)](https://napari-hub.org/plugins/napari-proofread-brainbow)

proofreading with napari

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/stable/index.html
-->

## Installation

You can install `napari-proofread-brainbow` via [pip]:

    pip install napari-proofread-brainbow




## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [MIT] license,
""napari-proofread-brainbow"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Operating System :: OS Independent', 'License :: OSI Approved :: MIT License']",,,,napari-proofread-brainbow.make_qwidget,,,,,https://pypi.org/project/napari-proofread-brainbow/,,
260,napari-properties-plotter,0.2.2,2022-01-28,2023-06-18,napari-properties-plotter,Lorenzo Gaifas,lorenzo.gaifas@gmail.com,BSD-3,https://github.com/brisvag/napari-properties-plotter,A napari plugin that automatically generates interactive plots based on layer properties.,>=3.7,"['napari-plugin-engine (>=0.1.4)', 'numpy', 'pandas', 'pyqtgraph', 'qtpy']","# napari-properties-plotter

[![License](https://img.shields.io/pypi/l/napari-properties-plotter.svg?color=green)](https://github.com/brisvag/napari-properties-plotter/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-properties-plotter.svg?color=green)](https://pypi.org/project/napari-properties-plotter)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-properties-plotter.svg?color=green)](https://python.org)
[![tests](https://github.com/brisvag/napari-properties-plotter/workflows/tests/badge.svg)](https://github.com/brisvag/napari-properties-plotter/actions)
[![codecov](https://codecov.io/gh/brisvag/napari-properties-plotter/branch/master/graph/badge.svg)](https://codecov.io/gh/brisvag/napari-properties-plotter)

A napari plugin that automatically generates interactive plots based on layer properties.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/docs/plugins/index.html
-->

## Installation

You can install `napari-properties-plotter` via [pip]:

    pip install napari-properties-plotter

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-properties-plotter"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/brisvag/napari-properties-plotter/issues
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/


","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/brisvag/napari-properties-plotter/issues', 'Documentation, https://github.com/brisvag/napari-properties-plotter#README.md', 'Source Code, https://github.com/brisvag/napari-properties-plotter', 'User Support, https://github.com/brisvag/napari-properties-plotter/issues']",,,napari-properties-plotter.PropertyPlotter,,,,,https://pypi.org/project/napari-properties-plotter,https://github.com/brisvag/napari-properties-plotter,
261,napari-properties-viewer,0.0.2,2022-02-10,2023-06-18,napari-properties-viewer,Kevin Yamauchi,kevin.yamauchi@gmail.com,BSD-3,https://github.com/kevinyamauchi/napari-properties-viewer,A viewer for napari layer properties,>=3.6,"['napari-plugin-engine (>=0.1.4)', 'numpy']","# napari-properties-viewer

[![License](https://img.shields.io/pypi/l/napari-properties-viewer.svg?color=green)](https://github.com/napari/napari-properties-viewer/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-properties-viewer.svg?color=green)](https://pypi.org/project/napari-properties-viewer)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-properties-viewer.svg?color=green)](https://python.org)
[![tests](https://github.com/kevinyamauchi/napari-properties-viewer/workflows/tests/badge.svg)](https://github.com/kevinyamauchi/napari-properties-viewer/actions)
[![codecov](https://codecov.io/gh/kevinyamauchi/napari-properties-viewer/branch/master/graph/badge.svg)](https://codecov.io/gh/kevinyamauchi/napari-properties-viewer)

A viewer for napari layer properties

![image](resources/properties_viewer.gif)
----------------------------------

This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/docs/plugins/index.html
-->

## Installation

You can install `napari-properties-viewer` via [pip]:

    pip install napari-properties-viewer
    
## Using the properties viewer table

1. Open a a napari viewer with a layer with properties (e.g., Points)
2. View the properties by opening the properties viewer plugin from Plugins menu -> Add dock widget -> napari-propertiews-viewer: properties table
3. The layer property values are now displayed in the table widget. You can edit the values by double clicking the cell of interest and entering a new value.

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-properties-viewer"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/kevinyamauchi/napari-properties-viewer/issues
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/


","['Development Status :: 4 - Beta', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']",,,,napari-properties-viewer.QtPropertiesTable,,,,,https://pypi.org/project/napari-properties-viewer,https://github.com/kevinyamauchi/napari-properties-viewer,
262,PSF simulator,0.3.1,2022-07-07,2023-11-07,napari-psf-simulator,Andrea Bassi,andrea1.bassi@polimi.it,BSD-3-Clause,https://github.com/andreabassi78/napari-psf-simulator,"A plugin for simulations of the Point Spread Function, with aberrations",>=3.8,"['numpy', 'magicgui', 'qtpy', 'PyCustomFocus >=3.3.6', 'matplotlib', 'scikit-image', 'scipy', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""qtpy ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'"", ""PyCustomFocus >=3.3.6 ; extra == 'testing'"", ""matplotlib ; extra == 'testing'"", ""scikit-image ; extra == 'testing'"", ""scipy ; extra == 'testing'""]","# napari-psf-simulator

[![License](https://img.shields.io/pypi/l/napari-psf-simulator.svg?color=green)](https://github.com/andreabassi78/napari-psf-simulator/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-psf-simulator.svg?color=green)](https://pypi.org/project/napari-psf-simulator)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-psf-simulator.svg?color=green)](https://python.org)
[![tests](https://github.com/andreabassi78/napari-psf-simulator/workflows/tests/badge.svg)](https://github.com/andreabassi78/napari-psf-simulator/actions)
[![codecov](https://codecov.io/gh/andreabassi78/napari-psf-simulator/branch/main/graph/badge.svg)](https://codecov.io/gh/andreabassi78/napari-psf-simulator)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-psf-simulator)](https://napari-hub.org/plugins/napari-psf-simulator)

A plugin for the simulation of the 3D Point Spread Function of an optical systen, particularly a microscope objective.
 
Calculates the PSF using scalar and vectorial models.  
The following aberrations are included:
- phase aberration described by a Zernike polynomials with n-m coefficients.
- aberration induced by a slab, with a refractive index different from the one at the object.  

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/stable/index.html
-->

## Installation

You can install `napari-psf-simulator` via [pip]:

    pip install napari-psf-simulator


To install latest development version :

    pip install git+https://github.com/andreabassi78/napari-psf-simulator.git


## Usage

1) Lauch the plugin and select the parameters of the microscope: `NA` (numerical aperture), `wavelenght`, `n` (refractive index at the object),
   `FOV xy` (field of view in the transverse direction), `FOV z` (field of view in the axial direction), `dxy` (pixel size, transverse sampling), `dz` (voxel depth, axial sampling), `lens radius` (physical aperture of the lens, used in vectorial model)

2) Select a propagation model between `scalar` and `vectorial`.  

3) Select an aberration type (if needed).

4) Press `Calculate PSF` to run the simulator. This will create a new image layer with the 3D PSF.
 
   The option `Show Airy disk` creates a circle with radius given by the diffraction limit (Rayleigh criterion).

![raw](https://github.com/andreabassi78/napari-psf-simulator/raw/main/images/figure.png)
**Napari viewer with the psf-simulator widget showing the in-focus plane of an aberrated PSF**

![raw](https://github.com/andreabassi78/napari-psf-simulator/raw/main/images/animation.gif)
**Slicing through a PSF aberrated with Zernike polynomials of order N=3, M=1 (coma)**

3) Click on the `Plot PSF Profile in Console` checkbox to see the x and z profiles of the PSF.
   They will show up in  the viewer console when `Calculate PSF` is executed.

![raw](https://github.com/andreabassi78/napari-psf-simulator/raw/main/images/Plot.png)
**Plot profile of the PSF, shown in the Console**

## Detailed documentation

An exhaustive documentation of the use of the plugin on scalar and vectoral propagation models can be found in [this] presentation.

A detailed explanation of the uses and advantages that simulating a PSF brings can be found [here].

The vectorial propagation model implements a secondary library: [pyfocus](https://github.com/fcaprile/PyFocus). The full documentation of this library can be found at [read the docs](https://pyfocus.readthedocs.io/en/latest/) and in the paper: ""PyFocus: A Python package for vectorial calculations of focused optical fields under realistic conditions. Application to toroidal foci."" https://doi.org/10.1016/j.cpc.2022.108315

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request. 
The plugin has been concived to be modular allowing the insertion of new aberations and pupils. Please contact the developers on github for adding new propagations and aberrations types. 
Any suggestions or contributions are welcome.

## License

Distributed under the terms of the [BSD-3] license,
""napari-psf-simulator"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/andreabassi78/napari-psf-simulator/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/

[this]: https://github.com/andreabassi78/napari-psf-simulator/raw/main/docs/napari_psf_simullator_presentation.pdf

[here]: https://github.com/andreabassi78/napari-psf-simulator/raw/main/docs/pyfocus_seminar.pptx
","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/andreabassi78/napari-psf-simulator/issues', 'Documentation, https://github.com/andreabassi78/napari-psf-simulator#README.md', 'Source Code, https://github.com/andreabassi78/napari-psf-simulator', 'User Support, https://github.com/andreabassi78/napari-psf-simulator/issues']",,,napari-psf-simulator.make_widget,,,,,https://pypi.org/project/napari-psf-simulator,https://github.com/andreabassi78/napari-psf-simulator,
263,napari PSSR,0.1,2023-04-18,2023-06-18,napari-pssr,William Patton,will.hunter.patton@gmail.com,MIT,https://github.com/pattonw/napari-pssr,A plugin for training and applying pssr,>=3.7,"['numpy', 'zarr', 'magicgui', 'bioimageio.core', 'gunpowder', 'matplotlib', 'torch', 'napari']","# napari-pssr

[![License](https://img.shields.io/pypi/l/napari-pssr.svg?color=green)](https://github.com/pattonw/napari-pssr/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-pssr.svg?color=green)](https://pypi.org/project/napari-pssr)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-pssr.svg?color=green)](https://python.org)
[![tests](https://github.com/pattonw/napari-pssr/workflows/tests/badge.svg)](https://github.com/pattonw/napari-pssr/actions)
[![codecov](https://codecov.io/gh/pattonw/napari-pssr/branch/main/graph/badge.svg)](https://codecov.io/gh/pattonw/napari-pssr)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-pssr)](https://napari-hub.org/plugins/napari-pssr)

A plugin for training and applying pssr

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/stable/index.html
-->

## Installation

You can install `napari-pssr` via [pip]:

    pip install napari-pssr

Some libraries need to be updated to the most recent version to get all features.
These will be updated once they are released on pypi
    
    pip install git+https://github.com/bioimage-io/core-bioimage-io-python"",
    pip install git+https://github.com/funkey/gunpowder.git@patch-1.2.3"",


To install latest development version :

    pip install git+https://github.com/pattonw/napari-pssr.git

## Model download

A sample model can be downloaded from `https://github.com/pattonw/model-specs/tree/main/pssr`. This model comes with some restrictive dependencies. To use follow these steps.
1) install this plugin following the directions provided above
2) install bioimageio.core via `pip install bioimageio.core` or `conda install -c conda-forge bioimageio.core`
3) `pip install fastai==1.0.55 tifffile libtiff czifile scikit-image`
4) `pip uninstall torch torchvision` (may need multiple runs)
5) `conda install pytorch==1.1.0 torchvision==0.3.0 cudatoolkit=10.0 -c pytorch`
6) `pip install pillow==6.1.0`

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [MIT] license,
""napari-pssr"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/pattonw/napari-pssr/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: MIT License']","['Bug Tracker, https://github.com/pattonw/napari-pssr/issues', 'Documentation, https://github.com/pattonw/napari-pssr#README.md', 'Source Code, https://github.com/pattonw/napari-pssr', 'User Support, https://github.com/pattonw/napari-pssr/issues']",,,napari-pssr.make_pssr_widget,napari-pssr.lr_em,,,,https://pypi.org/project/napari-pssr,https://github.com/pattonw/napari-pssr,
264,napari-pyclesperanto-assistant,0.22.1,2022-04-01,2023-06-18,napari-pyclesperanto-assistant,"Robert Haase, Talley Lambert",robert.haase@tu-dresden.de,BSD-3-Clause,https://github.com/clesperanto/napari_pyclesperanto_assistant,GPU-accelerated image processing in napari using OpenCL,>=3.6,"['napari-plugin-engine (>=0.1.4)', 'pyopencl', 'toolz', 'scikit-image', 'napari (>=0.4.15)', 'pyclesperanto-prototype (>=0.22.0)', 'magicgui', 'numpy (!=1.19.4)', 'pyperclip', 'loguru', 'jupytext', 'jupyter', 'pandas', 'napari-tools-menu (>=0.1.8)', 'napari-time-slicer (>=0.4.0)', 'napari-skimage-regionprops (>=0.2.0)', 'napari-workflows (>=0.1.1)', 'napari-assistant (>=0.2.0)']","# napari-pyclesperanto-assistant
[![Image.sc forum](https://img.shields.io/badge/dynamic/json.svg?label=forum&url=https%3A%2F%2Fforum.image.sc%2Ftag%2Fclesperanto.json&query=%24.topic_list.tags.0.topic_count&colorB=brightgreen&suffix=%20topics&logo=data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAA4AAAAOCAYAAAAfSC3RAAABPklEQVR42m3SyyqFURTA8Y2BER0TDyExZ+aSPIKUlPIITFzKeQWXwhBlQrmFgUzMMFLKZeguBu5y+//17dP3nc5vuPdee6299gohUYYaDGOyyACq4JmQVoFujOMR77hNfOAGM+hBOQqB9TjHD36xhAa04RCuuXeKOvwHVWIKL9jCK2bRiV284QgL8MwEjAneeo9VNOEaBhzALGtoRy02cIcWhE34jj5YxgW+E5Z4iTPkMYpPLCNY3hdOYEfNbKYdmNngZ1jyEzw7h7AIb3fRTQ95OAZ6yQpGYHMMtOTgouktYwxuXsHgWLLl+4x++Kx1FJrjLTagA77bTPvYgw1rRqY56e+w7GNYsqX6JfPwi7aR+Y5SA+BXtKIRfkfJAYgj14tpOF6+I46c4/cAM3UhM3JxyKsxiOIhH0IO6SH/A1Kb1WBeUjbkAAAAAElFTkSuQmCC)](https://forum.image.sc/tag/clesperanto)
[![website](https://img.shields.io/website?url=http%3A%2F%2Fclesperanto.net)](http://clesperanto.net)
[![License](https://img.shields.io/pypi/l/napari-pyclesperanto-assistant.svg?color=green)](https://github.com/clesperanto/napari-pyclesperanto-assistant/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-pyclesperanto-assistant.svg?color=green)](https://pypi.org/project/napari-pyclesperanto-assistant)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-pyclesperanto-assistant.svg?color=green)](https://python.org)
[![tests](https://github.com/clesperanto/napari_pyclesperanto_assistant/workflows/tests/badge.svg)](https://github.com/clesperanto/napari_pyclesperanto_assistant/actions)
[![codecov](https://codecov.io/gh/clesperanto/napari_pyclesperanto_assistant/branch/master/graph/badge.svg)](https://codecov.io/gh/clesperanto/napari_pyclesperanto_assistant)
[![Development Status](https://img.shields.io/pypi/status/napari_pyclesperanto_assistant.svg)](https://en.wikipedia.org/wiki/Software_release_life_cycle#Alpha)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-pyclesperanto-assistant)](https://napari-hub.org/plugins/napari-pyclesperanto-assistant)
[![DOI](https://zenodo.org/badge/322312181.svg)](https://zenodo.org/badge/latestdoi/322312181)

The py-clEsperanto-assistant is a yet experimental [napari](https://github.com/napari/napari) plugin for building GPU-accelerated image processing workflows. 
It is part of the [clEsperanto](http://clesperanto.net) project and thus, aims at removing programming language related barriers between image processing ecosystems in the life sciences. 
It uses [pyclesperanto](https://github.com/clEsperanto/pyclesperanto_prototype) and with that [pyopencl](https://documen.tician.de/pyopencl/) as backend for processing images.

This napari plugin adds some menu entries to the Tools menu. You can recognize them with their suffix `(clEsperanto)` in brackets.
Furthermore, it can be used from the [napari-assistant](https://www.napari-hub.org/plugins/napari-assistant) graphical user interface. 
Therefore, just click the menu `Tools > Utilities > Assistant (na)` or run `naparia` from the command line.

![](https://github.com/clEsperanto/napari_pyclesperanto_assistant/raw/master/docs/images/virtual_4d_support1.gif)

## Usage

### Start up the assistant
Start up napari, e.g. from the command line:
```
napari
```

Load example data, e.g. from the menu `File > Open Samples > clEsperanto > CalibZAPWfixed` and 
start the assistant from the menu `Tools > Utilities > Assistant (na)`.

![](https://github.com/clEsperanto/napari_pyclesperanto_assistant/raw/master/docs/images/screenshot1.png)

In case of two dimensional timelapse data, an initial conversion step might be necessary depending on your data source. 
Click the menu `Tools > Utilities > Convert to 2d timelapse`. In the dialog, select the dataset and click ok. 
You can delete the original dataset afterwards:

![](https://github.com/clEsperanto/napari_pyclesperanto_assistant/raw/master/docs/images/screenshot1a.png)

### Set up a workflow

Choose categories of operations in the top right panel, for example start with denoising using a Gaussian Blur with sigma 1 in x and y.

![](https://github.com/clEsperanto/napari_pyclesperanto_assistant/raw/master/docs/images/screenshot2.png)

Continue with background removal using the top-hat filter with radius 5 in x and y.

![](https://github.com/clEsperanto/napari_pyclesperanto_assistant/raw/master/docs/images/screenshot2a.png)

For labeling the objects, use [Voronoi-Otsu-Labeling](https://nbviewer.jupyter.org/github/clEsperanto/pyclesperanto_prototype/blob/master/demo/segmentation/voronoi_otsu_labeling.ipynb) with both sigma parameters set to 2.

![](https://github.com/clEsperanto/napari_pyclesperanto_assistant/raw/master/docs/images/screenshot2b.png)

The labeled objects can be extended using a Voronoi diagram to derive a estimations of cell boundaries.

![](https://github.com/clEsperanto/napari_pyclesperanto_assistant/raw/master/docs/images/screenshot2c.png)

You can then configure napari to show the label boundaries on top of the original image:

![](https://github.com/clEsperanto/napari_pyclesperanto_assistant/raw/master/docs/images/screenshot2d.png)

When your workflow is set up, click the play button below your dataset:

![](https://github.com/clEsperanto/napari_pyclesperanto_assistant/raw/master/docs/images/timelapse_2d.gif)

### Neighbor statistics

When working with 2D or 3D data you can analyze measurements in relationship with their neighbors. 
For example, you can measure the area of blobs as shown in the example shown below using the menu 
`Tools > Measurements > Statistics of labeled pixels (clesperant)` and visualize it as `area` image by double-clicking on the table column (1).
Additionally, you can measure the maximum area of the 6 nearest neighbors using the menu `Tools > Measurments > Neighborhood statistics of measurements`.
The new column will then be called ""max_nn6_area..."" (2). When visualizing such parametric images next by each other, it is recommended to use
[napari-brightness-contrast](https://www.napari-hub.org/plugins/napari-brightness-contrast) and visualize the same intensity range to see differences correctly.

![](https://github.com/clEsperanto/napari_pyclesperanto_assistant/raw/master/docs/images/neighbor_statistics.png)

### Code generation
You can also export your workflow as Python/Jython code or as notebook. See the [napari-assistant documentation](https://www.napari-hub.org/plugins/napari-assistant) for details.

## Features
[pyclesperanto](https://github.com/clEsperanto/pyclesperanto_prototype) offers various possibilities for processing images. It comes from developers who work in life sciences and thus, it may be focused towards processing two- and three-dimensional microscopy image data showing cells and tissues. A selection of pyclesperanto's functionality is available via the assistant user interface. Typical workflows which can be built with this assistant include
* image filtering
  * denoising / noise reduction (mean, median, Gaussian blur)
  * background subtraction for uneven illumination or out-of-focus light (bottom-hat, top-hat, subtract Gaussian background)
  * grey value morphology (local minimum, maximum. variance)
  * gamma correction
  * Laplace operator
  * Sobel operator
* combining images
  * masking
  * image math (adding, subtracting, multiplying, dividing images) 
  * absolute / squared difference
* image transformations
  * translation
  * rotation
  * scale
  * reduce stack  
  * sub-stacks
* image projections
  * minimum / mean / maximum / sum / standard deviation projections
* image segmentation
  * binarization (thresholding, local maxima detection)
  * labeling
  * regionalization
  * instance segmentation
  * semantic segmentation
  * detect label edges
  * label spots
  * connected component labeling
  * Voronoi-Otsu-labeling
* post-processing of binary images
  * dilation
  * erosion
  * binary opening
  * binary closing 
  * binary and / or / xor
* post-processing of label images
  * dilation (expansion) of labels
  * extend labels via Voronoi
  * exclude labels on edges
  * exclude labels within / out of size / value range
  * merge touching labels
* parametric maps
  * proximal / touching neighbor count
  * distance measurements to touching / proximal / n-nearest neighbors
  * pixel count map
  * mean / maximum / extension ratio map
* label measurements / post processing of parametric maps
  * minimum / mean / maximum / standard deviation intensity maps
  * minimum / mean / maximum / standard deviation of touching / n-nearest / neighbors
* neighbor meshes
  * touching neighbors
  * n-nearest neighbors
  * proximal neighbors
  * distance meshes
* measurements based on label images
  * bounding box 2D / 3D
  * minimum / mean / maximum / sum / standard deviation intensity
  * center of mass
  * centroid
  * mean / maximum distance to centroid (and extension ratio shape descriptor)
  * mean / maximum distance to center of mass (and extension ratio shape descriptor)
  * statistics of neighbors (See related [publication](https://www.frontiersin.org/articles/10.3389/fcomp.2021.774396/full))
* code export
  * python / Fiji-compatible jython
  * python jupyter notebooks
* pyclesperanto scripting
  * cell segmentation
  * cell counting
  * cell differentiation
  * tissue classification

## Installation

It is recommended to install the assistant using conda. If you have never used conda before, it is recommended to read 
[this blog post](https://biapol.github.io/blog/johannes_mueller/anaconda_getting_started/) first. 

```shell
conda create --name cle_39 python=3.9 napari-pyclesperanto-assistant
conda activate cle_39
```

Mac-users please also install this:

    conda install -c conda-forge ocl_icd_wrapper_apple
    
Linux users please also install this:
    
    conda install -c conda-forge ocl-icd-system

You can then start the napari-assistant using this command:

```
naparia
```


## Feedback and contributions welcome!
clEsperanto is developed in the open because we believe in the open source community. See our [community guidelines](https://clij.github.io/clij2-docs/community_guidelines). Feel free to drop feedback as [github issue](https://github.com/clEsperanto/pyclesperanto_prototype/issues) or via [image.sc](https://image.sc)

## Acknowledgements
This project was supported by the Deutsche Forschungsgemeinschaft under Germanyâ€™s Excellence Strategy â€“ EXC2068 - Cluster of Excellence ""Physics of Life"" of TU Dresden.
This project has been made possible in part by grant number [2021-240341 (Napari plugin accelerator grant)](https://chanzuckerberg.com/science/programs-resources/imaging/napari/improving-image-processing/) from the Chan Zuckerberg Initiative DAF, an advised fund of the Silicon Valley Community Foundation.

[Imprint](https://clesperanto.github.io/imprint)

","['Programming Language :: Python :: 3', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Framework :: napari', 'Intended Audience :: Science/Research', 'Development Status :: 3 - Alpha']","['Bug Tracker, https://github.com/clEsperanto/napari_pyclesperanto_assistant/issues', 'Documentation, https://github.com/clEsperanto/napari_pyclesperanto_assistant/', 'Source Code, https://github.com/clEsperanto/napari_pyclesperanto_assistant', 'User Support, https://forum.image.sc/tag/clij']",,,napari-pyclesperanto-assistant.Assistant,napari-pyclesperanto-assistant._load_Lund,,,,https://pypi.org/project/napari-pyclesperanto-assistant,https://github.com/clesperanto/napari_pyclesperanto_assistant,
265,napari pymeshlab,0.0.5,,,napari-pymeshlab,"Zach Marin, Robert Haase",zach.marin@yale.edu,MIT,,"Interfaces between napari and pymeshlab library to allow import, export and construction of surfaces.",>=3.7,"['npe2', 'numpy', 'pymeshlab']","# napari-pymeshlab

[![License](https://img.shields.io/pypi/l/napari-pymeshlab.svg?color=green)](https://github.com/zacsimile/napari-pymeshlab/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-pymeshlab.svg?color=green)](https://pypi.org/project/napari-pymeshlab)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-pymeshlab.svg?color=green)](https://python.org)
[![tests](https://github.com/zacsimile/napari-pymeshlab/workflows/tests/badge.svg)](https://github.com/zacsimile/napari-pymeshlab/actions)
[![codecov](https://codecov.io/gh/zacsimile/napari-pymeshlab/branch/main/graph/badge.svg)](https://codecov.io/gh/zacsimile/napari-pymeshlab)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-pymeshlab)](https://napari-hub.org/plugins/napari-pymeshlab)

Interfaces between `napari` and the `pymeshlab` library to allow import, export, construction and processing of surfaces. 

This is a WIP and feature requests are welcome. Please check [PyMeshLab](https://pymeshlab.readthedocs.io/en/latest/)
for possible features.

![img.png](docs/screenshot.png)

## Feature list

- Read/write .3ds, .apts, .asc, .bre, .ctm, .dae, .e57, .es, .fbx, .glb, .gltf, .obj, .off, .pdb, .ply,
                  .ptx, .qobj, .stl, .vmi, .wrl, .x3d, .x3dv
- [Screened Poisson Surface Reconstruction](https://www.cs.jhu.edu/~misha/MyPapers/ToG13.pdf)
- [Convex hull of a surface](https://pymeshlab.readthedocs.io/en/0.1.9/tutorials/apply_filter.html)
- [Laplacian smoothing of surfaces](https://pymeshlab.readthedocs.io/en/0.1.9/filter_list.html#laplacian_smooth)
- [Smoothing surfaces using Taubin's method](https://pymeshlab.readthedocs.io/en/0.1.9/filter_list.html#taubin_smooth)
- [Surface simplification using clustering decimation](https://pymeshlab.readthedocs.io/en/0.1.9/filter_list.html#simplification_clustering_decimation)
- [colorize_curvature_apss](https://pymeshlab.readthedocs.io/en/0.1.9/filter_list.html#colorize_curvature_apss)

Some functions are shown in the [demo notebook](docs/demo.ipynb).

----------------------------------

<!--

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/stable/index.html
-->

## Installation 

You can install `napari-pymeshlab` via [pip]:

    pip install napari-pymeshlab




## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [GNU GPL v3.0] license,
""napari-pymeshlab"" is free and open source software

## Issues

If you encounter any problems, please [file an issue](https://github.com/zacsimile/napari-pymeshlab/issues) along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/


","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: GNU General Public License v3 (GPLv3)']","['Bug Tracker, https://github.com/zacsimile/napari-pymeshlab/issues', 'Documentation, https://github.com/zacsimile/napari-pymeshlab#README.md', 'Source Code, https://github.com/zacsimile/napari-pymeshlab', 'User Support, https://github.com/zacsimile/napari-pymeshlab/issues']",napari-pymeshlab.get_mesh_reader,napari-pymeshlab.write_single_surface,napari-pymeshlab.screened_poisson_reconstruction,napari-pymeshlab.make_sphere,"['*.3ds', '*.apts', '*.asc', '*.bre', '*.ctm', '*.dae', '*.e57', '*.es', '*.fbx', '*.glb', '*.gltf', '*.obj', '*.off', '*.pdb', '*.ply', '*.ptx', '*.qobj', '*.stl', '*.vmi', '*.wrl', '*.x3d', '.x3dv']","['.3ds', '.apts', '.asc', '.bre', '.ctm', '.dae', '.e57', '.es', '.fbx', '.glb', '.gltf', '.obj', '.off', '.pdb', '.ply', '.ptx', '.qobj', '.stl', '.vmi', '.wrl', '.x3d', '.x3dv']",,https://pypi.org/project/napari-pymeshlab,,
266,napari pystackreg,0.1.4,2022-07-18,2023-06-18,napari-pystackreg,Gregor Lichtner,gregor.lichtner@med.uni-greifswald.de,Apache-2.0,https://github.com/glichtner/napari-pystackreg,Robust image registration for napari,>=3.8,"['magicgui', 'numpy', 'pystackreg (>=0.2.6)', 'qtpy', ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""tox ; extra == 'testing'""]","# napari-pystackreg

[![License](https://img.shields.io/pypi/l/napari-pystackreg.svg?color=green)](https://github.com/glichtner/napari-pystackreg/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-pystackreg.svg?color=green)](https://pypi.org/project/napari-pystackreg)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-pystackreg.svg?color=green)](https://python.org)
[![tests](https://github.com/glichtner/napari-pystackreg/workflows/tests/badge.svg)](https://github.com/glichtner/napari-pystackreg/actions)
[![codecov](https://codecov.io/gh/glichtner/napari-pystackreg/branch/main/graph/badge.svg)](https://codecov.io/gh/glichtner/napari-pystackreg)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-pystackreg)](https://napari-hub.org/plugins/napari-pystackreg)

Robust image registration for napari.

## Summary
napari-pystackreg offers the image registration capabilities of the python package
[pystackreg](https://github.com/glichtner/pystackreg) for napari.

![](https://github.com/glichtner/napari-pystackreg/raw/main/docs/napari-pystackreg.gif)

## Description

pyStackReg is used to align (register) one or more images to a common reference image, as is required usually in
time-resolved fluorescence or wide-field microscopy.
It is directly ported from the source code of the ImageJ plugin ``TurboReg`` and provides additionally the
functionality of the ImageJ plugin ``StackReg``, both of which were written by Philippe Thevenaz/EPFL
(available at http://bigwww.epfl.ch/thevenaz/turboreg/).

pyStackReg provides the following five types of distortion:

- Translation
- Rigid body (translation + rotation)
- Scaled rotation (translation + rotation + scaling)
- Affine (translation + rotation + scaling + shearing)
- Bilinear (non-linear transformation; does not preserve straight lines)

pyStackReg supports the full functionality of StackReg plus some additional options, e.g., using different reference
images and having access to the actual transformation matrices (please see the examples below). Note that pyStackReg
uses the high quality (i.e. high accuracy) mode of TurboReg that uses cubic spline interpolation for transformation.

Please note: The bilinear transformation cannot be propagated, as a combination of bilinear transformations does not
generally result in a bilinear transformation. Therefore, stack registration/transform functions won't work with
bilinear transformation when using ""previous"" image as reference image. You can either use another reference (
""first"" or ""mean"" for first or mean image, respectively), or try to register/transform each image of the stack
separately to its respective previous image (and use the already transformed previous image as reference for the
next image).

## Installation

You can install ``napari-pystackreg`` via [pip](https://pypi.org/project/pip/) from [PyPI](https://pypi.org/):

    pip install napari-pystackreg

You can also install ``napari-pystackreg`` via [conda](https://docs.conda.io/en/latest/):

    conda install -c conda-forge napari-pystackreg

Or install it via napari's plugin installer.

    Plugins > Install/Uninstall Plugins... > Filter for ""napari-pystackreg"" > Install

To install latest development version:

    pip install git+https://github.com/glichtner/napari-pystackreg.git

## Usage


### Open Plugin User Interface

Start up napari, e.g. from the command line:

    napari

Then, load an image stack (e.g. via ``File > Open Image...``) that you want to register. You can also use the example
stack provided by the pluging (``File > Open Sample > napari-pystackreg: PC12 moving example``).
Then, select the ``napari-pystackreg`` plugin from the ``Plugins > napari-pystackreg: pystackreg`` menu.

![](https://github.com/glichtner/napari-pystackreg/raw/main/docs/ui-initial.png)

### User Interface Options
A variety of options are available to control the registration process:

* `Image Stack`: The image layer that should be registered/transformed.
* `Transformation`: The type of transformation that should be applied.
  - `Translation`: translation
  - `Rigid body`: translation + rotation
  - `Scaled rotation`: translation + rotation + scaling
  - `Affine`: translation + rotation + scaling + shearing
  - `Bilinear`: non-linear transformation; does not preserve straight lines
* `Reference frame:` The reference image for registration.
  - `Previous frame`: Aligns each frame (image) to its previous frame in the stack
  - `Mean (all frames)`: Aligns each frame (image) to the average of all images in the stack
  - `Mean (first n frames)`: Aligns each frame (image) to the mean of the first n frames in the stack. n is a tuneable parameter.
* `Moving-average stack before register`: Apply a moving average to the stack before registration. This can be useful to
  reduce noise in the stack (if the signal-to-noise ratio is very low). The moving average is applied to the stack only
  for determining the transformation matrices, but not for the actual transforming of the stack.
* `Transformation matrix file`: Transformation matrices can be saved to or loaded from a file for permanent storage.

### Reference frame
The reference frame is the frame to which the other frames are aligned. The default option is to use the
`Previous frame`, which will register each frame to its respective previous frame in the stack. Alternatively, the
reference frame can be set to the mean of all frames in the stack (`Mean (all frames)`) or the mean of the first n
frames in the stack (`Mean (first n frames)`). The latter option can be useful if the first frames in the stack are more
stable than the later frames (e.g. if the first frames are taken before the sample is moved). When selecting the
`Mean (first n frames)` option, the number of frames to use for the mean can be set via the spinbox below the option.

![](https://github.com/glichtner/napari-pystackreg/raw/main/docs/ui-reference-mean-n.png)

### Moving average before registration
To increase registration performance with low signal-to-noise ratio stacks, a moving average can be applied to the
stack before registration. The moving average is applied to the stack only for determining the
transformation matrices, but not for the actual transforming of the stack. That means that the transformed stack will
still contain the original frames (however registered), but not the averaged frames.

When selecting the `Moving-average stack before register` option, the number of frames to use for the moving average can
be set via the spinbox below the option.

![](https://github.com/glichtner/napari-pystackreg/raw/main/docs/ui-moving-average.png)

### Transformation matrix file
The transformation matrices can be saved to or loaded from a file for permanent storage. This can be useful if you want
to apply the same transformation to another stack (e.g. a different channel of the same sample). The transformation
matrices are saved as a numpy array in a binary file (``.npy``). The file can be loaded via the `Load` button and saved
via the `Save` button.

![](https://github.com/glichtner/napari-pystackreg/raw/main/docs/ui-register-tmat.png)

### Register/Transform
To perform the actual registration and transformation steps, click the `Register` and `Transform` buttons, respectively.

The `Register` button will register the stack to the reference by determining the appropriate transformation matrices,
without actually transforming the stack. The transformation matrices can be saved to a file via the `Save` button in the
`Transformation matrix file` section.

![](https://github.com/glichtner/napari-pystackreg/raw/main/docs/ui-registered.png)

The `Transform` button (1) will transform the stack to the reference by applying the transformation matrices that are
currently loaded to the stack selected in `Image Stack`. For the button to become active, either the transformation
matrices have to be loaded from a file via the `Load` button in the `Transformation matrix file` section, or the
`Register` button has to be clicked first to determine the transformation matrices.

The `Transform` button will also add a new image layer to the napari viewer (2) with the transformed stack. The name of the
new layer will be the name of the original stack with the prefix `Registered`.

![](https://github.com/glichtner/napari-pystackreg/raw/main/docs/ui-transformed.png)

Finally, the `Register & Transform` button will perform both the registration and transformation steps in one go.

----------------------------------

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [Apache Software License 2.0] license,
""napari-pystackreg"" is free and open source software.

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

## Acknowledgments

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/glichtner/napari-pystackreg/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 4 - Beta', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: Apache Software License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Software Development :: Testing']","['Bug Tracker, https://github.com/glichtner/napari-pystackreg/issues', 'Documentation, https://github.com/glichtner/napari-pystackreg#README.md', 'Source Code, https://github.com/glichtner/napari-pystackreg', 'User Support, https://github.com/glichtner/napari-pystackreg/issues']",,,napari-pystackreg.pystackreg,napari-pystackreg.load_sample_data,,,,https://pypi.org/project/napari-pystackreg,https://github.com/glichtner/napari-pystackreg,
267,QR-Code,0.0.1,2023-03-30,2023-06-18,napari-qrcode,Kyle Harrington,czi@kyleharrington.com,BSD-3-Clause,https://github.com/kephale/napari-qrcode,A napari plugin to generate QR-Codes,>=3.8,"['numpy', 'magicgui', 'qtpy', 'qrcode', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-qrcode

[![License BSD-3](https://img.shields.io/pypi/l/napari-qrcode.svg?color=green)](https://github.com/kephale/napari-qrcode/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-qrcode.svg?color=green)](https://pypi.org/project/napari-qrcode)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-qrcode.svg?color=green)](https://python.org)
[![tests](https://github.com/kephale/napari-qrcode/workflows/tests/badge.svg)](https://github.com/kephale/napari-qrcode/actions)
[![codecov](https://codecov.io/gh/kephale/napari-qrcode/branch/main/graph/badge.svg)](https://codecov.io/gh/kephale/napari-qrcode)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-qrcode)](https://napari-hub.org/plugins/napari-qrcode)

A napari plugin to generate QR-Codes

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-qrcode` via [pip]:

    pip install napari-qrcode



To install latest development version :

    pip install git+https://github.com/kephale/napari-qrcode.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-qrcode"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/kephale/napari-qrcode/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/kephale/napari-qrcode/issues', 'Documentation, https://github.com/kephale/napari-qrcode#README.md', 'Source Code, https://github.com/kephale/napari-qrcode', 'User Support, https://github.com/kephale/napari-qrcode/issues']",,,napari-qrcode.qrcode_widget,,,,,https://pypi.org/project/napari-qrcode,https://github.com/kephale/napari-qrcode,
268,napari Quoll,0.0.1,,,napari-quoll,Elaine Ho,Elaine.Ho@rfi.ac.uk,Apache-2.0,,Resolution estimation for electron tomography,>=3.7,"['numpy', 'magicgui', 'qtpy', 'quoll', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-quoll

[![License](https://img.shields.io/badge/License-Apache_2.0-green.svg)](https://opensource.org/licenses/Apache-2.0)
[![PyPI](https://img.shields.io/pypi/v/napari-quoll.svg?color=green)](https://pypi.org/project/napari-quoll)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-quoll.svg?color=green)](https://python.org)
[![tests](https://github.com/rosalindfranklininstitute/napari-quoll/workflows/tests/badge.svg)](https://github.com/rosalindfranklininstitute/napari-quoll/actions)
[![codecov](https://codecov.io/gh/rosalindfranklininstitute/napari-quoll/branch/main/graph/badge.svg)](https://codecov.io/gh/rosalindfranklininstitute/napari-quoll)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-quoll)](https://napari-hub.org/plugins/napari-quoll)

Resolution estimation for electron tomography

The Python package which does the resolution estimation is [Quoll](https://github.com/rosalindfranklininstitute/quoll). This repository, `napari-quoll` is just the Napari plugin.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-quoll` via [pip] into a <b>Python 3.7</b> environment, replacing <env_name> with an environment name of your choice:

    conda -n create <env_name> python=3.7
    conda activate <env_name>
    pip install napari-quoll



To install latest development version :

    pip install git+https://github.com/rosalindfranklininstitute/napari-quoll.git

<b>Note:</b> Due to [miplib]() dependencies, this plugin only works on Python 3.7 environments.


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [Apache Software License 2.0] license,
""napari-quoll"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/rosalindfranklininstitute/napari-quoll/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: Apache Software License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/rosalindfranklininstitute/napari-quoll/issues', 'Documentation, https://github.com/rosalindfranklininstitute/napari-quoll#README.md', 'Source Code, https://github.com/rosalindfranklininstitute/napari-quoll', 'User Support, https://github.com/rosalindfranklininstitute/napari-quoll/issues']",,,napari-quoll.make_quoll_widget,,,,,https://pypi.org/project/napari-quoll,,
269,Napari Select Foreground,0.0.7,2023-11-18,2023-11-22,napari-rembg,Mallory Wittwer,mallory.wittwer@epfl.ch,BSD-3-Clause,https://pypi.org/project/napari-rembg,AI-based foreground extraction in scientific and natural images.,>=3.8,"['magicgui', 'qtpy', 'napari[all] >=0.4.16', ""rembg ; extra == 'local'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","![EPFL Center for Imaging logo](https://imaging.epfl.ch/resources/logo-for-gitlab.svg)
# napari-rembg

Segment images using a collection of fast and lightweight generalist segmentation models in Napari. This plugin is based on the [rembg](https://github.com/danielgatis/rembg) project.

![demo](./assets/demo.gif)

**Key features**

- Choose among **five generalist segmentation models**, including SAM (Segment Anything Model).
- Quickly annotate individual objects by drawing **bounding boxes** around them.
- Possibility to generate predictions via a remote **web API** and keep the installation lightweight on client machines.
- Compatible with 2D, RGB, 2D+t, and 3D images (slice by slice).

## Installation

You can install `napari-rembg` via [pip]. If you wish to use your local machine for the predictions (most users):

    pip install ""napari-rembg[local]""

If you wish to generate predictions from a [web api](#running-the-segmentation-via-a-web-api), go for a minimal install:

    pip install napari-rembg

## Models

- [u2net](https://github.com/xuebinqin/U-2-Net): A pre-trained model for general use cases.
- [u2netp](https://github.com/xuebinqin/U-2-Net): A lightweight version of u2net.
- [silueta](https://github.com/xuebinqin/U-2-Net/issues/295): Same as u2net with a size reduced to 43 Mb.
- [isnet](https://github.com/xuebinqin/DIS): A pre-trained model for general use cases.
- [sam](https://github.com/facebookresearch/segment-anything): Segment Anything Model pre-trained for any use cases (`vit_b`)

![models](./assets/comparison.png)

The models automatically get downloaded in the user's home folder in the `.u2net` directory the first time inference is run.

## Usage

Start `napari-rembg` from the `Plugins` menu of Napari:

```
Plugins > Napari Select Foreground > Select foreground
```

### Segment an image loaded into Napari

Select your image in the `Image` dropdown and press `Run`. The output segmentation appears in the `Labels` layer selected in the `Mask` field (if no layer is selected, a new one is created).

### Segment individual objects using bounding boxes

- Click on the `Add` button next to the `ROI` field. This adds a `Shapes layer` to the viewer.
- Click and drag bounding boxes around objects in the image. Each time you draw a bounding box a segmentation is generated in the region selected.

![screenshot](./assets/screenshot.gif)

You can choose to auto-increment the label index to distinguish individual objects. Deselect that option to annotate a single foreground class.

## Running the segmentation via a web API

You can run the `rembg` segmentation via a web API running in a `docker` container.

**Advantages**
- The segmentation can be run on a remote machine with optimization (e.g. GPU).
- The segmentation models will be downloaded inside the docker container instead of the user's file system.
- You can minimally install the package with `pip install napari-rembg` on the client's machine. This will *not* install the `rembg` library, which can solve potential dependency conflicts or bugs.

**Setup**

See [these instructions](./src/rembg-api/README.md) on how to set up the docker container and web API.

**Usage**

Start `napari-rembg` from the `Plugins` menu of Napari:

```
Plugins > Napari Select Foreground > Select foreground (Web API)
```

## Related projects

If you are looking for similar generalist segmentation plugins, check out these related projects:

- [napari-sam](https://github.com/MIC-DKFZ/napari-sam)
- [napari-segment-anything](https://github.com/royerlab/napari-segment-anything)

## Contributing

Contributions are very welcome. 

## License

Distributed under the terms of the [BSD-3] license,
""napari-rembg"" is free and open source software.

## Issues

If you encounter any problems, please file an issue along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Source Code, https://github.com/EPFL-Center-for-Imaging/napari-rembg.git']",,,napari-rembg.local,,,,,https://pypi.org/project/napari-rembg,,
270,Result stack,0.0.1,2023-04-04,2023-06-18,napari-result-stack,Hanjin Liu,liuhanjin-sc@g.ecc.u-tokyo.ac.jp,BSD-3-Clause,https://github.com/hanjinliu/napari-result-stack,Widgets and type annotations for storing function results of any types,>=3.8,"['numpy', 'magicgui', 'qtpy', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-result-stack

[![License BSD-3](https://img.shields.io/pypi/l/napari-result-stack.svg?color=green)](https://github.com/hanjinliu/napari-result-stack/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-result-stack.svg?color=green)](https://pypi.org/project/napari-result-stack)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-result-stack.svg?color=green)](https://python.org)
[![tests](https://github.com/hanjinliu/napari-result-stack/workflows/tests/badge.svg)](https://github.com/hanjinliu/napari-result-stack/actions)
[![codecov](https://codecov.io/gh/hanjinliu/napari-result-stack/branch/main/graph/badge.svg)](https://codecov.io/gh/hanjinliu/napari-result-stack)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-result-stack)](https://napari-hub.org/plugins/napari-result-stack)

Widgets and type annotations for storing function results of any types.

## `Stored` type

Type `Stored[T]` is equivalent to `T` for the type checker, but `magicgui` is aware of this annotation and behaves as a ""storage"" for the `T` instances.

```python
from pathlib import Path
import pandas as pd
from magicgui import magicgui
from napari_result_stack import Stored

# Returned values will be stored in a result stack.
@magicgui
def provide_data(path: Path) -> Stored[pd.DataFrame]:
    return pd.read_csv(path)

# You can choose one of the values stored in the result stack
# for the argument `df` from a ComboBox widget.
@magicgui
def print_data(df: Stored[pd.DataFrame]):
    print(df)
```

![](https://github.com/hanjinliu/napari-result-stack/blob/main/images/demo-0.gif)

- Different types use different storage. e.g. `Stored[int]` and `Stored[str]` do not share the same place.
- Even for the same type, you can specify the second key to split the storage. e.g. `Stored[int]`, `Stored[int, 0]` and `Stored[int, ""my-plugin-name""]` use the distinct storages.

## Manually store variables

`Stored.valuesof[T]` is a `list`-like object that returns a view of the values stored in `Stored[T]`. This value view is useful if you want to store values outside `@magicgui`.

```python
from magicgui.widgets import PushButton
from datetime import datetime
from napari_result_stack import Stored

button = PushButton(text=""Click!"")

@button.changed.connect
def _record_now():
    Stored.valuesof[datetime].append(datetime.now())

```

## Result stack widget

`napari-result-stack` provides a plugin widget that is helpful to inspect all the stored values.

![](https://github.com/hanjinliu/napari-result-stack/blob/main/images/demo-1.gif)


<details><summary>Show code</summary><div>

```python
from napari_result_stack import Stored
from magicgui import magicgui
import numpy as np
import pandas as pd

@magicgui
def f0() -> Stored[pd.DataFrame]:
    return pd.DataFrame(np.random.random((4, 3)))

@magicgui
def f1(x: Stored[pd.DataFrame]) -> Stored[float]:
    return np.mean(np.array(x))

viewer.window.add_dock_widget(f0, name=""returns a DataFrame"")
viewer.window.add_dock_widget(f1, name=""mean of a DataFrame"")
```

---
</div></details>



----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-result-stack` via [pip]:

    pip install napari-result-stack



To install latest development version :

    pip install git+https://github.com/hanjinliu/napari-result-stack.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-result-stack"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/hanjinliu/napari-result-stack/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/hanjinliu/napari-result-stack/issues', 'Documentation, https://github.com/hanjinliu/napari-result-stack#README.md', 'Source Code, https://github.com/hanjinliu/napari-result-stack', 'User Support, https://github.com/hanjinliu/napari-result-stack/issues']",,,napari-result-stack.make_qwidget,,,,,https://pypi.org/project/napari-result-stack,https://github.com/hanjinliu/napari-result-stack,
271,Rioxarray Plugin,0.0.1,2023-04-12,2023-06-18,napari-rioxarray,Dr. Andrew Annex,ama6fy@virginia.edu,BSD-3-Clause,https://github.com/AndrewAnnex/napari-rioxarray,A rioxarray plugin for napari supporting GDAL raster datatypes,>=3.8,"['numpy', 'napari', 'rioxarray', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'""]","# napari-rioxarray

[![License BSD-3](https://img.shields.io/pypi/l/napari-rioxarray.svg?color=green)](https://github.com/AndrewAnnex/napari-rioxarray/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-rioxarray.svg?color=green)](https://pypi.org/project/napari-rioxarray)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-rioxarray.svg?color=green)](https://python.org)
[![tests](https://github.com/AndrewAnnex/napari-rioxarray/workflows/tests/badge.svg)](https://github.com/AndrewAnnex/napari-rioxarray/actions)
[![codecov](https://codecov.io/gh/AndrewAnnex/napari-rioxarray/branch/main/graph/badge.svg)](https://codecov.io/gh/AndrewAnnex/napari-rioxarray)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-rioxarray)](https://napari-hub.org/plugins/napari-rioxarray)

A rioxarray plugin for napari supporting GDAL raster datatypes

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/index.html
-->

## Installation

You can install `napari-rioxarray` via [pip]:

    pip install napari-rioxarray



To install latest development version :

    pip install git+https://github.com/AndrewAnnex/napari-rioxarray.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-rioxarray"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/AndrewAnnex/napari-rioxarray/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/AndrewAnnex/napari-rioxarray/issues', 'Documentation, https://github.com/AndrewAnnex/napari-rioxarray#README.md', 'Source Code, https://github.com/AndrewAnnex/napari-rioxarray', 'User Support, https://github.com/AndrewAnnex/napari-rioxarray/issues']",napari-rioxarray.get_reader,,,,"['*.vrt', '*.tif', '*.tiff', '*.TIF', '*.TIFF', '*.img', '*.lbl', '*.cub', '*.fits', '*.IMG', '*.LBL', '*.CUB', '*.FITS']",,,https://pypi.org/project/napari-rioxarray,https://github.com/AndrewAnnex/napari-rioxarray,
272,napari-roi,0.1.8,2022-01-31,2023-06-18,napari-roi,Jonas Windhager,jonas@windhager.io,MIT,https://github.com/BodenmillerGroup/napari-roi,Select regions of interest (ROIs) using napari,>=3.8,"['numpy', 'pandas', 'qtpy']","# napari-roi

[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-roi)](https://napari-hub.org/plugins/napari-roi)
[![PyPI](https://img.shields.io/pypi/v/napari-roi.svg?color=green)](https://pypi.org/project/napari-roi)
[![License](https://img.shields.io/pypi/l/napari-roi.svg?color=green)](https://github.com/BodenmillerGroup/napari-roi/raw/main/LICENSE)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-roi.svg?color=green)](https://python.org)
[![Issues](https://img.shields.io/github/issues/BodenmillerGroup/napari-roi)](https://github.com/BodenmillerGroup/napari-roi/issues)
[![Pull requests](https://img.shields.io/github/issues-pr/BodenmillerGroup/napari-roi)](https://github.com/BodenmillerGroup/napari-roi/pulls)

Select regions of interest (ROIs) using napari

## Installation

You can install napari-roi via [pip](https://pypi.org/project/pip/):

    pip install napari-roi

Alternatively, you can install napari-roi via [conda](https://conda.io/):

    conda install -c conda-forge napari-roi

## Usage

The *napari-roi* plugin can be opened from within napari (`napari -> napari-roi: regions of interest`) and operates on napari *Shapes* layers.

ROIs can be added to any napari *Shapes* layer, either by drawing a standard napari shape (e.g. rectangle), or by adding a rectangular ROI of specified size using the `Add ROI` functionality in the *napari-roi* widget. Each ROI is associated with a name, a position (X/Y origin), and a size (width/height). The location of the X/Y origin of all ROIs can be chosen in the *napari-roi* widget. Note that any shape supported by napari (e.g. ellipse, rectangle, polygon, line, path) can serve as an ROI; for non-rectangular shapes, *napari-roi* computes rectangular bounding boxes aligned with the napari coordinate system to determine their positions and sizes. ROIs can be edited or deleted by modifying the corresponding shapes in napari, or by editing the corresponding row in the *napari-roi* widget.

All ROIs in the current *Shapes* layer can be saved to a comma-separated values (CSV) file using the `Save` functionality in the *napari-roi* widget. When the `Autosave` option is checked, the file is automatically updated on every ROI change. Note that the selected file is specific to the current *Shapes* layer; ROIs from different *Shapes* layers cannot be saved to the same file. ROIs can be loaded from a previously saved file and added to the current *Shapes* layer by opening the file in the *napari-roi* widget.

CSV files saved using *napari-roi* adhere to the following format:

| Columns | Description |
| --- | --- |
| `Name` | ROI name |
| `X`, `Y` | Position (X/Y origin) |
| `W`, `H` | Size (width/height) |

## Authors

Created and maintained by [Jonas Windhager](mailto:jonas@windhager.io) until February 2023.

Maintained by [Milad Adibi](mailto:milad.adibi@uzh.ch) from February 2023.

## Contributing

[Contributing](https://github.com/BodenmillerGroup/napari-roi/blob/main/CONTRIBUTING.md)

## Changelog

[Changelog](https://github.com/BodenmillerGroup/napari-roi/blob/main/CHANGELOG.md)

## License

[MIT](https://github.com/BodenmillerGroup/napari-roi/blob/main/LICENSE)
","['Framework :: napari', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'License :: OSI Approved :: MIT License']","['Bug Tracker, https://github.com/BodenmillerGroup/napari-roi/issues', 'Documentation, https://github.com/BodenmillerGroup/napari-roi#README.md', 'Source Code, https://github.com/BodenmillerGroup/napari-roi', 'User Support, https://github.com/BodenmillerGroup/napari-roi/issues']",,,napari-roi.ROIWidget,,,,,https://pypi.org/project/napari-roi,https://github.com/BodenmillerGroup/napari-roi,
273,ROI Manager,0.0.2,,,napari-roi-manager,Hanjin Liu,Hanjin Liu <liuhanjin-sc@g.ecc.u-tokyo.ac.jp>,,,A ROI Manager Widget with an UI similar to ImageJ,>=3.9,"['numpy', 'qtpy', ""napari; extra == 'testing'"", ""pyqt5; extra == 'testing'"", ""pytest; extra == 'testing'"", ""pytest-cov; extra == 'testing'"", ""pytest-qt; extra == 'testing'"", ""tox; extra == 'testing'""]","# napari-roi-manager

[![License BSD-3](https://img.shields.io/pypi/l/napari-roi-manager.svg?color=green)](https://github.com/hanjinliu/napari-roi-manager/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-roi-manager.svg?color=green)](https://pypi.org/project/napari-roi-manager)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-roi-manager.svg?color=green)](https://python.org)
[![tests](https://github.com/hanjinliu/napari-roi-manager/workflows/tests/badge.svg)](https://github.com/hanjinliu/napari-roi-manager/actions)
[![codecov](https://codecov.io/gh/hanjinliu/napari-roi-manager/branch/main/graph/badge.svg)](https://codecov.io/gh/hanjinliu/napari-roi-manager)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-roi-manager)](https://napari-hub.org/plugins/napari-roi-manager)

A ROI Manager Widget with an UI similar to ImageJ

![](https://github.com/hanjinliu/napari-roi-manager/blob/main/images/demo.gif)

This Plugin requires `napari>=0.4.19`.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.


## Installation

You can install `napari-roi-manager` via [pip]:

    pip install napari-roi-manager



To install latest development version :

    pip install git+https://github.com/hanjinliu/napari-roi-manager.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-roi-manager"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/hanjinliu/napari-roi-manager/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/hanjinliu/napari-roi-manager/issues', 'Documentation, https://github.com/hanjinliu/napari-roi-manager#README.md', 'Homepage, https://github.com/hanjinliu/napari-roi-manager', 'Source Code, https://github.com/hanjinliu/napari-roi-manager', 'User Support, https://github.com/hanjinliu/napari-roi-manager/issues']",,,napari-roi-manager.make_qwidget,,,,,https://pypi.org/project/napari-roi-manager,,
274,Roi Registration,0.1.4,2022-06-16,2023-11-07,napari-roi-registration,Andrea Bassi and Giorgia Tortora,giorgia.tortora@polimi.it,BSD-3-Clause,https://github.com/GiorgiaTortora/napari-roi-registration,A plugin to perform registration of regions-of-interests in time-lapse data.,>=3.8,"['numpy', 'magicgui', 'qtpy', 'scikit-image', 'opencv-python', 'matplotlib', 'openpyxl', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'"", ""scikit-image ; extra == 'testing'"", ""opencv-python-headless ; extra == 'testing'"", ""matplotlib ; extra == 'testing'"", ""openpyxl ; extra == 'testing'""]","# napari-roi-registration

[![License](https://img.shields.io/pypi/l/napari-roi-registration.svg?color=green)](https://github.com/GiorgiaTortora/napari-roi-registration/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-roi-registration.svg?color=green)](https://pypi.org/project/napari-roi-registration)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-roi-registration.svg?color=green)](https://python.org)
[![tests](https://github.com/GiorgiaTortora/napari-roi-registration/workflows/tests/badge.svg)](https://github.com/GiorgiaTortora/napari-roi-registration/actions)
[![codecov](https://codecov.io/gh/GiorgiaTortora/napari-roi-registration/branch/main/graph/badge.svg)](https://codecov.io/gh/GiorgiaTortora/napari-roi-registration)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-roi-registration)](https://napari-hub.org/plugins/napari-roi-registration)

A Napari plugin for the registration of regions of interests (ROI) in a time lapse acquistion and processing of the intensity of the registered data.

The ROI are defined using a Labels layer. Registration of multiple ROIs is supported.  

The `Registration` widget uses the user-defined labels, constructs a rectangular ROI around each of them and registers the ROIs in each time frame.

The `Processing` widget measures the ROI displacements and extracts the average intensity of the ROI, calculated on the area of the labels.

The `Subtract background` widget subtracts a background on each frame, calculated as the mean intensity on a Labels layer.
Tipically useful when ambient light affects the measurement.  

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/stable/index.html
-->

![raw](https://github.com/GiorgiaTortora/napari-roi-registration/raw/main/images/roi_registration.gif)

## Installation

You can install `napari-roi-registration` via [pip]:

    pip install napari-roi-registration



To install latest development version :

    pip install git+https://github.com/GiorgiaTortora/napari-roi-registration.git

## Usage

A detailed guide which shows how to use the widgets of the napari-roi-registration plugin and how to properly choose the parameters can be found [here]. A demo video is available at this [link](https://www.youtube.com/watch?v=oXyAqZdFrSE). [Sample datasets](https://polimi365-my.sharepoint.com/:f:/g/personal/10853110_polimi_it/ErHvu3QXhktGq-NLqFdZXMYBWXaRNIZWlQhWg5EdOgbmWg?e=HeExQl) are available.

### Registration Widget

1. Create a new Labels layer and draw one or more labels where you want to select a ROI (Region Of Interest). Each color in the same Labels layer represents a different label which will correspond to a different ROI.

![raw](https://github.com/GiorgiaTortora/napari-roi-registration/raw/main/images/Picture1.png)

2. Push the `Register ROIs` button: registration of the entire stack will be performed. When the registration is finished two new layers will appear in the viewer. One layer contains the centroids of the drawn labels while the other contains the bounding boxes enclosing the ROIs.
The registration starts from the currently selected frame. If `register entire stack` is selected, the registration will create a new layer for each label, with the registered ROI stacks.

![raw](https://github.com/GiorgiaTortora/napari-roi-registration/raw/main/images/Picture2.png)

### Processing Widget

Pushing the `Process registered ROIs` button, the registered ROIs will be analyzed. The intensity of the registered ROIs (measured on the area of the selected label) and the displacement of the ROIs will be calculated.
If `plot results` is selected the plot of displacement vs time index and mean intensity vs time index will appear in the Console.
Choosing the `save results` option, an excel file containing ROIs positions, displacements and intensities, will be saved. 

![raw](https://github.com/GiorgiaTortora/napari-roi-registration/raw/main/images/Picture3.png)

### Background Widget

1. Create a new Labels layer and draw a label on the area where you want to calculate the background. 

![raw](https://github.com/GiorgiaTortora/napari-roi-registration/raw/main/images/Picture4.png)

2. Push the `Subtract background` button. A new image layer will appear in the viewer. This layer contains the image to which the background was subtracted.

## Contributing 

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-roi-registration"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[here]: https://github.com/GiorgiaTortora/napari-roi-registration/blob/main/docs/index.md

[file an issue]: https://github.com/GiorgiaTortora/napari-roi-registration/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/GiorgiaTortora/napari-roi-registration/issues', 'Documentation, https://github.com/GiorgiaTortora/napari-roi-registration#README.md', 'Source Code, https://github.com/GiorgiaTortora/napari-roi-registration', 'User Support, https://github.com/GiorgiaTortora/napari-roi-registration/issues']",,,napari-roi-registration.make_background_widget,,,,,https://pypi.org/project/napari-roi-registration,https://github.com/GiorgiaTortora/napari-roi-registration,
275,napari sairyscan,0.0.2,,,napari-sairyscan,Sylvain Prigent,meriadec.prigent@gmail.com,BSD-3-Clause,,Airyscan image reconstruction,>=3.8,"['numpy', 'magicgui', 'qtpy', 'sairyscan (>=0.0.2)', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-sairyscan

[![License](https://img.shields.io/pypi/l/napari-sairyscan.svg?color=green)](https://github.com/sylvainprigent/napari-sairyscan/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-sairyscan.svg?color=green)](https://pypi.org/project/napari-sairyscan)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-sairyscan.svg?color=green)](https://python.org)
[![tests](https://github.com/sylvainprigent/napari-sairyscan/workflows/tests/badge.svg)](https://github.com/sylvainprigent/napari-sairyscan/actions)
[![codecov](https://codecov.io/gh/sylvainprigent/napari-sairyscan/branch/main/graph/badge.svg)](https://codecov.io/gh/sylvainprigent/napari-sairyscan)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-sairyscan)](https://napari-hub.org/plugins/napari-sairyscan)

Airyscan image reconstruction

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/index.html
-->

## Installation

You can install `napari-sairyscan` via [pip]:

    pip install napari-sairyscan



To install latest development version :

    pip install git+https://github.com/sylvainprigent/napari-sairyscan.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-sairyscan"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/sylvainprigent/napari-sairyscan/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/sylvainprigent/napari-sairyscan/issues', 'Documentation, https://github.com/sylvainprigent/napari-sairyscan#README.md', 'Source Code, https://github.com/sylvainprigent/napari-sairyscan', 'User Support, https://github.com/sylvainprigent/napari-sairyscan/issues']",napari-sairyscan.get_reader,,napari-sairyscan.make_qwidget,napari-sairyscan.make_sample_data,['*.czi'],,,https://pypi.org/project/napari-sairyscan,,
276,Segment Anything,0.4.13,2023-05-05,2023-08-03,napari-sam,Karol Gotkowski,karol.gotkowski@dkfz.de,Apache-2.0,https://github.com/MIC-DKFZ/napari-sam,Segment anything with Meta AI's new SAM model!,>=3.8,"['numpy', 'magicgui', 'qtpy', 'napari', 'vispy', 'tqdm', 'napari-nifti', 'superqt', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# Segment Anything Model (SAM) in Napari

[![License Apache Software License 2.0](https://img.shields.io/pypi/l/napari-sam.svg?color=green)](https://github.com/MIC-DKFZ/napari-sam/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-sam.svg?color=green)](https://pypi.org/project/napari-sam)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-sam.svg?color=green)](https://python.org)
[![tests](https://github.com/MIC-DKFZ/napari-sam/workflows/tests/badge.svg)](https://github.com/MIC-DKFZ/napari-sam/actions)
[![codecov](https://codecov.io/gh/MIC-DKFZ/napari-sam/branch/main/graph/badge.svg)](https://codecov.io/gh/MIC-DKFZ/napari-sam)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-sam)](https://napari-hub.org/plugins/napari-sam)

Segment anything with our **Napari** integration of Meta AI's new **Segment Anything Model (SAM)**!

SAM is the new segmentation system from Meta AI capable of **one-click segmentation of any object**, and now, our plugin neatly integrates this into Napari.

We have already **extended** SAM's click-based foreground separation to full **click-based semantic segmentation and instance segmentation**!

At last, our SAM integration supports both **2D and 3D images**!

----------------------------------

Everything mode             |  Click-based semantic segmentation mode |  Click-based instance segmentation mode
:-------------------------:|:-------------------------:|:-------------------------:
![](https://github.com/MIC-DKFZ/napari-sam/raw/main/cats_everything.png)  |  ![](https://github.com/MIC-DKFZ/napari-sam/raw/main/cats_semantic.png)  |  ![](https://github.com/MIC-DKFZ/napari-sam/raw/main/cats_instance.png)


----------------------------------
<h2 align=""center"">SAM in Napari demo</h2>
<div align=""center"">

https://user-images.githubusercontent.com/3471895/236152620-0de983db-954b-4480-97b9-901ee82f8edd.mp4

</div>

----------------------------------

## Installation

The plugin requires `python>=3.8`, as well as `pytorch>=1.7` and `torchvision>=0.8`. Please follow the instructions here to install both PyTorch and TorchVision dependencies. Installing both PyTorch and TorchVision with CUDA support is strongly recommended.

Install Napari via [pip]:
    
    pip install napari[all]

You can install `napari-sam` via [pip]:

    pip install git+https://github.com/facebookresearch/segment-anything.git
    pip install napari-sam



To install latest development version :

    pip install git+https://github.com/MIC-DKFZ/napari-sam.git

## Usage

Start Napari from the console with:

    napari

Then navigate to `Plugins -> Segment Anything (napari-sam)` and drag & drop an image into Napari. At last create, a labels layer that will be used for the SAM predictions, by clicking in the layer list on the third button.

You can then auto-download one of the available SAM models (this can take 1-2 minutes),  activate one of the annotations & segmentation modes, and you are ready to go!


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [Apache Software License 2.0] license,
""napari-sam"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/MIC-DKFZ/napari-sam/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/

# Acknowledgements
<img src=""https://github.com/MIC-DKFZ/napari-sam/raw/main/HI_Logo.png"" height=""100px"" />

<img src=""https://github.com/MIC-DKFZ/napari-sam/raw/main/dkfz_logo.png"" height=""100px"" />

napari-sam is developed and maintained by the Applied Computer Vision Lab (ACVL) of [Helmholtz Imaging](http://helmholtz-imaging.de) 
and the [Division of Medical Image Computing](https://www.dkfz.de/en/mic/index.php) at the 
[German Cancer Research Center (DKFZ)](https://www.dkfz.de/en/index.html).
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: Apache Software License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/MIC-DKFZ/napari-sam/issues', 'Documentation, https://github.com/MIC-DKFZ/napari-sam#README.md', 'Source Code, https://github.com/MIC-DKFZ/napari-sam', 'User Support, https://github.com/MIC-DKFZ/napari-sam/issues']",,,napari-sam.make_qwidget,,,,,https://pypi.org/project/napari-sam,https://github.com/MIC-DKFZ/napari-sam,
277,napari-SAM4IS,0.0.6,2023-05-05,2023-12-08,napari-SAM4IS,Hiroki Kawai,h.kawai888@gmail.com,Apache-2.0,https://github.com/hiroalchem/napari-SAM4IS,Create annotations for instance segmentation using Segment Anything models,>=3.8,"['numpy', 'magicgui', 'qtpy', 'torch', 'torchvision', 'scikit-image', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-SAM4IS

[![License Apache Software License 2.0](https://img.shields.io/pypi/l/napari-SAM4IS.svg?color=green)](https://github.com/hiroalchem/napari-SAM4IS/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-SAM4IS.svg?color=green)](https://pypi.org/project/napari-SAM4IS)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-SAM4IS.svg?color=green)](https://python.org)
[![tests](https://github.com/hiroalchem/napari-SAM4IS/workflows/tests/badge.svg)](https://github.com/hiroalchem/napari-SAM4IS/actions)
[![codecov](https://codecov.io/gh/hiroalchem/napari-SAM4IS/branch/main/graph/badge.svg)](https://codecov.io/gh/hiroalchem/napari-SAM4IS)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-SAM4IS)](https://napari-hub.org/plugins/napari-SAM4IS)


### napari plugin for instance and semantic segmentation annotation using Segment Anything Model (SAM)

This is a plugin for [napari](https://napari.org/), a multi-dimensional image viewer for Python, that allows for instance and semantic segmentation annotation. This plugin provides an easy-to-use interface for annotating images with the option to output annotations as COCO format.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

To use this plugin, you'll need to install the [napari](https://napari.org/stable/tutorials/fundamentals/installation.html) multi-dimensional image viewer and the [Segment Anything Model (SAM)](https://github.com/facebookresearch/segment-anything) library.

### napari Installation

You can install napari using pip:

```
pip install ""napari[all]""
```

Alternatively, you can install napari and all of its dependencies with conda:

```
conda install -c conda-forge napari
```

For more detailed instructions, please refer to the [napari installation guide](https://napari.org/stable/tutorials/fundamentals/installation.html).

### SAM Installation

You can install SAM from the [official GitHub repository](https://github.com/facebookresearch/segment-anything) using pip:

```
pip install git+https://github.com/facebookresearch/segment-anything.git
```

Or you can install from source by cloning the repository:

```
git clone https://github.com/facebookresearch/segment-anything.git
cd segment-anything
pip install -e .
```

For more detailed instructions, please refer to the [SAM installation guide](https://github.com/facebookresearch/segment-anything#installation).

### napari-SAM4IS Installation

You can install `napari-SAM4IS` via [pip]:

    pip install napari-SAM4IS



To install latest development version :

    pip install git+https://github.com/hiroalchem/napari-SAM4IS.git

## Usage
### Preparation
1. Open an image in napari and launch the plugin. (Opening an image after launching the plugin is also possible.)
2. Upon launching the plugin, three layers will be automatically created: SAM-Box, SAM-Predict, and Accepted. The usage of these layers will be explained later.
3. In the widget that appears, select the model you want to use and click the load button. (The default option is recommended.)
4. Next, select the image layer you want to annotate.
5. Then, select whether you want to do instance segmentation or semantic segmentation. (Note that for 3D images, semantic segmentation should be chosen in the current version.)
6. Finally, select the output layer as ""shapes"" for instance segmentation or ""labels"" for semantic segmentation. (For instance segmentation, the ""Accept"" layer can also be used.)

### Annotation
1. Select the SAM-Box layer and use the rectangle tool to enclose the object you want to segment.
2. An automatic segmentation mask will be created and output to the SAM-Predict layer.
3. If you want to make adjustments, do so in the SAM-Predict layer.
4. To accept or reject the annotation, press ""a"" or ""r"" on the keyboard, respectively.
5. If you accept the annotation, it will be output as label 1 for semantic segmentation or converted to a polygon and output to the designated layer for instance segmentation.
6. If you reject the annotation, the segmentation mask in the SAM-Predict layer will be discarded.
7. After accepting or rejecting the annotation, the SAM-Predict layer will automatically reset to blank and return to the SAM-Box layer.

### Saving
1. If you have output to the labels layer, use napari's standard functionality to save the mask.
2. If you have output to the shapes layer, you can save the shapes layer using napari's standard functionality, or you can click the ""save"" button to output a JSON file in COCO format for each image in the folder. (The JSON file will have the same name as the image.)



## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [Apache Software License 2.0] license,
""napari-SAM4IS"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/hiroalchem/napari-SAM4IS/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: Apache Software License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/hiroalchem/napari-SAM4IS/issues', 'Documentation, https://github.com/hiroalchem/napari-SAM4IS#README.md', 'Source Code, https://github.com/hiroalchem/napari-SAM4IS', 'User Support, https://github.com/hiroalchem/napari-SAM4IS/issues']",,,napari-SAM4IS.make_sam_widget,,,,,https://pypi.org/project/napari-SAM4IS,https://github.com/hiroalchem/napari-SAM4IS,
278,sc3D Viewer,1.1.0,2022-08-18,2023-07-27,napari-sc3D-viewer,Leo Guignard,leo.guignard@univ-amu.fr,MIT,https://github.com/GuignardLab/napari-sc3D-viewer,A plugin to visualize 3D single cell omics,>=3.8,"['numpy', 'magicgui', 'qtpy', 'sc-3D', 'matplotlib', ""pyvista ; extra == 'pyvista'"", ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-sc3D-viewer

[![License](https://img.shields.io/pypi/l/napari-sc3D-viewer.svg?color=green)](https://raw.githubusercontent.com/GuignardLab/napari-sc3D-viewer/main/LICENSE)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-sc3D-viewer.svg?color=green)](https://python.org)
[![PyPI](https://img.shields.io/pypi/v/napari-sc3D-viewer.svg?color=green)](https://pypi.org/project/napari-sc3D-viewer)
[![tests](https://github.com/GuignardLab/napari-sc3D-viewer/workflows/tests/badge.svg)](https://github.com/GuignardLab/napari-sc3D-viewer/actions)
[![codecov](https://codecov.io/gh/GuignardLab/napari-sc3D-viewer/branch/main/graph/badge.svg)](https://codecov.io/gh/GuignardLab/napari-sc3D-viewer)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-sc3D-viewer)](https://napari-hub.org/plugins/napari-sc3D-viewer)

A plugin to visualise 3D spatial single cell omics

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

## Test and atlas datasets

Because the datasets representing the mouse embryo at stages E8.5 and E9.0 are rather large, it is not possible to host them on GitHub. They are instead hosted on figshare at the following links:

- [E8.5 replicate 1](https://figshare.com/s/1c29d867bc8b90d754d2)
- [E8.5 replicate 2](https://doi.org/10.6084/m9.figshare.21695849.v1)
- [E9.0 replicate 1](https://doi.org/10.6084/m9.figshare.21695879.v1)

Once downloaded, one can open them in the viewer as explained below (note that the files for the tissue names are stored in the json file there: `napari-sc3D-viewer/test_data/corresptissues.json`). It can be downloaded by right-clicking on the following [link](https://raw.githubusercontent.com/GuignardLab/napari-sc3D-viewer/main/test_data/corresptissues.json) and then clicking on ""Save link as"".

## Installation

----------------------------------

__Disclaimer:__
While we tried to make the installation and usage as easy as possible, please keep in mind that [napari-sc3d-viewer] is still under development, it has been and is being developed by a single person. We will be happy to answer any question and help in any way.

----------------------------------

There are many ways to install our viewer, but the global idea is that it works in two steps:

- first installing [napari]
- then installing the [napari-sc3d-viewer] plugin.

Installing [napari] and the [napari-sc3d-viewer] plugin can be done either through command line or using an interface.

If you have decided to use command line, as [napari] developers do, we strongly recommend to install the viewer in an environement such as a conda environment `conda` for example:

```shell
conda create -n sc3D python=3.10
conda activate sc3D
```

### Installing napari

The first step is to [install napari](https://napari.org/stable/tutorials/fundamentals/installation.html) on your computer. The previous link should explain how to do so. There you can find either the installation via terminal or directly by [downloading the binary](https://napari.org/stable/tutorials/fundamentals/installation.html#install-as-a-bundled-app).

#### Quick trouble shooting

Installing [napari] can sometimes be difficult. If you try to install [napari] via the command line and it gets stuck ""resolving the environment"" you can try to install it the following way:

```shell
conda create -n sc3D python=3.10
conda activate sc3D
conda install pyqt pip
pip install napari
```

### Installing napari-sc3D-viewer

Once [napari] is installed, you can install `napari-sc3D-viewer`.
As for [napari], [napari-sc3D-viewer] can be installed either through an interface or via the terminal.

#### Installation via graphical interface

To install [napari-sc3D-viewer] with a visual interface, you should use the [napari's plugin manager](https://napari.org/stable/plugins/find_and_install_plugin.html) look for the plugin there and install it as explained in the previous link.

#### Installation via the terminal

Another way is to install `napari-sc3D-viewer` via [pip] or via [conda]:

```shell
conda install napari-sc3d-viewer
```

or

```shell
pip install napari-sc3d-viewer
```

Finally, to install latest development version :

```shell
pip install git+https://github.com/GuignardLab/napari-sc3D-viewer.git
```

#### Installation of the surface computation module

To install the surface computation enabled version it is necessary to use Python 3.9 (until [VTK] is ported to Python 3.10) and you can run one of the following commands:

```shell
pip install '.[pyvista]'
```

from the correct folder or

```shell
pip install 'napari-sc3D-viewer[pyvista]'
```

or

```shell
conda install 'napari-sc3D-viewer[pyvista]'
```

to install directly from pip or

```shell
pip install 'napari-sc3D-viewer[pyvista] @ git+https://github.com/GuignardLab/napari-sc3D-viewer.git'
```

to install the latest version

## Usage

`napari-sc3D-viewer` allows users to easily visualise and navigate 3D spatial single-cell transcriptomics using napari.

### Starting the plugin

First, you need to start [napari], for example, one can start it from a terminal just by typing:

```shell
napari
```

in the correct environment.

Then, one can follow the following steps to browse the dataset.

To open the plugin you can click on the ""Load spatial single cell"" from the `Plugins -> napari-sc3d-viewer` menu:
![loading image](https://raw.githubusercontent.com/GuignardLab/napari-sc3D-viewer/main/images/0.openplugin.png)

Once opened you should have an interface poping similar to the one showed in the image below (note that it might not be exactly the same depending on the version of the viewer you are using).

### Loading and opening a dataset

The expected dataset is a [scanpy]/[anndata] h5ad file together with an optional json file that maps cluster id numbers to actual tissue/cluster name.

The json file should look like that:

```json
{
    ""1"": ""Endoderm"",
    ""2"": ""Heart"",
    ""10"": ""Anterior neuroectoderm""
}
```

If no json file or a wrong json file is given, the original cluster id numbers are used.

The h5ad file should be informed in (1) and the json file in (2).
![loading image](https://raw.githubusercontent.com/GuignardLab/napari-sc3D-viewer/main/images/1.loading.png)

Let `data` be your h5ad data structure. To work properly, the viewer is expecting 4 different columns to be present in the h5ad file:

- the cluster id column (by default named 'predicted.id' that can be accessed as `data.obs['predicted.id']`)
- the 3D position column (by default named 'X_spatial_registered' that can be accessed as `data.obsm['X_spatial_registered']`)
- the gene names if not already in the column name (by default named 'feature_name' that can be accessed as `data.var['feature_name']`)
- umap coordinates (by default named 'X_umap' that can be accessed as `data.obsm['X_umap']`)

If the default column names are not consistent with your dataset, they can be changed in the tab `Parameters` (3) next to the tab `Loading files`

Once all the data paths and fields are correctly informed pressing the `Load Atlas` button (4) will load the dataset.

### Exploring a dataset

Once the dataset is loaded there are few options to explore it.

The viewer should look like to the following:
![viewer](https://raw.githubusercontent.com/GuignardLab/napari-sc3D-viewer/main/images/2.viewer.png)

It is divided in two main parts, the Tissue visualisation (1) part and the Metric visualisation (2) one.
Both of them are themselves split in two and three tabs respectively. All these tabs allow you to visualise and explore the dataset in different fashions.

The Tissues tab (1.1) allows to select the tissues to display, to show the legend and to colour the cells according to their tissue types.

The Surfaces tab (1.2) allows to construct coarse surfaces of tissues and to display them.

The Single metric tab (2.1) allows to display a metric, whether it is a gene intensity or a numerical metric that is embedded in the visualised dataset. This tab also allows to threshold cells according to the viewed metric, to change the contrast and the colour map.

The 2 Genes (2.2) tab allows to display gene coexpression.

The umap tab (2.3) allows to display the umap of the selected cells and to manually select subcategories of cells to be displayed.

![viewer](https://raw.githubusercontent.com/GuignardLab/napari-sc3D-viewer/main/images/3.description.png)

#### Explanatory ""videos""

The plugin is meant to be easy to use. That means that you should be able to play with it and figure things out by yourself.

That being said, it is not always that easy. You can find below a series of videos showing how to perform some of the main features.

#### Loading data

![Loading data video](https://raw.githubusercontent.com/GuignardLab/napari-sc3D-viewer/main/images/loading.gif)

#### Selecting tissues

![Selecting tissues video](https://raw.githubusercontent.com/GuignardLab/napari-sc3D-viewer/main/images/tissue-select.gif)

#### Displaying one gene

![Displaying one gene video](https://raw.githubusercontent.com/GuignardLab/napari-sc3D-viewer/main/images/gene1.gif)

#### Displaying two genes co-expression

![Displaying genes video](https://raw.githubusercontent.com/GuignardLab/napari-sc3D-viewer/main/images/gene2.gif)

#### Playing with the umap

![Playing with the umap video](https://raw.githubusercontent.com/GuignardLab/napari-sc3D-viewer/main/images/umap.gif)

#### Computing and processing the surface

![Computing and processing the surface video](https://raw.githubusercontent.com/GuignardLab/napari-sc3D-viewer/main/images/surfaces.gif)

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [MIT] license,
""napari-sc3D-viewer"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/GuignardLab/napari-sc3D-viewer/issues
[napari-sc3d-viewer]: https://github.com/GuignardLab/napari-sc3D-viewer

[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[VTK]: https://vtk.org/
[scanpy]: https://scanpy.readthedocs.io/en/latest/index.html
[anndata]: https://anndata.readthedocs.io/en/latest/
[conda]: https://conda.io
","['Development Status :: 4 - Beta', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Operating System :: OS Independent', 'License :: OSI Approved :: MIT License']","['Bug Tracker, https://github.com/GuignardLab/napari-sc3D-viewer/issues', 'Documentation, https://github.com/GuignardLab/napari-sc3D-viewer#README.md', 'Source Code, https://github.com/GuignardLab/napari-sc3D-viewer', 'User Support, https://github.com/GuignardLab/napari-sc3D-viewer/issues', 'Twitter, https://twitter.com/guignardlab']",,,napari-sc3D-viewer.load_atlas,,,,,https://pypi.org/project/napari-sc3D-viewer,https://github.com/GuignardLab/napari-sc3D-viewer,
279,napari-script-editor,0.2.10,2022-02-14,2023-07-08,napari-script-editor,Robert Haase,robert.haase@tu-dresden.de,BSD-3-Clause,https://github.com/haesleinhuepf/napari-script-editor,A python script editor for napari,>=3.7,"['napari-plugin-engine (>=0.1.4)', 'numpy', 'napari', 'haesleinhuepf-pyqode.core (>=2.15.5)', 'haesleinhuepf-pyqode.python (>=2.15.2)', 'napari-tools-menu', 'jedi (>=0.18.0)', 'pyflakes (<=2.4.0)', 'imageio (!=2.22.1)']","# napari-script-editor

[![License](https://img.shields.io/pypi/l/napari-script-editor.svg?color=green)](https://github.com/haesleinhuepf/napari-script-editor/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-script-editor.svg?color=green)](https://pypi.org/project/napari-script-editor)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-script-editor.svg?color=green)](https://python.org)
[![tests](https://github.com/haesleinhuepf/napari-script-editor/workflows/tests/badge.svg)](https://github.com/haesleinhuepf/napari-script-editor/actions)
[![codecov](https://codecov.io/gh/haesleinhuepf/napari-script-editor/branch/main/graph/badge.svg)](https://codecov.io/gh/haesleinhuepf/napari-script-editor)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-script-editor)](https://napari-hub.org/plugins/napari-script-editor)

A python script editor for napari based on [haesleinhuepf's fork of PyQode](https://github.com/haesleinhuepf/pyqode.core).

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.

![](https://github.com/haesleinhuepf/napari-script-editor/raw/main/docs/screenshot2.png)

## Usage

Start the script editor from the menu `Tools > Scripts > Script Editor`. Use the auto-completion while typing, 
check out the [napari tutorials](https://napari.org/tutorials/) and the
[example scripts](https://github.com/haesleinhuepf/napari-script-editor/tree/main/example_scripts). 
Use the `Run` button to execute a script.

![](https://github.com/haesleinhuepf/napari-script-editor/raw/main/docs/type_and_run_screencast.gif)

If you save the script to the folder "".napari-scripts"" in your home directory, you will find the script in the 
`Tools > Scripts` menu in napari. You can then also start it from there.

![](https://github.com/haesleinhuepf/napari-script-editor/raw/main/docs/run_from_menu_screencast.gif)

Note: If you have scripts, that might be useful to others, please send them as 
[pull-request](https://github.com/haesleinhuepf/napari-script-editor/pulls) to the examples in 
repository or share them in any other way that suits you.

### chatGPT support

In case [openAI API](https://openai.com/blog/openai-api) is installed, you find another button in the script editor to `Ask chatGPT`. 
Enter a prompt in the script editor and click the button. The script editor will send the prompt to
chatGPT and replace it with the answer. For example try entering:
```python
Write Python code for segmenting an image using these steps:
    * Apply a Gaussian blur
    * Threshold the image using Otsu's method
    * Apply connected component labeling
```
and it will replace it with code accordingly. If it doesn't work in the first attempt, try again. ChatGPT's answers are not always the same.

![](https://github.com/haesleinhuepf/napari-script-editor/raw/main/docs/ask_chatgpt.gif)


## Installation
* Get a python environment, e.g. via [mini-conda](https://docs.conda.io/en/latest/miniconda.html). 
  If you never used python/conda environments before, please follow the instructions 
  [here](https://mpicbg-scicomp.github.io/ipf_howtoguides/guides/Python_Conda_Environments) first.
* Install [napari](https://github.com/napari/napari) using conda. 

```
conda install -c conda-forge napari
```

Afterwards, install `napari-script-editor` using pip:

```
pip install napari-script-editor
```

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-script-editor"" is free and open source software

## Known issues

* Sometimes, the script editor thinks, the file has been changed on disk and asks to reload it.

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/haesleinhuepf/napari-script-editor/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 3 - Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Scientific/Engineering :: Image Processing', 'Topic :: Text Editors :: Integrated Development Environments (IDE)', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/haesleinhuepf/napari-script-editor/issues', 'Documentation, https://github.com/haesleinhuepf/napari-script-editor#README.md', 'Source Code, https://github.com/haesleinhuepf/napari-script-editor', 'User Support, https://github.com/haesleinhuepf/napari-script-editor/issues']",,,napari-script-editor.ScriptEditor,,,,,https://pypi.org/project/napari-script-editor,https://github.com/haesleinhuepf/napari-script-editor,
280,napari sdeconv,1.0.1,2022-02-13,2023-06-18,napari-sdeconv,Sylvain Prigent,meriadec.prigent@gmail.com,BSD-3-Clause,https://github.com/sylvainprigent/napari-sdeconv,2D and 3D deconvolution,>=3.8,"['numpy', 'magicgui', 'qtpy', 'sdeconv (>=1.0.1)', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'"", ""sdeconv (>=1.0.1) ; extra == 'testing'""]","# napari-sdeconv

[![License BSD-3](https://img.shields.io/pypi/l/napari-sdeconv.svg?color=green)](https://github.com/sylvainprigent/napari-sdeconv/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-sdeconv.svg?color=green)](https://pypi.org/project/napari-sdeconv)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-sdeconv.svg?color=green)](https://python.org)
[![tests](https://github.com/sylvainprigent/napari-sdeconv/workflows/tests/badge.svg)](https://github.com/sylvainprigent/napari-sdeconv/actions)
[![codecov](https://codecov.io/gh/sylvainprigent/napari-sdeconv/branch/main/graph/badge.svg)](https://codecov.io/gh/sylvainprigent/napari-sdeconv)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-sdeconv)](https://napari-hub.org/plugins/napari-sdeconv)

2D and 3D deconvolution

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/index.html
-->

## Installation

You can install `napari-sdeconv` via [pip]:

    pip install napari-sdeconv



To install latest development version :

    pip install git+https://github.com/sylvainprigent/napari-sdeconv.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-sdeconv"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/sylvainprigent/napari-sdeconv/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Software Development :: Testing']","['Bug Tracker, https://github.com/sylvainprigent/napari-sdeconv/issues', 'Documentation, https://github.com/sylvainprigent/napari-sdeconv#README.md', 'Source Code, https://github.com/sylvainprigent/napari-sdeconv', 'User Support, https://github.com/sylvainprigent/napari-sdeconv/issues']",,,napari-sdeconv.gaussian_widget,napari-sdeconv.make_sample_data,,,,https://pypi.org/project/napari-sdeconv,https://github.com/sylvainprigent/napari-sdeconv,
281,SeedSeg Segmentation,0.0.2,2023-08-01,2023-08-03,napari-seedseg,Reza Akbarian Bafghi,reza.akb98@gmail.com,BSD-3,https://github.com/rezaakb/napari-seedseg,A simple plugin for segmentation,>=3.8,"['napari', 'numpy', 'magicgui', 'qtpy', 'opencv-python-headless', 'scikit-image >=0.19.3', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-seedseg

[![License BSD-3](https://img.shields.io/pypi/l/napari-seedseg.svg?color=green)](https://github.com/rezaakb/napari-seedseg/tree/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-seedseg.svg?color=green)](https://pypi.org/project/napari-seedseg)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-seedseg.svg?color=green)](https://python.org)
[![tests](https://github.com/rezaakb/napari-seedseg/workflows/tests/badge.svg)](https://github.com/rezaakb/napari-seedseg/actions)
[![codecov](https://codecov.io/gh/rezaakb/napari-seedseg/branch/main/graph/badge.svg)](https://codecov.io/gh/rezaakb/napari-seedseg)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-seedseg)](https://napari-hub.org/plugins/napari-seedseg)

A simple plugin for 2D medical image segmentation. In this project, we are trying to use Flood method for segmentation. 
Flood segmentation, also known as flood fill or region growing, is an image segmentation technique that starts from a seed point and expands to neighboring pixels with similar properties (e.g., intensity, color). In our project, you only can segment one label at the time. Below is a description of the repository's structure and the purpose of each file:

    .
    ├── setup.cfg              # package metadata
    ├── pyproject.toml         # use setuptools
    ├── src/napari_seedseg     
    │   ├── napari.yaml        # Load and stress tests
    │   ├── __init.py__        # Python package metadata files
    │   ├── _widget.py         # Widget contributions
    │   ├── _layers.py         # Layers contributions
    │   └── _method.py         # Methods contributions
    └── ...

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-seedseg` via [pip]:

    pip install napari-seedseg



To install latest development version :

    pip install git+https://github.com/rezaakb/napari-seedseg.git


## Packages
In this project we have used these packages:

    numpy
    magicgui
    qtpy
    opencv-python-headless
    scikit-image>=0.19.3



## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-seedseg"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/rezaakb/napari-seedseg/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/rezaakb/napari-seedseg/issues', 'Documentation, https://github.com/rezaakb/napari-seedseg#README.md', 'Source Code, https://github.com/rezaakb/napari-seedseg', 'User Support, https://github.com/rezaakb/napari-seedseg/issues']",,,napari-seedseg.make_qwidget,,,,,https://pypi.org/project/napari-seedseg,https://github.com/rezaakb/napari-seedseg,
282,Segment organoid,0.3.12,2023-04-23,2023-09-07,napari-segment,Andrey Aristov,aaristov@pasteur.fr,BSD-3-Clause,https://github.com/aaristov/napari-segment,Segment organoids and measure intensities,>=3.8,"['dask', 'imageio-ffmpeg', 'matplotlib', 'napari', 'nd2', 'numpy', 'pytest-qt', 'scikit-image', 'zarr']","# napari-segment

[![License](https://img.shields.io/pypi/l/napari-segment.svg?color=green)](https://github.com/aaristov/napari-segment/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-segment.svg?color=green)](https://pypi.org/project/napari-segment)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-segment.svg?color=green)](https://python.org)
[![tests](https://github.com/aaristov/napari-segment/workflows/tests/badge.svg)](https://github.com/aaristov/napari-segment/actions)
[![codecov](https://codecov.io/gh/aaristov/napari-segment/branch/main/graph/badge.svg)](https://codecov.io/gh/aaristov/napari-segment)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-segment)](https://napari-hub.org/plugins/napari-segment)

Interactively segment organoids/spheroids/aggregates in brightfield/fluorescence from nd2 multipositional stack.
----------------------------------

![image](https://user-images.githubusercontent.com/11408456/201948817-255717a6-5f5c-45a2-ae01-2e0cbb1e29e8.png)


## Installation

```pip install napari-segment```

or

From napari plugin

![image](https://user-images.githubusercontent.com/11408456/201949692-33f94eaf-ac43-44dd-8c21-e9f9a460c5b2.png)


## Usage for segmentation

1. Drag your nd2 file into napari (otherwise try the Sample data from File / Open Sample / napari-segment)
2. Lauch Plugins -> napari-segment: Segment multipos
3. Select the brightfield channel
4. The data is lazily loaded from nd2 dataset and dynamically segmented in the viewer.
5. Binning 1-8 allows to skip small features and focus on bigger objects, also makes processing faster.
![image](https://user-images.githubusercontent.com/11408456/201701163-70c4af51-8a3a-42a0-adb9-32f0114eb49d.png)
6. Various preprocessing modes allow segmentation of different objects:
![image](https://user-images.githubusercontent.com/11408456/201701809-f16a23ea-d14a-4b38-8b8c-08a113416509.png)

  - Invert: will use the dark shadow around aggregate - best for very old aggregates , out of focus (File / Open Sample / napari-segment / Old aggregate)
  
  ![image](https://user-images.githubusercontent.com/11408456/201701950-efd86fae-d85b-471c-bb44-a0e328e26adc.png)

  - Gradient: best for very sharp edges, early aggregates, single cells (File / Open Sample / napari-segment / Early aggregate) 
  
  ![image](https://user-images.githubusercontent.com/11408456/201705697-5d0d0643-44b6-4cb9-9208-4a29dd899d8c.png)
  
  
  - Gauss diff: Fluorescence images
  The result of preprocessing will be shown in the ""Preprocessing"" layer.
7. Smooth, Theshold and Erode parameters allow you to adjust the preliminary segmentation -> they all will appear in the ""Detections"" layer as outlines 

  ![image](https://user-images.githubusercontent.com/11408456/201703675-cff6bac1-bb2a-4d45-963f-6e6d00309c77.png)

8. Min/max diameter and eccentricity allow you to filter out unwanted regions -> the good regions will appear in the ""selected labels"" layer as filled areas.

![image](https://user-images.githubusercontent.com/11408456/201703754-2c83a8d6-70c2-444a-8e30-54a39c901cd0.png)
![image](https://user-images.githubusercontent.com/11408456/201707025-9121f0dc-3939-48f0-ae75-884891be8d66.png)


9. Once satisfied, click ""Save the params!"" - it will automatically create file.nd2.params.yml file, so you can recall how the segmentation was done. Next time you open the same dataset, the parameters will be loaded automatically from this file. 

10. Next section is for quantifying the sizes. Pixel size will be retrieved automatically from metadata. If not: update it manually and click Update plots to see the correct sizes. Click on any suspected value to see the corresponding frame and try to adjust the above parameters. 

![image](https://user-images.githubusercontent.com/11408456/201704881-b2303b9a-50c6-49c7-80ff-a6099cc2a151.png)

11. If impossible to get good results with automatic pipeline, click Clone for manual correction: this will create an editable ""Manual"" layer which you can edin with built-in tools in napari. Click ""Update plots"" to see the updated values. 

12. ""Save csv!"" will generate a csv file with regionprops. 


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-segment"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/aaristov/napari-segment/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Software Development :: Testing']","['Bug Tracker, https://github.com/aaristov/napari-segment/issues', 'Documentation, https://github.com/aaristov/napari-segment#README.md', 'Source Code, https://github.com/aaristov/napari-segment', 'User Support, https://github.com/aaristov/napari-segment/issues']",napari-segment.get_reader,napari-segment.write_multiple,napari-segment.make_qwidget,napari-segment.make_late_aggregate,"['*.npy', '*.nd2', '*.tif']",,['.npy'],https://pypi.org/project/napari-segment,https://github.com/aaristov/napari-segment,
283,Segment Anything,0.1.4,2023-05-05,2023-06-18,napari-segment-anything,Jordao Bragantini,jordao.bragantini@czbiohub.org,Apache-2.0,https://github.com/jookuma/napari-segment-anything,Napari plugin of Segment Anything Model (SAM),>=3.8,"['numpy', 'torch', 'torchvision', 'segment-anything', 'qtpy', 'magicgui', 'napari', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-segment-anything

[![License Apache Software License 2.0](https://img.shields.io/pypi/l/napari-segment-anything.svg?color=green)](https://github.com/jookuma/napari-segment-anything/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-segment-anything.svg?color=green)](https://pypi.org/project/napari-segment-anything)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-segment-anything.svg?color=green)](https://python.org)
[![tests](https://github.com/jookuma/napari-segment-anything/workflows/tests/badge.svg)](https://github.com/jookuma/napari-segment-anything/actions)
[![codecov](https://codecov.io/gh/jookuma/napari-segment-anything/branch/main/graph/badge.svg)](https://codecov.io/gh/jookuma/napari-segment-anything)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-segment-anything)](https://napari-hub.org/plugins/napari-segment-anything)

Napari plugin of [Segment Anything Model (SAM)](https://github.com/facebookresearch/segment-anything)

Download the network weights [here](https://github.com/facebookresearch/segment-anything#model-checkpoints)


https://user-images.githubusercontent.com/21022743/230456433-2fa7bc40-a735-4d73-8d87-ecf776bbe2be.mp4


----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

## Installation

You can install `napari-segment-anything` via [pip]:

```bash
pip install napari-segment-anything
```

We recommend installing the latest development version because this package is being developed:

```bash
pip install git+https://github.com/jookuma/napari-segment-anything.git
```

**IMPORTANT**: `napari` won't work if you don't have `pyqt5` or `pyside2` installed.

## Instructions

### Opening napari-segment-anything

This software is napari plugin, so once you have napari installed you can open it using the command line:

```bash
napari <your image path> -w napari-segment-anything 'Segment Anything'
```

I noticed that sometimes napari fails to load the plugin widget from the command line, go to step 2 from below to load it.

If you prefer the user interface you need to:

1) Drag and drop your image into napari to load it;
2) Go to the ""Plugins"" file menu in the upper right corner and select the ""Segment Anything"" plugin.
3) Follow the instructions below for usage.

**IMPORTANT**: If you get an error make sure you have `pyqt5` or `pyside2` installed.

### Usage

- Interactions are done on the ""SAM points"" and ""SAM box"" layers using the existing functionalities of napari. Only rectangle shapes trigger the network prediction.
- For points supervision, left clicks are positive cues (object) and right clicks are negative (background).
- Press the ""Confirm Annot."" button (or the ""C"" key) to propagate the current segmentation mask to the label image.
- Use the napari labels layer features to delete or edit already confirmed labels.

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [Apache Software License 2.0] license,
""napari-segment-anything"" is a free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/jookuma/napari-segment-anything/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: Apache Software License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/jookuma/napari-segment-anything/issues', 'Documentation, https://github.com/jookuma/napari-segment-anything#README.md', 'Source Code, https://github.com/jookuma/napari-segment-anything', 'User Support, https://github.com/jookuma/napari-segment-anything/issues']",,,napari-segment-anything.samwidget,,,,,https://pypi.org/project/napari-segment-anything,https://github.com/jookuma/napari-segment-anything,
284,napari-segment-blobs-and-things-with-membranes,0.3.8,2022-02-05,2024-03-26,napari-segment-blobs-and-things-with-membranes,Robert Haase,robert.haase@tu-dresden.de,BSD-3-Clause,https://github.com/haesleinhuepf/napari-segment-blobs-and-things-with-membranes,A plugin based on scikit-image for segmenting nuclei and cells based on fluorescent microscopy images with high intensity in nuclei and/or membranes,>=3.8,"['napari-plugin-engine >=0.1.4', 'numpy', 'scikit-image', 'scipy', 'napari-tools-menu >=0.1.17', 'napari-time-slicer >=0.4.8', 'napari-assistant', 'stackview >=0.3.2']","# napari-segment-blobs-and-things-with-membranes (nsbatwm)

[![License](https://img.shields.io/pypi/l/napari-segment-blobs-and-things-with-membranes.svg?color=green)](https://github.com/haesleinhuepf/napari-segment-blobs-and-things-with-membranes/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-segment-blobs-and-things-with-membranes.svg?color=green)](https://pypi.org/project/napari-segment-blobs-and-things-with-membranes)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-segment-blobs-and-things-with-membranes.svg?color=green)](https://python.org)
[![tests](https://github.com/haesleinhuepf/napari-segment-blobs-and-things-with-membranes/workflows/tests/badge.svg)](https://github.com/haesleinhuepf/napari-segment-blobs-and-things-with-membranes/actions)
[![codecov](https://codecov.io/gh/haesleinhuepf/napari-segment-blobs-and-things-with-membranes/branch/master/graph/badge.svg)](https://codecov.io/gh/haesleinhuepf/napari-segment-blobs-and-things-with-membranes)
[![Development Status](https://img.shields.io/pypi/status/napari-segment-blobs-and-things-with-membranes.svg)](https://en.wikipedia.org/wiki/Software_release_life_cycle#Alpha)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-segment-blobs-and-things-with-membranes)](https://napari-hub.org/plugins/napari-segment-blobs-and-things-with-membranes)
[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.7027634.svg)](https://doi.org/10.5281/zenodo.7027634)

This napari-plugin is based on scikit-image and allows segmenting nuclei and cells based on fluorescence microscopy images with high intensity in nuclei and/or membranes.

## Usage

This plugin populates image processing operations to the `Tools` menu in napari.
You can recognize them with their suffix `(nsbatwm)` in brackets.
Furthermore, it can be used from the [napari-assistant](https://www.napari-hub.org/plugins/napari-assistant) graphical user interface. 
Therefore, just click the menu `Tools > Utilities > Assistant (na)` or run `naparia` from the command line.

![img.png](https://github.com/haesleinhuepf/napari-segment-blobs-and-things-with-membranes/raw/main/docs/tools_menu_screenshot.png)

You can also call these functions as shown in [the demo notebook](https://github.com/haesleinhuepf/napari-segment-blobs-and-things-with-membranes/blob/main/docs/demo.ipynb).

### Voronoi-Otsu-Labeling

This algorithm uses [Otsu's thresholding method](https://ieeexplore.ieee.org/document/4310076) in combination with 
[Gaussian blur](https://scikit-image.org/docs/dev/api/skimage.filters.html#skimage.filters.gaussian) and a 
[Voronoi-Tesselation](https://en.wikipedia.org/wiki/Voronoi_diagram) 
approach to label bright objects such as nuclei in an intensity image. The alogrithm has two sigma parameters which allow
you to fine-tune where objects should be cut (`spot_sigma`) and how smooth outlines should be (`outline_sigma`).
This implementation aims to be similar to [Voronoi-Otsu-Labeling in clesperanto](https://github.com/clEsperanto/pyclesperanto_prototype/blob/master/demo/segmentation/voronoi_otsu_labeling.ipynb).

![img.png](https://github.com/haesleinhuepf/napari-segment-blobs-and-things-with-membranes/raw/main/docs/voronoi_otsu_labeling.png)

### Seeded Watershed

Starting from an image showing high-intensity membranes and a seed-image where objects have been labeled (e.g. using Voronoi-Otsu-Labeling),
objects are labeled that are constrained by the membranes.

![img.png](https://github.com/haesleinhuepf/napari-segment-blobs-and-things-with-membranes/raw/main/docs/seeded_watershed.png)

### Seeded Watershed with mask

If there is additionally a mask image available, one can use the `Seeded Watershed with mask`, to constraint the flooding 
on a membrane image (1), starting from nuclei (2), limited by a mask image (3) to produce a cell segmentation within the mask (4).

![img.png](https://github.com/haesleinhuepf/napari-segment-blobs-and-things-with-membranes/raw/main/docs/seeded_watershed_with_mask.png)

### Seeded Watershed using local minima as starting points

Similar to the Seeded Watershed and Voronoi-Otsu-Labeling explained above, you can use this tool to segment an image
showing membranes without an additional image showing nuclei. The two sigma parameters allow to fine tune how close 
objects can be and how precise their boundaries are detected.

![img.png](https://github.com/haesleinhuepf/napari-segment-blobs-and-things-with-membranes/raw/main/docs/local_minima_seeded_watershed.png)

### Gaussian blur

Applies a [Gaussian blur](https://scikit-image.org/docs/dev/api/skimage.filters.html#skimage.filters.gaussian) to an
image. This might be useful for denoising, e.g. before applying the Threshold-Otsu method.

![img.png](https://github.com/haesleinhuepf/napari-segment-blobs-and-things-with-membranes/raw/main/docs/gaussian_blur.png)

### Subtract background

Subtracts background using [scikit-image's rolling-ball algorithm](https://scikit-image.org/docs/stable/auto_examples/segmentation/plot_rolling_ball.html). 
This might be useful, for example to make intensity of membranes more similar in different regions of an image.

![img.png](https://github.com/haesleinhuepf/napari-segment-blobs-and-things-with-membranes/raw/main/docs/subtract_background.png)

### Threshold Otsu

Binarizes an image using [scikit-image's threshold Otsu algorithm](https://scikit-image.org/docs/dev/auto_examples/segmentation/plot_thresholding.html), also known as 
[Otsu's method](https://ieeexplore.ieee.org/document/4310076).

![img.png](https://github.com/haesleinhuepf/napari-segment-blobs-and-things-with-membranes/raw/main/docs/threshold_otsu.png)

### Split touching objects (formerly known as binary watershed).

In case objects stick together after thresholding, this tool might help.
It aims to deliver similar results as [ImageJ's watershed implementation](https://imagej.nih.gov/ij/docs/menus/process.html#watershed).

![img.png](https://github.com/haesleinhuepf/napari-segment-blobs-and-things-with-membranes/raw/main/docs/binary_watershed.png)

### Connected component labeling

Takes a binary image and produces a label image with all separated objects labeled differently. Under the hood, it uses
[scikit-image's label function](https://scikit-image.org/docs/dev/auto_examples/segmentation/plot_label.html).

![img.png](https://github.com/haesleinhuepf/napari-segment-blobs-and-things-with-membranes/raw/main/docs/connected_component_labeling.png)

### Manual split and merge labels

Split and merge labels in napari manually via the `Tools > Utilities menu`:

![](https://github.com/haesleinhuepf/napari-segment-blobs-and-things-with-membranes/raw/main/docs/split_and_merge_demo.gif)

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.

## Installation

This plugin is part of devbio-napari. To install it, please follow its [installation instructions](https://github.com/haesleinhuepf/devbio-napari#installation).

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-segment-blobs-and-things-with-membranes"" is free and open source software

## Issues

If you encounter any problems, please create a thread on [image.sc] along with a detailed description and tag [@haesleinhuepf].

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/haesleinhuepf/napari-segment-blobs-and-things-with-membranes/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/

[image.sc]: https://image.sc
[@haesleinhuepf]: https://twitter.com/haesleinhuepf
","['Development Status :: 3 - Alpha', 'Intended Audience :: Science/Research', 'Framework :: napari', 'Topic :: Scientific/Engineering :: Image Processing', 'Topic :: Scientific/Engineering :: Information Analysis', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/haesleinhuepf/napari-segment-blobs-and-things-with-membranes/issues', 'Documentation, https://github.com/haesleinhuepf/napari-segment-blobs-and-things-with-membranes#README.md', 'Source Code, https://github.com/haesleinhuepf/napari-segment-blobs-and-things-with-membranes', 'User Support, https://github.com/haesleinhuepf/napari-segment-blobs-and-things-with-membranes/issues']",,,napari-segment-blobs-and-things-with-membranes.napari_experimental_provide_function,,,,,https://pypi.org/project/napari-segment-blobs-and-things-with-membranes,https://github.com/haesleinhuepf/napari-segment-blobs-and-things-with-membranes,
285,Napari Segment Everything,0.1.5,,,napari-segment-everything,"Brian Northan, Ian Coccimiglio",bnorthan@gmail.com,BSD-3-Clause,,A Napari SAM plugin to segment everything in your image (not just some things),>=3.8,"['numpy', 'torch', 'torchvision', 'segment-anything', 'magicgui', 'qtpy', 'scikit-image', 'napari', 'gdown', 'opencv-python', 'timm', 'torchpack', 'onnx', 'onnxsim', 'matplotlib', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-segment-everything

[![License BSD-3](https://img.shields.io/pypi/l/napari-segment-everything.svg?color=green)](https://github.com/True-North-Intelligent-Algorithms/napari-segment-everything/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-segment-everything.svg?color=green)](https://pypi.org/project/napari-segment-everything)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-segment-everything.svg?color=green)](https://python.org)
[![tests](https://github.com/True-North-Intelligent-Algorithms/napari-segment-everything/workflows/tests/badge.svg)](https://github.com/True-North-Intelligent-Algorithms/napari-segment-everything/actions)
[![codecov](https://codecov.io/gh/True-North-Intelligent-Algorithms/napari-segment-everything/branch/main/graph/badge.svg)](https://codecov.io/gh/True-North-Intelligent-Algorithms/napari-segment-everything)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-segment-everything)](https://napari-hub.org/plugins/napari-segment-everything)

A Napari SAM plugin to segment everything in your image (not just some things)

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

https://github.com/True-North-Intelligent-Algorithms/napari-segment-everything/assets/4366342/1f451e4a-bf66-4b77-a91d-4fa283270160

## Instructions

### 0. Select recipe (implementation)

Use the 'select recipe' combo box to choose the implementation.   Currently 'Mobile SAM v2', 'Mobile SAM finetuned' and 'SAM Automatic Mask Generator' are available.  Not that the sub-options will change slightly depending on which recipe you choose.  'Mobile SAM v2' and 'Mobile SAM finetuned' (finetuned using Cellpose training data) first use a bounding box detector to locate objects then feed the bounding boxes to SAM.  'SAM Automatic Mask Generator' uses a grid of points as the prompt for SAM.  Our experiments indicate that the 'Mobile SAM' recipes work well in most cases.  'SAM Automatic Mask Generator' may be useful for cases where bounding box detection was sub-optimal.  

### 1. Generate 3D labels

In the first step adjust SAM settings and generate a 3D representation of your labels.  The 3D view is needed to represent overlapping labels (labels that overlap in xy can be represented at different z).  After tweaking settings press 'Generate 3D labels'.  Be patient.  SAM with permissive settings can potentially find thousands of labels in a complicated image.  At least 6G of GPU memory is recommended to run SAM and to render to 3D label map (which can be large). 

### 2. Filter 3D labels

In the next step select a stat (solidity, hue, IOE, stability and other stats are available) then use the sliders and number boxes to filter out labels that do not represent structure of interest.  If you double click on a label a popup will appear containing the stats for that label.  Inpect stats for labels you want to keep, and labels you want to eliminate to help determine the filter settings. 

### 3. Generate 2D labels

In this step the 3D labels are projected to a 2D label map, use the dropdown to choose between projecting big labels in front or small labels in front.

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-segment-everything"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']",,,,napari-segment-everything.napari_segment_everything,,,,,https://pypi.org/project/napari-segment-everything,,
286,serialcellpose,0.2.2,2023-12-04,2023-12-04,napari-serialcellpose,Guillaume Witz,guillaume.witz@unibe.ch,BSD-3-Clause,https://pypi.org/project/napari-serialcellpose,A simple plugin to batch segment cells with cellpose,>=3.8,"['cellpose', 'numpy', 'magicgui', 'qtpy', 'matplotlib', 'napari-skimage-regionprops', 'napari-aicsimageio', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-serialcellpose

[![License](https://img.shields.io/pypi/l/napari-serialcellpose.svg?color=green)](https://github.com/guiwitz/napari-serialcellpose/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-serialcellpose.svg?color=green)](https://pypi.org/project/napari-serialcellpose)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-serialcellpose.svg?color=green)](https://python.org)
[![tests](https://github.com/guiwitz/napari-serialcellpose/workflows/tests/badge.svg)](https://github.com/guiwitz/napari-serialcellpose/actions)
[![codecov](https://codecov.io/gh/guiwitz/napari-serialcellpose/branch/main/graph/badge.svg)](https://codecov.io/gh/guiwitz/napari-serialcellpose)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-serialcellpose)](https://napari-hub.org/plugins/napari-serialcellpose)

This napari plugin allows you to segment single images or series of images using built-in or custom Cellpose models as well as to analyze the properties of these segmented regions (""region properties""). Properties can be visualized for a single image or a complete experiment in the form of histograms that can also be filtered (e.g. based on area size, mean intensity etc.) Thanks to the [napari-skimage-regionprops](https://github.com/haesleinhuepf/napari-skimage-regionprops) plugin, properties of segmented objects can be interactively explored at a single object level.

## Main goal

The main goal of this plugin is to simplify the classical image processing pipeline of image segmentation followed by region analysis via Cellpose. It allows to quickly get a quantification of a set of images without the need for any scripting.

## Installation

In order to use this plugin, whe highly recommend to create a specific environment and to install the required software in it. You can create a conda environment using:

    conda create -n serialcellpose python=3.8.5 napari -c conda-forge

Then activate it and install the plugin:
    
    conda activate serialcellpose
    pip install napari-serialcellpose

### Potential issue with PyTorch

Cellpose and therefore the plugin and napari can crash without warning in some cases with ```torch==1.12.0```. This can be fixed by reverting to an earlier version using:
    
    pip install torch==1.11.0

### GPU

In order to use a GPU:

1. Uninstall the PyTorch version that gets installed by default with Cellpose:

        pip uninstall torch

2. Make sure your have up-to-date drivers for your NVIDIA card installed.

3. Re-install a GPU version of PyTorch via conda using a command that you can find [here](https://pytorch.org/get-started/locally/) (this takes care of the cuda toolkit, cudnn etc. so **no need to install manually anything more than the driver**). The command will look like this:

        conda install pytorch torchvision cudatoolkit=11.3 -c pytorch

### Plugin Updates

To update the plugin, you only need to activate the existing environment and install the new version:

    conda activate serialcellpose
    pip install napari-serialcellpose -U

## Usage: segmentation

The main interface is shown below. The sequence of events should be the following:

1. Select a folder containing images. The list of files within that folder will appear in the area above. You can also just drag and drop a folder or an image in that area. When selecting an image, it gets displayed in the viewer. Images are opened via [aicsimageio](https://allencellmodeling.github.io/aicsimageio/). You can use grayscale images, RGB images or multi-channel images. In the latter case, **make sure each channel opens as a separate layer when you open them using the napari-aicsimagio importer**.
2. If you want to save the segmentation and tables with properties, select a folder that will contain the output.
3. Select the type of cellpose model.
4. If you use a custom model, select its location.
5. Run the analysis on the currently selected image or on all files in the folder.
### Options

6. Select if you want to use a GPU or not.
7. If you are using multi-channel images, you can specify which channel to segment and optionally which to use as ""nuclei"" channel to help cell segmentation.
8. In case you are using one of the built-in models, you can set the estimated diameter of your objects.
9. In the Options tab you will find a few more options for segmentation, including the two thresholds ```flow_threshold``` and ```cellprob_threshold```. You can also decide to discard objects touching the border. Using the ```Select options yml file``` you can select a ```.yml``` file which contains a list of additional options to pass to the ```eval``` method of the Cellpose model. **Note that options specified in the yml file will override options set in the GUI**. The file [my_options.yml](https://raw.githubusercontent.com/guiwitz/napari-serialcellpose/main/src/napari_serialcellpose/_tests/my_options.yml) is an example of such a file where for example the ```diameter``` (also available in the GUI) and ```resample``` (not available in the GUI) options are set. 

<img src=""https://github.com/guiwitz/napari-serialcellpose/raw/main/illustrations/napari_serialcellpose_gui1.png"" alt=""image"" width=""500"">
<img src=""https://github.com/guiwitz/napari-serialcellpose/raw/main/illustrations/napari_serialcellpose_gui1b.png"" alt=""image"" width=""500"">

### Properties

10. After segmentation, properties of the objects can automatically be computed. You can select which properties should be computed in the Options tab. As defined in ```napari-skimage-regionprops``` properties are grouped by types. If you want to measure intensity properties such as mean intensity, you have to specify which channel (```Analysis channel```) you want to perform the measurement on.

### Output

The results of the analysis are saved in the folder chosen in #2. The segmentation mask is saved with the same name as the original image with the suffix ```_mask.tif```. A table with properties is saved in the subfolder ```tables``` also with the same name as the image with the suffix ```props.csv```. If you run the plugin on multiple files in a folder, a ```summary.csv``` file is also generated which compiles all the data.
## Usage: post-processing

After the analysis is done, when you select an image, the corresponding segmentation mask is shown on top of the image as shown below. This also works for saved segmentations: in that case you just select a folder with data and the corresponding output folder.

<img src=""https://github.com/guiwitz/napari-serialcellpose/raw/main/illustrations/napari_serialcellpose_gui2.png"" alt=""image"" width=""500"">

### Properties

If you head to the **Properties** tab, you will find there two histograms showing the distribution of two properties that you can choose from a list at the top of the window. Below the plot you find the table containing information for each cell (each line is a cell).

As shown below, if you select the box ```show selected```, you can select items in the properties table and it will highlight the corresponding cell in the viewer. If you select the pipet tool, you can also select a cell and see the corresponding line in the table highlighted.

<img src=""https://github.com/guiwitz/napari-serialcellpose/raw/main/illustrations/napari_serialcellpose_gui3.png"" alt=""image"" width=""500"">

### Summary

Finally if you select the **Summary** tab, and click on ```Load summary```, it will load all data of the current output folder and create histograms of two properties that can be selected. An additional property can be used for filtering the data. Using the sliders, one can set a minimum and maximum threshold on the ""filtering property"", which will create a sub-selection of the data.

<img src=""https://github.com/guiwitz/napari-serialcellpose/raw/main/illustrations/napari_serialcellpose_gui4.png"" alt=""image"" width=""500"">

## Data

Sample data were acquired by Fabian Blank at the DBMR, University of Bern.

## License

Distributed under the terms of the [BSD-3] license,
""napari-serialcellpose"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/guiwitz/napari-serialcellpose/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/guiwitz/napari-serialcellpose/issues', 'Documentation, https://github.com/guiwitz/napari-serialcellpose#README.md', 'Source Code, https://github.com/guiwitz/napari-serialcellpose', 'User Support, https://github.com/guiwitz/napari-serialcellpose/issues']",,,napari-serialcellpose.make_qwidget,,,,,https://pypi.org/project/napari-serialcellpose,,
287,shape odyssey,0.1.1,,,napari-shape-odyssey,Johannes Soltwedel,johannes_richard.soltwedel@tu-dresden.de,BSD-3-Clause,,Analyze shapes of meshes,>=3.8,"['numpy', 'vedo', 'pandas', 'napari', 'napari-stress', 'napari-process-points-and-surfaces', 'pyfmaps', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""PyQt5 ; extra == 'testing'""]","# napari-shape-odyssey

[![License BSD-3](https://img.shields.io/pypi/l/napari-shape-odyssey.svg?color=green)](https://github.com/jo-mueller/napari-shape-odyssey/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-shape-odyssey.svg?color=green)](https://pypi.org/project/napari-shape-odyssey)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-shape-odyssey.svg?color=green)](https://python.org)
[![tests](https://github.com/jo-mueller/napari-shape-odyssey/workflows/tests/badge.svg)](https://github.com/jo-mueller/napari-shape-odyssey/actions)
[![codecov](https://codecov.io/gh/jo-mueller/napari-shape-odyssey/branch/main/graph/badge.svg)](https://codecov.io/gh/jo-mueller/napari-shape-odyssey)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-shape-odyssey)](https://napari-hub.org/plugins/napari-shape-odyssey)

Analyze shapes of meshes: This plugin provides advanced measures of shape for meshes. It is based largely on the following libraries and tools:

* [PyFM](https:/github.com/robinmagnet/pyfm)
* [boundary-first-flattening](https://github.com/GeometryCollective/boundary-first-flattening)

## Shape analysis

This plugin provides Laplace spectra ([Reuter, Wolter, Peinecke (2005)](https://dl.acm.org/doi/abs/10.1145/1060244.1060256)), heat kernel signatures ([Bronstein & Kokkinos (2010)](https://ieeexplore.ieee.org/abstract/document/5539838/)) & wave kernel signatures ([Audrey, Schlickewei, Cremers et al.](https://ieeexplore.ieee.org/abstract/document/6130444)).

**Laplace spectra** can be imagined to be the equivalent of resonance modes on the surface of a mesh. The resonance and the resonance modes can, for typical objects, look like this:

![](https://github.com/jo-mueller/napari-shape-odyssey/raw/main/docs/imgs/Eigenvalues.gif)

**Heat kernel signatures**: Heat dissipation on a mesh depends on local geometry. You can use the heat kernel signature to easily generate a large number of local features of shape

![](https://github.com/jo-mueller/napari-shape-odyssey/raw/main/docs/imgs/heat_kernel_signature.gif)

## Unwrapping

This plugin provides a number of methods to unwrap a mesh into basic shapes such as spheres or disks. The method relies on [boundary-first flattening](https://github.com/GeometryCollective/boundary-first-flattening) - currently it's only available on Windows.

![](https://github.com/jo-mueller/napari-shape-odyssey/raw/main/docs/imgs/unwrap_to_sphere.png)



----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-shape-odyssey` via [pip]:

´´´bash
    pip install napari-shape-odyssey
    napari-skimage-regionprops @ git+https://github.com/jo-mueller/napari-skimage-regionprops.git
    pyFM @ git+https://github.com/RobinMagnet/pyFM.git
´´´




## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-shape-odyssey"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/jo-mueller/napari-shape-odyssey/issues', 'Documentation, https://jo-mueller.github.io/napari-shape-odyssey/intro.html', 'Source Code, https://github.com/jo-mueller/napari-shape-odyssey', 'User Support, https://github.com/jo-mueller/napari-shape-odyssey/issues']",napari-shape-odyssey.get_reader,napari-shape-odyssey.write_multiple,napari-shape-odyssey.shape_fingerprint_spectral,,"['*.obj', '*.stl', '*.off', '*.ply', '*.vtk', '*.vtp']",,['.npy'],https://pypi.org/project/napari-shape-odyssey,,
288,napari sif file reader,0.0.2,2023-04-11,2023-11-06,napari-sif-reader,Ruben Lopez,rjlopez2@gmail.com,BSD-3-Clause,https://github.com/rjlopez2/napari-sif-reader,This is a simple wraper to read .sif format files from Andor Technology.,>=3.8,"['numpy', 'sif-parser', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pillow ; extra == 'testing'""]","# napari-sif-reader

[![License BSD-3](https://img.shields.io/pypi/l/napari-sif-reader.svg?color=green)](https://github.com/rjlopez2/napari-sif-reader/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-sif-reader.svg?color=green)](https://pypi.org/project/napari-sif-reader)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-sif-reader.svg?color=green)](https://python.org)
[![tests](https://github.com/rjlopez2/napari-sif-reader/workflows/tests/badge.svg)](https://github.com/rjlopez2/napari-sif-reader/actions)
[![codecov](https://codecov.io/gh/rjlopez2/napari-sif-reader/branch/main/graph/badge.svg)](https://codecov.io/gh/rjlopez2/napari-sif-reader)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-sif-reader)](https://napari-hub.org/plugins/napari-sif-reader)

This is a simple wraper to read .sif format files from Andor Technology.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-sif-reader` via [pip]:

    pip install napari-sif-reader



To install latest development version :

    pip install git+https://github.com/rjlopez2/napari-sif-reader.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-sif-reader"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/rjlopez2/napari-sif-reader/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/rjlopez2/napari-sif-reader/issues', 'Documentation, https://github.com/rjlopez2/napari-sif-reader#README.md', 'Source Code, https://github.com/rjlopez2/napari-sif-reader', 'User Support, https://github.com/rjlopez2/napari-sif-reader/issues']",napari-sif-reader.get_reader,,,napari-sif-reader.make_sample_data,['*.sif'],,,https://pypi.org/project/napari-sif-reader,https://github.com/rjlopez2/napari-sif-reader,
289,SIFTReg,0.1.2,2022-08-18,2023-06-18,napari-sift-registration,John Fozard,john.fozard@gmail.com,BSD-3-Clause,https://github.com/jfozard/napari-sift-registration,"Simple plugin for SIFT keypoint detection, and affine registration with RANSAC, based on scikit-image",>=3.8,"['numpy', 'magicgui', 'qtpy', 'scikit-image', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# skimage-sift-registration

[![License BSD-3](https://img.shields.io/pypi/l/napari-sift-registration.svg?color=green)](https://github.com/jfozard/napari-sift-registration/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-sift-registration.svg?color=green)](https://pypi.org/project/napari-sift-registration)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-sift-registration.svg?color=green)](https://python.org)
[![tests](https://github.com/jfozard/napari-sift-registration/workflows/tests/badge.svg)](https://github.com/jfozard/napari-sift-registration/actions)
[![codecov](https://codecov.io/gh/jfozard/napari-sift-registration/branch/main/graph/badge.svg)](https://codecov.io/gh/jfozard/napari-sift-registration)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-sift-registration)](https://napari-hub.org/plugins/napari-sift-registration)

Simple plugin for 2D keypoint detection and affine registration with RANSAC.

----------------------------------

![moving image](test_data/test1.png)
![fixed image](test_data/test2.png)

Artificial data 

![moving image with inlier keypoints](doc/moving_keypoints.png)
![fixed image with inlier keypoints](doc/fixed_keypoints.png)

Moving and fixed images showing inlier keypoints after RANSAC


----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.
It uses the [scikit-image] SIFT keypoint detection routines to find distinctive image points and generate local descriptions of the image around them.
Correspondences between the two images are then found by looking for pairs of keypoints, one in each of the two images, with closely matching descriptors.



For typical images, many of these correspondences will be wrong. To reduce these false correspondences, the plugin applies the RANSAC algorithm. This randomly selects a small subset of the matching pairs of keypoints, estimates the affine transformation between this subset of keypoints, and then evaluates how many of the other pairs of keypoints also closely agree with this affine transformation (""inliers""). A large number of random samples are tested, and the transformation with the most inliers retained.

The plugin outputs two points layers, one for each image, containing all the corresponding (inlier) SIFT keypoints. It also uses the estimated affine transformation between the two images to deform the ""moving"" image layer onto the ""fixed"" image layer.

This approach is an attempt to provide similar functionality to the Stephan Saalfeld's Fiji ""Extract SIFT Correspondences"" plugin [extract], and more-or-less
just provides a napari interface to the existing routines in scikit-image. There are great examples in the scikit-image documentation (e.g. [SIFT-example] and [RANSAC-example]) that can be used if you would like to use these routines in your own analysis scripts.


## Installation

You can install `napari-sift-registration` via [pip]:

    pip install napari-sift-registration

To install the latest development version :

    pip install git+https://github.com/jfozard/napari-sift-registration.git

## Usage

### Basic usage

- Load two 2D single channel images in Napari.
- Select the menu item Plugins > napari-sift-registration
- Select these two images as the ""Moving image layer"" and the ""Fixed image layer"". The moving image will be deformed by the transformation to look like the fixed image.
- The remaining parameters are the default settings from scikit-image; try these default values first.

### Advanced usage

The parameter values for SIFT feature detection, keypoint matching and RANSAC are accessible from the plugin gui. For further information about their use, see the appropriate scikit-image documentation:

Upsampling before feature detection, maximum number of octaves, maximum number of scales in every octave, blur level of seed image, feature descriptor size, feature descriptor orientation bins: see [scikit-image-SIFT].

Closest/next closest ratio: see [scikit-image-match_descriptors]

Minimum number of points sampled for each RANSAC model, distance for points to be inliers in RANSAC model, maximum number of trials in RANSAC model: see [scikit-image-RANSAC]

Only show inlier keypoints: If checked, only show corresponding keypoints that are inliers after RANSAC. If unchecked, show all corresponding keypoints.

### Limitations

Only 2D, single channel images (for now).

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-sift-registration"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[extract]: https://imagej.net/plugins/feature-extraction
[scikit-image]: https://scikit-image.org/
[SIFT-example]: https://scikit-image.org/docs/stable/auto_examples/features_detection/plot_sift.html
[RANSAC-example]: https://scikit-image.org/docs/stable/auto_examples/transform/plot_matching.html
[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[scikit-image-SIFT]: https://scikit-image.org/docs/stable/api/skimage.feature.html#skimage.feature.SIFT
[scikit-image-match_descriptors]: https://scikit-image.org/docs/stable/api/skimage.feature.html#skimage.feature.match_descriptors
[scikit-image-RANSAC]: https://scikit-image.org/docs/stable/api/skimage.measure.html#skimage.measure.ransac

[file an issue]: https://github.com/jfozard/napari-sift-registration/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 3 - Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Scientific/Engineering :: Image Processing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/jfozard/napari-sift-registration/issues', 'Documentation, https://github.com/jfozard/napari-sift-registration#README.md', 'Source Code, https://github.com/jfozard/napari-sift-registration', 'User Support, https://github.com/jfozard/napari-sift-registration/issues']",,,napari-sift-registration.make_magic_widget,,,,,https://pypi.org/project/napari-sift-registration,https://github.com/jfozard/napari-sift-registration,
290,Napari Signal Selector,0.0.3,2023-10-29,2023-10-29,napari-signal-selector,Marcelo Leomil Zoccoler,marzoccoler@gmail.com,BSD-3-Clause,https://pypi.org/project/napari-signal-selector,"An interactive signal selector for napari, based on napari-matplotlib.",>=3.8,"['numpy', 'magicgui', 'qtpy', 'napari-matplotlib >=1.1.0', 'napari-skimage-regionprops', 'cmap', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-signal-selector

[![License BSD-3](https://img.shields.io/pypi/l/napari-signal-selector.svg?color=green)](https://github.com/zoccoler/napari-signal-selector/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-signal-selector.svg?color=green)](https://pypi.org/project/napari-signal-selector)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-signal-selector.svg?color=green)](https://python.org)
[![tests](https://github.com/zoccoler/napari-signal-selector/workflows/tests/badge.svg)](https://github.com/zoccoler/napari-signal-selector/actions)
[![codecov](https://codecov.io/gh/zoccoler/napari-signal-selector/branch/main/graph/badge.svg)](https://codecov.io/gh/zoccoler/napari-signal-selector)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-signal-selector)](https://napari-hub.org/plugins/napari-signal-selector)

An interactive signal selector and annotator for napari, based on [napari-matplotlib](https://github.com/matplotlib/napari-matplotlib#napari-matplotlib).

[Jump to Intallation](#installation)

----------------------------------

## Usage

This plugin opens an embedded plotter in napari capable of plotting and interacting (selecting/annotating) with individual object signals (typically temporal features).

![plotting](https://github.com/zoccoler/napari-signal-selector/raw/main/images/plotting.gif)

### Input Data

napari-signal-selector works with a [Labels layer](https://napari.org/stable/howtos/layers/labels.html) containing segmented objects and whose `features` attribute contains a table that follows the example structure shown below:

| `label` | `frame` | `feature` | ...  |
|-------|-------|---------|---|
| 1     | 0     | 1.0     | ...  |
| 2     | 0     | 1.0     | ...  |
| 3     | 0     | 0.5     | ...  |
| 4     | 0     | 0.5     | ...  |
| 1     | 1     | 2.0     | ...  |
| 2     | 1     | 1.0     | ...  |
| 3     | 1     | 1.0     | ...  |
| 4     | 1     | 1.0     | ...  |
| 1     | 2     | 3.0     | ...  |
| 2     | 2     | 1.0     | ...  |
| 3     | 2     | 0.5     | ...  |
| 4     | 2     | 1.5     | ...  |
| ⋮     | ⋮     | ⋮     |   |

Basically, it needs an object identifier (in this case, the `label` column) that matches the labels in the Labels layer, and other columns containing x- and y-axis numbers to plot. Typically, x-axis is some temporal-related property.

Here is how one could add such a layer to a napari viewer via code (check [this example notebook](./examples/synthetic_example.ipynb) for more details):

```python
viewer.add_labels(labels_image, features = table)
```

If a layer like this is selected, you can choose what to plot by means of dropdown fields in the bottom of the plotter.

Below is a basic example using the ""Flashing Polygons"" synthetic data:

![intro](https://github.com/zoccoler/napari-signal-selector/raw/main/images/intro.gif)

## Tools

### Selection Tool

The selection tool (arrowhead icon) is a toggle button which enables you to select individual signals. Once activated, the icon gets highlighted and you can click over individual signals to select them. Right-clicking unselects everything.

![select](https://github.com/zoccoler/napari-signal-selector/raw/main/images/select.gif)

If the region you want to click is too crowded, consider zooming in first and then selecting.

![zoom-select](https://github.com/zoccoler/napari-signal-selector/raw/main/images/zoom_select.gif)

And if you know which label you want to select, you can enable `'show selected'` from the Labels layer options to solely display one label at a time. The Lables layer picker tool may help you get the right label.

![show-selected](https://github.com/zoccoler/napari-signal-selector/raw/main/images/show_selected.gif)

### Annotation Tool

Once one or multiple signals are selected, you can annotate them with the annotation tool (brush with a 'plus' icon). You need to choose a signal class first.
*Remember to right-click to remove previous selections when annotating different signal classes!*

![annotation](https://github.com/zoccoler/napari-signal-selector/raw/main/images/annotation.gif)

Annotations are saved back in the table in a new column called 'Annotations'.
*Currently multiple annotations is not possible, i.e., more than one class assigned to the same part of the signal.*

### Span-Selection Tool

You can use the span-selection tool (bounded horizontal arrows icon) to sub-select one or multiple parts of signals. Right-click to unselect regions. Hold 'SHIFT' while dragging the mouse to select multiple sub-regions.

![span-select](https://github.com/zoccoler/napari-signal-selector/raw/main/images/span_select.gif)

You can use this in conjunction with the annotation tool to have sub-regions from the same signal with different annotations.

![](https://github.com/zoccoler/napari-signal-selector/raw/main/images/span_annotation.gif)

### Deletion Tool

If you made a mistake, you can remove previous annotations by selecting signal(s) and clicking on the trash icon at the right of the toolbar (or just annotate them with class 0).

![delete](https://github.com/zoccoler/napari-signal-selector/raw/main/images/delete.gif)

Also, with the selection tool enbaled, by holding 'SHIFT' and left-clicking, you can select all signals. This may be useful to delete all previous annotations.

![select-delete-all](https://github.com/zoccoler/napari-signal-selector/raw/main/images/select_delete_all.gif)

### Exporting Annotations

The table with annotations can be displayed in napari using the 'Show table' widget from [napari-skimage-regionprops plugin](https://github.com/haesleinhuepf/napari-skimage-regionprops#napari-skimage-regionprops-nsr), which is available under `Tools > Measurements > Show Table (nsr)`.

![](https://github.com/zoccoler/napari-signal-selector/raw/main/images/table_view.gif)

By the way, with `'show selected'` checked, you can click on a label row in the table and see the corresponding label in the image **...and** in the plotter!

To export the table, click on `'Save as csv...'`.

## Installation

You can install `napari-signal-selector` via [pip]. Follow these steps from a terminal.

We recommend using `mamba-forge` whenever possible. Click [here](https://github.com/conda-forge/miniforge#mambaforge) to choose the right download option for your OS.
**If you do not use `mamba-forge`, replace the `mamba` term whenever you see it below with `conda`.**

Create a conda environment :

    mamba create -n napari-ss-env napari pyqt python=3.9
    
Activate the environment :

    mamba activate napari-ss-env

Install `napari-signal-selector` via [pip] :

    pip install napari-signal-selector

Alternatively, install latest development version with :

    pip install git+https://github.com/zoccoler/napari-signal-selector.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-signal-selector"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/zoccoler/napari-signal-selector/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/zoccoler/napari-signal-selector/issues', 'Documentation, https://github.com/zoccoler/napari-signal-selector#README.md', 'Source Code, https://github.com/zoccoler/napari-signal-selector', 'User Support, https://github.com/zoccoler/napari-signal-selector/issues']",,,napari-signal-selector.make_inter_features_line_widget,napari-signal-selector.load_flashing_polygons_data,,,,https://pypi.org/project/napari-signal-selector,,
291,napari SIM processor,0.1.1,2022-07-07,2023-11-07,napari-sim-processor,Andrea Bassi and Mark Neil,andrea1.bassi@polimi.it,BSD-3-Clause,https://github.com/andreabassi78/napari-sim-processor,A plugin to process Structured Illumination Microscopy data with gpu acceleration,>=3.8,"['numpy', 'scipy', 'magicgui', 'qtpy', 'matplotlib', 'superqt >=0.3.2', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'"", ""matplotlib ; extra == 'testing'"", ""numpy ; extra == 'testing'"", ""scipy ; extra == 'testing'"", ""superqt ; extra == 'testing'""]","# napari-sim-processor

[![License](https://img.shields.io/pypi/l/napari-sim-processor.svg?color=green)](https://github.com/andreabassi78/napari-sim-processor/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-sim-processor.svg?color=green)](https://pypi.org/project/napari-sim-processor)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-sim-processor.svg?color=green)](https://python.org)
[![tests](https://github.com/andreabassi78/napari-sim-processor/workflows/tests/badge.svg)](https://github.com/andreabassi78/napari-sim-processor/actions)
[![codecov](https://codecov.io/gh/andreabassi78/napari-sim-processor/branch/main/graph/badge.svg)](https://codecov.io/gh/andreabassi78/napari-sim-processor)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-sim-processor)](https://napari-hub.org/plugins/napari-sim-processor)

A Napari plugin for the reconstruction of Structured Illumination Microscopy (SIM) with GPU acceleration (pytorch/cupy if installed).
Currently supports:    
   - conventional SIM data with a generic number of angles and phases (typically, 3 angles and 3 phases are used for resolution improvement in 2D, but any combination can be processed by the widget)
   - hexagonal SIM data with 7 phases, as used in [this] publication.
   - 3D SIM, for resolution enhancement in three dimensions. This is available in the [3dSIM] branch  

The SIM processing widget accepts image stacks organized in 5D (`angle`,`phase`,`z`,`y`,`x`).

The reshape widget can be used to easily reshape the data if they are not organized as 5D (angle,phase,z,y,x).

For 3D stacks (raw images) with multiple z-frames, a batch reconstruction method is available, as described [here].

Syntetic raw-image stacks of Structured Illumination Microscopy can be easily simulated using the napari [SIMulator] pluging.
	 
----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/index.html
-->

## Installation

You can install `napari-sim-processor` via [pip]:

    pip install napari-sim-processor


To install latest development version :

    pip install git+https://github.com/andreabassi78/napari-sim-processor.git


## Usage

1) Open napari. 

2) Launch the reshape and sim-processor widgets.

3) Open your raw image stack (using the napari built-in or your own file opener).

![raw](https://github.com/andreabassi78/napari-sim-processor/raw/main/images/Picture1.png)

4) If your image is ordered as a 5D stack (angle, phase, z-frame, y, x) go to point 6. 

5) In the reshape widget, select the actual number of acquired angles, phases, and frames (red arrow) and press `Reshape Stack`.
 Note that the label axis of the viewer will be updated (green arrow).

![raw](https://github.com/andreabassi78/napari-sim-processor/raw/main/images/Picture1b.png)

6) In the sim-reconstruction widget press the Select image layer button. Note that the number of phases and angles will be updated (blue arrow). 

7) Choose the correct parameters of the SIM acquisition (`NA`, `pixelsize`, `M`, etc.) and processing parameters (`alpha`, `beta`, w, `eta`, `group`):
   - `w`: parameter of the Weiner filter.
   - `eta`: constant used for calibration. It should be slightly smaller than the carrier frequency (in pupil radius units).
   - `group`: for stacks with multiple z-frames, it is the number of frames that are used together for the calibration process.
	
For details on the other parameters see [here].

8) Calibrate the SIM processor, pressing the `Calibrate` button. This will find the carrier frequencies (red circles if the `Show Carrier` checkbox is selected), the modulation amplitude and the phase, using cross correlation analysis.

9) Click on the checkboxes to show the power spectrum of the raw image (`Show power spectrum`) or the cross-correlation (`Show Xcorr`), to see if the found carrier frequency is correct.

![raw](https://github.com/andreabassi78/napari-sim-processor/raw/main/images/Picture2b.png)
**Napari viewer showing the power spectrum of the raw stack. The pupil circle is in blue. A circle corresponding to `eta` is shown in green.**

![raw](https://github.com/andreabassi78/napari-sim-processor/raw/main/images/Picture2.png)
**Napari viewer showing the cross-correlation of the raw stack. The red circles indicate the found carrier frequencies**

10) Run the reconstruction of a single plane (`SIM reconstruction`) or of a stack (`Stack reconstruction`). After execution, a new image_layer will be added to the napari viewer. Click on the `Batch reconstruction` checkbox in order to process an entire stack in one shot. Click on the pytorch checkbox for gpu acceleration.

![raw](https://github.com/andreabassi78/napari-sim-processor/raw/main/images/Picture3b.png)
**Napari viewer with widgets showing a pseudo-widefield reconstruction**

![raw](https://github.com/andreabassi78/napari-sim-processor/raw/main/images/Picture3.png)
**Napari viewer with widgets showing a SIM reconstruction**

## GPU processing

The underlying processing classes will use numpy (and FFTW if available) for 
its calculations. For GPU accelerated processing you need to have either the 
PyTorch (tested with torch v1.11.0+cu113) or the CuPy (tested with cupy-cuda113 
v10.4.0) package installed.  Make sure to match the package cuda version to the CUDA library 
installed on your system otherwise PyTorch will default to CPU and CuPy will not work at all.  

Both packages give significant speedup on even relatively modest CUDA GPUs compared 
to Numpy, and PyTorch running on the CPU only can show improvements relative to numpy 
and FFTW. Selection of which processing package to use is via a ComboBox in the 
napari_sim_processor widget.  Only available packages are shown. 

Other than requiring a CUDA GPU it is advisable to have significant GPU memory 
available, particularly when processing large datasets.  Batch processing is the 
most memory hungry of the methods, but can process 280x512x512 datasets on a 4GB GPU.

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-sim-processor"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/andreabassi78/napari-sim-processor/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/

[here]: https://doi.org/10.1098/rsta.2020.0162
[this]: https://doi.org/10.1364/OE.466225
[3dSIM]: https://github.com/andreabassi78/napari-sim-processor/tree/3dSIM
[SIMulator]: https://www.napari-hub.org/plugins/napari-generic-SIMulator
","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/andreabassi78/napari-sim-processor/issues', 'Documentation, https://github.com/andreabassi78/napari-sim-processor#README.md', 'Source Code, https://github.com/andreabassi78/napari-sim-processor', 'User Support, https://github.com/andreabassi78/napari-sim-processor/issues']",,,napari-sim-processor.make_sim_widget,,,,,https://pypi.org/project/napari-sim-processor,https://github.com/andreabassi78/napari-sim-processor,
292,SimpleAnnotate,0.0.3,2023-11-18,2023-11-18,napari-simpleannotate,Hiroki Kawai,h.kawai888@gmail.com,BSD-3-Clause,https://pypi.org/project/napari-simpleannotate,A simple plugin to label image,>=3.8,"['numpy', 'magicgui', 'pyyaml', 'qtpy', 'scikit-image', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-simpleannotate

[![License BSD-3](https://img.shields.io/pypi/l/napari-simpleannotate.svg?color=green)](https://github.com/hiroalchem/napari-simpleannotate/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-simpleannotate.svg?color=green)](https://pypi.org/project/napari-simpleannotate)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-simpleannotate.svg?color=green)](https://python.org)
[![tests](https://github.com/hiroalchem/napari-simpleannotate/workflows/tests/badge.svg)](https://github.com/hiroalchem/napari-simpleannotate/actions)
[![codecov](https://codecov.io/gh/hiroalchem/napari-simpleannotate/branch/main/graph/badge.svg)](https://codecov.io/gh/hiroalchem/napari-simpleannotate)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-simpleannotate)](https://napari-hub.org/plugins/napari-simpleannotate)

A simple plugin to label image

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

![overview](https://github.com/hiroalchem/napari-simpleannotate/raw/main/images/dog_and_cat.jpg)


## Installation

You can install `napari-simpleannotate` via [pip]:

    pip install napari-simpleannotate



To install latest development version :

    pip install git+https://github.com/hiroalchem/napari-simpleannotate.git


## How to use

1. **Opening Files or Directories**:
   - Click the `Open File` button to open an image file.
   - Click the `Open Directory` button to open a directory containing images.
   - If there's a `class.yaml` in the directory of the selected file or within the selected directory, it will be automatically detected. A popup will appear, giving you the option to load it.

2. **Class Management**:
   - Enter the class name in the textbox and click the `Add class` button to add a class. When adding a class name, a number is automatically assigned to it. This number will be used when saving annotations.
   - Select a class from the class list and click the `Delete selected class` button to remove it.

3. **Annotating Images**:
   - Use napari's rectangle tool to annotate the images. If you have a class selected, the annotation will automatically be assigned to that class.
   - For existing rectangles, you can change their class by selecting the rectangle and then choosing a different class from the list.

4. **Saving Annotations**:
   - Click the `Save Annotations` button to save the annotations in YOLO format.
   - Along with saving the annotations, the `class.yaml` will also be saved. If a `class.yaml` already exists and its content is different from the current one, a popup will appear asking for confirmation to overwrite it.


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-simpleannotate"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/hiroalchem/napari-simpleannotate/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/hiroalchem/napari-simpleannotate/issues', 'Documentation, https://github.com/hiroalchem/napari-simpleannotate#README.md', 'Source Code, https://github.com/hiroalchem/napari-simpleannotate', 'User Support, https://github.com/hiroalchem/napari-simpleannotate/issues']",,,napari-simpleannotate.make_bboxwidget,,,,,https://pypi.org/project/napari-simpleannotate,,
293,napari-simpleitk-image-processing,0.4.5,2022-02-05,2023-06-18,napari-simpleitk-image-processing,Robert Haase,robert.haase@tu-dresden.de,BSD-3-Clause,https://github.com/haesleinhuepf/napari-simpleitk-image-processing,Process and analyze images using SimpleITK in napari,>=3.8,"['napari-plugin-engine (>=0.1.4)', 'numpy', 'simpleitk', 'napari-tools-menu (>=0.1.17)', 'napari-time-slicer', 'napari-skimage-regionprops (>=0.5.1)', 'napari-assistant (>=0.3.10)', 'pandas', 'stackview (>=0.3.2)']","# napari-simpleitk-image-processing (n-SimpleITK)

[![License](https://img.shields.io/pypi/l/napari-simpleitk-image-processing.svg?color=green)](https://github.com/haesleinhuepf/napari-simpleitk-image-processing/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-simpleitk-image-processing.svg?color=green)](https://pypi.org/project/napari-simpleitk-image-processing)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-simpleitk-image-processing.svg?color=green)](https://python.org)
[![tests](https://github.com/haesleinhuepf/napari-simpleitk-image-processing/workflows/tests/badge.svg)](https://github.com/haesleinhuepf/napari-simpleitk-image-processing/actions)
[![codecov](https://codecov.io/gh/haesleinhuepf/napari-simpleitk-image-processing/branch/main/graph/badge.svg)](https://codecov.io/gh/haesleinhuepf/napari-simpleitk-image-processing)
[![Development Status](https://img.shields.io/pypi/status/napari-simpleitk-image-processing.svg)](https://en.wikipedia.org/wiki/Software_release_life_cycle#Alpha)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-simpleitk-image-processing)](https://napari-hub.org/plugins/napari-simpleitk-image-processing)
[![DOI](https://zenodo.org/badge/432729955.svg)](https://zenodo.org/badge/latestdoi/432729955)

Process images using [SimpleITK](https://simpleitk.org/) in [napari]

## Usage

Filters, segmentation algorithms and measurements provided by this napari plugin can be found in the `Tools` menu. 
You can recognize them with their suffix `(n-SimpleITK)` in brackets.
Furthermore, it can be used from the [napari-assistant](https://www.napari-hub.org/plugins/napari-assistant) graphical user interface. 
Therefore, just click the menu `Tools > Utilities > Assistant (na)` or run `naparia` from the command line.

![img.png](https://github.com/haesleinhuepf/napari-simpleitk-image-processing/raw/main/docs/screenshot_with_assistant.png)

All filters implemented in this napari plugin are also demonstrated in [this notebook](https://github.com/haesleinhuepf/napari-simpleitk-image-processing/blob/main/docs/demo.ipynb).

### Gaussian blur

Applies a [Gaussian blur](https://en.wikipedia.org/wiki/Gaussian_blur)
to an image. This might be useful for denoising, e.g. before applying the Threshold-Otsu method.

![img.png](https://github.com/haesleinhuepf/napari-simpleitk-image-processing/raw/main/docs/gaussian_blur.png)

### Median filter

Applies a [median filter](https://en.wikipedia.org/wiki/Median_filter) to an image. 
Compared to the Gaussian blur this method preserves edges in the image better. 
It also performs slower.

![img.png](https://github.com/haesleinhuepf/napari-simpleitk-image-processing/raw/main/docs/median_filter.png)

### Bilateral filter

The [bilateral filter](https://en.wikipedia.org/wiki/Bilateral_filter) allows denoising an image
while preserving edges.

![img.png](https://github.com/haesleinhuepf/napari-simpleitk-image-processing/raw/main/docs/bilateral.png)

### Threshold Otsu

Binarizes an image using [Otsu's method](https://ieeexplore.ieee.org/document/4310076).

![img.png](https://github.com/haesleinhuepf/napari-simpleitk-image-processing/raw/main/docs/threshold_otsu.png)

### Connected Component Labeling

Takes a binary image and labels all objects with individual numbers to produce a label image.

![img.png](https://github.com/haesleinhuepf/napari-simpleitk-image-processing/raw/main/docs/connected_component_labeling.png)

### Measurements

This function allows determining intensity and shape statistics from labeled images. I can be found in the `Tools > Measurement tables` menu.

![img.png](https://github.com/haesleinhuepf/napari-simpleitk-image-processing/raw/main/docs/measurements.png)

### Signed Maurer distance map

A distance map (more precise: [Signed Maurer Distance Map](https://itk.org/ITKExamples/src/Filtering/DistanceMap/MaurerDistanceMapOfBinary/Documentation.html)) can be useful for visualizing distances within binary images between black/white borders. 
Positive values in this image correspond to a white (value=1) pixel's distance to the next black pixel.
Black pixel's (value=0) distance to the next white pixel are represented in this map with negative values.

![img.png](https://github.com/haesleinhuepf/napari-simpleitk-image-processing/raw/main/docs/signed_maured_distance_map.png)

### Binary fill holes

Fills holes in a binary image.

![img.png](https://github.com/haesleinhuepf/napari-simpleitk-image-processing/raw/main/docs/binary_fill_holes.png)

### Touching objects labeling

Starting from a binary image, touching objects can be splits into multiple regions, similar to the [Watershed segmentation in ImageJ](https://imagej.net/plugins/classic-watershed).

![img.png](https://github.com/haesleinhuepf/napari-simpleitk-image-processing/raw/main/docs/Touching_object_labeling.png)

### Morphological Watershed

The [morhological watershed](http://insightsoftwareconsortium.github.io/SimpleITK-Notebooks/Python_html/32_Watersheds_Segmentation.html)
allows to segment images showing membranes. Before segmentation, a filter such as the Gaussian blur or a median filter
should be used to eliminate noise. It also makes sense to increase the thickness of membranes using a maximum filter. 
See [this notebook](https://github.com/clEsperanto/pyclesperanto_prototype/blob/master/demo/segmentation/segmentation_2d_membranes.ipynb) for details.

![img.png](https://github.com/haesleinhuepf/napari-simpleitk-image-processing/raw/main/docs/morphological_watershed.png)

### Watershed-Otsu-Labeling

This algorithm uses [Otsu's thresholding method](https://ieeexplore.ieee.org/document/4310076) in combination with 
[Gaussian blur](https://en.wikipedia.org/wiki/Gaussian_blur) and the 
[Watershed-algorithm](https://en.wikipedia.org/wiki/Watershed_(image_processing)) 
approach to label bright objects such as nuclei in an intensity image. The alogrithm has two sigma parameters and a 
level parameter which allow you to fine-tune where objects should be cut (`spot_sigma`) and how smooth outlines 
should be (`outline_sigma`). The `watershed_level` parameter determines how deep an intensity valley between two maxima 
has to be to differentiate the two maxima. 
This implementation is similar to [Voronoi-Otsu-Labeling in clesperanto](https://github.com/clEsperanto/pyclesperanto_prototype/blob/master/demo/segmentation/voronoi_otsu_labeling.ipynb).


![img.png](https://github.com/haesleinhuepf/napari-simpleitk-image-processing/raw/main/docs/watershed_otsu_labeling.png)

### Richardson-Lucy Deconvolution

[Richardson-Lucy deconvolution](https://en.wikipedia.org/wiki/Richardson%E2%80%93Lucy_deconvolution)
allows to restore image quality if the point-spread-function of the optical system used 
for acquisition is known or can be approximated.

![img.png](https://github.com/haesleinhuepf/napari-simpleitk-image-processing/raw/main/docs/Richardson-Lucy-Deconvolution.png)


## Installation

You can install `napari-simpleitk-image-processing` via using `conda` and `pip`.
If you have never used `conda` before, please go through [this tutorial](https://biapol.github.io/blog/johannes_mueller/anaconda_getting_started/) first.

    conda install -c conda-forge napari
    pip install napari-simpleitk-image-processing

## See also

There are other napari plugins with similar functionality for processing images and extracting features:
* [morphometrics](https://www.napari-hub.org/plugins/morphometrics)
* [PartSeg](https://www.napari-hub.org/plugins/PartSeg)
* [napari-skimage-regionprops](https://www.napari-hub.org/plugins/napari-skimage-regionprops)
* [napari-cupy-image-processing](https://www.napari-hub.org/plugins/napari-cupy-image-processing)
* [napari-pyclesperanto-assistant](https://www.napari-hub.org/plugins/napari-pyclesperanto-assistant)
* [napari-allencell-segmenter](https://napari-hub.org/plugins/napari-allencell-segmenter)
* [RedLionfish](https://www.napari-hub.org/plugins/RedLionfish)
* [bbii-decon](https://www.napari-hub.org/plugins/bbii-decon)  
* [napari-segment-blobs-and-things-with-membranes](https://www.napari-hub.org/plugins/napari-segment-blobs-and-things-with-membranes)

Furthermore, there are plugins for postprocessing extracted measurements
* [napari-feature-classifier](https://www.napari-hub.org/plugins/napari-feature-classifier)
* [napari-clusters-plotter](https://www.napari-hub.org/plugins/napari-clusters-plotter)

## Contributing

Contributions are very welcome. There are many useful algorithms available in 
[SimpleITK](https://simpleitk.org/). If you want another one available here in this napari
plugin, don't hesitate to send a [pull-request](https://github.com/haesleinhuepf/napari-simpleitk-image-processing/pulls).
This repository just holds wrappers for SimpleITK-functions, see [this file](https://github.com/haesleinhuepf/napari-simpleitk-image-processing/raw/main/src/napari_simpleitk_image_processing/_simpleitk_image_processing.py#L51) for how those wrappers
can be written.

## License

Distributed under the terms of the [BSD-3] license,
""napari-simpleitk-image-processing"" is free and open source software

## Citation

For implementing this napari plugin, the 
[SimpleITK python notebooks](https://insightsoftwareconsortium.github.io/SimpleITK-Notebooks/) were very helpful. 
Thus, if you find the plugin useful, consider citing the SimpleITK notebooks:

Z. Yaniv, B. C. Lowekamp, H. J. Johnson, R. Beare, 
""SimpleITK Image-Analysis Notebooks: a Collaborative Environment for Education and Reproducible Research"", \
J Digit Imaging., 31(3): 290-303, 2018, [https://doi.org/10.1007/s10278-017-0037-8](https://doi.org/10.1007/s10278-017-0037-8).

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/haesleinhuepf/napari-simpleitk-image-processing/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 3 - Alpha', 'Intended Audience :: Science/Research', 'Framework :: napari', 'Topic :: Scientific/Engineering :: Image Processing', 'Topic :: Scientific/Engineering :: Information Analysis', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/haesleinhuepf/napari-simpleitk-image-processing/issues', 'Documentation, https://github.com/haesleinhuepf/napari-simpleitk-image-processing#README.md', 'Source Code, https://github.com/haesleinhuepf/napari-simpleitk-image-processing', 'User Support, https://github.com/haesleinhuepf/napari-simpleitk-image-processing/issues']",,,napari-simpleitk-image-processing.napari_experimental_provide_function,,,,,https://pypi.org/project/napari-simpleitk-image-processing,https://github.com/haesleinhuepf/napari-simpleitk-image-processing,
294,Sketchpose,0.1.8,,,napari-sketchpose,Clément Cazorla,clement.cazorla31@gmail.com,GPL-3.0-only,,A segmentation plugin to adapt Omnipose implementation to partial labelling.,>=3.8,"['numpy', 'magicgui', 'qtpy', 'cellpose-omni ==0.9.1', 'omnipose ==0.4.4', 'pyqtgraph ==0.13.3', 'matplotlib', 'light-the-torch', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-sketchpose

[![License GNU GPL v3.0](https://img.shields.io/pypi/l/napari-sketchpose.svg?color=green)](https://github.com/koopa31/napari-sketchpose/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-sketchpose.svg?color=green)](https://pypi.org/project/napari-sketchpose)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-sketchpose.svg?color=green)](https://python.org)
[![tests](https://github.com/koopa31/napari-sketchpose/workflows/tests/badge.svg)](https://github.com/koopa31/napari-sketchpose/actions)
[![codecov](https://codecov.io/gh/koopa31/napari-sketchpose/branch/main/graph/badge.svg)](https://codecov.io/gh/koopa31/napari-sketchpose)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-sketchpose)](https://napari-hub.org/plugins/napari-sketchpose)

A plugin to adapt the Omnipose implementation to frugal labeling. It aims to facilitate the training from scratch or the 
use of transfer learning with little data, by not needing to draw entire cells, but a few squiggles instead (see GIF below).


If you use this plugin please cite the [paper](https://hal.science/hal-04330824): 

Clément Cazorla, Nathanaël Munier, Renaud Morin, Pierre Weiss. Sketchpose: Learning to Segment
Cells with Partial Annotations. 2023. ffhal-04330824f

```bibtex
@unpublished{cazorla:hal-04330824,
      TITLE = {{Sketchpose: Learning to Segment Cells with Partial Annotations}},
      AUTHOR = {Cazorla, Cl{\'e}ment and Munier, Nathana{\""e}l and Morin, Renaud and Weiss, Pierre},
      URL = {https://hal.science/hal-04330824},
      NOTE = {working paper or preprint},
      YEAR = {2023},
      MONTH = Dec,
      KEYWORDS = {Cellpose -Segmentation -Frugal learning -Napari -Deep learning -Distance map},
      PDF = {https://hal.science/hal-04330824/file/sketchpose_hal.pdf},
      HAL_ID = {hal-04330824},
      HAL_VERSION = {v1},
    }

```


![](https://bitbucket.org/koopa31/napari-sketchpose/raw/b691817e9e20a3c1c2bc69277579f6fb9b26354e/images/frugalpose.gif)
Image Credit: Eduard Muzhevskyi
----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation



First, we advise you to create a conda environment in Python 3.10, in which you will run Napari:

    conda create -n sketchpose_env python=3.10
    conda activate sketchpose_env
    conda install pip
    python -m pip install ""napari[all]"" --upgrade

You can install `napari_sketchpose` via [pip]:

    pip install napari_sketchpose

WARNING:

For Windows users, CUDA version of PyTorch may not be installed properly. When the plugin starts for the first time, it checks whether
CUDA version is installed. If not, it tries to install it using light-the-torch library. If this does not work, you should re-install 
CUDA torch and torchvision versions manually, otherwise the plugin will not work properly.

## Tutorial

We strongly recommend reading the [documentation] to get the most out of the plugin.
A step-by-step tutorial illustrated with GIFs will guide you through the various stages.

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [GNU GPL v3.0] license,
""napari-sketchpose"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
[documentation]: https://sketchpose-doc.readthedocs.io/en/latest/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: GNU General Public License v3 (GPLv3)', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://bitbucket.org/koopa31/napari-sketchpose/issues?status=new&status=open&status=submitted&is_spam=!spam', 'Documentation, https://sketchpose-doc.readthedocs.io/en/latest/', 'Source Code, https://bitbucket.org/koopa31/napari-sketchpose/src/master', 'User Support, https://bitbucket.org/koopa31/napari-sketchpose/issues?status=new&status=open&status=submitted&is_spam=!spam']",napari-sketchpose.get_reader,napari-sketchpose.write_multiple,napari-sketchpose.make_qwidget,napari-sketchpose.make_sample_data,['*.npy'],,['.npy'],https://pypi.org/project/napari-sketchpose,,
295,napari-skimage-regionprops,0.10.1,2022-02-02,2023-06-18,napari-skimage-regionprops,"Marcelo Zoccoler, Robert Haase",robert.haase@tu-dresden.de,BSD-3,https://github.com/haesleinhuepf/napari-skimage-regionprops,A regionprops table widget plugin for napari,>=3.8,"['napari-plugin-engine (>=0.1.4)', 'numpy', 'scikit-image', 'napari', 'pandas', 'napari-tools-menu (>=0.1.19)', 'napari-workflows', 'imageio (!=2.22.1)', 'Deprecated']","# napari-skimage-regionprops (nsr)



[![License](https://img.shields.io/pypi/l/napari-skimage-regionprops.svg?color=green)](https://github.com/haesleinhuepf/napari-skimage-regionprops/raw/master/LICENSE)

[![PyPI](https://img.shields.io/pypi/v/napari-skimage-regionprops.svg?color=green)](https://pypi.org/project/napari-skimage-regionprops)

[![Python Version](https://img.shields.io/pypi/pyversions/napari-skimage-regionprops.svg?color=green)](https://python.org)

[![tests](https://github.com/haesleinhuepf/napari-skimage-regionprops/workflows/tests/badge.svg)](https://github.com/haesleinhuepf/napari-skimage-regionprops/actions)

[![codecov](https://codecov.io/gh/haesleinhuepf/napari-skimage-regionprops/branch/master/graph/badge.svg)](https://codecov.io/gh/haesleinhuepf/napari-skimage-regionprops)

[![Development Status](https://img.shields.io/pypi/status/napari-skimage-regionprops.svg)](https://en.wikipedia.org/wiki/Software_release_life_cycle#Alpha)

[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-skimage-regionprops)](https://napari-hub.org/plugins/napari-skimage-regionprops)



 

A [napari] plugin for measuring properties of labeled objects based on [scikit-image]



![](https://github.com/haesleinhuepf/napari-skimage-regionprops/raw/master/images/interactive.gif)



## Usage: measure region properties



From the menu `Tools > Measurement > Regionprops (nsr)` you can open a dialog where you can choose an intensity image, a corresponding label image and the features you want to measure:



![img.png](https://github.com/haesleinhuepf/napari-skimage-regionprops/raw/master/images/dialog.png)



If you want to interface with the labels and see which table row corresponds to which labeled object, use the label picker and

activate the `show selected` checkbox.



![](https://github.com/haesleinhuepf/napari-skimage-regionprops/raw/master/images/interactive.png)



If you closed a table and want to reopen it, you can use the menu `Tools > Measurements > Show table (nsr)` to reopen it. 

You just need to select the labels layer the properties are associated with.



For visualizing measurements with different grey values, as parametric images, you can double-click table headers.



![img.png](https://github.com/haesleinhuepf/napari-skimage-regionprops/raw/master/images/label_value_visualization.gif)



## Usage: measure point intensities



Analogously, also the intensity and coordinates of point layers can be measured using the menu `Tools > Measurement > Measure intensity at point coordinates (nsr)`. 

Also these measurements can be visualized by double-clicking table headers:



![img.png](measure_point_intensity.png)



![img_1.png](measure_point_coordinate.png)



## Working with time-lapse and tracking data



Note that tables for time-lapse data should include a column named ""frame"", which indicates which slice in

time the given row refers to. If you want to import your own csv files for time-lapse data make sure to include this column.

If you have tracking data where each column specifies measurements for a track instead of a label at a specific time point,

this column must not be added.



In case you have 2D time-lapse data you need to convert it into a suitable shape using the function: `Tools > Utilities > Convert 3D stack to 2D time-lapse (time-slicer)`,

which can be found in the [napari time slicer](https://www.napari-hub.org/plugins/napari-time-slicer).



Last but not least, make sure that in case of time-lapse data the label image has labels that are subsquently labeled per timepoint.

E.g. a dataset where label 5 is missing at timepoint 4 may be visualized incorrectly.



## Usage: multichannel or multi-label data



If you want to relate objects from one channels to objects from another channel, you can use `Tools > Measurement tables > Object Features/Properties (scikit-image, nsr)`. 

This plugin module allos you to answer questions like:

  - how many objects I have inside other objects?

  - what is the average intensity of the objects inside other objects?

For that, you need at least two labeled images in napari. You can relate objects along with their features. 

If intensity features are also wanted, then you also need to provide two intensity images. 

Below, there is a small example on how to use it. 

Also, take a look at [this example notebook](https://github.com/haesleinhuepf/napari-skimage-regionprops/blob/master/demo/measure_relationship_to_other_channels_plugin.ipynb).

 

 ![](https://github.com/haesleinhuepf/napari-skimage-regionprops/raw/master/images/things_inside_things_demo.gif)



## Usage, programmatically



You can also control the tables programmatically. See this 

[example notebook](https://github.com/haesleinhuepf/napari-skimage-regionprops/blob/master/demo/tables.ipynb) for details on regionprops and

[this example notebook](https://github.com/haesleinhuepf/napari-skimage-regionprops/blob/master/demo/measure_points.ipynb) for details on measuring intensity at point coordinates. For creating parametric map images, see [this notebook](https://github.com/haesleinhuepf/napari-skimage-regionprops/blob/master/demo/map_measurements.ipynb).





## Features

The user can select categories of features for feature extraction in the user interface. These categories contain measurements from the scikit-image [regionprops list of measurements](https://scikit-image.org/docs/dev/api/skimage.measure.html#skimage.measure.regionprops) library:

* size:

  * area

  * bbox_area

  * convex_area

  * equivalent_diameter

* intensity:

  * max_intensity 

  * mean_intensity

  * min_intensity

  * standard_deviation_intensity (`extra_properties` implementation using numpy)

* perimeter:

  * perimeter

  * perimeter_crofton

* shape

  * major_axis_length

  * minor_axis_length

  * orientation

  * solidity

  * eccentricity

  * extent

  * feret_diameter_max

  * local_centroid

  * roundness as defined for 2D labels [by ImageJ](https://imagej.nih.gov/ij/docs/menus/analyze.html#set)

  * circularity as defined for 2D labels  [by ImageJ](https://imagej.nih.gov/ij/docs/menus/analyze.html#set)

  * aspect_ratio as defined for 2D labels [by ImageJ](https://imagej.nih.gov/ij/docs/menus/analyze.html#set)

* position:

  * centroid

  * bbox

  * weighted_centroid

* moments:

  * moments

  * moments_central

  * moments_hu

  * moments_normalized



 



This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.



## See also



There are other napari plugins with similar functionality for extracting features:

* [morphometrics](https://www.napari-hub.org/plugins/morphometrics)

* [PartSeg](https://www.napari-hub.org/plugins/PartSeg)

* [napari-simpleitk-image-processing](https://www.napari-hub.org/plugins/napari-simpleitk-image-processing)

* [napari-cupy-image-processing](https://www.napari-hub.org/plugins/napari-cupy-image-processing)

* [napari-pyclesperanto-assistant](https://www.napari-hub.org/plugins/napari-pyclesperanto-assistant)



Furthermore, there are plugins for postprocessing extracted measurements

* [napari-feature-classifier](https://www.napari-hub.org/plugins/napari-feature-classifier)

* [napari-clusters-plotter](https://www.napari-hub.org/plugins/napari-clusters-plotter)

* [napari-accelerated-pixel-and-object-classification](https://www.napari-hub.org/plugins/napari-accelerated-pixel-and-object-classification)



## Installation



You can install `napari-skimage-regionprops` via [pip]:



    pip install napari-skimage-regionprops



Or if you plan to develop it:



    git clone https://github.com/haesleinhuepf/napari-skimage-regionprops

    cd napari-skimage-regionprops

    pip install -e .



If there is an error message suggesting that git is not installed, run `conda install git`.



## Contributing



Contributions are very welcome. Tests can be run with [tox], please ensure

the coverage at least stays the same before you submit a pull request.



## License



Distributed under the terms of the [BSD-3] license,

""napari-skimage-regionprops"" is free and open source software



## Issues



If you encounter any problems, please create a thread on [image.sc] along with a detailed description and tag [@haesleinhuepf].



[napari]: https://github.com/napari/napari

[Cookiecutter]: https://github.com/audreyr/cookiecutter

[@napari]: https://github.com/napari

[BSD-3]: http://opensource.org/licenses/BSD-3-Clause

[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[image.sc]: https://image.sc

[napari]: https://github.com/napari/napari

[tox]: https://tox.readthedocs.io/en/latest/

[pip]: https://pypi.org/project/pip/

[PyPI]: https://pypi.org/

[scikit-image]: https://scikit-image.org/

[@haesleinhuepf]: https://twitter.com/haesleinhuepf

","['Development Status :: 4 - Beta', 'Intended Audience :: Science/Research', 'Framework :: napari', 'Topic :: Scientific/Engineering :: Image Processing', 'Topic :: Scientific/Engineering :: Information Analysis', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']",,,,napari-skimage-regionprops.napari_experimental_provide_function,,,,,https://pypi.org/project/napari-skimage-regionprops,https://github.com/haesleinhuepf/napari-skimage-regionprops,
296,BP04 Practical,0.0.9,,,napari-SMLMLAB,Piers Turner,piers.turner@physics.ox.ac.uk,BSD-3-Clause,,Napari widget for BP04 Practical,>=3.9,"['napari[all]', 'numpy', 'magicgui', 'qtpy', 'scipy', 'pyqtgraph', 'picassosr', 'matplotlib', 'tqdm', 'pyqt5-tools', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-SMLMLAB

[![License BSD-3](https://img.shields.io/pypi/l/napari-SMLMLAB.svg?color=green)](https://github.com/piedrro/napari-SMLMLAB/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-SMLMLAB.svg?color=green)](https://pypi.org/project/napari-SMLMLAB)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-SMLMLAB.svg?color=green)](https://python.org)
[![tests](https://github.com/piedrro/napari-SMLMLAB/workflows/tests/badge.svg)](https://github.com/piedrro/napari-SMLMLAB/actions)
[![codecov](https://codecov.io/gh/piedrro/napari-SMLMLAB/branch/main/graph/badge.svg)](https://codecov.io/gh/piedrro/napari-SMLMLAB)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-SMLMLAB)](https://napari-hub.org/plugins/napari-SMLMLAB)

Napari widget for BP04 Practical

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-SMLMLAB` via [pip]:

    pip install napari-SMLMLAB

To install latest development version :

    conda create –-name napari-SMLMLAB python==3.9
    conda activate napari-SMLMLAB
    conda install -c anaconda git
    conda update --all

    pip install napari[all]

    pip install git+https://github.com/piedrro/napari-SMLMLAB.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-SMLMLAB"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/piedrro/napari-SMLMLAB/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/piedrro/napari-SMLMLAB/issues', 'Documentation, https://github.com/piedrro/napari-SMLMLAB#README.md', 'Source Code, https://github.com/piedrro/napari-SMLMLAB', 'User Support, https://github.com/piedrro/napari-SMLMLAB/issues']",,,napari-SMLMLAB.make_qwidget,,,,,https://pypi.org/project/napari-SMLMLAB,,
297,Napari Solarized,0.1.1,2023-03-30,2023-06-18,napari-solarized,Ashley Anderson,aandersoniii@chanzuckerberg.com,MIT,https://github.com/aganders3/napari-solarized,Solarized themes for napari,>=3.8,"[""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""npe2 ; extra == 'testing'"", ""typer ; extra == 'testing'"", ""importlib-resources ; extra == 'testing'""]","# napari-solarized

Solarized (-ish) themes for napari, based on [solarized](https://ethanschoonover.com/solarized/).

![solarized dark screenshot](https://raw.githubusercontent.com/aganders3/napari-solarized/main/screenshot_dark.png)
![solarized light screenshot](https://raw.githubusercontent.com/aganders3/napari-solarized/main/screenshot_light.png)

[![License MIT](https://img.shields.io/pypi/l/napari-solarized.svg?color=green)](https://github.com/aganders3/napari-solarized/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-solarized.svg?color=green)](https://pypi.org/project/napari-solarized)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-solarized.svg?color=green)](https://python.org)
[![tests](https://github.com/aganders3/napari-solarized/workflows/tests/badge.svg)](https://github.com/aganders3/napari-solarized/actions)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-solarized)](https://napari-hub.org/plugins/napari-solarized)

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

## Installation

You can install `napari-solarized` via [pip]:

    pip install napari-solarized



To install latest development version :

    pip install git+https://github.com/aganders3/napari-solarized.git


## Contributing

Contributions are very welcome.

## License

Distributed under the terms of the [MIT] license,
""napari-solarized"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/aganders3/napari-solarized/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: Mozilla Public License 2.0 (MPL 2.0)', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/aganders3/napari-solarized/issues', 'Documentation, https://github.com/aganders3/napari-solarized#README.md', 'Source Code, https://github.com/aganders3/napari-solarized', 'User Support, https://github.com/aganders3/napari-solarized/issues']",,,,,,,,https://pypi.org/project/napari-solarized,https://github.com/aganders3/napari-solarized,
298,napari-spacetx-explorer,0.1.8,2022-02-10,2023-06-18,napari-spacetx-explorer,Sebastian Gonzalez-Tirado,sebastian.gonzalez@embl.de,BSD-3,https://github.com/sebgoti/napari-spacetx-explorer,visualizer for spatial omic data,>=3.7,"['napari', 'napari-plugin-engine (>=0.1.4)', 'numpy', 'pandas']","# napari-spacetx-explorer

[![License](https://img.shields.io/pypi/l/napari-spacetx-explorer.svg?color=green)](https://github.com/sebgoti/napari-spacetx-explorer/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-spacetx-explorer.svg?color=green)](https://pypi.org/project/napari-spacetx-explorer)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-spacetx-explorer.svg?color=green)](https://python.org)
[![tests](https://github.com/sebgoti/napari-spacetx-explorer/workflows/tests/badge.svg)](https://github.com/sebgoti/napari-spacetx-explorer/actions)
[![codecov](https://codecov.io/gh/sebgoti/napari-spacetx-explorer/branch/master/graph/badge.svg)](https://codecov.io/gh/sebgoti/napari-spacetx-explorer)

A napari plugin for interactive visualization of decoded spots from spatial transcriptomic data stored as CSV

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.

The plugin code was written by Sebastian Gonzalez-Tirado.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/docs/plugins/index.html
-->
## Reader hookspec

`napari-spacetx-explorer` allows the user to open and visualize CSV files that
have point-data stored in a given format. The main target is for users who
want to analyze decoded spot maps from spatial omics experiments but it can
used as well for any other type of coordinate data where each point has assigned
a label (e. g. a gene) as a string and the x and y-coordinates of the point's center.
The header for these data must be 'target', 'xc', and 'yc', respectively.

![img.png](https://github.com/sebgoti/napari-spacetx-explorer/raw/main/docs/Read_Hookspec.png)

## Selecting genes

After loading the gene/target maps it is possible to select specific groups for better visualization.
This creates a new ""Points"" layer in napari with the selected groups displayed in different colors.

![img.png](https://github.com/sebgoti/napari-spacetx-explorer/raw/main/docs/_function_hookspec.png)

## Loading data in OME.ZARR format

The plugin napari-ome-zarr can be used to display whole-tissue images in addition to the spot maps produced with the 
`napari-spacetx-explorer` plugin.

![img.png](https://github.com/sebgoti/napari-spacetx-explorer/raw/main/docs/_ome_zarr_napari_spacetx_explorer.png)

## Installation

The easiest installation is via the ""Install/Uninstall Plugins..."" under the Plugins menu in napari.  
Another way is through [pip] 

    pip install napari-spacetx-explorer

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-spacetx-explorer"" is free and open source software

## Issues

If you encounter any problems or would like some support, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/sebgoti/napari-spacetx-explorer/issues
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/


","['Development Status :: 3 - Alpha', 'Intended Audience :: Science/Research', 'Framework :: napari', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/sebgoti/napari-spacetx-explorer/issues', 'Documentation, https://github.com/sebgoti/napari-spacetx-explorer#README.md', 'Source Code, https://github.com/sebgoti/napari-spacetx-explorer', 'User Support, https://github.com/sebgoti/napari-spacetx-explorer/issues']",napari-spacetx-explorer.napari_get_reader,,napari-spacetx-explorer.napari_experimental_provide_function,,['*'],,,https://pypi.org/project/napari-spacetx-explorer,https://github.com/sebgoti/napari-spacetx-explorer,
299,napari-spatial-omics,0.0.8,2022-02-13,2023-06-18,napari-spatial-omics,Sebastian Gonzalez-Tirado,sebgoti8@gmail.com,BSD-3-Clause,https://github.com/sebgoti/napari-spatial-omics,A simple plugin to visualize spatial omic data stored in CSV format,>=3.7,"['napari-plugin-engine (>=0.1.4)', 'numpy', 'pandas']","# napari-spatial-omics

[![License](https://img.shields.io/pypi/l/napari-spatial-omics.svg?color=green)](https://github.com/sebgoti/napari-spatial-omics/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-spatial-omics.svg?color=green)](https://pypi.org/project/napari-spatial-omics)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-spatial-omics.svg?color=green)](https://python.org)
[![tests](https://github.com/sebgoti/napari-spatial-omics/workflows/tests/badge.svg)](https://github.com/sebgoti/napari-spatial-omics/actions)
[![codecov](https://codecov.io/gh/sebgoti/napari-spatial-omics/branch/main/graph/badge.svg)](https://codecov.io/gh/sebgoti/napari-spatial-omics)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-spatial-omics)](https://napari-hub.org/plugins/napari-spatial-omics)

A simple plugin to visualize spatial omic data stored in CSV format

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/stable/index.html
-->

## Installation

You can install `napari-spatial-omics` via [pip]:

    pip install napari-spatial-omics



To install latest development version :

    pip install git+https://github.com/sebgoti/napari-spatial-omics.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-spatial-omics"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/sebgoti/napari-spatial-omics/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/


","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/sebgoti/napari-spatial-omics/issues', 'Documentation, https://github.com/sebgoti/napari-spatial-omics#README.md', 'Source Code, https://github.com/sebgoti/napari-spatial-omics', 'User Support, https://github.com/sebgoti/napari-spatial-omics/issues']",napari-spatial-omics.napari_get_reader,,napari-spatial-omics.example_magic_widget,,['*'],,,https://pypi.org/project/napari-spatial-omics,https://github.com/sebgoti/napari-spatial-omics,
300,napari spatialdata,0.4.1,2022-08-18,2023-11-23,napari-spatialdata,giovanni palla,giov.pll@gmail.com,BSD-3-Clause,https://github.com/scverse/napari-spatialdata.git,Interactive visualization of spatial omics data with napari,>=3.9,"['anndata', 'click', 'cycler', 'dask', 'geopandas', 'loguru', 'matplotlib', 'napari >=0.4.19', 'napari-matplotlib', 'numba', 'numpy', 'packaging', 'pandas', 'pillow', 'qtpy', 'scanpy', 'scipy', 'shapely', 'scikit-learn', 'spatialdata >=0.0.15', 'superqt', 'typing-extensions >=4.8.0', 'vispy', 'xarray', ""PyQt5 ; extra == 'all'"", ""sphinx >=4.5 ; extra == 'doc'"", ""sphinx-book-theme >=1.0.0 ; extra == 'doc'"", ""myst-parser ; extra == 'doc'"", ""sphinxcontrib-bibtex >=1.0.0 ; extra == 'doc'"", ""sphinx-autodoc-typehints >=1.11.0 ; extra == 'doc'"", ""sphinx-autobuild ; extra == 'doc'"", ""scanpydoc ; extra == 'doc'"", ""ipykernel ; extra == 'doc'"", ""ipython ; extra == 'doc'"", ""sphinx-copybutton ; extra == 'doc'"", ""sphinx-qt-documentation ; extra == 'doc'"", ""myst-nb ; extra == 'doc'"", ""squidpy ; extra == 'doc'"", ""spatialdata >=0.1.0-pre0 ; extra == 'pre'"", ""pydantic <2 ; extra == 'readthedocs'"", ""loguru ; extra == 'test'"", ""pytest ; extra == 'test'"", ""pytest-cov ; extra == 'test'"", ""pytest-qt ; extra == 'test'"", ""pre-commit >=2.9.0 ; extra == 'test'""]","![SpatialData banner](https://github.com/scverse/spatialdata/blob/main/docs/_static/img/spatialdata_horizontal.png?raw=true)

# napari-spatialdata: interactive exploration and annotation of spatial omics data

[![License](https://img.shields.io/pypi/l/napari-spatialdata.svg?color=green)](https://github.com/scverse/napari-spatialdata/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-spatialdata.svg?color=green)](https://pypi.org/project/napari-spatialdata)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-spatialdata.svg?color=green)](https://python.org)
[![tests](https://github.com/scverse/napari-spatialdata/workflows/tests/badge.svg)](https://github.com/scverse/napari-spatialdata/actions)
[![codecov](https://codecov.io/gh/scverse/napari-spatialdata/branch/main/graph/badge.svg?token=ASqlOKnOj7)](https://codecov.io/gh/scverse/napari-spatialdata)
[![pre-commit.ci status](https://results.pre-commit.ci/badge/github/scverse/napari-spatialdata/main.svg)](https://results.pre-commit.ci/latest/github/scverse/napari-spatialdata/main)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-spatialdata)](https://napari-hub.org/plugins/napari-spatialdata)
[![DOI](https://zenodo.org/badge/477021400.svg)](https://zenodo.org/badge/latestdoi/477021400)

This repository contains a napari plugin for interactively exploring and annotating SpatialData objects. `napari-spatialdata` is part of the `SpatialData` ecosystem. To learn more about SpatialData, please see the [documentation](https://spatialdata.scverse.org/).

## Installation

You can install `napari-spatialdata` via [pip]:

    pip install napari-spatialdata[extra]

The `extra` command will install the qt bindings `PyQt5`.

Note: if you have an M1/M2 Mac then you may get an error when installing `PyQt5` via `pip`. A solution is to first install `napari` via conda (which will correctly install `PyQt5`), using

```
mamba install -c conda-forge napari pyqt
```

and then install `napari-spatialdata` via `pip`, but without the `extra` option:

```
pip install napari-spatialdata
```

You can find more details on this in the [installation instructions](https://spatialdata.scverse.org/en/latest/installation.html).

## Using napari-spatialdata as default zarr reader

If you would like to use the plugin as the default zarr reader, in napari please go to `File` -> `Preferences`
-> `Plugins` and follow the instructions under `File extension readers`.

## Development Version

You can install `napari-spatialdata` from Github with:

    pip install git+https://github.com/scverse/napari-spatialdata

Or, you can also install in editable mode after cloning the repo by:

    git clone https://github.com/scverse/napari-spatialdata
    cd napari-spatialdata
    pip install -e .

Note: when performing an editable install of `napari-spatialdata`, `spatialdata` will be reinstalled from `pip`. So, if you previously also made an editable install of `spatialdata`, you need to re-run `pip install -e .` on the `spatialdata` repository. Please find more details on this in the [installation instructions](https://spatialdata.scverse.org/en/latest/installation.html).

## Getting started

To learn how to use the `napari-spatialdata` plugin, please see the [documentation](https://spatialdata.scverse.org/projects/napari/en/latest/notebooks/spatialdata.html). To learn how to integrate napari-spatialdata into your analysis workflows, please see the [SpatialData tutorials](https://spatialdata.scverse.org/en/latest/tutorials/notebooks/notebooks.html). In particular:

- [Annotating regions of interest with napari](https://spatialdata.scverse.org/en/latest/tutorials/notebooks/notebooks/examples/napari_rois.html)
- [Use landmark annotations to align multiple -omics layers](https://spatialdata.scverse.org/en/latest/tutorials/notebooks/notebooks/examples/alignment_using_landmarks.html)

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-spatialdata"" is free and open source software

## Issues

If you encounter any problems, please file an [issue] along with a detailed description.

## Citation

Marconato, L., Palla, G., Yamauchi, K.A. et al. SpatialData: an open and universal data framework for spatial omics. Nat Methods (2024). https://doi.org/10.1038/s41592-024-02212-x

[napari]: https://github.com/napari/napari
[cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[mit]: http://opensource.org/licenses/MIT
[bsd-3]: http://opensource.org/licenses/BSD-3-Clause
[gnu gpl v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[gnu lgpl v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[apache software license 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[mozilla public license 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[pypi]: https://pypi.org/
[issue]: https://github.com/scverse/napari-spatialdata/issues
","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/scverse/napari-spatialdata/issues', 'Documentation, https://github.com/scverse/napari-spatialdata#README.md', 'Source Code, https://github.com/scverse/napari-spatialdata', 'User Support, https://github.com/scverse/napari-spatialdata/issues']",napari-spatialdata.get_reader,,napari-spatialdata.QtAdataScatterWidget,,['*.zarr'],,,https://pypi.org/project/napari-spatialdata,https://github.com/scverse/napari-spatialdata.git,
301,SplineDist,0.3.1,2023-11-18,2023-11-18,napari-splinedist,Dr. Thorsten Beier,derthorstebeier@gmail.com,MIT,https://pypi.org/project/napari-splinedist,A napari SplineDist plugin,>=3.8,"['pydantic', 'numpy', 'magicgui', 'qtpy', 'stardist (>=0.8.3)', 'splinedist (>=0.1.2)', 'napari-splineit (>=0.3.0)', 'requests', 'tensorflow', 'opencv-python-headless', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-splinedist

[![License MIT](https://img.shields.io/pypi/l/napari-splinedist.svg?color=green)](https://github.com/DerThorsten/napari-splinedist/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-splinedist.svg?color=green)](https://pypi.org/project/napari-splinedist)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-splinedist.svg?color=green)](https://python.org)
[![tests](https://github.com/DerThorsten/napari-splinedist/workflows/tests/badge.svg)](https://github.com/DerThorsten/napari-splinedist/actions)
[![codecov](https://codecov.io/gh/DerThorsten/napari-splinedist/branch/main/graph/badge.svg)](https://codecov.io/gh/DerThorsten/napari-splinedist)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-splinedist)](https://napari-hub.org/plugins/napari-splinedist)

A napari SplineDist plugin

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-splinedist` via [pip]:

    pip install napari-splinedist



To install latest development version :

    pip install git+https://github.com/DerThorsten/napari-splinedist.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [MIT] license,
""napari-splinedist"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/DerThorsten/napari-splinedist/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: MIT License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/DerThorsten/napari-splinedist/issues', 'Documentation, https://github.com/DerThorsten/napari-splinedist#README.md', 'Source Code, https://github.com/DerThorsten/napari-splinedist', 'User Support, https://github.com/DerThorsten/napari-splinedist/issues']",,,napari-splinedist.make_qwidget,napari-splinedist.sample_data_bbbc038,,,,https://pypi.org/project/napari-splinedist,,
302,Napari SplineIt2,0.3.0,2022-07-11,2023-06-18,napari-splineit,Thorsten Beier,derthorstenbeier@gmail.com,BSD-3-Clause,https://github.com/uhlmanngroup/napari-splineit,A napari plugin for spline manipulation,>=3.7,"['numpy', 'qtpy', 'scikit-image', 'scipy', ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""tox ; extra == 'testing'""]","# napari-splineit

[![License](https://img.shields.io/pypi/l/napari-splineit.svg?color=green)](https://github.com/uhlmanngroup/napari-splineit/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-splineit.svg?color=green)](https://pypi.org/project/napari-splineit)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-splineit.svg?color=green)](https://python.org)
[![tests](https://github.com/uhlmanngroup/napari-splineit/workflows/tests/badge.svg)](https://github.com/uhlmanngroup/napari-splineit/actions)
[![codecov](https://codecov.io/gh/uhlmanngroup/napari-splineit/branch/main/graph/badge.svg)](https://codecov.io/gh/uhlmanngroup/napari-splineit)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-splineit)](https://napari-hub.org/plugins/napari-splineit)

A napari plugin for the interactive manipulation of spline-interpolation based geometrical models

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/stable/index.html
-->

## Installation

You can install `napari-splineit` via [pip]:

    pip install napari-splineit



To install latest development version :

    pip install git+https://github.com/uhlmanngroup/napari-splineit.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-splineit"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/uhlmanngroup/napari-splineit/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Software Development :: Testing']","['Bug Tracker, https://github.com/uhlmanngroup/napari-splineit/issues', 'Documentation, https://github.com/uhlmanngroup/napari-splineit#README.md', 'Source Code, https://github.com/uhlmanngroup/napari-splineit', 'User Support, https://github.com/uhlmanngroup/napari-splineit/issues']",napari-splineit.read_splineit,napari-splineit.write_splineit_json,napari-splineit.make_qwidget,napari-splineit.make_sample_data_coins,['*.splineit'],['.splineit'],,https://pypi.org/project/napari-splineit,https://github.com/uhlmanngroup/napari-splineit,
303,Spot Finder,0.0.1,,,napari-spofi,Christian Schulze,drchrisch@gmail.com,BSD-3-Clause,,napari plugin to interactively train and test a StarDist model,>=3.8,"['numpy', 'pandas', 'magicgui', 'qtpy', 'scikit-image', 'pyclesperanto', 'tensorflow', 'stardist', ""tox ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-spofi

[![License BSD-3](https://img.shields.io/pypi/l/napari-spofi.svg?color=green)](https://github.com/githubuser/napari-spofi/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-spofi.svg?color=green)](https://pypi.org/project/napari-spofi)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-spofi.svg?color=green)](https://python.org)
[![tests](https://github.com/githubuser/napari-spofi/workflows/tests/badge.svg)](https://github.com/githubuser/napari-spofi/actions)
[![codecov](https://codecov.io/gh/githubuser/napari-spofi/branch/main/graph/badge.svg)](https://codecov.io/gh/githubuser/napari-spofi)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-spofi)](https://napari-hub.org/plugins/napari-spofi)

napari plugin to interactively train and test a StarDist model

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started


and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Description

This plugin provides tools for annotating spots in a 3D two-channel image (hdf5 type input file),
submitting tiles for StarDist model generation or model re-training, and refining initial annotations
based on predictions (kind of human-in-the-loop approach).

The objects of interest in the image are sphere-like spots with a diameter of just a
few pixels and are thus well suited for StarDist instance segmentation. The image 
dimensions are typically 1024x1024 pixels in xy and ≥ 64 sections in z.


## Installation

With python and pip installed (e.g., via miniconda or miniforge),
it is recommended to create a new environment and install `napari-spofi` using pip.

    pip install napari napari-spofi

## Starting `napari-spofi`

Start `napari` and select ""spot finder (napari-spofi)"" from the ""plugin"" menu.

### Annotate image
Go to the 'annotation' section of the widget and create a new directory for annotations. Add an image
folder containing at least one h5 file (foreground and background, e.g., 'ch1' & 'ch2'). Select an image file, foreground and background
channels. Load the image file.

Inspect the image for distinct regions. To help locate relevant tile positions, make
the 'checkerboard' layer visible. While the 'tiles' layer is active, double-click a tile
to add it to the list of tiles. This list will be used to generate a set of 
images and masks for training purposes.

Switch to napari's 2D view. Navigate to the centre section of each spot in the active tile
and annotate by adding points (one point per spot) using the 'true' points layer. The
built-in heuristic will automatically annotate pixels that belong to individual spots.
Some image enhancement step before loading images may be beneficial. 

Annotate tiles in one or a multiple images.
To prepare training data, use the 'extract spots' button.

### Train a StarDist model
Go to the 'training' section of the widget. Adjust the ""number of epochs"". For a first
check, 100 epochs is a good start. The plugin uses a simplified setup for StarDist
configurations (please see [StarDist](https://github.com/stardist/stardist/) for a full discussion).

Start training and watch the 'loss' and 'val_loss' values, which should decrease
steadily while their ratio should roughly remain at 1 as training progresses.

The retrain option allows the selection of an existing model for retraining.

### Predict instances
Go to the 'prediction' section of the widget to start spot prediction for the
currently loaded image. Select the appropriate model from the given annotation
directory. The 'threshold' value is calculated from the validation data and can be
adjusted. Start a new prediction and load the predicted spots when the process has
finished. (It is possible to load an existing prediction).

### Polish annotation
Predicted spots will be loaded into two new layers: 'predicted' and 'edited'. The
'predicted' layer is not editable and gives an overview of the spots found. Check
your annotation in the active tiles ('true' layer) and compare it carefully with
the spots in the 'edited' layer.
Adjust the positions of the spots or remove any incorrect spots from the 'edited'
layer. Extract the spots and train a new model or retrain the model.



## Contributing

Contributions are very welcome.

## License

Distributed under the terms of the [BSD-3] license,
""napari-spofi"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing', 'Topic :: Scientific/Engineering :: Visualization']","['Bug Tracker, https://github.com/drchrisch/napari-spofi/issues', 'Documentation, https://github.com/drchrisch/napari-spofi#README.md', 'Source Code, https://github.com/drchrisch/napari-spofi', 'User Support, https://github.com/drchrisch/napari-spofi/issues']",,,napari-spofi.widget,,,,,https://pypi.org/project/napari-spofi,,
304,napari-spotiflow,0.2.0,,,napari-spotiflow,"Albert Dominguez Mantes, Martin Weigert","albert.dominguezmantes@epfl.ch, martin.weigert@epfl.ch",BSD-3-Clause,,Napari plugin for Spotiflow,"<3.12,>=3.9","['spotiflow', 'npe2', 'napari']","[![License: BSD-3](https://img.shields.io/badge/License-BSD3-blue.svg)](https://www.gnu.org/licenses/bsd3)
[![PyPI](https://img.shields.io/pypi/v/napari-spotiflow.svg?color=green)](https://pypi.org/project/napari-spotiflow)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-spotiflow.svg?color=green)](https://python.org)
[![tests](https://github.com/weigertlab/napari-spotiflow/workflows/tests/badge.svg)](https://github.com/weigertlab/napari-spotiflow/actions)
[![PyPI - Downloads](https://img.shields.io/pypi/dm/napari-spotiflow)](https://pypistats.org/packages/napari-spotiflow)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-spotiflow)](https://napari-hub.org/plugins/napari-spotiflow)

![Logo](artwork/spotiflow_logo.png)
---

# napari-spotiflow

Napari plugin for *Spotiflow*, a deep learning-based, threshold-agnostic, and subpixel-accurate spot detection method for fluorescence microscopy. For the main repo, see [here](https://github.com/weigertlab/spotiflow). 

  
https://github.com/weigertlab/napari-spotiflow/assets/11042162/02940480-daa9-4a21-8cf5-ad73c26c9838

If you use this plugin for your research, please [cite us](https://github.com/weigertlab/spotiflow#how-to-cite).

----------------------------------

# Usage 

1. Open the image (or open one of our samples, _e.g._ `File > Open Sample > napari-spotiflow > HybISS`)
2. Start the plugin `Plugins > napari-spotiflow`
3. Select model (pretrained or custom trained) and optionally adjust any other parameters
4. Click `run`

## Supported input formats
- 2D (YX, YXC or CYX)
- 2D+t (TYX, TYXC or TCYX)

## Installation

The plugin can be installed directly from PyPi (make sure you use a conda environment with `napari` and `spotiflow` installed):

```
pip install napari-spotiflow
```
","['Development Status :: 4 - Beta', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/weigertlab/napari-spotiflow/issues', 'Documentation, https://github.com/weigertlab/napari-spotiflow#README.md', 'Source Code, https://github.com/weigertlab/napari-spotiflow', 'User Support, https://github.com/weigertlab/napari-spotiflow/issues']",napari-spotiflow.reader,,napari-spotiflow.widget,napari-spotiflow.data.hybiss_2d,['*.csv'],,,https://pypi.org/project/napari-spotiflow,,
305,Spreadsheet,0.0.4,2023-12-08,2023-12-08,napari-spreadsheet,Hanjin Liu,liuhanjin-sc@g.ecc.u-tokyo.ac.jp,BSD-3-Clause,https://pypi.org/project/napari-spreadsheet,A spreadsheet widget for napari,>=3.8,"['magicgui', 'napari', 'numpy', 'pandas', 'qtpy', 'tabulous (>=0.5.0)', ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""tox ; extra == 'testing'""]","# napari-spreadsheet

[![License BSD-3](https://img.shields.io/pypi/l/napari-spreadsheet.svg?color=green)](https://github.com/hanjinliu/napari-spreadsheet/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-spreadsheet.svg?color=green)](https://pypi.org/project/napari-spreadsheet)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-spreadsheet.svg?color=green)](https://python.org)
[![tests](https://github.com/hanjinliu/napari-spreadsheet/workflows/tests/badge.svg)](https://github.com/hanjinliu/napari-spreadsheet/actions)
[![codecov](https://codecov.io/gh/hanjinliu/napari-spreadsheet/branch/main/graph/badge.svg)](https://codecov.io/gh/hanjinliu/napari-spreadsheet)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-spreadsheet)](https://napari-hub.org/plugins/napari-spreadsheet)

Let's replace Microsoft Excel or Google Spreadsheet with `napari-spreadsheet` for your daily image analysis.

### Highlights

- Convert layer features to a spreadsheet.
- Update layer features from a spreadsheet.
- Send spreadsheet data to the namespace of napari's console directly.

![](https://github.com/hanjinliu/napari-spreadsheet/blob/main/images/image.png)

This plugin is largely dependent on [tabulous](https://github.com/hanjinliu/tabulous). To know more about the user interface, please see the [documentation](https://hanjinliu.github.io/tabulous/main/user_interface.html).

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-spreadsheet` via [pip]:

    pip install napari-spreadsheet



To install latest development version :

    pip install git+https://github.com/hanjinliu/napari-spreadsheet.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-spreadsheet"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/hanjinliu/napari-spreadsheet/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/hanjinliu/napari-spreadsheet/issues', 'Documentation, https://github.com/hanjinliu/napari-spreadsheet#README.md', 'Source Code, https://github.com/hanjinliu/napari-spreadsheet', 'User Support, https://github.com/hanjinliu/napari-spreadsheet/issues']",napari-spreadsheet.read_table_data,,napari-spreadsheet.make_qwidget,,"['*.txt', '*.dat', '*.csv', '*.xlsx']",,,https://pypi.org/project/napari-spreadsheet,,
306,Stable Diffusion,0.1.1,2023-04-17,2023-07-25,napari-stable-diffusion,Kyle Harrington,napari@kyleharrington.com,BSD-3-Clause,https://github.com/kephale/napari-stable-diffusion,A demo of stable diffusion in napari,>=3.8,"['napari', 'napari-plugin-engine (>=0.1.4)', 'numpy', 'magicgui', 'qtpy', 'diffusers', 'transformers', 'torch', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-stable-diffusion

[![License BSD-3](https://img.shields.io/pypi/l/napari-stable-diffusion.svg?color=green)](https://github.com/kephale/napari-stable-diffusion/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-stable-diffusion.svg?color=green)](https://pypi.org/project/napari-stable-diffusion)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-stable-diffusion.svg?color=green)](https://python.org)
[![tests](https://github.com/kephale/napari-stable-diffusion/workflows/tests/badge.svg)](https://github.com/kephale/napari-stable-diffusion/actions)
[![codecov](https://codecov.io/gh/kephale/napari-stable-diffusion/branch/main/graph/badge.svg)](https://codecov.io/gh/kephale/napari-stable-diffusion)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-stable-diffusion)](https://napari-hub.org/plugins/napari-stable-diffusion)

A demo of stable diffusion in napari.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

![demo image of napari-stable-diffusion of the prompt ""a unicorn and a dinosaur eating cookies and drinking tea""](https://github.com/kephale/napari-stable-diffusion/raw/main/napari_stable_diffusion_demo.png)

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-stable-diffusion` via [pip]:

    pip install napari-stable-diffusion

To install latest development version :

    pip install git+https://github.com/kephale/napari-stable-diffusion.git

You will also need to sign up with HuggingFace and [generate an access
token](https://huggingface.co/docs/hub/security-tokens) to get access to the
Stable Diffusion model we use.

When you have generated your access token you can either permanently
set the `HF_TOKEN_SD` environment variable in your `.bashrc` or whichever file
your OS uses, or you can include it on the command line

```
HF_TOKEN_SD=""hf_aaaAaaaasdadsadsaoaoaoasoidijo"" napari
```

For more information on the Stable Diffusion model itself, please see https://huggingface.co/CompVis/stable-diffusion-v1-4.

### Apple M1 specific instructions

To utilize the M1 GPU, the nightly version of PyTorch needs to be
installed. Consider using `conda` or `mamba` like this:

```
mamba create -c pytorch-nightly -n napari-stable-diffusion python=3.9 pip pyqt pytorch torchvision
pip install git+https://github.com/kephale/napari-stable-diffusion.git
```

## Next steps

- Image 2 Image support
- Inpainting support

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-stable-diffusion"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/kephale/napari-stable-diffusion/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/kephale/napari-stable-diffusion/issues', 'Documentation, https://github.com/kephale/napari-stable-diffusion#README.md', 'Source Code, https://github.com/kephale/napari-stable-diffusion', 'User Support, https://github.com/kephale/napari-stable-diffusion/issues']",,,napari-stable-diffusion.make_qwidget,,,,,https://pypi.org/project/napari-stable-diffusion,https://github.com/kephale/napari-stable-diffusion,
307,napari Steinpose,0.1.0,2023-12-09,2023-12-09,napari-steinpose,Guillaume Witz,guillaume.witz@unibe.ch,BSD-3-Clause,https://pypi.org/project/napari-steinpose,A plugin to process Imaging Mass Cytometry data with cellpose and steinbock,>=3.8,"['torch (==1.11.0)', 'cellpose', 'numpy', 'magicgui', 'qtpy', 'matplotlib', 'readimc', 'steinbock', 'pandas', 'aicsimageio', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'"", ""pytest-order ; extra == 'testing'""]","# napari-steinpose

[![License BSD-3](https://img.shields.io/pypi/l/napari-steinpose.svg?color=green)](https://github.com/guiwitz/napari-steinpose/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-steinpose.svg?color=green)](https://pypi.org/project/napari-steinpose)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-steinpose.svg?color=green)](https://python.org)
[![tests](https://github.com/guiwitz/napari-steinpose/workflows/tests/badge.svg)](https://github.com/guiwitz/napari-steinpose/actions)
[![codecov](https://codecov.io/gh/guiwitz/napari-steinpose/branch/main/graph/badge.svg)](https://codecov.io/gh/guiwitz/napari-steinpose)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-steinpose)](https://napari-hub.org/plugins/napari-steinpose)

This napari plugin allows to segment and extract information from Imaging Mass Cytometry data by combining the [cellpose](http://www.cellpose.org/) and [steinbock](https://bodenmillergroup.github.io/steinbock/v0.14.2/) tools.

## Installation

In order to use this plugin, whe highly recommend to create a specific environment and to install the required software in it. You can create a conda environment using:

    conda create -n steinpose python=3.8.5 napari -c conda-forge

Then activate it and install the plugin:
    
    conda activate steinpose
    pip install napari-steinpose

### Potential issue with PyTorch

Cellpose and therefore the plugin and napari can crash without warning in some cases with ```torch==1.12.0```. This can be fixed by reverting to an earlier version using:
    
    pip install torch==1.11.0

### GPU

In order to use a GPU:

1. Uninstall the PyTorch version that gets installed by default with Cellpose:

        pip uninstall torch

2. Make sure your have up-to-date drivers for your NVIDIA card installed.

3. Re-install a GPU version of PyTorch via conda using a command that you can find [here](https://pytorch.org/get-started/locally/) (this takes care of the cuda toolkit, cudnn etc. so **no need to install manually anything more than the driver**). The command will look like this:

        conda install pytorch torchvision cudatoolkit=11.3 -c pytorch

### Plugin Updates

To update the plugin, you only need to activate the existing environment and install the new version:

    conda activate steinpose
    pip install git+https://github.com/guiwitz/napari-steinpose.git -U

## Usage

Here is a short summary on how to proceed to use the plugin. For more detailed information, please visit [this page](https://guiwitz.github.io/napari-steinpose).

### Load data

Using the ""Select data folder"" button, select a folder containing your .mcd files. The contents of the folder will appear in the List of images box. When you select one of the files it is loaded in the viewer. Using the ROI spinpox, you can change the roi (or acquisition) to be visualized.
### Segmentation

1. In the channels tab, choose the combination of channels to use to define images to segment. You can choose what type of projection (mean, min etc.) is used to combine channels. You can either select channels defining both cells and nuclei or just a single channel. **Note that if you want to just segment nuclei, you need to select them as ""cell channel"".**

2. To save the output, select a folder using the ""Select output folder"" button.

3. In the segmentation tab, pick a cellpose model to use. If you use one of the built-in models, you can specify the average diameter of objects to detect.

4. In the Options tab, you can set a few more options:
   - cellpose options: you can adjust the flow threshold and cell probabilities. If cells are missing try to use higher values of flow threshold (close to 1) and lower values for the cell probabilities (around -6)
   - segmentation options: you can decide to remove segmentation touching the image border, and you can also decide to expand the segmented objects by a fixed number of pixels. If a segmentation is displayed in the viewer, adjusting this parameter will live-adjust the mask.

5. You can first test the segmentation using the ""Run on current image"" button. Once segmentation is done, the corresponding mask is displayed. You can then run the segmentation over all ROIs of **all .mcd files** present in the folder by using the ""Run on folder"" button.

### Post-processing

In the Segmentation tab, if you tick the box ""Run steinbock post-processing"", information will directly be extracted from images and masks at the end of segmentation. Processing is done via steinbock and generates files compatible with further downstream processing.

In the Export tab, you can select what type of information to export: object intensities, geometric properties and object neighbourhood. Note that if you have performed a segmentation without post-processing, you can still run post-processing using the ""Run steinbock postproc"" button.

### Saving settings

To avoid having to re-type the same settings repeatedly, you can export a give configuration using the ""Export config"" button in the Options tab. This generates a human readable .yml file with:
- segmentation options
- channels selected for projections

The file is saved in the output folder. You can just copy the file in a new empty output folder to use it for an other analysis run. Once you select that folder containing a configuration file, you can import it with the ""Import config"" button. **Note that you need to have an image opened so that channels can be selected properly.**
## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-steinpose"" is free and open source software

## Authors

The author of this plugin is Guillaume Witz, Data Science Lab and Microscopy Imaging Center, University of Bern. This plugin is the result of a collaboration with the Imaging Mass Cytometry and Mass Cytometry Platform, University of Bern.

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/guiwitz/napari-steinpose/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/guiwitz/napari-steinpose/issues', 'Documentation, https://github.com/guiwitz/napari-steinpose#README.md', 'Source Code, https://github.com/guiwitz/napari-steinpose', 'User Support, https://github.com/guiwitz/napari-steinpose/issues']",napari-steinpose.get_reader,,napari-steinpose.make_qwidget,,['*.mcd'],,,https://pypi.org/project/napari-steinpose,,
308,napari-stl-exporter,0.1.5,2022-02-02,2023-07-25,napari-stl-exporter,Johannes Soltwedel,johannes_richard.soltwedel@tu-dresden.de,BSD-3-Clause,https://github.com/jo-mueller/napari-stl-exporter,Exports label images to 3D-printable stl files.,>=3.7,"['napari', 'scikit-image', 'vedo (>=2023.4.6)', 'npe2', 'numpy']","# napari-stl-exporter

[![License](https://img.shields.io/pypi/l/napari-stl-exporter.svg?color=green)](https://github.com/jo-mueller/napari-stl-exporter/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-stl-exporter.svg?color=green)](https://pypi.org/project/napari-stl-exporter)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-stl-exporter.svg?color=green)](https://python.org)
[![tests](https://github.com/jo-mueller/napari-stl-exporter/workflows/tests/badge.svg)](https://github.com/jo-mueller/napari-stl-exporter/actions)
[![codecov](https://codecov.io/gh/jo-mueller/napari-stl-exporter/branch/main/graph/badge.svg?token=9zctLzazD9)](https://codecov.io/gh/jo-mueller/napari-stl-exporter)

This plugin allows to import and export surface data in Napari to common file formats. The generated file formats can be read by other common applications, and - in particular - allow *3D-printing*.

![](https://github.com/jo-mueller/napari-stl-exporter/raw/main/doc/model_and_printed_model.png)


### Supported file formats:
Currently supported file formats for export include and rely on the [vedo io API](https://vedo.embl.es/autodocs/content/vedo/io.html#vedo.io).
* *.stl*: [Standard triangle language](https://en.wikipedia.org/wiki/STL_%28file_format%29)
* *.ply*: [Polygon file format](https://en.wikipedia.org/wiki/PLY_(file_format))
* *.obj*: [Wavefront object](https://en.wikipedia.org/wiki/Wavefront_.obj_file)

### Supported Napari layers:

Currently supported Napari layer types are:
* [Surface layers](https://napari.org/howtos/layers/surface.html)
* [Label layers](https://napari.org/howtos/layers/labels.html): The label data is converted to surface data under the hood using the [marching cubes algorithm](https://scikit-image.org/docs/dev/api/skimage.measure.html#skimage.measure.marching_cubes) implemented in [scikit-image](https://scikit-image.org/) and is then exported using [Vedo](https://vedo.embl.es/). Warning: This can be slow for large image data!

### Import/export

**Interactively:** To export the data, simply save the selected layer with `File > Save Selected Layer(s)` and specify the file ending to be `some_file.[file_ending]`, for supported file types, see above. Similarly, supported file types can be imported into Napari with `File > `

**From code**: A [Napari Label layer](https://napari.org/api/napari.layers.Labels.html) can be added to the viewer as described in the [napari reference](https://napari.org/gallery/add_labels.html?highlight=add_labels) with this code snippet:

```python
import napari
import numpy as np

# Load and binarize image
label_image = np.zeros((100, 100, 100), dtype=int)
label_image[25:75, 25:75, 25:75] = 1

# Add data to viewer
viewer = napari.Viewer()
label_layer = viewer.add_labels(data, name='3D object')

# save the layer as 3D printable file to disc
napari.save_layers(r'/some/path/test.stl', [label_layer])
```

### Sample data
You can create sample label/surface data for export using the built-in functions as shown here:

![](https://github.com/jo-mueller/napari-stl-exporter/raw/main/doc/1_sample_data.png)

...or from code with

```Python
import napari_stl_exporter

pyramid = napari_stl_exporter.make_pyramid_surface()

```

### 3D-printing
To actually send your object to a 3D-printer, it has to be further converted to the *.gcode* format with a Slicer program. The latter convert the 3D object to machine-relevant parameters (printing detail, motor trajectories, etc). Popular slicers are:

* [Slic3r](https://slic3r.org/): Documentation [here](https://manual.slic3r.org/intro/overview)
* [Prusa Slicer](https://www.prusa3d.com/prusaslicer/): Tutorial [here](https://help.prusa3d.com/en/article/first-print-with-prusaslicer_1753)

*Note*: You can also upload the STL file to [github.com](https://github.com) and interact with it in the browser:

![](https://github.com/jo-mueller/napari-stl-exporter/raw/main/doc/pyramid_browser_screenshot.png)

#### Digital elevation models

DIgital elevation models (DEMs) can be printed with the napari-stl-exporter following these steps:

1. Go to the [open topography repository](https://portal.opentopography.org/raster?opentopoID=OTSDEM.032021.4326.2) and select a region of your choice, then download it as a GeoTiff file (`.tif`, intensity encodes elevation)
2. Open the downloaded tif image use the image conversion plugin (´Plugins > napari-stl-exporter > 2D image to surface´) to convert the downloaded image to a surface. CHeck the `solidify` option to make it readily 3D-printable.

![](https://github.com/jo-mueller/napari-stl-exporter/raw/main/doc/landscape_to_surface.png)

3. Export the created surface layer as `.stl` or `.ply` file. Open it in your Slicer of choice (you may have to scale it according to the size limitations of your printer) and off you go!

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/docs/plugins/index.html
-->

## Installation

You can install `napari-stl-exporter` via [pip]:

    pip install napari-stl-exporter

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-stl-exporter"" is free and open source software

## Issues

If you encounter any problems, please [file an issue](https://github.com/jo-mueller/napari-stl-exporter/issues) along with a detailed description or post to image.sc and tag ```El_Pollo_Diablo```

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 3 - Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Project Site, https://github.com/jo-mueller/napari-stl-exporter', 'Report Issues, https://github.com/jo-mueller/napari-stl-exporter/issues', 'Documentation, https://pypi.org/project/napari-stl-exporter/', 'User Support, https://github.com/jo-mueller/napari-stl-exporter/issues', 'Twitter, https://twitter.com/jm_mightypirate']",napari-stl-exporter.import_surface,napari-stl-exporter.write_labels,napari-stl-exporter.convert_image_to_surface,napari-stl-exporter.make_pyramid_label,"['*.stl', '*.ply', '*.obj']","['.stl', '.ply', '.obj']","['.stl', '.ply', '.obj']",https://pypi.org/project/napari-stl-exporter,https://github.com/jo-mueller/napari-stl-exporter,
309,napari-stracking,0.1.9,2022-08-18,2023-06-18,napari-stracking,Sylvain Prigent,sylvain.prigent@inria.fr,BSD 3-Clause,https://github.com/sylvainprigent/napari-stracking,Linking and tracks analysis,>=3.7,"['napari', 'napari-plugin-engine (>=0.1.4)', 'numpy', 'stracking (>=0.1.9)']","# napari-stracking

[![License](https://img.shields.io/pypi/l/napari-stracking.svg?color=green)](https://github.com/sylvainprigent/napari-stracking/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-stracking.svg?color=green)](https://pypi.org/project/napari-stracking)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-stracking.svg?color=green)](https://python.org)
[![tests](https://github.com/sylvainprigent/napari-stracking/workflows/tests/badge.svg)](https://github.com/sylvainprigent/napari-stracking/actions)
[![codecov](https://codecov.io/gh/sylvainprigent/napari-stracking/branch/master/graph/badge.svg)](https://codecov.io/gh/sylvainprigent/napari-stracking)

`napari-stracking` is a suite of **Napari** plugins for the [stracking library](
https://sylvainprigent.github.io/stracking/) dedicated to particles tracking in 2D+t and 3D+t images. Each step of
the tracking process is separated in independent plugins to ease the creation of pipelines.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/docs/plugins/index.html
-->

## Installation

You can install `napari-stracking` via [pip]:

    pip install napari-stracking

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-stracking"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/sylvainprigent/napari-stracking/issues
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/


","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/sylvainprigent/napari-stracking/issues', 'Documentation, https://github.com/sylvainprigent/napari-stracking#README.md', 'Source Code, https://github.com/sylvainprigent/napari-stracking', 'User Support, https://github.com/sylvainprigent/napari-stracking/issues']",,,napari-stracking.SParticlesProperties,,,,,https://pypi.org/project/napari-stracking,https://github.com/sylvainprigent/napari-stracking,
310,napari-subboxer,0.0.1,2022-02-02,2023-06-18,napari-subboxer,Alister Burt,alisterburt@gmail.com,BSD-3-Clause,https://github.com/alisterburt/napari-subboxer,A napari plugin for interacting with electron cryotomograms,>=3.7,"['napari-plugin-engine (>=0.1.4)', 'numpy', 'napari[pyqt5] (==0.4.12)', 'mrcfile', 'typer', 'eulerangles', 'starfile', 'einops', 'pydantic']","# napari-subboxer

[![License](https://img.shields.io/pypi/l/napari-subboxer.svg?color=green)](https://github.com/alisterburt/napari-subboxer/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-subboxer.svg?color=green)](https://pypi.org/project/napari-subboxer)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-subboxer.svg?color=green)](https://python.org)
[![tests](https://github.com/alisterburt/napari-subboxer/workflows/tests/badge.svg)](https://github.com/alisterburt/napari-subboxer/actions)
[![codecov](https://codecov.io/gh/alisterburt/napari-subboxer/branch/master/graph/badge.svg)](https://codecov.io/gh/alisterburt/napari-subboxer)

A napari plugin for visualising and interacting with electron cryotomograms.


## Installation

You can install `napari-subboxer` via [pip]:

    pip install napari-subboxer

## Usage

This plugin provides a user interface for opening electron cryotomograms in 
napari as both volumes and slices through volumes.

![demo](https://user-images.githubusercontent.com/7307488/138575305-b05c4735-9c03-4629-bfb0-9612ea8f26fd.gif)

The plugin can be opened from the `plugins` menu in napari, or with 
`napari-subboxer` at the command line.

![plugins-menu](https://user-images.githubusercontent.com/7307488/138575015-00ea78d9-02c1-44bc-9034-0c0a7fa8d973.png)

```yaml
Usage: napari-subboxer [TOMOGRAM_FILE]

  An interactive tool for defining and applying relative transforms
  on sets of particles in napari.

Arguments:
  [TOMOGRAM_FILE]

Options:
  --help                          Show this message and exit.

```

## Contributing

Contributions are very welcome. 

## License

Distributed under the terms of the [BSD-3] license,
""napari-subboxer"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/alisterburt/napari-subboxer/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/


","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/alisterburt/napari-subboxer/issues', 'Documentation, https://github.com/alisterburt/napari-subboxer#README.md', 'Source Code, https://github.com/alisterburt/napari-subboxer', 'User Support, https://github.com/alisterburt/napari-subboxer/issues']",,,napari-subboxer.SubboxingWidget,,,,,https://pypi.org/project/napari-subboxer,https://github.com/alisterburt/napari-subboxer,
311,superres,0.1.1,2023-12-09,2023-12-09,napari-superres,rocco.dantuono@hotmail.it,rocco.dantuono@hotmail.it,BSD-3-Clause,https://pypi.org/project/napari-superres,Fluorescence Fluctuation-based Super Resolution (FF-SRM) Methods,>=3.8,"['matplotlib', 'magicgui', 'qtpy', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-superres

[![License BSD-3](https://img.shields.io/pypi/l/napari-superres.svg?color=green)](https://github.com/RoccoDAnt/napari-superres/blob/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-superres.svg?color=green)](https://pypi.org/project/napari-superres)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-superres.svg?color=green)](https://python.org)
[![tests](https://github.com/RoccoDAnt/napari-superres/workflows/tests/badge.svg)](https://github.com/RoccoDAnt/napari-superres/actions)
[![codecov](https://codecov.io/gh/RoccoDAnt/napari-superres/branch/main/graph/badge.svg)](https://codecov.io/gh/RoccoDAnt/napari-superres)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/RoccoDAnt/napari-superres)](https://napari-hub.org/plugins/napari-superres)


A collection of super-resolution microscopy FF-SRM methods.

Open-source implementation of methods for Fluorescence Fluctuation based Super Resolution Microscopy (FF-SRM):

Review: [Alva et al., 2022. “Fluorescence Fluctuation-Based Super-Resolution Microscopy: Basic Concepts for an Easy Start.” Journal of Microscopy, August.](https://onlinelibrary.wiley.com/doi/10.1111/jmi.13135)

MSSR article: [Torres-García, E., Pinto-Cámara, R., Linares, A. et al. Extending resolution within a single imaging frame. Nat Commun 13, 7452 (2022).](https://doi.org/10.1038/s41467-022-34693-9)

ESI article: [Idir Yahiatene, Simon Hennig, Marcel Müller, Thomas Huser (2015/2016). ""Entropy-based Super-resolution Imaging (ESI): From Disorder to Fine Detail"" ACS Photonics 8, 2 (2015)](https://doi.org/10.1021/acsphotonics.5b00307)

SOFI article: [T. Dertinger, R. Colyer, G. Iyer, and J. Enderlein. Fast, background-free, 3D super-resolution optical fluctuation imaging (SOFI). PNAS 52, 106 (2009) ](https://doi.org/10.1073/pnas.0907866106)

SRRF article: [Gustafsson, N., Culley, S., Ashdown, G., D. M. Owen, P. Matos Pereira, and R. Henriques. Fast live-cell conventional fluorophore nanoscopy with ImageJ through super-resolution radial fluctuations. Nat Commun 7, 12471 (2016)](https://www.nature.com/articles/ncomms12471)

MUSICAL article: [K. Agarwal and R. Machan, Multiple Signal Classification Algorithm for super-resolution fluorescence microscopy, Nature Communications, vol. 7, article id. 13752, (2016)](https://www.nature.com/articles/ncomms13752)



Methods implemented:
- MSSR
- ESI
- SOFI
- SRRF
- MUSICAL
- Split channels


| **Super Resolution Radial Fluctuations (SRRF)**  | **Mean-Shift Super Resolution (MSSR)** | **Entropy-based Super-resolution Imaging (ESI)** |
| --- | --- | --- |
| ![](https://raw.githubusercontent.com/RoccoDAnt/napari-superres/main/docs/Fig_7_SRRF_Alva_2022.png) | ![](https://raw.githubusercontent.com/RoccoDAnt/napari-superres/main/docs/Fig_2a_MSSR_Garcia_2021.png) | ![](https://raw.githubusercontent.com/RoccoDAnt/napari-superres/main/docs/Fig_6_ESI_Alva_2022.png) |
from Fig. 7 of [Alva et al., 2022](https://onlinelibrary.wiley.com/doi/10.1111/jmi.13135) | from Fig. 2 of [García et al., 2021](https://www.biorxiv.org/content/10.1101/2021.10.17.464398v2.full)|  from Fig. 6 of [Alva et al., 2022](https://onlinelibrary.wiley.com/doi/10.1111/jmi.13135)|


Repositories available:
- [ESI](https://github.com/biophotonics-bielefeld/ESI) GitHub repository
- [PySOFI](https://github.com/xiyuyi-at-LLNL/pysofi) GitHub repository
- [MUSICAL](https://sites.google.com/site/uthkrishth/musical) Google site

----------------------------------


This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->


## Installation
First install napari viewer (if you haven't):

    conda create -y -n napari-env -c conda-forge python=3.9
    conda activate napari-env
    pip install ""napari[all]""

For details check: https://napari.org/stable/




You can install the plugin [graphically](https://github.com/LIBREhub/napari-LatAm-Workshop-2023/blob/napari-superres/docs/day3/napari-superres/napari-superres_installation_guide.pdf).

or install latest development version :

    pip install git+https://github.com/RoccoDAnt/napari-superres.git

You might need to install [git](https://git-scm.com/book/en/v2/Getting-Started-Installing-Git) first.

----------------------------------
Examples of use:

| **Original**  | **tMSSR** |
| --- | --- |
| <p align=""center""> <img src=""https://raw.githubusercontent.com/RoccoDAnt/napari-superres/main/docs/single-frame-good-exposure.png"" width=100% height=100%> </p>| <p align=""center""> <img src=""https://raw.githubusercontent.com/RoccoDAnt/napari-superres/main/docs/tmssr-mean-mag2.png"" width=48% height=48%> </p>|
| Parameters: | Amplification: 2, Order: 0, PSF FWHM: 6, <br> Interpolation: Bicubic, Statistical integration: CV*sigma |

| **Original**  | **ESI** |
| --- | --- |
| <p align=""center""> <img src=""https://raw.githubusercontent.com/RoccoDAnt/napari-superres/main/docs/synt.png"" width=40% height=40%> </p> | <p align=""center""> <img src=""https://raw.githubusercontent.com/RoccoDAnt/napari-superres/main/docs/ESI.png"" width=50% height=50%> </p> |
| Parameters: | image in output: 2, bins: 2, Order: 2 |

| **Original**  | **SOFI** |
| --- | --- |
|<p align=""center""> <img src=""https://raw.githubusercontent.com/RoccoDAnt/napari-superres/main/docs/noSOFI.png"" width=100% height=100%> </p> | <p align=""center""> <img src=""https://raw.githubusercontent.com/RoccoDAnt/napari-superres/main/docs/SOFI.png"" width=100% height=100%> </p> |
| Parameters: | Amplification factor: 2, Moment Order: 4, lambda parameter: 1.5, No. Iterations: 20, Window size: 100|

| **Original**  | **SRRF** |
| --- | --- |
|<p align=""center""> <img src=""https://raw.githubusercontent.com/RoccoDAnt/napari-superres/main/docs/synt.png"" width=50% height=50%> </p> | <p align=""center""> <img src=""https://raw.githubusercontent.com/RoccoDAnt/napari-superres/main/docs/SRRF.png"" width=50% height=50%> </p>|
| Parameters: | Amplification: 2, Spatial radius: 5, Symmetry Axis: 6, Start frame: 0, End frame: 48|

| **Original**  | **MUSICAL** |
| --- | --- |
| <p align=""center""> <img src=""https://raw.githubusercontent.com/RoccoDAnt/napari-superres/main/docs/musical_mean.png"" width=70% height=100%> </p> | <p align=""center""> <img src=""https://raw.githubusercontent.com/RoccoDAnt/napari-superres/main/docs/MUSICAL-CardioMyoblast_Mitochondria.png"" width=70% height=100%> </p>|
| Parameters: | Emission [nm]: 510 NA: 1.4, Mag: 100, Pizel size: 8000, Threshold: -0.5, Alpha: 4, Subpixels per pixel: 20|
----------------------------------



## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-superres"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/RoccoDAnt/napari-superres/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/RoccoDAnt/napari-superres/issues', 'Documentation, https://github.com/RoccoDAnt/napari-superres#README.md', 'Source Code, https://github.com/RoccoDAnt/napari-superres', 'User Support, https://github.com/RoccoDAnt/napari-superres/issues']",napari-superres.get_reader,napari-superres.write_multiple,napari-superres.make_mssr_caller,,['*.npy'],,['.npy'],https://pypi.org/project/napari-superres,,
312,napari-svetlana,0.3.2,,,napari-svetlana,Clément Cazorla,clement.cazorla31@gmail.com,GPL-3.0-only,,A classification plugin for the ROIs of a segmentation mask.,>=3.9,"['napari-plugin-engine >=0.1.4', 'numpy', 'albumentations ==1.0.3', 'joblib ==1.2.0', 'light-the-torch', 'matplotlib', 'opencv-python ==4.8.1.78', 'PyQt5', 'cupy-cuda102 ==10.6.0', 'xlsxwriter', 'pandas', 'npe2', 'pooch', 'cucim ==22.6.0 ; platform_system == ""Linux""']","# napari_svetlana

[![License](https://img.shields.io/pypi/l/napari_svetlana.svg?color=green)](https://bitbucket.org/koopa31/napari_svetlana/src/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari_svetlana.svg?color=green)](https://pypi.org/project/napari_svetlana)
[![Python Version](https://img.shields.io/pypi/pyversions/napari_svetlana.svg?color=green)](https://python.org)
[![tests](https://bitbucket.org/koopa31/napari_svetlana/workflows/tests/badge.svg)](https://bitbucket.org/koopa31/napari_svetlana/actions)
[![codecov](https://codecov.io/gh/koopa31/napari_svetlana/branch/main/graph/badge.svg)](https://codecov.io/gh/koopa31/napari_svetlana)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-svetlana)](https://napari-hub.org/plugins/napari-svetlana)
[![Documentation](https://readthedocs.org/projects/svetlana-documentation/badge/?version=latest)](https://svetlana-documentation.readthedocs.io/en/latest/)

The aim of this plugin is to classify the output of a segmentation algorithm.
The inputs are :
<ul>
  <li>A folder of raw images</li>
  <li>Their segmentation masks where each ROI has its own label.</li>
</ul>

Svetlana can process 2D, 3D and multichannel image. If you want to use it to work on cell images, we strongly
recommend the use of [Cellpose](https://www.cellpose.org) for the segmentation part, as it provides excellent quality results and a standard output format
accepted by Svetlana (labels masks). 

If you use this plugin please cite the [paper](https://hal.inria.fr/hal-03927879): 

Cazorla, C., Weiss, P., & Morin, R. (2023). Svetlana: a Supervised Segmentation Classifier for Napari.

```bibtex
@unpublished{weiss:hal-03927879,
  TITLE = {{Svetlana: a Supervised Segmentation Classifier for Napari}},
  AUTHOR = {Weiss, Pierre and Cazorla, Cl{\'e}ment and Morin, Renaud},
  URL = {https://hal.inria.fr/hal-03927879},
  NOTE = {working paper or preprint},
  YEAR = {2023},
  MONTH = Jan,
  PDF = {https://hal.inria.fr/hal-03927879/file/main_nature.pdf},
  HAL_ID = {hal-03927879},
  HAL_VERSION = {v1},
}

```


![](https://bitbucket.org/koopa31/napari_svetlana/raw/bca8788111b38d97bd172c7caac87cc488ace699/images/Videogif.gif)


----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/stable/index.html
-->

## Installation

First install Napari in a Python 3.9 Conda environment following these instructions :

```bash
conda create -n svetlana_env python=3.9
conda activate svetlana_env
conda install pip
python -m pip install ""napari[all]""==0.4.17
```

Then, you can install `napari_svetlana` via [pip](https://pypi.org/project/napari-svetlana/), or directly from the Napari plugin manager (see Napari documentation):
```bash
pip install napari_svetlana
```
WARNING:

If you have a Cuda compatible GPU on your computer, some computations may be accelerated
using [Cupy](https://pypi.org/project/cupy/). Unfortunately, Cupy needs Cudatoolkit to be installed. This library can only be installed via 
Conda while the plugin is a pip plugin, so it must be installed manually for the moment:
```bash
conda install cudatoolkit=10.2 
```
Also note that the library ([Cucim](https://pypi.org/project/cucim/)) that we use to improve these performances, computing morphological operations on GPU
is unfortunately only available for Linux systems. Hence, if you are a Windows user, this installation is not necessary.

## Tutorial

Many advanced features are available in Svetlana, such as data augmentation or contextual information reduction, to optimize the performance of your classifier. Thus, we strongly encourage you to
check our [Youtube tutorial](https://www.youtube.com/watch?v=u_FKuHta-RE) and
our [documentation](https://svetlana-documentation.readthedocs.io/en/latest/).
A button called **TRY ON DEMO IMAGE** is available in the annotation plugin and enables you to apply the YouTube
tutorial to the same test images to learn how to use the plugin. Feel free to try it to test all the features
that Svetlana offers.

## Similar Napari plugins

Joel Luethi developed a similar method for objects classification called [napari feature classifier](https://www.napari-hub.org/plugins/napari-feature-classifier).
Also, [apoc](https://www.napari-hub.org/plugins/napari-accelerated-pixel-and-object-classification) by Robert Haase is available in Napari for pixels and objects classification.

## Contributing

Contributions are very welcome.

## License

Distributed under the terms of the [BSD-3] license,
""napari_svetlana"" is free and open source software

## Acknowledgements

The method was developed by [Clément Cazorla](https://koopa31.github.io/), [Renaud Morin](https://www.linkedin.com/in/renaud-morin-6a42665b/?originalSubdomain=fr) and [Pierre Weiss](https://www.math.univ-toulouse.fr/~weiss/). And the plugin was written by
Clément Cazorla. The project is co-funded by [Imactiv-3D](https://www.imactiv-3d.com/) and [CNRS](https://www.cnrs.fr/fr).

## Issues

If you encounter any problems, please [file an issue](https://bitbucket.org/koopa31/napari_svetlana/issues?status=new&status=open) along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: GNU General Public License v3 (GPLv3)']","['Bug Tracker, https://bitbucket.org/koopa31/napari_svetlana/issues?status=new&status=open', 'Documentation, https://svetlana-documentation.readthedocs.io/en/latest/', 'Source Code, https://bitbucket.org/koopa31/napari_svetlana/src/main/', 'User Support, https://bitbucket.org/koopa31/napari_svetlana/issues?status=new&status=open']",napari-svetlana.get_reader,napari-svetlana.write_image,napari-svetlana.Annotation,,['*.npy'],,,https://pypi.org/project/napari-svetlana,,
313,napari SVG,0.1.10,2020-06-03,2023-06-27,napari-svg,Nicholas Sofroniew,sofroniewn@gmail.com,BSD-3,https://github.com/napari/napari-svg,A plugin for reading and writing svg files with napari,>=3.7,"['imageio (>=2.5.0)', 'numpy (>=1.16.0)', 'napari-plugin-engine (>=0.1.4)', 'vispy (>=0.6.4)', ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""napari (>=0.4) ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-svg

[![License](https://img.shields.io/pypi/l/napari-svg.svg?color=green)](https://github.com/napari/napari-svg/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-svg.svg?color=green)](https://pypi.org/project/napari-svg)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-svg.svg?color=green)](https://python.org)
[![tests](https://github.com/napari/napari-svg/workflows/tests/badge.svg)](https://github.com/napari/napari-svg/actions)
[![codecov](https://codecov.io/gh/napari/napari-svg/branch/master/graph/badge.svg)](https://codecov.io/gh/napari/napari-svg)

A plugin for reading and writing svg files with napari

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/docs/plugins/index.html
-->

## Installation

You can install `napari-svg` via [pip]:

    pip install napari-svg

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-svg"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/napari/napari-svg/issues
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 4 - Beta', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']",,,napari-svg.svg_writer,,,,['.svg'],,https://pypi.org/project/napari-svg,https://github.com/napari/napari-svg,
314,napari-tabu,0.1.5,2022-02-02,2023-06-18,napari-tabu,Robert Haase,robert.haase@tu-dresden.de,BSD-3-Clause,https://github.com/haesleinhuepf/napari-tabu,A plugin for handling multiple napari windows,>=3.7,"['napari-plugin-engine (>=0.1.4)', 'numpy', 'napari', 'napari-tools-menu']","# napari-tabu

[![License](https://img.shields.io/pypi/l/napari-tabu.svg?color=green)](https://github.com/haesleinhuepf/napari-tabu/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-tabu.svg?color=green)](https://pypi.org/project/napari-tabu)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-tabu.svg?color=green)](https://python.org)
[![tests](https://github.com/haesleinhuepf/napari-tabu/workflows/tests/badge.svg)](https://github.com/haesleinhuepf/napari-tabu/actions)
[![codecov](https://codecov.io/gh/haesleinhuepf/napari-tabu/branch/master/graph/badge.svg)](https://codecov.io/gh/haesleinhuepf/napari-tabu)

A plugin for handling multiple napari windows
![](https://github.com/haesleinhuepf/napari-tabu/raw/main/docs/napari-tabu-screencast.gif)

----------------------------------

## Usage

To open a new window, first click the menu `Plugins > napari-tabu: open new window`
![](https://github.com/haesleinhuepf/napari-tabu/raw/main/docs/new_window_menu.png)

Afterwards, select the layer which should be opened in the new window and click on `Run`:
![](https://github.com/haesleinhuepf/napari-tabu/raw/main/docs/new_window_dialog.png)

When you're done with working with the new window, you can send back the result of your work using the `Send current layer back to main napari` butoon:
![](https://github.com/haesleinhuepf/napari-tabu/raw/main/docs/send_back.png)

This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.

## Installation

You can install `napari-tabu` via [pip]:

    pip install napari-tabu

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-tabu"" is free and open source software

## Issues

If you encounter any problems, please open a thread on [image.sc](https://image.sc) along with a detailed description and tag [@haesleinhuepf](https://github.com/haesleinhuepf).

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/haesleinhuepf/napari-tabu/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/


","['Development Status :: 3 - Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Scientific/Engineering :: Image Processing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/haesleinhuepf/napari-tabu/issues', 'Documentation, https://github.com/haesleinhuepf/napari-tabu#README.md', 'Source Code, https://github.com/haesleinhuepf/napari-tabu', 'User Support, https://github.com/haesleinhuepf/napari-tabu/issues']",,,napari-tabu.napari_experimental_provide_function,,,,,https://pypi.org/project/napari-tabu,https://github.com/haesleinhuepf/napari-tabu,
315,napari-text-layer,0.1.2,2022-01-29,2023-06-18,napari-text-layer,Hanjin Liu,liuhanjin-sc@g.ecc.u-tokyo.ac.jp,BSD 3-Clause,https://pypi.org/project/napari-text-layer/,Text layer for bio-image annotation.,>=3.7,,"# napari-text-layer

Napari text layer for bio-image annotation.

![](https://github.com/hanjinliu/napari-text-layer/raw/main/GIFs/annot.gif)

![](https://github.com/hanjinliu/napari-text-layer/raw/main/GIFs/age.gif)

### Installation

You can install using pip:

```
pip install napari-text-layer
```

### Keybindings and mouse callbacks

- ""&rarr;"", ""&larr;"", ""&uarr;"", ""&darr;"" ... Move selected shapes by 1 pixel.
- ""F2"" ... Enter edit mode at the selected shape (or the last one if no shape is selected).
- ""Enter"" ... Finish edit mode or add a new shape at the same interval.
- ""Ctrl"" + ""Shift"" + ""<"" or "">"" ... Change font size.
- double click ... Enter edit mode at the clicked shape.


","['Framework :: napari', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9']",,,,napari-text-layer.TextLayerOverview,,,,,https://pypi.org/project/napari-text-layer/,,
316,napari-threedee,0.0.18,2022-10-24,2024-04-29,napari-threedee,napari team,napari-steering-council@googlegroups.com,BSD-3-Clause,https://github.com/alisterburt/napari-threedee,A suite of useful tools based on 3D interactivity in napari,>=3.8,"['einops', 'imageio !=2.11.0,!=2.22.1,>=2.5.0', 'libigl', 'magicgui', 'napari', 'numpy', 'pandas', 'psygnal', 'pydantic', 'qtpy', 'scipy', 'superqt', 'vispy', 'zarr', 'morphosamplers', ""lxml[html_clean] >5 ; extra == 'dev'"", ""mkdocs ; extra == 'dev'"", ""mkdocs-gallery >0.7.6 ; extra == 'dev'"", ""mkdocs-material ; extra == 'dev'"", ""mkdocstrings[python] ; extra == 'dev'"", ""mkdocs-video ; extra == 'dev'"", ""napari[all] ; extra == 'dev'"", ""pytest ; extra == 'dev'"", ""pytest-qt ; extra == 'dev'"", ""qtgallery ; extra == 'dev'"", ""scikit-image[data] ; extra == 'dev'""]","# napari-threedee

[![License](https://img.shields.io/pypi/l/napari-threedee.svg?color=green)](https://github.com/alisterburt/napari-threedee/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-threedee.svg?color=green)](https://pypi.org/project/napari-threedee)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-threedee.svg?color=green)](https://python.org)
[![tests](https://github.com/napari-threedee/napari-threedee/workflows/tests/badge.svg)](https://github.com/napari-threedee/napari-threedee/actions)
[![codecov](https://codecov.io/gh/napari-threedee/napari-threedee/branch/main/graph/badge.svg)](https://codecov.io/gh/napari-threedee/napari-threedee)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-threedee)](https://napari-hub.org/plugins/napari-threedee)

A suite of useful tools based on 3D interactivity in napari

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/docs/plugins/index.html
-->

## Installation

You can install `napari-threedee` via [pip]:

    pip install napari-threedee



To install latest development version :

    pip install git+https://github.com/alisterburt/napari-threedee.git

## Example applications

See the full list of [example gallery scripts here on our website](https://napari-threedee.github.io/generated/gallery/).

<table border=""0"">
<tr><td>


<img src=""https://user-images.githubusercontent.com/1120672/173021751-9206de7d-5675-4aac-aa9e-8585457a7799.gif""
width=""300""/>

</td><td>

[mesh lighting control](https://github.com/napari-threedee/napari-threedee/blob/main/docs/examples/plugin/mesh_headlight_plugin.py)

</td></tr><tr><td>

<img src=""https://user-images.githubusercontent.com/1120672/173022286-2473b6b2-a20e-4514-88a4-8295e001f099.gif""
width=""300""/>

</td><td>

[annotate points on planes](https://github.com/napari-threedee/napari-threedee/blob/main/docs/examples/plugin/point_annotator_plugin.py)

</td></tr><tr><td>

<img src=""https://user-images.githubusercontent.com/1120672/173023185-b6936d1d-590c-4b9b-816a-3779dfe774da.gif""
width=""300""/>

</td><td>

[render plane manipulator](https://github.com/napari-threedee/napari-threedee/blob/main/docs/examples/plugin/render_plane_manipulator_plugin.py)

</td></tr><tr><td>

<img src=""https://user-images.githubusercontent.com/1120672/173023795-7150d3c2-d3d1-4913-981d-1092c1b59f21.gif""
width=""300""/>

</td><td>

[layer manipulator](https://github.com/napari-threedee/napari-threedee/blob/main/docs/examples/plugin/layer_manipulator_plugin.py)

</td></tr><tr><td>

<img src=""https://user-images.githubusercontent.com/1120672/173024361-2f05c68b-e94d-4734-9f5e-1606391e6463.gif""
width=""300""/>

</td><td>

[point manipulator](https://github.com/napari-threedee/napari-threedee/blob/main/docs/examples/plugin/points_manipulator_plugin.py)


</td></tr></table>


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-threedee"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/alisterburt/napari-threedee/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/napari-threedee/napari-threedee/issues', 'Documentation, https://github.com/napari-threedee/napari-threedee#README.md', 'Source Code, https://github.com/napari-threedee/napari-threedee', 'User Support, https://github.com/napari-threedee/napari-threedee/issues']",napari-threedee.read_n3d,napari-threedee.write_n3d,napari-threedee.QtPointAnnotatorWidget,,['*.n3d'],['.n3d'],,https://pypi.org/project/napari-threedee,https://github.com/alisterburt/napari-threedee,
317,napari-tiff,0.1.2,,,napari-tiff,"Genevieve Buckley, napari-tiff contributors",napari core developers <napari-core-devs@googlegroups.com>,"
Copyright (c) 2020, Genevieve Buckley
All rights reserved.

Redistribution and use in source and binary forms, with or without
modification, are permitted provided that the following conditions are met:

* Redistributions of source code must retain the above copyright notice, this
  list of conditions and the following disclaimer.

* Redistributions in binary form must reproduce the above copyright notice,
  this list of conditions and the following disclaimer in the documentation
  and/or other materials provided with the distribution.

* Neither the name of napari-tiff nor the names of its
  contributors may be used to endorse or promote products derived from
  this software without specific prior written permission.

THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""
AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
",,official napari tiff reader and writer.,>=3.10,"['imagecodecs', 'numpy', 'tifffile >=2020.5.7', 'vispy', ""tox ; extra == 'dev'"", ""build ; extra == 'dev'"", ""pytest ; extra == 'testing'""]","# napari-tiff

[![License](https://img.shields.io/pypi/l/napari-tiff.svg?color=green)](https://github.com/napari/napari-tiff/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-tiff.svg?color=green)](https://pypi.org/project/napari-tiff)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-tiff.svg?color=green)](https://python.org)
[![tests](https://github.com/GenevieveBuckley/napari-tiff/workflows/tests/badge.svg)](https://github.com/GenevieveBuckley/napari-tiff/actions)
[![codecov](https://codecov.io/gh/GenevieveBuckley/napari-tiff/branch/master/graph/badge.svg)](https://codecov.io/gh/GenevieveBuckley/napari-tiff)

A napari plugin for tiff images.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/docs/plugins/index.html
-->

## Installation

You can install `napari-tiff` via [pip]:

    pip install napari-tiff

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-tiff"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/GenevieveBuckley/napari-tiff/issues
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 3 - Alpha', 'Intended Audience :: Developers', 'Intended Audience :: Education', 'Intended Audience :: Science/Research', 'Framework :: napari', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Topic :: Software Development :: Libraries', 'Topic :: Scientific/Engineering', 'Programming Language :: Python :: Implementation :: CPython', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['source, https://github.com/napari/napari-tiff', 'tracker, https://github.com/napari/napari-tiff/issues']",napari-tiff.get_reader,,,,"['*.tiff', '*.tif', '*.zip']",,,https://pypi.org/project/napari-tiff,,
318,napari TileDB bioimaging,0.0.1,2023-12-08,2023-12-08,napari-tiledb-bioimg,"TileDB, Inc.",help@tiledb.io,MIT,https://pypi.org/project/napari-tiledb-bioimg,Support reading and writing TileDB-Bioimaging image arrays within Napari,>=3.8,"['dask', 'tiledb-bioimg (>=0.2.1)', ""tiledb-cloud ; extra == 'cloud'"", ""napari ; extra == 'testing'"", ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'""]","# napari-tiledb-bioimg

[![License MIT](https://img.shields.io/pypi/l/napari-tiledb-bioimg.svg?color=green)](https://github.com/TileDB-Inc/napari-tiledb-bioimg/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-tiledb-bioimg.svg?color=green)](https://pypi.org/project/napari-tiledb-bioimg)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-tiledb-bioimg.svg?color=green)](https://python.org)
[![tests](https://github.com/TileDB-Inc/napari-tiledb-bioimg/workflows/tests/badge.svg)](https://github.com/TileDB-Inc/napari-tiledb-bioimg/actions)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-tiledb-bioimg)](https://napari-hub.org/plugins/napari-tiledb-bioimg)

This plugin supports reading and writing TileDB-BioImaging multi-resolution arrays within Napari.

----------------------------------

## Demo

https://github.com/TileDB-Inc/napari-tiledb-bioimg/assets/327706/b408d634-6ad0-4160-8571-18cf8e37b4cc

## Installation

[pending PyPI release!] You can install `napari-tiledb-bioimg` via [pip]:

    pip install napari-tiledb-bioimg

## Quickstart

After [ingesting data using `tiledb-bioimg`](https://github.com/TileDB-Inc/TileDB-BioImaging#examples), then:

- Local images can be loaded using Napari's `File -> Open Folder`, and selecting the TileDB array folder. Choose the `napari-tiledb-bioimg` plugin, if prompted.

- Remote arrays (S3, TileDB Cloud) may be loaded using either the `napari` CLI command:

```
napari --plugin napari-tiledb-bioimg s3://<bucket>/<path/to/tiledb_array>
```

- ... or the Napari viewer load command within the Python prompt:

```
# Within a Napari-enabled Python/IPython prompt, run:
import napari
viewer = napari.Viewer()

viewer.open(""tiledb://<namespace>/<array name or UUID>"", plugin=""napari-tiledb-bioimg"")
```


## Contributing

Contributions are very welcome. Tests can be run with tox or pytest.

### Installation from git:

```
pip install git+https://github.com/TileDB-Inc/napari-tiledb-bioimg.git
```

## License

Distributed under the terms of the [MIT] license,
""napari-tiledb-bioimg"" is free and open source software.

## Issues

If you encounter any problems, please [file an issue](https://github.com/TileDB-Inc/napari-tiledb-bioimg/issues/new) along with a detailed description.
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: MIT License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']",,napari-tiledb-bioimg.get_reader,napari-tiledb-bioimg.write_image_lossless,napari-tiledb-bioimg.make_qwidget,,"['tiledb://*', 's3://*', '*.tdb', '*.tiledb']",,,https://pypi.org/project/napari-tiledb-bioimg,,
319,napari-tiler,0.0.9,2022-02-17,2023-06-18,napari-tiler,Tim Morello,tdmorello@gmail.com,LICENCE,https://pypi.org/project/napari-tiler/,N-dimensional tiling and merging support for napari,">=3.7,<3.11","['importlib-metadata (<4.3); python_version < ""3.8""', 'napari-plugin-engine (>=0.2.0,<0.3.0)', 'napari-tools-menu (>=0.1.7,<0.2.0)', 'numpy (>=1.21.4,<2.0.0)', 'tiler (>=0.4.1,<0.5.0)']","# napari-tiler

[![License](https://img.shields.io/pypi/l/napari-tiler.svg?color=green)](https://github.com/tdmorello/napari-tiler/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-tiler.svg?color=green)](https://pypi.org/project/napari-tiler)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-tiler.svg?color=green)](https://python.org)
[![tests](https://github.com/tdmorello/napari-tiler/workflows/tests/badge.svg)](https://github.com/tdmorello/napari-tiler/actions)
[![codecov](https://codecov.io/gh/tdmorello/napari-tiler/branch/main/graph/badge.svg)](https://codecov.io/gh/tdmorello/napari-tiler)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-tiler)](https://napari-hub.org/plugins/napari-tiler)
[![PyPI - Downloads](https://img.shields.io/pypi/dm/napari-tiler.svg)](https://pypistats.org/packages/napari-tiler)
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/python/black)
[![Development Status](https://img.shields.io/pypi/status/napari-tiler.svg)](https://github.com/tdmorello/napari-tiler)

N-dimensional tiling and merging support for napari

This plugin allows the user to split an image into a stack of tiles and subsequently merge the tiles to reconstruct the orignal image.
See [Tiler](https://pypi.org/project/tiler/) by [@thelay](https://github.com/the-lay) for more details.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/stable/index.html
-->

## Installation

### Option 1 (recommended)

You can install `napari-tiler` from the napari plugin manager. Go to `Plugins -> Install/Uninstall Package(s)`, then search for `napari-tiler`. Click `Install`.

### Option 2

You can also install `napari-tiler` via [pip]:

    pip install napari-tiler

To install latest development version:

    pip install git+https://github.com/tdmorello/napari-tiler.git

## Quick Start

1. Open a file in napari. The file may have any number of dimensions (e.g. z-stack, time series, ...)
2. Start the plugin ( `Plugins -> napari-tiler: make_tiles` )
3. Select the input layer from the dropdown box
4. Select parameters for tiling
5. Click `Run`

## Contributing

This project uses [Poetry](https://github.com/python-poetry/poetry) for dependency management.
To set up the development environment, it is recommended to use:

    conda env create -f environment.yaml

Contributions are very welcome. Tests can be run with [tox], please ensure the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-tiler"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/tdmorello/napari-tiler/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/

","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'License :: Other/Proprietary License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Topic :: Software Development :: Testing']","['Bug Tracker, https://github.com/tdmorello/napari-tiler/issues', 'Documentation, https://github.com/tdmorello/napari-tiler#README.md', 'Source Code, https://github.com/tdmorello/napari-tiler', 'User Support, https://github.com/tdmorello/napari-tiler/issues']",,,napari-tiler.TilerWidget,,,,,https://pypi.org/project/napari-tiler/,,
320,TSP,0.0.6,2022-02-01,2023-07-25,napari-time-series-plotter,Christopher Nauroth-Kress,nauroth_C@ukw.de,BSD-3-Clause,https://github.com/ch-n/napari-time_series_plotter,"A Plugin for napari to visualize pixel values over the first dimension (time -> t+3D, t+2D) as graphs.",>=3.8,"['napari-matplotlib (<1.0)', 'numpy', 'pandas', 'qtpy', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-time_series_plotter

[![License](https://img.shields.io/pypi/l/napari-time_series_plotter.svg?color=green)](https://github.com/ch-n/napari-time_series_plotter/raw/main/LICENSE)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-time_series_plotter.svg?color=green)](https://python.org)
[![PyPI](https://img.shields.io/pypi/v/napari-time_series_plotter.svg?color=blue)](https://pypi.org/project/napari-time_series_plotter)
[![Anaconda-Server Badge](https://anaconda.org/conda-forge/napari-time-series-plotter/badges/version.svg)](https://anaconda.org/conda-forge/napari-time-series-plotter)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-time-series-plotter)](https://napari-hub.org/plugins/napari-time-series-plotter)
[![tests](https://github.com/ch-n/napari-time_series_plotter/workflows/tests/badge.svg)](https://github.com/ch-n/napari-time_series_plotter/actions)
[![codecov](https://codecov.io/gh/ch-n/napari-time_series_plotter/branch/main/graph/badge.svg)](https://codecov.io/gh/ch-n/napari-time_series_plotter)


## Description
Napari-time_series_plotter (TSP) is a plugin for the `napari` ndimensional image viewer. 

**TSP** adds live plotting of time-resolved images to napari. You can select and visualize pixel/voxel or ROI mean values from one or multiple image layers as intensity-over-time line plots (The first image dimension is handled as time) and save the figures or the underlying time series data as CSV file. TSP supports 3D to nD images (3D: t+2D, nD: t+nD).

**Plotting** is handeled by the `Explorer` widget, it offers three different plotting modes: Voxel, Shapes, Points
<br>--> Voxel mode offers live plotting while moving the cursor over an image layer
<br>--> Shapes mode offers shape-based ROI plotting the ROI combination method can be one of [Mean, Median, STD, Sum, Min, Max]; multiple ROIs can be plotted simultaneously
<br>--> Points mode offers simultaneous, point-based plotting of multiple voxels
<br>You can modify and save the plots through the canvas toolbar.
<br>Plotting powered by `napari-matplotlib`.

**Viewing** the time series as a table is handled by the `Inspector` widget. You can load the data you've plotted and inspect the single time point values of each selection. The columns are named like the plots in the `Explorer`. You can copy the whole tabe or a selection to the clipboard or directly expot it to a CSV file to save the time series.

----------------------------------

## Installation
You can either install the latest version via pip or conda.

**pip:**

    pip install napari-time-series-plotter

or download the packaged `tar.gz` file from the release assets and install it with 
    
    pip install /path/to/file.tar.gz

**conda:**

    conda install -c conda-forge napari-time-series-plotter


Alternatively, you can install the plugin directly in the `napari` viewer plugin manager, the napari hub, or the release assets.

<br>

To install the latest development version install directly from the relevant GitHub branch.

## Usage
### Basics and Live plotting

[![basic_demo](./demo_videos/TSP_basic_and_voxel_plotting_demo.jpg)](./demo_videos/TSP_basic_and_voxel_plotting_demo.webm)
    
1. Select the `TSPExplorer` widget in the `Plugins` tab of the napari viewer
2. Use the `LayerSelector` to choose the image layers you want to source for plotting
3. Move the corsor over the layer while holding ""Shift""

The `Options` tab offers multiple options to customize your plot. 
- Set custom title or axe labels
- Switch between autoscaling and manually defined max and min values of the axes
- Switch to label truncation in the options tab if your layer names are too long for the figure legend (set max length manually)
- Set a scaling factor for the X-axis

The plot can be modified and saved through its toolbar above.

### Plotting ROIs

[![roi_demo](./demo_videos/TSP_ROI_plotting_demo.jpg)](./demo_videos//TSP_ROI_plotting_demo.webm)

1. Select the Shapes plotting mode via the `Options` tab (Voxel mode is the default).
2. Use the `LayerSelector` to choose the image layers you want to source for plotting.
2. Add one ore more shapes to the ""ROI Selection"" layer.
   <br>The ""ROI Selection"" shapes are 2D only, effecting the currently displayed slice.
   <br>(newly added shapes might have to be moved before they are correctly plottet)
3. Reposition or remove shapes if needed.
4. Change the ROI mode in the `Options` tab (Default: mean).

### Plotting multiple Points

[![points_demo](./demo_videos/TSP_Points_plotting_demo.jpg)](./demo_videos/TSP_Points_plotting_demo.webm)

1. Select the Shapes plotting mode via the `Options` tab (Voxel mode is the default).
2. Use the `LayerSelector` to choose the image layers you want to source for plotting.
3. Add one or more points to the ""Point selection"" layer.
   <br>The points can be on different slices (3D and 4D support only) or images (grid mode)
4. Reposition or remove points if needed.

### View time series as table

[![points_demo](./demo_videos/TSP_Inspector_demo.jpg)](./demo_videos/TSP_Inspector_demo.webm)

1. Select the `TSPInspector` widget in the `Plugins` tab of the napari viewer
2. Press the load from plot button to load the currently displayed plots into the `Inspector`

You can copy the whole table or a selection to your clipboard or export it to CSV file through the buttons above.

## ToDo (help welcome)
- [ ] Add Sphinx documentation

## Version 0.1.0 Milestones
- [X] Update to napari-plugin-engine2 [#5](https://github.com/ch-n/napari-time_series_plotter/issues/5)
- [X] Update widget GUI [#6](https://github.com/ch-n/napari-time_series_plotter/issues/6)
- [x] Add widget to save pixel/voxel time series to file [#7](https://github.com/ch-n/napari-time_series_plotter/issues/7)
- [X] Add ROI and multi-voxel plotting [#14](https://github.com/ch-n/napari-time_series_plotter/issues/14)
- [ ] Evaluate and close remaining issues ([#22](https://github.com/ch-n/napari-time_series_plotter/issues/22), [#25](https://github.com/ch-n/napari-time_series_plotter/issues/25),)

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-time_series_plotter"" is free and open-source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

--------------

## References
This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

Images used in the demo gif were taken from [The Cancer Imaging Archive] <br>

    DOI: https://doi.org/10.7937/K9/TCIA.2015.VOSN3HN1
    Images: 1.3.6.1.4.1.9328.50.16.281868838636204210586871132130856898223
            1.3.6.1.4.1.9328.50.16.254461916058189583774506642993503110733

[The Cancer Imaging Archive]: https://www.cancerimagingarchive.net/
[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/ch-n/napari-time_series_plotter/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/ch-n/napari-time_series_plotter/issues', 'Documentation, https://github.com/ch-n/napari-time_series_plotter#README.md', 'Source Code, https://github.com/ch-n/napari-time_series_plotter', 'User Support, https://github.com/ch-n/napari-time_series_plotter/issues']",,,napari-time-series-plotter.Explorer,,,,,https://pypi.org/project/napari-time-series-plotter,https://github.com/ch-n/napari-time_series_plotter,
321,napari-time-slicer,0.5.0,2022-02-02,2023-11-12,napari-time-slicer,Robert Haase,robert.haase@tu-dresden.de,BSD-3-Clause,https://github.com/haesleinhuepf/napari-time-slicer,A meta plugin for processing timelapse data in napari timepoint by timepoint,>=3.8,"['napari-plugin-engine >=0.1.4', 'numpy', 'toolz', 'napari-tools-menu', 'napari-workflows']","# napari-time-slicer

[![License](https://img.shields.io/pypi/l/napari-time-slicer.svg?color=green)](https://github.com/haesleinhuepf/napari-time-slicer/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-time-slicer.svg?color=green)](https://pypi.org/project/napari-time-slicer)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-time-slicer.svg?color=green)](https://python.org)
[![tests](https://github.com/haesleinhuepf/napari-time-slicer/workflows/tests/badge.svg)](https://github.com/haesleinhuepf/napari-time-slicer/actions)
[![codecov](https://codecov.io/gh/haesleinhuepf/napari-time-slicer/branch/main/graph/badge.svg)](https://codecov.io/gh/haesleinhuepf/napari-time-slicer)
[![Development Status](https://img.shields.io/pypi/status/napari-time-slicer.svg)](https://en.wikipedia.org/wiki/Software_release_life_cycle#Alpha)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-time-slicer)](https://napari-hub.org/plugins/napari-time-slicer)

A meta plugin for processing timelapse data timepoint by timepoint. It 
enables a list of napari plugins to process 2D+t or 3D+t data step by step when the user goes 
through the timelapse. Currently, these plugins are using `napari-time-slicer`:
* [napari-segment-blobs-and-things-with-membranes](https://www.napari-hub.org/plugins/napari-segment-blobs-and-things-with-membranes)
* [napari-cupy-image-processing](https://www.napari-hub.org/plugins/napari-cupy-image-processing)
* [napari-pyclesperanto-assistant](https://www.napari-hub.org/plugins/napari-pyclesperanto-assistant)
* [napari-accelerated-pixel-and-object-classification](https://www.napari-hub.org/plugins/napari-accelerated-pixel-and-object-classification)
* [napari-simpleitk-image-processing](https://www.napari-hub.org/plugins/napari-simpleitk-image-processing)
* [napari-stress](https://www.napari-hub.org/plugins/napari-stress)
* [napari-process-points-and-surfaces](https://www.napari-hub.org/plugins/napari-process-points-and-surfaces)

`napari-time-slicer` enables inter-plugin communication, e.g. allowing to combine the plugins listed above in 
one image processing workflow for segmenting a timelapse dataset:

![](https://github.com/haesleinhuepf/napari-time-slicer/raw/main/images/screencast1.gif)

The workflow can then also be exported as a script. The 'Generate Code' button can be found in the [Workflow Inspector](https://www.napari-hub.org/plugins/napari-workflow-inspector)


If you want to convert a 3D dataset into a 2D + time dataset, use the 
menu `Tools > Utilities > Convert 3D stack to 2D timelapse (time-slicer)`. It will turn the 3D dataset to a 4D datset
where the Z-dimension (index 1) has only 1 element, which will in napari be displayed with a time-slider. Note: It is 
recommended to remove the original 3D dataset after this conversion.

## Working with large on-the-fly processed datasets

Using the [napari-assistant](https://www.napari-hub.org/plugins/napari-assistant) complex image processing workflows on timelapse datasets can be setup. 
In combination with the time-slicer it is possible to process time-lapse data that is larger than available computer memory.
In case the workflow only consists of images and label-images and out-of-memory issues arise, consider storing intermediate results on disk following this procedure: 
After setting up the workflow and testing it on a couple of selected frames, store the entire processed timelapse dataset to disk 
using the menu `Tools > Utilities > Convert to file-backed timelapse data (time-slicer)`. It will open this dialog, where you can select 
![img.png](https://github.com/haesleinhuepf/napari-time-slicer/raw/main/images/convert_to_file_backed_timelapse.png)

It is recommended to enter a folder location in the text field. 
If not provided, a temporary folder will be created, typically in the User's temp folder in the home directory. 
The user is responsible for emptying this folder from time to time.
The data stored in this folder can also be loaded into napari using its `File > Open Folder...` menu.

Executing this operation can take time as every timepoint of the timelapse is computed. 
Afterwards, there will be another layer available in napari, which is typically faster to navigate through. 
Consider removing the layer(s) that were only needed to determine the new file-backed layer.

![img.png](https://github.com/haesleinhuepf/napari-time-slicer/raw/main/images/new_file_backed_layer.png)

## Usage for plugin developers

Plugins which implement the `napari_experimental_provide_function` hook can make use of the `@time_slicer`. At the moment,
only functions which take `napari.types.ImageData`, `napari.types.LabelsData` and basic python types such as `int` 
and `float` are supported. If you annotate such a function with `@time_slicer` it will internally convert any 4D dataset
to a 3D dataset according to the timepoint currently selected in napari. Furthermore, when the napari user changes the
current timepoint or the input data of the function changes, a re-computation is invoked. Thus, it is recommended to 
only use the `time_slicer` for functions which can provide [almost] real-time performance. Another constraint is that 
these annotated functions have to have a `viewer` parameter. This is necessary to read the current timepoint from the 
viewer when invoking the re-computions.

Example
```python
import napari
from napari_time_slicer import time_slicer

@time_slicer
def threshold_otsu(image:napari.types.ImageData, viewer: napari.Viewer = None) -> napari.types.LabelsData:
    # ...
```

You can see a full implementations of this concept in the napari plugins listed above.

If you want to combine slicing in time and processing z-stack images slice-by-slice, you can use the `@slice_by_slice` annotation.
Make sure, to insert it after `@time_slicer` as shown below and implemented in [napari-pillow-image-processing](https://github.com/haesleinhuepf/napari-pillow-image-processing/blob/4d846b226739843124953f16059241d917cde8e1/src/napari_pillow_image_processing/__init__.py#L151)

```python
from napari_time_slicer import slice_by_slice

@time_slicer
@slice_by_slice
def blur_2d(image:napari.types.ImageData, sigma:float = 1, viewer: napari.Viewer = None) -> napari.types.LabelsData:
    # ...
```

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

## Installation

You can install `napari-time-slicer` via [pip]:

    pip install napari-time-slicer



To install latest development version :

    pip install git+https://github.com/haesleinhuepf/napari-time-slicer.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-time-slicer"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/haesleinhuepf/napari-time-slicer/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 3 - Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Scientific/Engineering :: Image Processing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/haesleinhuepf/napari-time-slicer/issues', 'Documentation, https://github.com/haesleinhuepf/napari-time-slicer#README.md', 'Source Code, https://github.com/haesleinhuepf/napari-time-slicer', 'User Support, https://github.com/haesleinhuepf/napari-time-slicer/issues']",,,napari-time-slicer.napari_experimental_provide_function,,,,,https://pypi.org/project/napari-time-slicer,https://github.com/haesleinhuepf/napari-time-slicer,
322,napari-timeseries-opener-plugin,0.1.8,2022-07-05,2023-06-18,napari-timeseries-opener-plugin,Niklas Netter,niknett@gmail.com,BSD-3-Clause,https://github.com/gatoniel/napari-timeseries-opener-plugin,Simple plugin that opens separate .tif files as a 3-dimensional layer.,>=3.7,"['napari-plugin-engine (>=0.1.4)', 'numpy', 'qtpy', 'magicgui', 'tifffile', 'stardist', 'tensorflow']","# napari-timeseries-opener-plugin

[![License](https://img.shields.io/pypi/l/napari-timeseries-opener-plugin.svg?color=green)](https://github.com/gatoniel/napari-timeseries-opener-plugin/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-timeseries-opener-plugin.svg?color=green)](https://pypi.org/project/napari-timeseries-opener-plugin)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-timeseries-opener-plugin.svg?color=green)](https://python.org)
[![tests](https://github.com/gatoniel/napari-timeseries-opener-plugin/workflows/tests/badge.svg)](https://github.com/gatoniel/napari-timeseries-opener-plugin/actions)
[![codecov](https://codecov.io/gh/gatoniel/napari-timeseries-opener-plugin/branch/main/graph/badge.svg)](https://codecov.io/gh/gatoniel/napari-timeseries-opener-plugin)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-timeseries-opener-plugin)](https://napari-hub.org/plugins/napari-timeseries-opener-plugin)

Simple plugin that opens separate .tif files as a 3-dimensional layer.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/stable/index.html
-->

## Run

In powershell run when you do not have sufficient GPU support in your environment
```
$env:CUDA_VISIBLE_DEVICES=-1; napari
```

## Installation

You can install `napari-timeseries-opener-plugin` via [pip]:

    pip install napari-timeseries-opener-plugin



To install latest development version :

    pip install git+https://github.com/gatoniel/napari-timeseries-opener-plugin.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-timeseries-opener-plugin"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/gatoniel/napari-timeseries-opener-plugin/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/gatoniel/napari-timeseries-opener-plugin/issues', 'Documentation, https://github.com/gatoniel/napari-timeseries-opener-plugin#README.md', 'Source Code, https://github.com/gatoniel/napari-timeseries-opener-plugin', 'User Support, https://github.com/gatoniel/napari-timeseries-opener-plugin/issues']",,,napari-timeseries-opener-plugin.LoadWidget,,,,,https://pypi.org/project/napari-timeseries-opener-plugin,https://github.com/gatoniel/napari-timeseries-opener-plugin,
323,Napari TissUUmaps,1.1.2,2022-02-10,2023-06-18,napari-tissuumaps,Nicolas Pielawski,nicolas@pielawski.fr,MIT,https://github.com/TissUUmaps/napari-tissuumaps,A plugin to export Napari projects to TissUUmaps.,>=3.8,"['numpy', ""napari ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""tox ; extra == 'testing'""]","# 🏝 napari-tissuumaps 🧫

[![License MIT](https://img.shields.io/pypi/l/napari-tissuumaps.svg?color=green)](https://github.com/npielawski/napari-tissuumaps/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-tissuumaps.svg?color=green)](https://pypi.org/project/napari-tissuumaps)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-tissuumaps.svg?color=green)](https://python.org)
[![tests](https://github.com/npielawski/napari-tissuumaps/workflows/tests/badge.svg)](https://github.com/npielawski/napari-tissuumaps/actions)
[![codecov](https://codecov.io/gh/npielawski/napari-tissuumaps/branch/main/graph/badge.svg)](https://codecov.io/gh/npielawski/napari-tissuumaps)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-tissuumaps)](https://napari-hub.org/plugins/napari-tissuumaps)

A plugin to export Napari projects to [TissUUmaps](https://tissuumaps.research.it.uu.se/).

----------------------------------

This plugins adds a new writer to [Napari] to export projects to [TissUUmaps](https://github.com/TissUUmaps/TissUUmaps). Exported projects can then be open on the browser or on a standalone GUI with [TissUUmaps](https://github.com/TissUUmaps/TissUUmaps). More information and demonstrations are available on the [TissUUmaps webpage](https://tissuumaps.research.it.uu.se/).

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## 🚀 Features

<p align=""center"">
  <img src=""images/screenshot.jpg"" alt=""Demonstration of a project exported from Napari to TissUUmaps."" width=""500"" />
</p>

The plugin now supports:

* Exporting images
* Exporting labels
* Exporting points
* Exporting shapes, including:
    * Polygons
    * Rectangles
    * Lines
    * Paths
    * Ellipses

The plugin exports the right color for the points, shapes and labels and also saves the visibility/opacity of each layers. The shapes are exported in the GeoJSON format, the points in CSV files, and images as TIFFs.

## 📺 Installation

You can install `napari-tissuumaps` via [pip]:

    pip install napari-tissuumaps

You can also install `napari-tissumaps` via [napari]:

In Napari, access the menubar, Plugins > Install/Uninstall Plugins.
Search for napari-tissuumaps in the list and choose install, or type
`napari-tissuumaps` in the ""install by name/url, or drop file..."" text area and choose
install.

## ⛏ Usage

To export a project for TissUUmaps, access the menubar, File > Save All Layers... and
type in a filename. Choose the `.tmap` extension in the dropdown and click on the Save
button, It will create a folder containing all the necessary files for TissUUmaps.

## 👩‍💻 Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## ⚖️ License

Distributed under the terms of the [MIT] license,
""napari-tissuumaps"" is free and open source software

## 🚒 Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: MIT License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Topic :: Scientific/Engineering :: Image Processing']",,,napari-tissuumaps.write_layers,,,,['.tmap'],,https://pypi.org/project/napari-tissuumaps,https://github.com/TissUUmaps/napari-tissuumaps,
324,Tomocube data viewer,2024.4,2023-04-19,2024-04-01,napari-tomocube-data-viewer,Dohyeon Lee,dleh428@kaist.ac.kr,MIT,https://github.com/ehgus/napari-tomocube-data-viewer,"""A plugin to visualize three-dimensional data from Tomocube's microscopy""",>=3.8,"['numpy', 'TCFile', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'""]","# napari-tomocube-data-viewer

[![License MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://github.com/ehgus/napari-tomocube-data-viewer/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-tomocube-data-viewer.svg?color=green)](https://pypi.org/project/napari-tomocube-data-viewer)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-tomocube-data-viewer)](https://napari-hub.org/plugins/napari-tomocube-data-viewer)

A plugin to visualize three-dimensional data from [Tomocube](https://www.tomocube.com/)'s holotomography

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-tomocube-data-viewer` via [pip] or [conda]:

    pip install napari-tomocube-data-viewer
    conda install napari-tomocube-data-viewer

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [MIT] license,
""napari-tomocube-data-viewer"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[conda]: https://docs.anaconda.com/free/miniconda/index.html
[file an issue]: https://github.com/ehgus/napari-tomocube-data-viewer/issues
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: MIT License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/ehgus/napari-tomocube-data-viewer/issues', 'Documentation, https://github.com/ehgus/napari-tomocube-data-viewer #README.md', 'Source Code, https://github.com/ehgus/napari-tomocube-data-viewer', 'User Support, https://github.com/ehgus/napari-tomocube-data-viewer/issues']",napari-tomocube-data-viewer.get_reader,,,,['*.TCF'],,,https://pypi.org/project/napari-tomocube-data-viewer,https://github.com/ehgus/napari-tomocube-data-viewer,
325,ToMoDL Reconstruction,0.1.16,,,napari-tomodl,"Marcos Antonio Obando, Germán Mato, Teresa Correia",marcos.obando@ib.edu.ar,MIT,,A plugin for optical projection tomography reconstruction with model-based neural networks.,<=3.9,"['magicgui', 'qtpy', 'napari[all]', 'pyqt5', 'phantominator', 'opencv-python', 'scikit-image', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-tomodl

[![License MIT](https://img.shields.io/pypi/l/napari-tomodl.svg?color=green)](https://github.com/marcoso96/napari-tomodl/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-tomodl.svg?color=green)](https://pypi.org/project/napari-tomodl)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-tomodl.svg?color=green)](https://python.org)
[![tests](https://github.com/marcoso96/napari-tomodl/workflows/tests/badge.svg)](https://github.com/marcoso96/napari-tomodl/actions)
[![codecov](https://codecov.io/gh/marcoso96/napari-tomodl/branch/main/graph/badge.svg)](https://codecov.io/gh/marcoso96/napari-tomodl)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-tomodl)](https://napari-hub.org/plugins/napari-tomodl)

A plugin for optical projection tomography reconstruction with model-based neural networks.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->
## Introduction and usage

ToMoDL allows users to reconstruct tomography images from its raw projections juts from uploading them as an ordered stack of files into the napari viewer.

1 - Load ordered stack: Click File -> Open Files as Stack... and load the angular projections for parallel beam optical tomography reconstruction.

![plot](https://raw.githubusercontent.com/marcoso96/ToMoDL/main/napari-tomodl/figures/fig3.png)

2 - Select the current volume in the dropdown menu with the button 'Select image layer'. Notice that the projections should be in grayscale and more than one slide in the stack.

![plot](https://raw.githubusercontent.com/marcoso96/ToMoDL/main/napari-tomodl/figures/fig4.png)

3 - If the axis is not correctly aligned in acquisition time, we provide an algorithm to do so by clicking on 'Align axis'. This will align the sinogram respect to the center of the detector in order to maximise the variance of the reconstructions. See Walls et al. 

4 - Reshape the reconstructed volume to a desired size. This can be useful to prevent exhausting your computing capabilities.

5 - Clip to circle should be False by default.

6 - Choose if filtering should be used. By the moment we only allow using ramp filtering for FBP only (both CPU and GPU).

7 - Choose the correct order of the axis of the projections (T -> Theta axis, Q -> Detector axis)

8 - Reconstruct! A new Layer should be created on top of the projections stack containing the reconstructed volume.

![plot](https://raw.githubusercontent.com/marcoso96/ToMoDL/main/napari-tomodl/figures/fig2.png)

## Installation

This package requires [torch-radon] for optimized GPU tomographic reconstruction:

    pip install 'torch-radon @ https://rosh-public.s3-eu-west-1.amazonaws.com/radon-v2/cuda-11.1/torch-1.8/torch_radon-2.0.0-cp38-cp38-linux_x86_64.whl'

and `PyTorch == 1.8.0` via wheel, which can be downloaded and installed with: 

    pip install 'torch @ https://download.pytorch.org/whl/cu111/torch-1.8.0%2Bcu111-cp38-cp38-linux_x86_64.whl'

You can install `napari-tomodl` via [pip]:

    pip install napari-tomodl




## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [MIT] license,
""napari-tomodl"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[napari]: https://github.com/napari/napari
[torch-radon]: https://github.com/matteo-ronchetti/torch-radon
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: MIT License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']",,,,napari-tomodl.make_reconstruct_widget,,,,,https://pypi.org/project/napari-tomodl,,
326,napari-tomoslice,0.0.7,2022-02-02,2023-06-18,napari-tomoslice,Alister Burt,alisterburt@gmail.com,BSD-3-Clause,https://github.com/alisterburt/napari-tomoslice,A napari plugin for interacting with electron cryotomograms,>=3.7,"['napari-plugin-engine (>=0.1.4)', 'numpy', 'napari (==0.4.12)', 'mrcfile', 'typer']","# napari-tomoslice

[![License](https://img.shields.io/pypi/l/napari-tomoslice.svg?color=green)](https://github.com/alisterburt/napari-tomoslice/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-tomoslice.svg?color=green)](https://pypi.org/project/napari-tomoslice)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-tomoslice.svg?color=green)](https://python.org)
[![tests](https://github.com/alisterburt/napari-tomoslice/workflows/tests/badge.svg)](https://github.com/alisterburt/napari-tomoslice/actions)
[![codecov](https://codecov.io/gh/alisterburt/napari-tomoslice/branch/master/graph/badge.svg)](https://codecov.io/gh/alisterburt/napari-tomoslice)

A napari plugin for visualising and interacting with electron cryotomograms.


## Installation

You can install `napari-tomoslice` via [pip]:

    pip install napari-tomoslice

## Usage

This plugin provides a user interface for opening electron cryotomograms in 
napari as both volumes and slices through volumes.

![demo](https://user-images.githubusercontent.com/7307488/138575305-b05c4735-9c03-4629-bfb0-9612ea8f26fd.gif)

The plugin can be opened from the `plugins` menu in napari, or with 
`napari-tomoslice` at the command line.

![plugins-menu](https://user-images.githubusercontent.com/7307488/138575015-00ea78d9-02c1-44bc-9034-0c0a7fa8d973.png)

```yaml
Usage: napari-tomoslice [TOMOGRAM_FILE]

  An interactive tomogram slice viewer in napari.

  Controls: 
  x/y/z - align normal vector along x/y/z axis 
  click and drag - shift plane along its normal vector
  alt-click - add point on plane (if points layer is active)
  o - align plane normal to view direction
  [] - decrease/increase plane thickness

Arguments:
  [TOMOGRAM_FILE]

Options:
  --help                          Show this message and exit.

```

## Contributing

Contributions are very welcome. 

## License

Distributed under the terms of the [BSD-3] license,
""napari-tomoslice"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/alisterburt/napari-tomoslice/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/


","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/alisterburt/napari-tomoslice/issues', 'Documentation, https://github.com/alisterburt/napari-tomoslice#README.md', 'Source Code, https://github.com/alisterburt/napari-tomoslice', 'User Support, https://github.com/alisterburt/napari-tomoslice/issues']",,,napari-tomoslice.TomoSliceWidget,,,,,https://pypi.org/project/napari-tomoslice,https://github.com/alisterburt/napari-tomoslice,
327,TomoTwin,0.4.0,2023-04-05,2023-12-08,napari-tomotwin,Thorsten Wagner,twa1@posteo.de,MPL-2.0,https://github.com/MPI-Dortmund/napari-tomotwin,Several tools for the work with TomoTwin,>=3.10,"['numpy', 'pandas', 'matplotlib', 'scipy', 'napari-clusters-plotter >=0.7.2', 'magicgui', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'""]","# napari-tomotwin

[![License Mozilla Public License 2.0](https://img.shields.io/pypi/l/napari-tomotwin.svg?color=green)](https://github.com/MPI-Dortmund/napari-tomotwin/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-tomotwin.svg?color=green)](https://pypi.org/project/napari-tomotwin)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-tomotwin.svg?color=green)](https://python.org)

Several tools for the work with TomoTwin :-)


## Installation

You can install `napari-tomotwin` via [pip]:

    pip install napari-tomotwin


## License

Distributed under the terms of the [Mozilla Public License 2.0] license,
""napari-tomotwin"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: Mozilla Public License 2.0 (MPL 2.0)', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']",,,,napari-tomotwin.UmapTool,,,,,https://pypi.org/project/napari-tomotwin,https://github.com/MPI-Dortmund/napari-tomotwin,
328,ToothFairy Annotator,0.0.16,2024-04-10,2024-04-24,napari-toothfairy-annotator,Luca Lumetti,lumetti.luca@gmail.com,MIT,https://github.com/LucaLumetti/napari-toothfairy-annotator,The plugin employed to annotate volumes employed in the ToothFairy 2 Challenge,>=3.8,"['numpy', 'magicgui', 'qtpy', 'scikit-image', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-toothfairy-annotator

[![License MIT](https://img.shields.io/pypi/l/napari-toothfairy-annotator.svg?color=green)](https://github.com/LucaLumetti/napari-toothfairy-annotator/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-toothfairy-annotator.svg?color=green)](https://pypi.org/project/napari-toothfairy-annotator)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-toothfairy-annotator.svg?color=green)](https://python.org)
[![tests](https://github.com/LucaLumetti/napari-toothfairy-annotator/workflows/tests/badge.svg)](https://github.com/LucaLumetti/napari-toothfairy-annotator/actions)
[![codecov](https://codecov.io/gh/LucaLumetti/napari-toothfairy-annotator/branch/main/graph/badge.svg)](https://codecov.io/gh/LucaLumetti/napari-toothfairy-annotator)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-toothfairy-annotator)](https://napari-hub.org/plugins/napari-toothfairy-annotator)

The plugin employed to annotate volumes employed in the ToothFairy 2 Challenge

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-toothfairy-annotator` via [pip]:

    pip install napari-toothfairy-annotator



To install latest development version :

    pip install git+https://github.com/LucaLumetti/napari-toothfairy-annotator.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [MIT] license,
""napari-toothfairy-annotator"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/LucaLumetti/napari-toothfairy-annotator/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: MIT License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/LucaLumetti/napari-toothfairy-annotator/issues', 'Documentation, https://github.com/LucaLumetti/napari-toothfairy-annotator#README.md', 'Source Code, https://github.com/LucaLumetti/napari-toothfairy-annotator', 'User Support, https://github.com/LucaLumetti/napari-toothfairy-annotator/issues']",napari-toothfairy-annotator.get_reader,napari-toothfairy-annotator.write_multiple,napari-toothfairy-annotator.annotator,,['*'],,['.npy'],https://pypi.org/project/napari-toothfairy-annotator,https://github.com/LucaLumetti/napari-toothfairy-annotator,
329,Napari Tracer Plugin,1.0.2,,,napari-tracing,Vasudha Jha,reachvasudha27@gmail.com,GPL-3.0-only,,A plugin to trace the brightest path between two points in an image,>=3.8,"['numpy', 'qtpy', 'brightest-path-lib', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-tracing

[![License GNU GPL v3.0](https://img.shields.io/pypi/l/napari-tracing.svg?color=green)](https://github.com/mapmanager/napari-tracing/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-tracing.svg?color=green)](https://pypi.org/project/napari-tracing)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-tracing.svg?color=green)](https://python.org)
<!-- [![tests](https://github.com/mapmanager/napari-tracing/workflows/tests/badge.svg)](https://github.com/mapmanager/napari-tracing/actions) -->
<!-- [![codecov](https://codecov.io/gh/mapmanager/napari-tracing/branch/main/graph/badge.svg)](https://codecov.io/gh/mapmanager/napari-tracing) -->
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-tracing)](https://napari-hub.org/plugins/napari-tracing)

## Napari Tracer Plugin

The `Napari Tracer Plugin` provides an intuitive interface for users to load images, perform brightest path tracing, and visualize the results. This plugin, which is built on top of the Napari viewer, enables users to explore and annotate complex images, and take advantage of the viewer's built-in features such as zooming, panning, and adjusting contrast while viewing their tracings. The `Napari Tracer Plugin` uses the brightest path tracing algorithms from [brightest-path-lib](https://github.com/mapmanager/brightest-path-lib) to provide an interactive path building process for users to create traced segments in 2D and 3D images.

## Examples

<video loop muted autoplay controls >
  <source src=""sample-2d-tracing.mp4"" type=""video/mp4"">
</video>

You can download our [2D](data/sample-2d.tif) and [3D](sample-3d.tif) example tif files.

## Features

1. Load images and trace paths in 2D and 3D.
1. Offloads computations to a background thread to ensure a responsive user interface.
1. Two tracing modes: disjoint and continuous. Disjoint segments refer to paths that do not share any points, while continuous segments start from the endpoint of a previously traced path.
1. Verify traced segments and cancel tracing if necessary.
1. Save traced paths in SWC format commonly used in biology to represent neuronal morphology.
1. Load previously saved tracings in SWC format.

## Installation

You can install `napari-tracing` via pip:

    pip install napari-tracing

To install latest development version :

    pip install git+https://github.com/mapmanager/napari-tracing.git

## Usage

Once installed, the Napari Tracer Plugin can be accessed from the Napari menu under ""Plugins"" > ""napari tracing: Tracer Widget"". This will open the plugin interface, where you can load your image and start tracing.

## Tracing

1. To trace a path, select the ""Trace"" mode and the image layer that you want to trace from their respective dropdowns.
2. Once you select the image, a points layer called the terminal points layer will be created on the Napari viewer where you can add the start and end point.
3. Click the ""Start Tracing"" button to perform brightest path tracing between the points.
4. The traced path will appear in a new points layer called the tracing result result layer in the Napari viewer as a line overlay.
5. Each new traced segment is verified, so you can either accept the tracing or reject it. If you choose to reject the tracing, you can try again with a different set of points if necessary.
6. You can click on the ""Cancel Tracing"" button to cancel a tracing that is in progress.

## Saving and loading tracings

1. To save a tracing, click on the ""Save Trace"" button from the plugin menu. This will save the traced path in SWC format to a file of your choosing.
1. To load a previously saved tracing, click on the ""Load Trace"" button and choose the SWC file you want to load. The traced path will appear in the Napari viewer.

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [GNU GPL v3.0] license,
""napari-tracing"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[file an issue]: https://github.com/mapmanager/napari-tracing/issues
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: GNU General Public License v3 (GPLv3)', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/mapmanager/napari-tracing/issues', 'Documentation, https://github.com/mapmanager/napari-tracing#README.md', 'Source Code, https://github.com/mapmanager/napari-tracing', 'User Support, https://github.com/mapmanager/napari-tracing/issues']",,,napari-tracing.make_qwidget,,,,,https://pypi.org/project/napari-tracing,,
330,Particle tracking,0.3.0,2023-11-08,2023-11-09,napari-trackpy,Roy Hoitink,L.D.Hoitink@uu.nl,MIT,https://pypi.org/project/napari-trackpy,Plugin to do trackpy particle tracking on microscopy data within napari,>=3.8,"['numpy', 'magicgui', 'qtpy', 'napari', 'napari-aicsimageio', 'readlif', 'trackpy', 'matplotlib', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-trackpy

[![License MIT](https://img.shields.io/pypi/l/napari-trackpy.svg?color=green)](https://github.com/rhoitink/napari-trackpy/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-trackpy.svg?color=green)](https://pypi.org/project/napari-trackpy)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-trackpy.svg?color=green)](https://python.org)
[![tests](https://github.com/rhoitink/napari-trackpy/workflows/tests/badge.svg)](https://github.com/rhoitink/napari-trackpy/actions)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-trackpy)](https://napari-hub.org/plugins/napari-trackpy)

Plugin to do [trackpy] particle tracking on 3D microscopy data within [napari]. Currently only tracking of XYZ data is implemented.

## Installation

You can install `napari-trackpy` via [pip]:

    pip install napari-trackpy

To install latest development version :

    pip install git+https://github.com/rhoitink/napari-trackpy.git

## How to use this plugin?
* Load your XYZ data (using [napari-aicsimageio])
* Make sure to split channels into different layers, such that the layer only contains 3D (XYZ) data
* Open the widget for the tracking plugin via `Plugins` > `XYZ particle tracking`
* Optimize the tracking settings for your dataset, for an extensive description of the settings, visit [this tutorial](http://soft-matter.github.io/trackpy/dev/tutorial/tracking-3d.html)
* Save your tracking data into the `.xyz` file format using `Ctrl`+`S` (on the points layer) or via the menu `File` > `Save Selected Layer(s)...`

## Contributing

Contributions are very welcome. Tests can be run with [tox].

## License

Distributed under the terms of the [MIT] license,
""napari-trackpy"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[trackpy]: https://github.com/soft-matter/trackpy
[napari-aicsimageio]: https://github.com/AllenCellModeling/napari-aicsimageio
[MIT]: http://opensource.org/licenses/MIT

[file an issue]: https://github.com/rhoitink/napari-trackpy/issues

[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: MIT License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/rhoitink/napari-trackpy/issues', 'Documentation, https://github.com/rhoitink/napari-trackpy#README.md', 'Source Code, https://github.com/rhoitink/napari-trackpy', 'User Support, https://github.com/rhoitink/napari-trackpy/issues']",,napari-trackpy.write_points_xyzfile,napari-trackpy.xyz_tracking,,,['.xyz'],,https://pypi.org/project/napari-trackpy,,
331,napari-tracks-reader,0.1.3,2022-02-11,2023-06-18,napari-tracks-reader,Sylvain Prigent,sylvain.prigent@inria.fr,GNU GPL v3.0,https://github.com/sylvainprigent/napari-tracks-reader,"Read tracks from txt (xml, csv) files to napari",>=3.6,"['napari-plugin-engine (>=0.1.4)', 'numpy', 'pandas (>=1.2.4)']","# napari-tracks-reader

[![License](https://img.shields.io/pypi/l/napari-tracks-reader.svg?color=green)](https://github.com/sylvainprigent/napari-tracks-reader/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-tracks-reader.svg?color=green)](https://pypi.org/project/napari-tracks-reader)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-tracks-reader.svg?color=green)](https://python.org)
[![tests](https://github.com/sylvainprigent/napari-tracks-reader/workflows/tests/badge.svg)](https://github.com/sylvainprigent/napari-tracks-reader/actions)
[![codecov](https://codecov.io/gh/sylvainprigent/napari-tracks-reader/branch/master/graph/badge.svg)](https://codecov.io/gh/sylvainprigent/napari-tracks-reader)

Read tracks from various tracking softwares output files to napari tracks layer.
Supported formats are:
- Trakmate model (xml)
- Icy (xml)
- TrackContestISBI2012 (xml) 

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/docs/plugins/index.html
-->

## Installation

You can install `napari-tracks-reader` via [pip]:

    pip install napari-tracks-reader

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [GNU GPL v3.0] license,
""napari-tracks-reader"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/sylvainprigent/napari-tracks-reader/issues
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/


","['Development Status :: 4 - Beta', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: GNU General Public License v3 (GPLv3)']",,napari-tracks-reader.napari_get_reader,,,,['*'],,,https://pypi.org/project/napari-tracks-reader,https://github.com/sylvainprigent/napari-tracks-reader,
332,napari TRAIT2D,0.1.4,2022-08-18,2023-06-18,napari-trait2d,Jacopo Abramo,jacopo.abramo@gmail.com,BSD-3-Clause,https://github.com/jacopoabramo/napari-trait2d,"A napari plugin for TRAIT2D, a software for quantitative analysis of single particle diffusion data",>=3.8,"['numpy', 'qtpy', 'napari[pyqt5]', 'dacite', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'""]","# napari-trait2d

[![License BSD-3](https://img.shields.io/pypi/l/napari-trait2d.svg?color=green)](https://github.com/jacopoabramo/napari-trait2d/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-trait2d.svg?color=green)](https://pypi.org/project/napari-trait2d)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-trait2d.svg?color=green)](https://python.org)
[![tests](https://github.com/jacopoabramo/napari-trait2d/workflows/tests/badge.svg)](https://github.com/jacopoabramo/napari-trait2d/actions)
[![codecov](https://codecov.io/gh/jacopoabramo/napari-trait2d/branch/main/graph/badge.svg)](https://codecov.io/gh/jacopoabramo/napari-trait2d)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-trait2d)](https://napari-hub.org/plugins/napari-trait2d)

A napari plugin for TRAIT2D, a software for quantitative analysis of single particle diffusion data

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/index.html
-->

## Installation

You can install `napari-trait2d` via [pip]:

    pip install napari-trait2d



To install latest development version :

    pip install git+https://github.com/jacopoabramo/napari-trait2d.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-trait2d"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/jacopoabramo/napari-trait2d/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10']","['Bug Tracker, https://github.com/jacopoabramo/napari-trait2d/issues', 'Documentation, https://github.com/jacopoabramo/napari-trait2d#README.md', 'Source Code, https://github.com/jacopoabramo/napari-trait2d', 'User Support, https://github.com/jacopoabramo/napari-trait2d/issues']",,,napari-trait2d.trait2d_widget,,,,,https://pypi.org/project/napari-trait2d,https://github.com/jacopoabramo/napari-trait2d,
333,Turing Patterns,0.3.2,2022-08-19,2023-06-18,napari-turing,Léo Guignard,leo.guignard@univ-amu.fr,MIT,https://github.com/leoguignard/napari-turing,A plugin to run simmple simulations of Turing patterns,>=3.8,"['numpy', 'scipy', 'scikit-image', 'magicgui', 'qtpy', 'napari', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-turing

[![License MIT](https://img.shields.io/pypi/l/napari-turing.svg?color=green)](https://github.com/leoguignard/napari-turing/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-turing.svg?color=green)](https://pypi.org/project/napari-turing)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-turing.svg?color=green)](https://python.org)
[![tests](https://github.com/leoguignard/napari-turing/workflows/tests/badge.svg)](https://github.com/leoguignard/napari-turing/actions)
[![codecov](https://codecov.io/gh/leoguignard/napari-turing/branch/main/graph/badge.svg)](https://codecov.io/gh/leoguignard/napari-turing)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-turing)](https://napari-hub.org/plugins/napari-turing)

A plugin to run simple simulations of Turing patterns

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/index.html
-->
![example 1](img/turing_patterns.gif)
![example 2](img/turing_patterns2.gif)

## Installation

You can install `napari-turing` via [pip] after downloading the content of

    pip install napari-turing


To install latest version :

    pip install git+https://github.com/leoguignard/napari-turing.git

## Troubleshooting

If the installation does not work just with the previous command, it might be useful to first install [napari] for example that way:

    conda install napari

## Creating a new model

To create your own model, you can use the template for models [here](src/napari_turing/Models/ModelTemplate.py).

Note that a bit of knowledge in Python is probably necessary and it might not be completely trivial at first but you'll manage :)

First you need to name the concentrations that you will use with the following [line](src/napari_turing/Models/ModelTemplate.py#L40):
```python
    _concentration_names = [""A"", ""I""]
```

Then, you need to declare its variables. For example you can create a parameter named `mu_a` the following way ([here in the code](src/napari_turing/Models/ModelTemplate.py#L53-L60)):
```python
    mu_a = ModelParameter(
        name=""mu_a"",  # Name of the parameter
        description=""Activator diffusion coefficient (10^-4)"",  # Description of the parameter for napari
        value=2.8,  # Initial and default value
        min=1,  # Minimum value the parameter can take
        max=5,  # Maximum value the parameter can take
        exponent=1e-4,  # All values given to this instance of the class will but multiplied by this value
    )
```

Then you need to list the parameters that are necessary to run the model (usually all the paramaters declared previously) and the parameters that you will allow the user to tune (for example, sometimes some of the parameters are co-dependent and there is no point in being able to tune both of them). That should be done the following way ([here in the code](src/napari_turing/Models/ModelTemplate.py#L86-89)):
```python
    # These are the parameters that are necessary to run the equations.
    _necessary_parameters = [tau, k, mu_a, mu_i]
    # These are the parameters that can be modified via napari
    _tunable_parameters = _necessary_parameters
```

If you want, you can specify what the method will return as a string, it will be displayed in the napari viewer ([here in the code](src/napari_turing/Models/ModelTemplate.py#L90-L98)):
```python
    # This function allows to display some information about the model
    # in napari
    def __str__(self) -> str:
        return (
            ""Equations (FitzHugh-Nagumo model):\n""
            ""  Concentration of Activator (a) and Inhibitor (i)\n""
            ""    - da/dt = mu_a * diffusion(a) + a - a^3 - i + k\n""
            ""    - tau * di/dt = mu_i * diffusion(i) + a - i""
        )
```

Now that the basics are declared, you will need to declare how to initialize your concentrations the following way ([here in the code](src/napari_turing/Models/ModelTemplate.py#L100-L116)):
```python
    # The following allows to reset the values of the concentrations.
    # The function takes the name of the concentration to initialize.
    # If no name is given or if it is None all the concentrations are
    # reinitialized.
    #
    # The reason why this function is useful is that some models 
    # require specific initialisations for them to work correctly
    # In the following example the concentrations are reintinalized
    # to a random value between -1 and 1.
    # This is the default behavior, so if you don't need to change
    # it you don't have to implement the function.
    def init_concentrations(self, C: Optional[str] = None) -> None:
        if C is None:
            for ci in self.concentration_names():
                self[ci] = np.random.random((self.size, self.size)) * 2 - 1
        else:
            self[C] = np.random.random((self.size, self.size)) * 2 - 1
```
In the previous example, the all concentrations are initialized the same way. If you need to have different initializations, you can do it the following way for example ([from the GrayScott model](src/napari_turing/Models/GrayScott.py#L68-L76)):
```python
    def init_concentrations(self, C: Optional[str] = None) -> None:
        if C == ""X"" or C is None:
            self[""X""] = np.ones((self.size, self.size))
        if C == ""Y"" or C is None:
            Y = np.zeros((self.size, self.size))
            nb_pos = 20
            pos = (np.random.random((2, nb_pos)) * self.size).astype(int)
            Y[pos[0], pos[1]] = 1
            self[""Y""] = Y
```
In this model, there are two concentrations, `X` and `Y` which are initialized differenty. Note that they can be accessed using `self[""X""]` or `self.X`.

Finally, you of course have to define the reaction equations and the diffusion equations. The way it is defined is with two functions, one for the reaction and one for the diffusion, that take as an input the name of the concentration to apply the function to and returns the new values. Then for each of your concentrations, their new values will be computed as followed:
```python
new_concentration = current_concentration + dt*(reaction + diffusion)
```

Here is an example for the reaction function ([here in the code](src/napari_turing/Models/ModelTemplate.py#L127-L136)):
```python 
    # This function defines the equations of the reactions.
    # It takes as an input which concentration to compute
    # (in this example we have to define how to compute A and I)
    def _reaction(self, c: str) -> np.ndarray:
        if c == ""A"":
            # Below is the reaction part of the equation (1)
            return self.A - self.A**3 - self.I + self.k 
        elif c == ""I"":
            # Below is the reaction part of the equation (2)
            return (self.A - self.I) / self.tau
```
Of course, if you have more concentrations, you will need to define more equations.

Here is an example for the reaction function ([here in the code](src/napari_turing/Models/ModelTemplate.py#L138-L166)):
```python
    # This function defines the equations of the diffusion.
    # It takes as an input which concentration to compute
    # (in this example we have to define how to compute A and I)
    # Here we compute the diffusion as follow:
    # A cell gives an equal fraction mu of its concentration to its neighbors
    # A cell recieves an equal fraction mu of concentration from its neighbors
    # Neighbors = (left, right, above, below)
    # In the case of oriented diffusion the amount recieved and given to the neighbors
    # is imbalanced according to the position of the neighbor.
    def _diffusion(self, c: str) -> np.ndarray:
        if c == ""A"":
            arr = self.A # Define the array of concentrations to diffuse for the reageant A
            mu = self.mu_a # Define the diffusion coefficient for the reageant A
        elif c == ""I"":
            arr = self.I # Define the array of concentrations to diffuse for the reageant I
            mu = self.mu_i # Define the diffusion coefficient for the reageant I
        
        # Computes what is recieved from neighboring cells
        from_cell = convolve(arr, self.kernel.value, mode=""constant"", cval=0)
        # Computes what is given to neighboring cells
        to_cell = self.nb_neighbs * arr

        # Computes the diffusion
        out = mu * (from_cell - to_cell) / (self.dx * self.dy)

        # In our case, the equation (2), for I specify that it has to be divided by tau
        if c == ""I"":
            out /= self.tau
        return out
```
The diffusion function is usually a standard one so it might not be necessary to overly change it.

You can find other model examples:
- [Brusselator](src/napari_turing/Models/Brusselator.py)
- [GrayScott](src/napari_turing/Models/GrayScott.py)
- [GameOfLife](src/napari_turing/Models/GameOfLife.py)

Once all that is done, let say you've saved your new model in the folder [Models](src/napari_turing/Models) under the name `NewModel.py` and the model class created is name `NewModel`. Then you need to declare you model in the [`_model_list.py`](src/napari_turing/Models/_model_list.py) file. To do so you need to add the following lines in the file:
```python
from enum import Enum
from .FitzHughNagumo import FitzHughNagumo
from .Brusselator import Brusselator
from .GrayScott import GrayScott
from .GameOfLife import GameOfLife
from .NewModel import NewModel ## THAT LINE HERE

class AvailableModels(Enum):
    FitzHughNagumo = FitzHughNagumo
    Brusselator = Brusselator
    GrayScott = GrayScott
    GameOfLife = GameOfLife
    NewModel = NewModel ## AND THAT OTHER LINE HERE
```

## Contributing

Contributions are very welcome.

## License

Distributed under the terms of the [MIT] license,
""napari-turing"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/leoguignard/napari-turing/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: MIT License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/leoguignard/napari-turing/issues', 'Documentation, https://github.com/leoguignard/napari-turing#README.md', 'Source Code, https://github.com/leoguignard/napari-turing', 'User Support, https://github.com/leoguignard/napari-turing/issues']",,,napari-turing.TuringViewer,,,,,https://pypi.org/project/napari-turing,https://github.com/leoguignard/napari-turing,
334,napari tyssue,0.1.2,2023-04-18,2023-06-18,napari-tyssue,Kyle Harrington,czi@kyleharrington.com,BSD-3-Clause,https://github.com/kephale/napari-tyssue,A napari plugin for use with the tyssue library,>=3.8,"['numpy', 'magicgui', 'qtpy', 'tyssue', 'quantities', 'pooch', 'tables', 'imageio-ffmpeg', 'invagination (==0.0.2)', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-tyssue

[![License BSD-3](https://img.shields.io/pypi/l/napari-tyssue.svg?color=green)](https://github.com/kephale/napari-tyssue/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-tyssue.svg?color=green)](https://pypi.org/project/napari-tyssue)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-tyssue.svg?color=green)](https://python.org)
[![tests](https://github.com/kephale/napari-tyssue/workflows/tests/badge.svg)](https://github.com/kephale/napari-tyssue/actions)
[![codecov](https://codecov.io/gh/kephale/napari-tyssue/branch/main/graph/badge.svg)](https://codecov.io/gh/kephale/napari-tyssue)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-tyssue)](https://napari-hub.org/plugins/napari-tyssue)

A napari plugin for use with the tyssue library

![napari-tyssue demo of apoptosis model](https://github.com/kephale/napari-tyssue/raw/main/assets/napari_tyssue_apoptosis.gif)


Example video of apoptosis demo simulation created based on the
apoptosis demo from
[tyssue-demo](https://github.com/DamCB/tyssue-demo).

![napari-tyssue demo of invagination model](https://github.com/kephale/napari-tyssue/raw/main/assets/napari_tyssue_invagination_3x.gif)


Example video of apoptosis demo simulation created based on work under
revision by Suzanne group at U Toulouse entitled
""Epithelio-mesenchymal transition generates an apico-basal driving
force required for tissue remodeling"" [available here](https://github.com/DamCB/invagination).

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You are better off using conda. You will need pytables, and ideally CGAL.

You can install `napari-tyssue` via [pip]:

    pip install napari-tyssue



To install latest development version :

    pip install git+https://github.com/kephale/napari-tyssue.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-tyssue"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/kephale/napari-tyssue/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/kephale/napari-tyssue/issues', 'Documentation, https://github.com/kephale/napari-tyssue#README.md', 'Source Code, https://github.com/kephale/napari-tyssue', 'User Support, https://github.com/kephale/napari-tyssue/issues']",,,napari-tyssue.make_apoptosis_widget,,,,,https://pypi.org/project/napari-tyssue,https://github.com/kephale/napari-tyssue,
335,U-FISH,0.0.1,2023-11-20,2023-11-20,napari-ufish,Weize Xu,vet.xwz@gmail.com,MIT,https://pypi.org/project/napari-ufish,Deep learning-based FISH spot calling method.,>=3.9,"['numpy', 'magicgui', 'qtpy', 'scikit-image', 'ufish', 'napari', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-ufish

[![License MIT](https://img.shields.io/pypi/l/napari-ufish.svg?color=green)](https://github.com/UFISH-Team/napari-ufish/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-ufish.svg?color=green)](https://pypi.org/project/napari-ufish)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-ufish.svg?color=green)](https://python.org)
[![tests](https://github.com/UFISH-Team/napari-ufish/workflows/tests/badge.svg)](https://github.com/UFISH-Team/napari-ufish/actions)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-ufish)](https://napari-hub.org/plugins/napari-ufish)

Deep learning-based FISH spot calling method.
The napari plugin for [U-FISH](https://github.com/UFISH-Team/U-FISH).

## Links

+ [U-FISH](https://github.com/UFISH-Team/U-FISH)
+ [U-FISH models](https://huggingface.co/GangCaoLab/U-FISH)
+ [FISH_spots dataset](https://huggingface.co/datasets/GangCaoLab/FISH_spots)

## TODO List

- [x] Sample image
- [x] Inference interface
    - [x] Inference parameters
    - [x] Load model from path
    - [x] Help information dialog
- [x] Training interface

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-ufish` via [pip]:

    pip install napari-ufish


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [MIT] license,
""napari-ufish"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: MIT License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Topic :: Scientific/Engineering :: Image Processing']",,,,napari-ufish.make_inference_widget,napari-ufish.make_sample_data,,,,https://pypi.org/project/napari-ufish,,
336,Napari UI tracer,0.1.2,2023-03-23,2023-06-18,napari-ui-tracer,Daniel Althviz,dalthviz@gmail.com,MIT,https://github.com/dalthviz/napari-ui-tracer,A plugin to help understand Napari UI components and check their source code definition,>=3.8,"['qtpy (>=2.3.0)', ""pre-commit ; extra == 'pre-commit'"", ""pyqt5 ; extra == 'pyqt5'"", ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'""]","# napari-ui-tracer

[![License MIT](https://img.shields.io/pypi/l/napari-ui-tracer.svg?color=green)](https://github.com/dalthviz/napari-ui-tracer/raw/main/LICENSE)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-ui-tracer.svg?color=green)](https://python.org)
[![PyPI](https://img.shields.io/pypi/v/napari-ui-tracer.svg?color=green)](https://pypi.org/project/napari-ui-tracer)
[![PyPI download month](https://img.shields.io/pypi/dm/napari-ui-tracer.svg?color=green)](https://pypi.org/project/napari-ui-tracer/)
[![conda version](https://img.shields.io/conda/vn/conda-forge/napari-ui-tracer.svg?color=blue)](https://anaconda.org/conda-forge/napari-ui-tracer)
[![conda download count](https://img.shields.io/conda/d/conda-forge/napari-ui-tracer.svg?color=blue)](https://anaconda.org/conda-forge/napari-ui-tracer)
[![tests](https://github.com/dalthviz/napari-ui-tracer/workflows/tests/badge.svg)](https://github.com/dalthviz/napari-ui-tracer/actions)
[![codecov](https://codecov.io/gh/dalthviz/napari-ui-tracer/branch/main/graph/badge.svg?token=E6je6vXOSA)](https://codecov.io/gh/dalthviz/napari-ui-tracer)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-ui-tracer)](https://napari-hub.org/plugins/napari-ui-tracer)

A plugin to help understand Napari UI components and locate their code definition

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

![GIF showing Napari UI tracer's functionality](https://raw.githubusercontent.com/dalthviz/napari-ui-tracer/main/images/napari-ui-tracer.gif)

## Installation

You can install `napari-ui-tracer` via [pip]:

    pip install napari-ui-tracer

Or via [conda]:

    conda install -c conda-forge napari-ui-tracer

To install latest development version :

    pip install git+https://github.com/dalthviz/napari-ui-tracer.git

## Usage

1. Show the plugin inside the napari interface:

    * You can launch napari with the plugin visible running:

            napari -w napari-ui-tracer

    * Or select it from `Plugins > Napari UI tracer widget`

2. Check the `Enable Qt event filter` checkbox:
    * Use `Ctrl/Cmd + Mouse button right click` to see the information available about any widget inside napari
    * An option to show objects documentation (object class docstring) can be used by checking the `Show object documentation` checkbox

3. Check the `Enable application events logging` checkbox:
    * A log like information with the events generated when interacting with the application will appear
    * Some configuration options are available:
        * `Stack depth`: Stack depth to show. Default to 20
        * `Allowed nested events`: How many sub-emit nesting levels to show (i.e. events that get triggered by other events). Default to 0

4. If you want to explore the related widget or event module source file, click the link in the output section of the plugin (the module file will open if you have a registered program to open such kind of file)

## Contributing

Contributions are very welcome. Pre-commit is used for formatting. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [MIT] license,
""napari-ui-tracer"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/dalthviz/napari-ui-tracer/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
[conda]: https://docs.conda.io/projects/conda/en/stable/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: MIT License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/dalthviz/napari-ui-tracer/issues', 'Documentation, https://github.com/dalthviz/napari-ui-tracer#README.md', 'Source Code, https://github.com/dalthviz/napari-ui-tracer', 'User Support, https://github.com/dalthviz/napari-ui-tracer/issues']",,,napari-ui-tracer.make_qwidget,,,,,https://pypi.org/project/napari-ui-tracer,https://github.com/dalthviz/napari-ui-tracer,
337,UMAP,0.0.1,,,napari-umap,Jordao Bragantini,jordao.bragantini@czbiohub.org,BSD-3-Clause,,A simple plugin to use with napari,>=3.8,"['numpy', 'magicgui', 'qtpy', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-umap

[![License BSD-3](https://img.shields.io/pypi/l/napari-umap.svg?color=green)](https://github.com/royerlab/napari-umap/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-umap.svg?color=green)](https://pypi.org/project/napari-umap)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-umap.svg?color=green)](https://python.org)
[![tests](https://github.com/royerlab/napari-umap/workflows/tests/badge.svg)](https://github.com/royerlab/napari-umap/actions)
[![codecov](https://codecov.io/gh/royerlab/napari-umap/branch/main/graph/badge.svg)](https://codecov.io/gh/royerlab/napari-umap)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-umap)](https://napari-hub.org/plugins/napari-umap)

A simple plugin to use with napari

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-umap` via [pip]:

    pip install napari-umap



To install latest development version :

    pip install git+https://github.com/royerlab/napari-umap.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-umap"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/royerlab/napari-umap/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/royerlab/napari-umap/issues', 'Documentation, https://github.com/royerlab/napari-umap#README.md', 'Source Code, https://github.com/royerlab/napari-umap', 'User Support, https://github.com/royerlab/napari-umap/issues']",,,napari-umap.make_qwidget,,,,,https://pypi.org/project/napari-umap,,
338,unicell,0.0.1.post3,2023-04-24,2023-06-18,napari-unicell,Jun Ma,junma.ma@mail.utoronto.ca,Apache-2.0,https://github.com/JunMa11/napari-unicell,universal cell segmentation models,>=3.8,"['torch', 'imagecodecs', 'scipy', 'numpy', 'magicgui', 'qtpy', 'scikit-image', 'monai', 'einops', 'PyQt5', 'napari', 'napari-plugin-engine', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-unicell

[![License Apache Software License 2.0](https://img.shields.io/pypi/l/napari-unicell.svg?color=green)](https://github.com/JunMa11/napari-unicell/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-unicell.svg?color=green)](https://pypi.org/project/napari-unicell)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-unicell.svg?color=green)](https://python.org)
[![tests](https://github.com/JunMa11/napari-unicell/workflows/tests/badge.svg)](https://github.com/JunMa11/napari-unicell/actions)
[![codecov](https://codecov.io/gh/JunMa11/napari-unicell/branch/main/graph/badge.svg)](https://codecov.io/gh/JunMa11/napari-unicell)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-unicell)](https://napari-hub.org/plugins/napari-unicell)

universal cell segmentation models

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/index.html
-->

## Installation

You can install `napari-unicell` via [pip]:

    pip install napari-unicell




## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [Apache Software License 2.0] license,
""napari-unicell"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/JunMa11/napari-unicell/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: Apache Software License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/JunMa11/napari-unicell/issues', 'Documentation, https://github.com/JunMa11/napari-unicell#README.md', 'Source Code, https://github.com/JunMa11/napari-unicell', 'User Support, https://github.com/JunMa11/napari-unicell/issues']",,,napari-unicell.unicell_widget,,,,,https://pypi.org/project/napari-unicell,https://github.com/JunMa11/napari-unicell,
339,napari validate random label predictions,0.0.1,2023-04-17,2023-06-18,napari-validate-random-label-predictions,Niklas Netter,niknett@gmail.com,BSD-3-Clause,https://github.com/gatoniel/napari-validate-random-label-predictions,Validate separate instances of label predictions manually,>=3.8,"['numpy', 'magicgui', 'qtpy', 'scikit-image', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-validate-random-label-predictions

[![License BSD-3](https://img.shields.io/pypi/l/napari-validate-random-label-predictions.svg?color=green)](https://github.com/gatoniel/napari-validate-random-label-predictions/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-validate-random-label-predictions.svg?color=green)](https://pypi.org/project/napari-validate-random-label-predictions)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-validate-random-label-predictions.svg?color=green)](https://python.org)
[![tests](https://github.com/gatoniel/napari-validate-random-label-predictions/workflows/tests/badge.svg)](https://github.com/gatoniel/napari-validate-random-label-predictions/actions)
[![codecov](https://codecov.io/gh/gatoniel/napari-validate-random-label-predictions/branch/main/graph/badge.svg)](https://codecov.io/gh/gatoniel/napari-validate-random-label-predictions)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-validate-random-label-predictions)](https://napari-hub.org/plugins/napari-validate-random-label-predictions)

Validate separate instances of label predictions manually

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-validate-random-label-predictions` via [pip]:

    pip install napari-validate-random-label-predictions



To install latest development version :

    pip install git+https://github.com/gatoniel/napari-validate-random-label-predictions.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-validate-random-label-predictions"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/gatoniel/napari-validate-random-label-predictions/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/gatoniel/napari-validate-random-label-predictions/issues', 'Documentation, https://github.com/gatoniel/napari-validate-random-label-predictions#README.md', 'Source Code, https://github.com/gatoniel/napari-validate-random-label-predictions', 'User Support, https://github.com/gatoniel/napari-validate-random-label-predictions/issues']",,,napari-validate-random-label-predictions.make_qwidget,,,,,https://pypi.org/project/napari-validate-random-label-predictions,https://github.com/gatoniel/napari-validate-random-label-predictions,
340,napari vedo bridge,0.0.4,2023-08-02,2023-08-02,napari-vedo-bridge,"Johannes Soltwedel, Marco Musy",johannes_richard.soltwedel@tu-dresden.de,BSD-3-Clause,https://github.com/jo-mueller/napari-vedo-bridge,Transfer mesh data between napari and vedo for interactive processing,>=3.8,"['numpy', 'magicgui', 'qtpy', 'vedo (>=2023.4.6)', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-vedo-bridge

[![License BSD-3](https://img.shields.io/pypi/l/napari-vedo-bridge.svg?color=green)](https://github.com/jo-mueller/napari-vedo-bridge/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-vedo-bridge.svg?color=green)](https://pypi.org/project/napari-vedo-bridge)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-vedo-bridge.svg?color=green)](https://python.org)
[![tests](https://github.com/jo-mueller/napari-vedo-bridge/workflows/tests/badge.svg)](https://github.com/jo-mueller/napari-vedo-bridge/actions)
[![codecov](https://codecov.io/gh/jo-mueller/napari-vedo-bridge/branch/main/graph/badge.svg)](https://codecov.io/gh/jo-mueller/napari-vedo-bridge)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-vedo-bridge)](https://napari-hub.org/plugins/napari-vedo-bridge)

To be able to use interactive processing of meshes in napari, this plugin provides a bridge to the vedo library. It allows to transfer meshes between napari and vedo and to use the interactive processing capabilities of vedo in napari. 

## Interactive mesh cutting
To interactively cut meshes in the napari-vedo MeshCutter, install the plugin (see below) and open the plugin it from the napari plugins menu (`Plugins > Mesh Cutter (napari-vedo-bridge)`). 

To cut meshes you can use the following cutters:
- `PlaneCutter`: cuts a mesh with a plane
- `SphereCutter`: cuts a mesh with a sphere
- `BoxCutter`: cuts a mesh with a box

![](https://github.com/jo-mueller/napari-vedo-bridge/raw/main/docs/imgs/screenshot_box_cutter.png)

To send and get data into and from the plugin, you can:

- Retrieve the current mesh from napari (click `Retrieve mesh from napari`) - this imports the **currently selected mesh layer** from napari
- Load a mesh from file (click `Load mesh`)
- Send a mesh to napari (click `Send back to napari`) - this creates a new mesh layer in napari




----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-vedo-bridge` via [pip]:

    pip install napari-vedo-bridge




## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-vedo-bridge"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/jo-mueller/napari-vedo-bridge/issues', 'Documentation, https://github.com/jo-mueller/napari-vedo-bridge#README.md', 'Source Code, https://github.com/jo-mueller/napari-vedo-bridge', 'User Support, https://github.com/jo-mueller/napari-vedo-bridge/issues']",,,napari-vedo-bridge.cutter_widget,,,,,https://pypi.org/project/napari-vedo-bridge,https://github.com/jo-mueller/napari-vedo-bridge,
341,napari-vemseg,0.0.9,,,napari-vemseg,Matous Elphick,matous.elphick@gmail.com,BSD-3-Clause,,A simple plugin for semi-automated segmentation of volume electron microscopy images.,>=3.8,"['torch', 'numpy', 'scikit-image', 'magicgui', 'qtpy', 'napari', 'tqdm', 'apoc', 'superqt', 'setuptools', 'vemseg']","
<img width=""250""  src=""https://github.com/MatousE/napari-vemseg/blob/main/images/VEMSEG-FINAL.svg""> 

# napari-vemseg


[![License BSD-3](https://img.shields.io/pypi/l/napari-vemseg.svg?color=green)](https://github.com/MatousE/napari-vemseg/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-vemseg.svg?color=green)](https://pypi.org/project/napari-vemseg)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-vemseg.svg?color=green)](https://python.org)
[![tests](https://github.com/MatousE/napari-vemseg/workflows/tests/badge.svg)](https://github.com/MatousE/napari-vemseg/actions)
[![codecov](https://codecov.io/gh/MatousE/napari-vemseg/branch/main/graph/badge.svg)](https://codecov.io/gh/MatousE/napari-vemseg)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-vemseg)](https://napari-hub.org/plugins/napari-vemseg)

A simple plugin to do semi-automated segmentation within napari using vemseg built on
XGBoost.

## Installation
### `conda` Installation and Environment Creation
To start with a conda environment must be created.
```
conda create -n vemseg-env python=3.8
conda activate vemseg-env
```
### `napari` Instillation
We must then install [napari]:

```
pip install ""napari[all]""
```
### `napari-vemseg` Instillation
You can finally install `napari-vemseg` via [pip]:
```
conda install pyopencl
pip install napari-vemseg
```
## Usage
### Train VEMClassifier

### Predict Using Pretrained VEMClassifier


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-vemseg"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Topic :: Scientific/Engineering :: Image Processing']",,,,napari-vemseg.vemseg_pixel_classifier,,,,,https://pypi.org/project/napari-vemseg,,
342,Vesicles Segmentation,0.0.1,2022-08-18,2023-06-18,napari-vesicles-segmentation,Alexis Japas,alexis.japas@proton.me,BSD-3-Clause,https://github.com/alexisjapas/napari-vesicles-segmentation,A simple plugin to detect vesicles in cells images.,>=3.8,"['numpy', 'magicgui', 'qtpy', 'scikit-image', 'scipy', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'"", ""scikit-image ; extra == 'testing'"", ""scipy ; extra == 'testing'""]","# napari-vesicles-segmentation

[![License BSD-3](https://img.shields.io/pypi/l/napari-vesicles-segmentation.svg?color=green)](https://github.com/alexisjapas/napari-vesicles-segmentation/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-vesicles-segmentation.svg?color=green)](https://pypi.org/project/napari-vesicles-segmentation)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-vesicles-segmentation.svg?color=green)](https://python.org)
[![tests](https://github.com/alexisjapas/napari-vesicles-segmentation/workflows/tests/badge.svg)](https://github.com/alexisjapas/napari-vesicles-segmentation/actions)
[![codecov](https://codecov.io/gh/alexisjapas/napari-vesicles-segmentation/branch/main/graph/badge.svg)](https://codecov.io/gh/alexisjapas/napari-vesicles-segmentation)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-vesicles-segmentation)](https://napari-hub.org/plugins/napari-vesicles-segmentation)

A simple plugin to detect vesicles in cells images.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/index.html
-->

## Installation

You can install `napari-vesicles-segmentation` via [pip]:

    pip install napari-vesicles-segmentation



To install latest development version :

    pip install git+https://github.com/alexisjapas/napari-vesicles-segmentation.git

## Usage
1. Open napari
2. Open your data
![usage-open-data](images/usage-open-data.png)
3. Launch the vesicles-segmentation plugin
4. Select the data you want to segment and set the parameters of the segmentation
![usage-setup](images/usage-setup.png)
    * **image**: The image to segment vesicles in. The image can be a 2D or 3D temporal stack of images.
    * **minimum vesicles size**: The minimum size of the vesicles to detect. Smaller detected vesicles are removed.
    * **membrane erosion**: The size of the disk radius used for eroding the cell. This is used to remove the external membrane. This parameter scales when downsizing the image, for more information see 'downsizing ratio' parameter.
    * **closing size**: The size of the disk radius used for closing the cell. This is used to fill holes in the cell. This parameter scales when downsizing the image, for more information see 'downsizing ratio' parameter.
    * **clip**: If set to zero, no standardization is performed. Otherwise, the standard deviation of the image is set to n_sigma * the standard deviation of the image, the image is standardized and its values are clipped to the range [-1, 1] in order to remove outliers. The higher the value of n_sigma, the less outliers are removed. This operation can lead to a better detection of the cell.
    * **downsampling ratio**: The downsampling ratio used for the downsampled image. This is used to speed up the computation. Downsampling the image have impact in reducing the resolution of erosion and closing e.g. for a downsize ratio of 2, setting the erosion size to 3 will result in an erosion size of 6.
    * **display cell detection**: If set to True, the cell detection is displayed in the viewer instead of the vesicle detection.
5. Click on the ""Segment"" button to start the segmentation. This can take few seconds or minutes depending on the size of the data. The result is added to the viewer as below.
![usage-segmentation](images/usage-segmentation.png)

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-vesicles-segmentation"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/alexisjapas/napari-vesicles-segmentation/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/alexisjapas/napari-vesicles-segmentation/issues', 'Documentation, https://github.com/alexisjapas/napari-vesicles-segmentation#README.md', 'Source Code, https://github.com/alexisjapas/napari-vesicles-segmentation', 'User Support, https://github.com/alexisjapas/napari-vesicles-segmentation/issues']",,,napari-vesicles-segmentation.make_qwidget,,,,,https://pypi.org/project/napari-vesicles-segmentation,https://github.com/alexisjapas/napari-vesicles-segmentation,
343,napari VideoCVDask,0.2.1,,,napari-video-cvdask,Nicholas A. Del Grosso,delgrosso.nick@gmail.com,MIT,,A Video File Reader that uses OpenCV2 and Dask Arrays,>=3.7,"['dask-image', 'av']","# napari-video-cvdask

[![License](https://img.shields.io/pypi/l/napari-video-cvdask.svg?color=green)](https://github.com/nickdelgrosso/napari-video-cvdask/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-video-cvdask.svg?color=green)](https://pypi.org/project/napari-video-cvdask)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-video-cvdask.svg?color=green)](https://python.org)
[![tests](https://github.com/nickdelgrosso/napari-video-cvdask/workflows/tests/badge.svg)](https://github.com/nickdelgrosso/napari-video-cvdask/actions)
[![codecov](https://codecov.io/gh/nickdelgrosso/napari-video-cvdask/branch/main/graph/badge.svg)](https://codecov.io/gh/nickdelgrosso/napari-video-cvdask)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-video-cvdask)](https://napari-hub.org/plugins/napari-video-cvdask)

A Video File Reader that used to use OpenCV2 and Dask Arrays, and now uses dask-image, which does the same thing but better.  (Pro-tip, never name a package after its dependencies!)

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.


## Installation

You can install `napari-video-cvdask` via [pip]:

    pip install napari-video-cvdask



To install latest development version :

    pip install git+https://github.com/nickdelgrosso/napari-video-cvdask.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [MIT] license,
""napari-video-cvdask"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.


","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Operating System :: OS Independent', 'License :: OSI Approved :: MIT License']","['Bug Tracker, https://github.com/nickdelgrosso/napari-video-cvdask/issues', 'Documentation, https://github.com/nickdelgrosso/napari-video-cvdask#README.md', 'Source Code, https://github.com/nickdelgrosso/napari-video-cvdask', 'User Support, https://github.com/nickdelgrosso/napari-video-cvdask/issues']",napari-video-cvdask.get_reader,,,,"['*.mp4', '*.mov', '*.avi']",,,https://pypi.org/project/napari-video-cvdask,,
344,VoDEx,1.0.12,2023-04-17,2023-06-18,napari-vodex,Anna Nadtochiy,lemonjustgithub@gmail.com,BSD-3-Clause,https://github.com/LemonJust/napari-vodex,A napari plugin for VoDEx : Volumetric Data and Experiment Manager. Allows to load volumetric data based on experimental conditions.,>=3.8,"['vodex (>=1.0.12)', 'numpy', 'magicgui', 'qtpy', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-vodex

[![License BSD-3](https://img.shields.io/pypi/l/napari-vodex.svg?color=green)](https://github.com/LemonJust/napari-vodex/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-vodex.svg?color=green)](https://pypi.org/project/napari-vodex)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-vodex.svg?color=green)](https://python.org)
[![tests](https://github.com/LemonJust/napari-vodex/workflows/tests/badge.svg)](https://github.com/LemonJust/napari-vodex/actions)
[![codecov](https://codecov.io/gh/LemonJust/napari-vodex/branch/main/graph/badge.svg)](https://codecov.io/gh/LemonJust/napari-vodex)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-vodex)](https://napari-hub.org/plugins/napari-vodex)

A plugin to load volumetric data based on experimental conditions.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-vodex` via [pip]:

    pip install napari-vodex



To install latest development version :

    pip install git+https://github.com/LemonJust/napari-vodex.git

## How-To Guide

To get started with napari_vodex, please see details and examples in [How-To Guide](https://lemonjust.github.io/vodex/napari/how-to/) .


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-vodex"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/LemonJust/napari-vodex/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 3 - Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/LemonJust/napari-vodex/issues', 'Documentation, https://lemonjust.github.io/vodex/napari/', 'Source Code, https://github.com/LemonJust/napari-vodex', 'User Support, https://github.com/LemonJust/napari-vodex/issues']",,,napari-vodex.vodex_qwidget,,,,,https://pypi.org/project/napari-vodex,https://github.com/LemonJust/napari-vodex,
345,napari-workflow-inspector,0.2.2,2022-02-05,2023-06-18,napari-workflow-inspector,Robert Haase,robert.haase@tu-dresden.de,BSD-3-Clause,https://github.com/haesleinhuepf/napari-workflow-inspector,Inspect relationships between image processing operations in active workflows in napari,>=3.7,"['napari-plugin-engine (>=0.1.4)', 'numpy', 'napari-tools-menu', 'networkx', 'matplotlib', 'napari-workflows']","# napari-workflow-inspector

[![License](https://img.shields.io/pypi/l/napari-workflow-inspector.svg?color=green)](https://github.com/haesleinhuepf/napari-workflow-inspector/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-workflow-inspector.svg?color=green)](https://pypi.org/project/napari-workflow-inspector)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-workflow-inspector.svg?color=green)](https://python.org)
[![tests](https://github.com/haesleinhuepf/napari-workflow-inspector/workflows/tests/badge.svg)](https://github.com/haesleinhuepf/napari-workflow-inspector/actions)
[![codecov](https://codecov.io/gh/haesleinhuepf/napari-workflow-inspector/branch/main/graph/badge.svg)](https://codecov.io/gh/haesleinhuepf/napari-workflow-inspector)
[![Development Status](https://img.shields.io/pypi/status/napari-workflow-inspector.svg)](https://en.wikipedia.org/wiki/Software_release_life_cycle#Alpha)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-workflow-inspector)](https://napari-hub.org/plugins/napari-workflow-inspector)

Inspect relationships between image processing operations in active workflows in napari. Open the inspector by clicking the menu `Tools > Visualization > Workflow Inspector`.

![img_1.png](https://github.com/haesleinhuepf/napari-workflow-inspector/raw/main/docs/screenshot_graph.png)

Also install the [napari-script-editor](https://www.napari-hub.org/plugins/napari-script-editor) 
to generate code from active workflows.

![img_2.png](https://github.com/haesleinhuepf/napari-workflow-inspector/raw/main/docs/screenshot_script_editor.png)

For recording workflows, all napari image processing plugins that use the `@time_slicer` interface are supported. See
[napari-time-slicer](https://www.napari-hub.org/plugins/napari-time-slicer) for a list. More to come, stay tuned.

## Installation

You can install `napari-workflow-inspector` via [pip]:

```
pip install napari-workflow-inspector
```

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-workflow-inspector"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/haesleinhuepf/napari-workflow-inspector/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/


","['Development Status :: 3 - Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Scientific/Engineering :: Image Processing', 'Topic :: Scientific/Engineering :: Information Analysis', 'Topic :: Scientific/Engineering :: Medical Science Apps.', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/haesleinhuepf/napari-workflow-inspector/issues', 'Documentation, https://github.com/haesleinhuepf/napari-workflow-inspector#README.md', 'Source Code, https://github.com/haesleinhuepf/napari-workflow-inspector', 'User Support, https://github.com/haesleinhuepf/napari-workflow-inspector/issues']",,,napari-workflow-inspector.WorkflowWidget,,,,,https://pypi.org/project/napari-workflow-inspector,https://github.com/haesleinhuepf/napari-workflow-inspector,
346,napari-workflow-optimizer,0.1.4,2022-02-14,2023-06-18,napari-workflow-optimizer,Robert Haase,robert.haase@tu-dresden.de,BSD-3-Clause,https://github.com/haesleinhuepf/napari-workflow-optimizer,Optimize image processing workflows in napari for segmentation quality,>=3.7,"['napari-plugin-engine (>=0.1.4)', 'numpy', 'pyclesperanto-prototype', 'scikit-learn', 'napari-time-slicer', 'matplotlib', 'scipy', 'napari-workflows', 'napari-assistant (>=0.1.9)']","# napari-workflow-optimizer

[![License](https://img.shields.io/pypi/l/napari-workflow-optimizer.svg?color=green)](https://github.com/haesleinhuepf/napari-workflow-optimizer/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-workflow-optimizer.svg?color=green)](https://pypi.org/project/napari-workflow-optimizer)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-workflow-optimizer.svg?color=green)](https://python.org)
[![tests](https://github.com/haesleinhuepf/napari-workflow-optimizer/workflows/tests/badge.svg)](https://github.com/haesleinhuepf/napari-workflow-optimizer/actions)
[![codecov](https://codecov.io/gh/haesleinhuepf/napari-workflow-optimizer/branch/main/graph/badge.svg)](https://codecov.io/gh/haesleinhuepf/napari-workflow-optimizer)
[![Development Status](https://img.shields.io/pypi/status/napari-workflow-optimizer.svg)](https://en.wikipedia.org/wiki/Software_release_life_cycle#Alpha)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-workflow-optimizer)](https://napari-hub.org/plugins/napari-workflow-optimizer)

Optimize image processing workflows in napari for segmentation quality

![img.png](https://github.com/haesleinhuepf/napari-workflow-optimizer/raw/main/docs/napari-workflow-optimizer.gif)

## Usage

The starting point for workflow optimization is a workflow and some reference (""ground truth"") labels image. 
The label image can be a sparse annotation, which means only some objects and also parts of objets are annotated (see [hints](https://github.com/haesleinhuepf/napari-workflow-optimizer#optimization-hints)). 
These datasets should be ready. You can reproduce the following procedure by downloading an 
[examle raw image](https://github.com/haesleinhuepf/napari-workflow-optimizer/blob/main/demo/membranes_2d.tif) (derived from the 
[scikit-image cells3d example data set](https://scikit-image.org/docs/dev/api/skimage.data.html#skimage.data.cells3d)) and a corresponding 
[sparse annotation label image](https://github.com/haesleinhuepf/napari-workflow-optimizer/blob/main/demo/membranes_2d_sparse_labels.tif).
For reproducing the following procedure, also follow the [installation instructions](https://github.com/haesleinhuepf/napari-workflow-optimizer#optimization-hints) below.
The whole procedure is [also shown in this video](https://github.com/haesleinhuepf/napari-workflow-optimizer/raw/main/docs/napari-workflow-optimizer.mp4), an extended version of the trailer above.

### Step 0: Loading data and setting up the workflow

Load the ""membranes_2d.tif"" data set, e.g. by drag&drop on napari and start the Assistant from the `Tools > Utilities > Assistant (clEsperanto)` menu.

![](https://github.com/haesleinhuepf/napari-workflow-optimizer/raw/main/docs/screenshot1_start_raw.png)

Click the `Label` button and select as operation ""Seeded watershed using local minima as seeds and an intensity threshold (nsbatwm)"".

![](https://github.com/haesleinhuepf/napari-workflow-optimizer/raw/main/docs/screenshot2_labeled_beginning.png)

Draw an annotation in a new labels layer or load the example spare annotation ""membranes_2d_sparse_labels.tif"". 

![](https://github.com/haesleinhuepf/napari-workflow-optimizer/raw/main/docs/screenshot4_loaded_manual_annotation.png)

In case the image is not displayed as label image, convert it to a label image by right-clicking on the entry in the layers list:

![](https://github.com/haesleinhuepf/napari-workflow-optimizer/raw/main/docs/screenshot3_load_manual_annotation.png)

### Step 1: The Workflow Optimizer

Start the Workflow Optimizer from the `Tools > Utilities > Workflow optimizer (Labels)` menu. 
Configure the target layer, showing the label image that should be optimized.
Select the manual annotation as reference layer for the optimization. 
Consider increasing the number of iterations. This number depends on your segmenation problem. 
In the present example, 100 iterations should be enough.

![](https://github.com/haesleinhuepf/napari-workflow-optimizer/raw/main/docs/screenshot5_start_optimization.png)

The optimizer will plot quality over the number of iterations to show the progress of optimization. 
To determine the quality, the optimizer will measure the maximum overlap ([Jaccard index](https://en.wikipedia.org/wiki/Jaccard_index)) 
of any labeled object over the manually annotated objects and calculate the mean of this value over all annotated objects.
After a moment, optimization will finish and update the labeled image. 
If your starting point for the optimization was already good, the result may now look better than before.

![](https://github.com/haesleinhuepf/napari-workflow-optimizer/raw/main/docs/screenshot6_finished_optimization.png)

### Step 2: Manual parameter space plotting

In case the result is not perfect yet (as the fringed segmentation above suggests), consider manual plotting of the 
individual parameters and their relation to segmentation quality to get an idea about the surrounding parameter space.
Therefore, click the `Plot` button next to one of the workflow parameters.
Select the range in which the labeling quality should be determined (green arrows). In our example, the optimizer was setting the parameter to 2.34. 
Thus, to demonstrate the procedure we plot the parameter space beween 0 and 10. 
The quality plotted over this parameter obviously has a local maxium at 2.34, which was detected by the optimizer.
However, it also has another local maxium at 8 and actually a plateau in the quality plot (orange arrows).

![](https://github.com/haesleinhuepf/napari-workflow-optimizer/raw/main/docs/screenshot7_parameter_quality_plot.png)

For further optimization, we re-configure the algorithm and set a new starting point for optimization of the parameter to 8.
Afterwards, we restart the optimization. It will then optimize the settings again from the new starting point.

![](https://github.com/haesleinhuepf/napari-workflow-optimizer/raw/main/docs/screenshot8_start_optimization_again.png)

After another moment, optimization will finish again, potentially leading to an even better result.

![](https://github.com/haesleinhuepf/napari-workflow-optimizer/raw/main/docs/screenshot9_finished_optimization_again.png)

### Step 3: Visualization of results

Make sure the segmentation has high quality by inspecting the result visually. Use the `contour` setting of the labels layer
and hide/show the outlines of the labeled layer:

![](https://github.com/haesleinhuepf/napari-workflow-optimizer/raw/main/docs/screenshot10_contours_on.png)

![](https://github.com/haesleinhuepf/napari-workflow-optimizer/raw/main/docs/screenshot11_contours_off.jpg)

### Optimization Hints

The Workflow Optimizer uses the [Nelder-Mead simplex method](https://en.wikipedia.org/wiki/Nelder%E2%80%93Mead_method)
for optimizing parameters. This algorithm varies individual parameters and makes steps in the parameter space ideally following a gradient 
to a local optimum. Hence, this algorithm may not be capable of determining a global optimum in parameter space. 
Parameter optimization is no magic. If it does not immediately work on your data, plot the parameters as introduced in Step 2 
and identify parameters with a clear gradient and those with many local maxima. 
Consider optimizing the parameters with many local maxima manually and de-selecting their checkboxes for the optimization.
The optimizer will then only optimize the parameters showing the clear gradient. 
Repeat these steps a couple of times to get a feeling for your parameter space. 

Furthermore, parameter optimization works well if
* the initial settings are close to a good segmentation,
* a small number of parameters (a short workflow) are optimized,
* the reference annotation is prepared carefully and
* the dataset is small. Consider using a small representative crop in case of bigger datasets.

### Workflow optimization scripting

For optimizing workflows from within a jupyter notebook, check out our [example notebook for optimization using spare labels](https://github.com/haesleinhuepf/napari-workflow-optimizer/blob/main/demo/sparse_label_image_optimizer.ipynb). 
The examples are more flexible than the graphical user interface and allow for example [optimizing intensity images](https://github.com/haesleinhuepf/napari-workflow-optimizer/blob/main/demo/intensity_image_optimizer.ipynb)
and [binary images](https://github.com/haesleinhuepf/napari-workflow-optimizer/blob/main/demo/binary_image_optimizer.ipynb).
The membrane segmentation workflow optimization similar to the one shown above is also available as [jupyter notebook](https://github.com/haesleinhuepf/napari-workflow-optimizer/blob/main/demo/membrane_segmentation.ipynb).

### Known issues

If you change the workflow architecture after the optimizer window was opened, please re-open it
to select the parameters that should be optimized. Changing parameters is ok and re-opening is not necessary.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

## Installation

Furthermore, to reproduce the procedure above, please download and install 
[napari](https://napari.org/),
[pyopencl](https://documen.tician.de/pyopencl/),
the [napari-pyclesperanto-assistant](https://www.napari-hub.org/plugins/napari-pyclesperanto-assistant) and
the [napari-segment-blobs-and-things-with-membranes](https://www.napari-hub.org/plugins/napari-segment-blobs-and-things-with-membranes) plugin. E.g. using 
[conda](https://docs.conda.io/en/latest/) and [pip](https://pypi.org/project/pip/):

```
conda create --name napari-opti python=3.8
conda activate napari-opti

conda install pyopencl napari
pip install napari-pyclesperanto-assistant napari-segment-blobs-and-things-with-membranes
pip install napari-workflow-optimizer
```

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-workflow-optimizer"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/haesleinhuepf/napari-workflow-optimizer/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/


","['Development Status :: 3 - Alpha', 'Intended Audience :: Science/Research', 'Framework :: napari', 'Topic :: Scientific/Engineering :: Image Processing', 'Topic :: Scientific/Engineering :: Information Analysis', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/haesleinhuepf/napari-workflow-optimizer/issues', 'Documentation, https://github.com/haesleinhuepf/napari-workflow-optimizer#README.md', 'Source Code, https://github.com/haesleinhuepf/napari-workflow-optimizer', 'User Support, https://github.com/haesleinhuepf/napari-workflow-optimizer/issues']",,,napari-workflow-optimizer.WorkflowOptimizer,,,,,https://pypi.org/project/napari-workflow-optimizer,https://github.com/haesleinhuepf/napari-workflow-optimizer,
347,Napari Workshop Browser,0.0.3,2023-07-17,2023-10-18,napari-workshop-browser,Kyle Harrington,napari@kyleharrington.com,BSD-3-Clause,https://github.com/kephale/napari-workshop-browser,A plugin to browse and follow napari workshops,>=3.8,"['numpy', 'superqt', 'qtpy', 'notebook <7.0.0', 'jupytext', 'napari', 'appdirs', 'requests', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-workshop-browser

[![License BSD-3](https://img.shields.io/pypi/l/napari-workshop-browser.svg?color=green)](https://github.com/kephale/napari-workshop-browser/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-workshop-browser.svg?color=green)](https://pypi.org/project/napari-workshop-browser)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-workshop-browser.svg?color=green)](https://python.org)
[![tests](https://github.com/kephale/napari-workshop-browser/workflows/tests/badge.svg)](https://github.com/kephale/napari-workshop-browser/actions)
[![codecov](https://codecov.io/gh/kephale/napari-workshop-browser/branch/main/graph/badge.svg)](https://codecov.io/gh/kephale/napari-workshop-browser)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-workshop-browser)](https://napari-hub.org/plugins/napari-workshop-browser)

A plugin to browse and follow napari workshops

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## How to use this

1. Download napari as an app (e.g. the latest napari releases are
   available here: https://github.com/napari/napari/releases)
2. Open napari
3. Select `Plugins \ Plugin Manager`
4. Install this plugin, and restart napari.
6. Run this plugin and enter the URL of your workshop's zip file
7. Click `Launch workshop`

## Installation

You can install `napari-workshop-browser` via [pip]:

    pip install napari-workshop-browser



To install latest development version :

    pip install git+https://github.com/kephale/napari-workshop-browser.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-workshop-browser"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/kephale/napari-workshop-browser/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/kephale/napari-workshop-browser/issues', 'Documentation, https://github.com/kephale/napari-workshop-browser#README.md', 'Source Code, https://github.com/kephale/napari-workshop-browser', 'User Support, https://github.com/kephale/napari-workshop-browser/issues']",,,napari-workshop-browser.make_qwidget,,,,,https://pypi.org/project/napari-workshop-browser,https://github.com/kephale/napari-workshop-browser,
348,Workshop 2023 demo plugin,1.0.4,,,napari-workshop-plugin,MetaCell,sean.martin@metacell.us,MIT,,A plugin to demonstrate some concepts from the 2023 workshop on software development related to napari,>=3.8,"['numpy <2,>=1.23', 'magicgui', 'qtpy', ""mkdocs-material ; extra == 'docs'"", ""mkdocstrings-python ; extra == 'docs'"", ""mkdocstrings ; extra == 'docs'"", ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-workshop-plugin

[![License MIT](https://img.shields.io/pypi/l/napari-workshop-plugin.svg?color=green)](https://github.com/MetaCell/napari-workshop-plugin/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-workshop-plugin.svg?color=green)](https://pypi.org/project/napari-workshop-plugin)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-workshop-plugin.svg?color=green)](https://python.org)
[![tests](https://github.com/seankmartin/napari-software-development-workshop/actions/workflows/test.yml/badge.svg)](https://github.com/seankmartin/napari-software-development-workshop/actions)
[![codecov](https://codecov.io/gh/seankmartin/napari-software-development-workshop/branch/main/graph/badge.svg)](https://codecov.io/gh/seankmartin/napari-software-development-workshop)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-workshop-plugin)](https://napari-hub.org/plugins/napari-workshop-plugin)

The purpose of this repository is to provide a template for a napari plugin that can be used as a starting point for the napari software development workshop 2023.
It should help you to see the basics of building documentation, testing, and continuous integration for a napari plugin.

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.
The cookiecutter plugin is also a great jumping off point for your own plugin development.

## Check out a template you can use for your own README

[template.md](template.md)

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-workshop-plugin` via [pip]:

    pip install napari-workshop-plugin

## License

Distributed under the terms of the [MIT] license,
""napari-workshop-plugin"" is free and open source software

## Issues

If you encounter any problems, please file an issue along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[pip]: https://pypi.org/project/pip/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: MIT License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/seankmartin/napari-software-development-workshop/issues', 'Documentation, https://seankmartin.github.io/napari-software-development-workshop/', 'Source Code, https://github.com/seankmartin/napari-software-development-workshop', 'User Support, https://napari.zulipchat.com']",napari-workshop-plugin.get_reader,,napari-workshop-plugin.make_widget,napari-workshop-plugin.sample_data,['*.npy'],,,https://pypi.org/project/napari-workshop-plugin,,
349,WSI Reader,0.1.4,2023-03-30,2023-08-22,napari-wsi,Philipp Plewa,philipp.plewa@astrazeneca.com,Apache-2.0,https://github.com/AstraZeneca/napari-wsi,A plugin to read whole slide images within napari.,">=3.10,<3.12","['dask[array] (>=2023)', 'imagecodecs (>=2023.9.18)', 'magicgui (>=0.7.3)', 'matplotlib (>=3.8)', 'napari (>=0.4.18)', 'numpy (>=1.26)', 'rasterio (>=1.3)', 'tifffile (>=2023)', 'zarr (>=2.16)']","# napari-wsi

[![PyPI](https://img.shields.io/pypi/v/napari-wsi.svg?color=green)](https://pypi.org/project/napari-wsi)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-wsi)](https://napari-hub.org/plugins/napari-wsi)
[![Tests](https://github.com/AstraZeneca/napari-wsi/actions/workflows/main.yml/badge.svg)](https://github.com/AstraZeneca/napari-wsi/actions)
![Maturity Level-1](https://img.shields.io/badge/Maturity%20Level-ML--1-yellow)

A plugin to read whole slide images within [napari].

---

## Installation

You can install `napari-wsi` via [pip]:

```bash
pip install napari-wsi
```

To install the latest development version, run:
```bash
pip install git+https://github.com/AstraZeneca/napari-wsi.git
```

# Description

This [napari] plugin provides a reader for various whole slide image formats.

By default, any of the following formats is read using the [tifffile] library.
If the image file contains a tag `GDAL_METADATA`, the [rasterio] library is used
instead.

- .bif
- .ndpi
- .qptiff
- .scn
- .svs
- .tif
- .tiff

# Quickstart

From the terminal:

```bash
napari CMU-1.svs
```

From python:

```python
import napari

viewer = napari.Viewer()
viewer.open(""CMU-1.svs"")
```

[napari]: https://github.com/napari/napari
[pip]: https://pypi.org/project/pip/
[rasterio]: https://github.com/rasterio/rasterio
[tifffile]: https://github.com/cgohlke/tifffile

","['Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: Apache Software License', 'Operating System :: OS Independent', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Topic :: Scientific/Engineering :: Image Processing']","['Repository, https://github.com/AstraZeneca/napari-wsi']",napari-wsi.get_wsi_reader,,napari-wsi.get_wsi_reader_widget,,"['*.bif', '*.ndpi', '*.qptiff', '*.scn', '*.svs', '*.tif', '*.tiff']",,,https://pypi.org/project/napari-wsi,https://github.com/AstraZeneca/napari-wsi,
350,napari-wsireg,0.1.2,,,napari-wsireg,Nathan Heath Patterson,heath.patterson@vanderbilt.edu,BSD-3-Clause,,plugin to perform whole slide image registration with wsireg,>=3.8,"['wsireg (>=0.3.6)', 'SimpleITK', 'czifile', 'dask', 'imagecodecs', 'napari', 'numpy', 'ome-types', 'pint', 'qtpy', 'tifffile', 'zarr (>=2.10.3)', 'napari-geojson', 'networkx', 'matplotlib']","# napari-wsireg

![Alt text](https://github.com/NHPatterson/napari-wsireg/blob/main/src/napari_wsireg/gui/resources/wsireg-logo-light.svg?raw=true ""wsireg"")

[//]: # ([![License]&#40;https://img.shields.io/pypi/l/napari-wsireg.svg?color=green&#41;]&#40;https://github.com/nhpatterson/napari-wsireg/raw/main/LICENSE&#41;)

[//]: # ([![PyPI]&#40;https://img.shields.io/pypi/v/napari-wsireg.svg?color=green&#41;]&#40;https://pypi.org/project/napari-wsireg&#41;)

[//]: # ([![Python Version]&#40;https://img.shields.io/pypi/pyversions/napari-wsireg.svg?color=green&#41;]&#40;https://python.org&#41;)

[//]: # ([![tests]&#40;https://github.com/nhpatterson/napari-wsireg/workflows/tests/badge.svg&#41;]&#40;https://github.com/nhpatterson/napari-wsireg/actions&#41;)

[//]: # ([![napari hub]&#40;https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-wsireg&#41;]&#40;https://napari-hub.org/plugins/napari-wsireg&#41;)


Plugin to perform whole slide image registration based on wsireg.

Please see [wsireg](https://github.com/nhpatterson/wsireg) for more info image formats, features and how registration works.


## Usage

Add images from napari layers or from file and set up ""registration paths"" between them. OME-TIFF is best supported format.

### Constructed registration graph in action

![Alt Text](assets/graph_in_action.gif)


_Solid arrows_: direct registration between two images.

_Dashed arrows_: indriect registration paths.

## Installation

You can install `napari-wsireg` via [pip]:

    pip install napari-wsireg



To install latest development version :

    pip install git+https://github.com/nhpatterson/napari-wsireg.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-wsireg"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/nhpatterson/napari-wsireg/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 4 - Beta', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Topic :: Software Development :: Testing']","['Bug Tracker, https://github.com/nhpatterson/napari-wsireg/issues', 'Documentation, https://github.com/nhpatterson/napari-wsireg#README.md', 'Source Code, https://github.com/nhpatterson/napari-wsireg', 'User Support, https://github.com/nhpatterson/napari-wsireg/issues']",,,napari-wsireg.make_qwidget,,,,,https://pypi.org/project/napari-wsireg,,
351,napari-yapic-prediction,0.2.0,2022-02-11,2023-06-18,napari-yapic-prediction,"Duway Nicolas Lesmes Leon, Pranjal Dhole","dlesmesleon@hotmail.com, dhole.pranjal@gmail.com",GNU GPL v3.0,https://github.com/yapic/napari-yapic-prediction,napari widget that performs image segmentation with yapic model in the napari window. Install TENSORFLOW to use this plugin.,>=3.6,"['napari-plugin-engine (>=0.1.4)', 'numpy', 'napari[all]', 'yapic', 'scikit-image']","# napari-yapic-prediction

[![License](https://img.shields.io/pypi/l/napari-yapic-prediction.svg?color=green)](https://github.com/yapic/napari-yapic-prediction/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-yapic-prediction.svg?color=green)](https://pypi.org/project/napari-yapic-prediction)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-yapic-prediction.svg?color=green)](https://python.org)
[![tests](https://github.com/yapic/napari-yapic-prediction/workflows/tests/badge.svg)](https://github.com/yapic/napari-yapic-prediction/actions)
[![codecov](https://codecov.io/gh/yapic/napari-yapic-prediction/branch/master/graph/badge.svg?token=amah2YwOpx)](https://codecov.io/gh/yapic/napari-yapic-prediction)

A napari widget plugin to perform YAPiC model segmentation prediction in the napari window. 

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/docs/plugins/index.html
-->

## Description

This napari plugin provides a widget to upload a [YAPiC] trained model and perform segmentation over all the present images in the napari window. The segmentation results are uploaded as napari layers into the viewer automatically with the name structure of *imgename_prediction*.

## Installation

1. Please install either GPU or CPU version of tensorflow that is compatible with your `cuda` and `cudnn` libraries before installing the plugin depending on your system.
One of the plugin dependency is `yapic` that currently has sensitivity to tensorflow versions.

2. You can install `napari-yapic-prediction` via [pip]:

    ```pip install napari-yapic-prediction```

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [GNU GPL v3.0] license,
""napari-yapic-prediction"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/yapic/napari-yapic-prediction/issues
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
[YAPiC]: https://yapic.github.io/yapic/


","['Development Status :: 4 - Beta', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Operating System :: OS Independent', 'License :: OSI Approved :: GNU General Public License v3 (GPLv3)']",,,,napari-yapic-prediction.MyWidget,,,,,https://pypi.org/project/napari-yapic-prediction,https://github.com/yapic/napari-yapic-prediction,
352,Yolo5 Mitosis Detector,0.0.1,,,napari-yolo5-mitosis-detector,Titouan Poquillon,titouan.poquillon@gmail.com,BSD-3-Clause,,A simple plugin to use yolo5 for mitosis detection with napari,>=3.9,"['numpy ==1.26.2', 'magicgui ==0.8.0', 'qtpy ==2.4.1', 'scikit-image ==0.20.0', 'opencv-python ==4.8.1.78', 'torch ==2.1.1', 'ultralytics ==8.0.222', 'shapely ==2.0.2', 'importlib-resources ==6.1.1', 'pandas ==2.1.3', 'napari-aicsimageio ==0.7.2', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-yolo5-mitosis-detector

[![License BSD-3](https://img.shields.io/pypi/l/napari-yolo5-mitosis-detector.svg?color=green)](https://github.com/TPoquillon/napari-yolo5-mitosis-detector/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-yolo5-mitosis-detector.svg?color=green)](https://pypi.org/project/napari-yolo5-mitosis-detector)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-yolo5-mitosis-detector.svg?color=green)](https://python.org)
[![tests](https://github.com/TPoquillon/napari-yolo5-mitosis-detector/workflows/tests/badge.svg)](https://github.com/TPoquillon/napari-yolo5-mitosis-detector/actions)
[![codecov](https://codecov.io/gh/TPoquillon/napari-yolo5-mitosis-detector/branch/main/graph/badge.svg)](https://codecov.io/gh/TPoquillon/napari-yolo5-mitosis-detector)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-yolo5-mitosis-detector)](https://napari-hub.org/plugins/napari-yolo5-mitosis-detector)

A simple plugin to use yolo5 for mitosis detection with napari

tpoquillon@gmail.com

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-yolo5-mitosis-detector` via [pip]:

    pip install napari-yolo5-mitosis-detector



To install latest development version :

    pip install git+https://github.com/TPoquillon/napari-yolo5-mitosis-detector.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-yolo5-mitosis-detector"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/TPoquillon/napari-yolo5-mitosis-detector/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/TPoquillon/napari-yolo5-mitosis-detector/issues', 'Documentation, https://github.com/TPoquillon/napari-yolo5-mitosis-detector#README.md', 'Source Code, https://github.com/TPoquillon/napari-yolo5-mitosis-detector', 'User Support, https://github.com/TPoquillon/napari-yolo5-mitosis-detector/issues']",,,napari-yolo5-mitosis-detector.make_yolov5_qwidget,,,,,https://pypi.org/project/napari-yolo5-mitosis-detector,,
353,napari-yolov5,0.2.14,2022-05-16,2023-06-18,napari-yolov5,Richard De Mets,demets.richard@gmail.com,GPL-3.0-only,https://github.com/rdemets/napari-yolov5,Plugin adapted from Ultralytics to bring YOLOv5 into Napari,>=3.7,"['connected-components-3d >=3.6.0', 'flask >=2.2.2', 'imageio-ffmpeg >=0.4.7', 'matplotlib >=3.2.2', 'napari-plugin-engine >=0.1.4', 'napari >=0.4.15', 'numpy >=1.18.5', 'opencv-python >=4.1.2', 'Pillow >=7.1.2', 'PyYAML >=5.3.1', 'qtpy >=2.2.1', 'requests >=2.23.0', 'scikit-image >=0.19.3', 'scipy >=1.4.1', 'tensorboard >=1.15.0', 'tensorflow >=2.10.0', 'torch >=1.9.0', 'torchvision >=0.8.1', 'tqdm >=4.41.0', 'seaborn >=0.11.2', 'wandb >=0.13.4']","# napari-yolov5

[![License](https://img.shields.io/pypi/l/napari-yolov5.svg?color=green)](https://github.com/rdemets/napari-yolov5/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-yolov5.svg?color=green)](https://pypi.org/project/napari-yolov5)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-yolov5.svg?color=green)](https://python.org)
[![tests](https://github.com/rdemets/napari-yolov5/workflows/tests/badge.svg)](https://github.com/rdemets/napari-yolov5/actions)
[![codecov](https://codecov.io/gh/rdemets/napari-yolov5/branch/main/graph/badge.svg)](https://codecov.io/gh/rdemets/napari-yolov5)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-yolov5)](https://napari-hub.org/plugins/napari-yolov5)

Plugin adapted from Ultralytics to bring YOLOv5 into Napari. 

Training and detection can be done using the GUI. Training dataset must be prepared prior to using this plugin. Further development will allow users to use Napari to prepare the dataset. Follow instructions stated on [Ultralytics Github](https://github.com/ultralytics/yolov5) to prepare the dataset.

The plugin includes 3 pre-trained networks that are able to identify mitosis stages or apoptosis on soSPIM images. More details can be found on the [pre-print](https://www.biorxiv.org/content/10.1101/2021.03.26.437121v1.full).

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/stable/index.html
-->

## Installation

First install conda and create an environment for the plugin
```
conda create --prefix env-napari-yolov5 python=3.9
conda activate env-napari-yolov5
```
You can install `napari-yolov5` and `napari` via [pip]:

    pip install napari-yolov5
    pip install napari[all]

For GPU support :
```
pip uninstall torch
pip install torchvision==0.10.0+cu111 -f https://download.pytorch.org/whl/torch_stable.html
```

## Usage

First select if you would like to train a new network or detect objects.

![alt text](https://github.com/rdemets/napari-yolov5/blob/main/src/napari_yolov5/resources/Readme/1.jpg?raw=true)


***For `Training` :***

Data preparation should be done following [Ultralytics'](https://github.com/ultralytics/yolov5) instructions.

Select the size of the network, the number of epochs, the number of images per batch to load on the GPU, the size of the images (must be a stride of 32), and the name of the network.

![alt text](https://github.com/rdemets/napari-yolov5/blob/main/src/napari_yolov5/resources/Readme/2.jpg?raw=true)

An example of the YAML config file is provided in `src/napari_yolov5/resources` folder.

![alt text](https://github.com/rdemets/napari-yolov5/blob/main/src/napari_yolov5/resources/Readme/3.jpg?raw=true)


Progress can be seen on the Terminal or on the right-hand side of the viewer.

![alt text](https://github.com/rdemets/napari-yolov5/blob/main/src/napari_yolov5/resources/Readme/4.jpg?raw=true)


***For `Detection` :***

It is possible to perform the detection on a single layer chosen in the list, all the layers opened, or by giving a folder path. For folder detection, all the images will be loaded as a single stack.

![alt text](https://github.com/rdemets/napari-yolov5/blob/main/src/napari_yolov5/resources/Readme/5.jpg?raw=true)

Nucleus size of the prediction layer has te be filled to resize the image to the training dataset. Nucleus size of the training dataset will be asked in case of a custom network.

Confidence threshold defines the minimum value for a detected object to be considered positive. 
iou nms threshold (intersection-over-union non-max-suppression) defines the overlapping area of two boxes as a single object. Only the box with the maximum confidence is kept.
Progress can be seen on the Terminal.

![alt text](https://github.com/rdemets/napari-yolov5/blob/main/src/napari_yolov5/resources/Readme/6.jpg?raw=true)

Few options allow for modification on how the boxes are being displayed (default : box + class + confidence score ; box + class ; box only) and if the box coordinates and the image overlay will be exported.
Post-processing option will perform a simple 3D assignment based on 3D connected component analysis. A median filter (1x1x3 XYZ) is applied prior to the assignment. 
The centroid of each object is then saved into a new point layer as a 3D point with a random color for each class. 

![alt text](https://github.com/rdemets/napari-yolov5/blob/main/src/napari_yolov5/resources/Readme/7.jpg?raw=true)

The localisation of each centroid is saved and the path is shown in the Terminal at the end of the detection. It is also possible now to define the export folder.

![alt text](https://github.com/rdemets/napari-yolov5/blob/main/src/napari_yolov5/resources/Readme/8.jpg?raw=true)


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [GNU GPL v3.0] license,
""napari-yolov5"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: GNU General Public License v3 (GPLv3)']",,,,napari-yolov5.widget_wrapper,,,,,https://pypi.org/project/napari-yolov5,https://github.com/rdemets/napari-yolov5,
354,napari-zelda,0.1.12,2022-02-10,2023-11-10,napari-zelda,"Rocco D'Antuono, Giuseppina Pisignano",rocco.dantuono@hotmail.it,BSD-3-Clause,https://github.com/RoccoDAnt/napari-zelda,ZELDA: a 3D Image Segmentation and Parent-Child relation plugin for microscopy image analysis in napari,>=3.7,"['datatable', 'json5', 'magicgui', 'matplotlib >=3.4.3', 'napari !=0.4.11', 'napari-plugin-engine >=0.1.4', 'numpy', 'pandas', 'scikit-image', 'scipy']","# napari-zelda

[![License](https://img.shields.io/pypi/l/napari-zelda.svg?color=green)](https://github.com/RoccoDAnt/napari-zelda/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-zelda.svg?color=green)](https://pypi.org/project/napari-zelda)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-zelda.svg?color=green)](https://python.org)
[![tests](https://github.com/RoccoDAnt/napari-zelda/workflows/tests/badge.svg)](https://github.com/RoccoDAnt/napari-zelda/actions)
[![codecov](https://codecov.io/gh/RoccoDAnt/napari-zelda/branch/master/graph/badge.svg)](https://codecov.io/gh/RoccoDAnt/napari-zelda)

## ZELDA: a 3D Image Segmentation and Parent-Child relation plugin for microscopy image analysis in napari
#### Authors: Rocco D'Antuono, Giuseppina Pisignano

###### Article: Front. Comput. Sci., 04 January 2022 | https://doi.org/10.3389/fcomp.2021.796117

###### Examples of 2D and 3D data sets: [https://doi.org/10.5281/zenodo.5651284](https://zenodo.org/record/5651284#.YYgn_WDP2Ch)
----------------------------------

## What you can do with ZELDA plugin for napari
The plugin can be used to analyze 2D/3D image data sets.  
Multidimensional images (each channel corresponding to a napari layer) can be used to:

1. Segment objects such as cells and organelles in 2D/3D.

2. Segment two populations in 2D/3D (e.g. cells and organelles, nuclei and nuclear spots, tissue structures and cells) establishing the ""Parent-Child"" relation: count how many mitochondria are contained in each cell, how many spots localize in every nucleus, how many cells are within a tissue compartment.

  Example: cell cytoplasms (parent objects) and mitochondria (child objects)
  ![](https://raw.githubusercontent.com/RoccoDAnt/napari-zelda/main/docs/2D-AF488.png) <br> **Actin** | ![](https://raw.githubusercontent.com/RoccoDAnt/napari-zelda/main/docs/2D-MT.png) <br> **Mitochondria**| ![](https://raw.githubusercontent.com/RoccoDAnt/napari-zelda/main/docs/2D-AF488_MT.png) <br> **Merge**
  ------ | ------| -----
  ![](https://raw.githubusercontent.com/RoccoDAnt/napari-zelda/main/docs/2D-AF488_parents.png) <br> **Parent cell cytoplasms** | ![](https://raw.githubusercontent.com/RoccoDAnt/napari-zelda/main/docs/2D-MT_children.png) <br> **Children mitochondria**| ![](https://raw.githubusercontent.com/RoccoDAnt/napari-zelda/main/docs/2D-MT_childrenbyParent.png) <br> **Children labelled by Parents**

The images shown above are available in the [**docs**](https://github.com/RoccoDAnt/napari-zelda/tree/main/docs) folder of this repository and were segmented using ZELDA with the following parameters:


   | **Parent objects** | **GB: sigma=2.0-> Th_parents=60.0-> DistMap-> Maxima: min_dist=10** |
   | -----|  ----|
   | **Children objects** | **GB: sigma=0.3-> Th_children=450.0 -> DistMap-> Maxima: min_dist=2**|

For small monitors it may be convenient to float the protocol panel

  |![](https://raw.githubusercontent.com/RoccoDAnt/napari-zelda/main/docs/Clipboard_ZELDA_Plugin-set_panel_to_float.png) <br> **Float a panel in napari** |
  ------ |

3. Plot results within napari interface.

    ![](https://raw.githubusercontent.com/RoccoDAnt/napari-zelda/main/docs/Plot_hist_Area.png) <br> **Histogram** | ![](https://raw.githubusercontent.com/RoccoDAnt/napari-zelda/main/docs/Plot_scatter_Area-EqDiam.png) <br> **Scatterplot**|
    ------ | ------|

4. Customize an image analysis workflow in graphical mode (no scripting knowledge required).

    | ![](https://raw.githubusercontent.com/RoccoDAnt/napari-zelda/main/docs/CustomProtocol.png) <br> **Custom image analysis workflow** |
    ------ |

5. Import and Export Protocols (image analysis workflows) in graphical mode (share with the community!).

    | ![](https://raw.githubusercontent.com/RoccoDAnt/napari-zelda/main/docs/Clipboard_Import_and_Export_Protocols.png) <br> **Import and Export of ZELDA Protocols** |
    ------ |

## Installation

**Option A.** The easiest option is to use the napari interface to install ZELDA (make sure napari!=0.4.11):
1. Plugins / Install/Uninstall Package(s)

  ![](https://raw.githubusercontent.com/RoccoDAnt/napari-zelda/main/docs/Clipboard_ZELDA_Plugin_install_in_napari.png)

2. Choose ZELDA
![](https://raw.githubusercontent.com/RoccoDAnt/napari-zelda/main/docs/Clipboard_ZELDA_Plugin_install_ZELDA_in_napari_Arrow.png)

3. ZELDA is installed
![](https://raw.githubusercontent.com/RoccoDAnt/napari-zelda/main/docs/Clipboard_ZELDA_Plugin_installed_ZELDA_in_napari_Arrow.png)

4. Launch ZELDA
![](https://raw.githubusercontent.com/RoccoDAnt/napari-zelda/main/docs/Clipboard_ZELDA_Launch_ZELDA.png)


**Option B.** You can install `napari-zelda` also via [pip]. For the best experience, create a conda environment and use napari!=0.4.11, using the following instructions:

    conda create -y -n napari-env python=3.8  
    conda activate napari-env
    conda install napari pyqt  
    pip install napari-zelda  


**Option C.** Alternatively, clone the repository and install locally via [pip]:

    pip install -e .

**Option D.** Get the latest code with [git](https://git-scm.com/book/en/v2/Getting-Started-Installing-Git) and [pip]:

    conda create -y -n napari-env python=3.8 git
    conda activate napari-env
    conda install napari pyqt
    pip install git+https://github.com/RoccoDAnt/napari-zelda.git


## Specifications

This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.

The GUI has been developed using [magicgui](https://github.com/napari/magicgui) widgets, while the image analysis and processing include functions from [scikit-image](https://scikit-image.org/), [SciPy](https://scipy.org/), and [NumPy](https://numpy.org/). Results are handled with [pandas](https://pandas.pydata.org/) and [datatable](https://datatable.readthedocs.io/en/latest/). Plots are obtained with [matplotlib](https://matplotlib.org/).  
<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/docs/plugins/index.html
-->


## Contributing

Contributions are welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

Users can add new protocol steps to their local installation using [magicgui](https://github.com/napari/magicgui) widgets.
Code can be added at the end of napari_zelda.py file:

>###Add here new functionalities for ZELDA ###
>
>###@magicgui(layout=""vertical"")
>
>###def new_functionality_widget(viewer: 'napari.Viewer'):
>
>###...
>
>###
>
>###End###



## License

Distributed under the terms of the [BSD-3] license,
""napari-zelda"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/RoccoDAnt/napari-zelda/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 3 - Alpha', 'Intended Audience :: Science/Research', 'Framework :: napari', 'Topic :: Scientific/Engineering', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']",,,,napari-zelda.launch_ZELDA,,,,,https://pypi.org/project/napari-zelda,https://github.com/RoccoDAnt/napari-zelda,
355,napari-zulip,0.0.2,2023-05-05,2023-06-18,napari-zulip,Kyle Harrington,czi@kyleharrington.com,BSD-3-Clause,https://github.com/kephale/napari-zulip,A simple plugin for interacting with Zulip from napari,>=3.9,"['numpy', 'magicgui', 'qtpy', 'zulip', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-zulip

[![License BSD-3](https://img.shields.io/pypi/l/napari-zulip.svg?color=green)](https://github.com/kephale/napari-zulip/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-zulip.svg?color=green)](https://pypi.org/project/napari-zulip)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-zulip.svg?color=green)](https://python.org)
[![tests](https://github.com/kephale/napari-zulip/workflows/tests/badge.svg)](https://github.com/kephale/napari-zulip/actions)
[![codecov](https://codecov.io/gh/kephale/napari-zulip/branch/main/graph/badge.svg)](https://codecov.io/gh/kephale/napari-zulip)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-zulip)](https://napari-hub.org/plugins/napari-zulip)

A simple plugin for interacting with Zulip from napari.

![An example screenshot of napari-zulip in action. It shows the plugin napari-boids and a filtered noise image, as well as a docked version of the napari-zulip plugin](./resources/demo_screenshot.png)  

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-zulip` via [pip]:

    pip install napari-zulip



To install latest development version :

    pip install git+https://github.com/kephale/napari-zulip.git

### Setting it up

The plugin is going to look for a file in `<home directory>/.zulip.d/napari.zulipchat.com.zuliprc`.

**If you want to use this on a different zulip then adjust the `napari.zulipchat.com` to whatever the correct domain should be.**

#### How to generate a `.zuliprc` file

In the Zulip app:
- Select `Menu`
- Select `Personal settings`
- Select `Account & privacy`
- Click on `Show/change your API key`
- Enter your password
- Click `Download .zuliprc` 
- Save the file as `<home directory>/.zulip.d/napari.zulipchat.com.zuliprc` (or change the domain name if using a different Zulip server)

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-zulip"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/kephale/napari-zulip/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/kephale/napari-zulip/issues', 'Documentation, https://github.com/kephale/napari-zulip#README.md', 'Source Code, https://github.com/kephale/napari-zulip', 'User Support, https://github.com/kephale/napari-zulip/issues']",,,napari-zulip.screenshot_to_Zulip,,,,,https://pypi.org/project/napari-zulip,https://github.com/kephale/napari-zulip,
356,CellSeg3D,0.1.2,2022-07-11,2023-12-15,napari_cellseg3d,,,MIT,https://github.com/AdaptiveMotorControlLab/CellSeg3d,Plugin for cell segmentation in 3D,,,,,,,,,,,,,https://pypi.org/project/napari_cellseg3d,https://github.com/AdaptiveMotorControlLab/CellSeg3d,
357,napari_hello,0.1.0,,,napari_hello,Your Name,,,,My napari plugin,,,,,,,,,,,,,https://pypi.org/project/napari_hello,,
358,napari_psf_analysis,1.1.3,2022-07-07,2023-06-18,napari_psf_analysis,Tim-Oliver Buchholz,,BSD-3-Clause,https://github.com/fmi-faim/napari-psf-analysis,A plugin to analyse point spread functions (PSFs).,,,,,,,,,,,,,https://pypi.org/project/napari_psf_analysis,https://github.com/fmi-faim/napari-psf-analysis,
359,napari_stress,0.3.5,2023-12-08,2024-01-15,napari_stress,"Johannes Soltwedel, Ben J. Gross, Elijah Shelton, Carlos Gomez, Otger Campas",,BSD-3-Clause,https://pypi.org/project/napari-stress,Interactive surface analysis in napari for measuring mechanical stresses in biological tissues,,,,,,,,,,,,,https://pypi.org/project/napari-stress,,
360,napari_video,0.2.9,2022-02-05,2023-06-18,napari_video,Jan Clemens,clemensjan@googlemail.com,,https://github.com/janclemenslab/napari-video,napari plugin for reading videos.,>=3.6,"['numpy', 'pyvideoreader']","# napari-video
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari_video)](https://napari-hub.org/plugins/napari_video)

Napari plugin for working with videos.

Relies on [pyvideoreader](https://pypi.org/project/pyvideoreader/) as a backend which itself uses [opencv](https://opencv.org) for reading videos.

## Installation
```shell
pip install napari[all] napari_video
```

## Usage
From a terminal:
```shell
napari video.avi
```

Or from within python:
```shell
import napari
from napari_video.napari_video import VideoReaderNP

path='video.mp4'
vr = VideoReaderNP(path)
with napari.gui_qt():
    viewer = napari.view_image(vr, name=path)
```

## Internals
`napari_video.napari_video.VideoReaderNP` exposes a video with a numpy-like interface, using opencv as a backend.

For instance, open a video:
```python
vr = VideoReaderNP('video.avi')
print(vr)
```
```
video.avi with 60932 frames of size (920, 912, 3) at 100.00 fps
```
Then

- `vr[100]` will return the 100th frame as a numpy array with shape `(902, 912, 3)`.
- `vr[100:200:10]` will return 10 frames evenly spaced between frame number 100 and 200 (shape `(10, 902, 912, 3)`).
- Note that by default, single-frame and slice indexing return 3D and 4D arrays, respectively. To consistently return 4D arrays, open the video with `remove_leading_singleton=False`. `vr[100]` will then return a `(1, 902, 912, 3)` array.
- We can also request specific ROIs and channels. For instance, `vr[100:200:10,100:400,800:850,1]` will return an array with shape `(10, 300, 50, 1)`.


","['License :: OSI Approved :: MIT License', 'Framework :: napari', 'Operating System :: OS Independent']","['Bug Tracker, https://github.com/janclemenslab/napari-video/issues', 'Documentation, https://github.com/janclemenslab/napari-video/blob/main/README.md', 'Source Code, https://github.com/janclemenslab/napari-video', 'User Support, https://github.com/janclemenslab/napari-video/issues']",napari_video.napari_get_reader,,,,['*'],,,https://pypi.org/project/napari_video,https://github.com/janclemenslab/napari-video,
361,napping,0.2.4,,,napping,Jonas Windhager,jonas.windhager@uzh.ch,MIT,,Control point mapping and coordination transformation using napari,>=3.8,"['imagecodecs', 'imageio', 'napari[all] (>=0.4.16)', 'numpy', 'pandas', 'qtpy', 'scikit-image']","# napping

[![PyPI](https://img.shields.io/pypi/v/napping.svg?color=green)](https://pypi.org/project/napping)
[![License](https://img.shields.io/pypi/l/napping.svg?color=green)](https://github.com/BodenmillerGroup/napping/raw/main/LICENSE)
[![Python Version](https://img.shields.io/pypi/pyversions/napping.svg?color=green)](https://python.org)
[![Issues](https://img.shields.io/github/issues/BodenmillerGroup/napping)](https://github.com/BodenmillerGroup/napping/issues)
[![Pull requests](https://img.shields.io/github/issues-pr/BodenmillerGroup/napping)](https://github.com/BodenmillerGroup/napping/pulls)

Control point mapping and coordinate transformation using napari

## Installation

You can install `napping` via [pip](https://pypi.org/project/pip/):

    pip install napping

To install latest development version:

    pip install git+https://github.com/BodenmillerGroup/napping.git

## Usage

Run `napping` for control point mapping and coordinate transformation

## Authors

Created and maintained by Jonas Windhager [jonas.windhager@uzh.ch](mailto:jonas.windhager@uzh.ch)

## Contributing

[Contributing](https://github.com/BodenmillerGroup/napping/blob/main/CONTRIBUTING.md)

## Changelog

[Changelog](https://github.com/BodenmillerGroup/napping/blob/main/CHANGELOG.md)

## License

[MIT](https://github.com/BodenmillerGroup/napping/blob/main/LICENSE.md)
","['Development Status :: 4 - Beta', 'Intended Audience :: Science/Research', 'Framework :: napari', 'Topic :: Scientific/Engineering :: Bio-Informatics', 'Topic :: Scientific/Engineering :: Image Processing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: MIT License']","['Bug Tracker, https://github.com/BodenmillerGroup/napping/issues', 'Documentation, https://github.com/BodenmillerGroup/napping/#README.md', 'Source Code, https://github.com/BodenmillerGroup/napping', 'User Support, https://github.com/BodenmillerGroup/napping/issues']",,,,,,,,https://pypi.org/project/napping,,
362,natari,0.2.7,2022-02-02,2023-06-18,natari,Robert Haase,robert.haase@tu-dresden.de,BSD-3-Clause,https://github.com/haesleinhuepf/natari,Napari gaming,>=3.7,"['napari-plugin-engine (>=0.1.4)', 'numpy', 'napari', 'scipy', 'napari-tools-menu']","# natari

[![License](https://img.shields.io/pypi/l/natari.svg?color=green)](https://github.com/haesleinhuepf/natari/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/natari.svg?color=green)](https://pypi.org/project/natari)
[![Python Version](https://img.shields.io/pypi/pyversions/natari.svg?color=green)](https://python.org)

Napari gaming

## Sliding puzzle

Restore the image by reordering the superpixels using the `W`, `A`, `S`, `D` keys! 

![](https://github.com/haesleinhuepf/natari/raw/master/images/sliding_puzzle.gif)

## Cell counting arcade
Commander! Cells are intruding our dish! Control your tiny space ship using `1` and `2` keys to move it left/right.
Use the `9` key to shoot a anti-cell bullet.

![](https://github.com/haesleinhuepf/natari/raw/master/images/cell_counting_arcade.gif)

The image originates from [BBBC022v1](https://bbbc.broadinstitute.org/BBBC022) (Gustafsdottir et al., PLOS ONE, 2013), available from the Broad Bioimage Benchmark Collection (Ljosa et al., Nature Methods, 2012).

## Snake
Two mitochondria navigating in a cell searching for stress granules. 
The two players can control their mito using the `W`, `A`, `S`, `D` and `I`, `J`, `K`, `L`  keys, respectively.

![](https://github.com/haesleinhuepf/natari/raw/master/images/snake.gif)

## Ping pong
Don't drop the organoid! Use your racket and hit it back to your colleague!
The two players can use `W`, `S` and `I`, `K` to control their racket, respectively.

![](https://github.com/haesleinhuepf/natari/raw/master/images/ping_pong.gif)


This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.

## Installation

You can install `natari` via [pip]:

    pip install natari

## Known issues

* To make the keyboard buttons work, you sometimes have to click within the image after starting the game.

## Contributing

Contributions are very welcome. 

## License

""natari"" is free and open source software. The code is in the public domain.

[See also: unlicense.org](https://unlicense.org)

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/haesleinhuepf/natari/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/


","['Development Status :: 3 - Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/haesleinhuepf/natari/issues', 'Documentation, https://github.com/haesleinhuepf/natari#README.md', 'Source Code, https://github.com/haesleinhuepf/natari', 'User Support, https://github.com/haesleinhuepf/natari/issues']",,,natari.napari_experimental_provide_function,,,,,https://pypi.org/project/natari,https://github.com/haesleinhuepf/natari,
363,Nellie,0.1.8,,,nellie,Austin E. Y. T. Lefebvre,austin.e.lefebvre+nellie@gmail.com,,,"Automated organelle segmentation, tracking, and hierarchical feature extraction in 2D/3D live-cell microscopy",>=3.9,"['numpy ==1.26.4', 'scipy ==1.12.0', 'scikit-image ==0.22.0', 'nd2 ==0.9.0', 'ome-types ==0.5.1.post1', 'pandas ==2.2.1', 'matplotlib ==3.8.3', 'napari[all]']","# Nellie
## Automated organelle segmentation, tracking, and hierarchical feature extraction in 2D/3D live-cell microscopy

<img src=""https://github.com/aelefebv/nellie/assets/26515909/96b7a113-be60-4028-bcd9-b444bdb943f6"" width=""200px"" align=""left"" /> *arXiv* 

  [Preprint Link](https://arxiv.org/abs/2403.13214) | [Cite](#reference)

**Abstract:** The analysis of dynamic organelles remains a formidable challenge, though key to understanding biological processes. We introduce Nellie, an automated and unbiased pipeline for segmentation, tracking, and feature extraction of diverse intracellular structures. Nellie adapts to image metadata, eliminating user input. Nellie’s preprocessing pipeline enhances structural contrast on multiple intracellular scales allowing for robust hierarchical segmentation of sub-organellar regions. Internal motion capture markers are generated and tracked via a radius-adaptive pattern matching scheme, and used as guides for sub-voxel flow interpolation. Nellie extracts a plethora of features at multiple hierarchical levels for deep and customizable analysis. Nellie features a Napari-based GUI that allows for code-free operation and visualization, while its modular open-source codebase invites customization by experienced users. 

**Nellie's pipeline and Napari plugin are both very much in early stages,** therefore [I highly encourage any and all feedback](#getting-help).

## Example output intermediates

https://github.com/aelefebv/nellie/assets/26515909/1df8bf1b-7116-4d19-b5fb-9658f744675b

## Installation

**Notes:** 
- It is recommended (but usually not required) to [create a new environment](https://docs.python.org/3/library/venv.html) for Nellie to avoid conflicts with other packages.
- May take several minutes to install.
- Choose one of the following methods, and only one!
### Option 1. Via Napari plugin manager:
If not already installed, install Napari: https://napari.org/stable/tutorials/fundamentals/installation
1. Open Napari
2. Go to ```Plugins > Install/Uninstall Plugins...```
3. Search for Nellie and click ```Install```
### Option 2. Via PIP:
```bash
pip install nellie
```
#### Option 2a for NVIDIA GPU acceleration, optional (Windows, Linux):
To use GPU acceleration via NVIDIA GPUs, you also need to install cupy:
```bash
pip install cupy-cudaXXx
```
- replace ```cupy-cudaXXx``` with the [appropriate version](https://docs.cupy.dev/en/stable/install.html#installing-cupy) for your CUDA version.
  - i.e. ```cupy-cuda11x``` for CUDA 11.x or ```cupy-cuda12x``` for CUDA 12.x
- if you don't have CUDA installed, [go here](https://docs.cupy.dev/en/stable/install.html).
- Mac Metal GPU-acceleration coming... eventually.

## Usage
The sample dataset shown below is in the repo if you want to play around without, and can be downloaded [here](https://github.com/aelefebv/nellie/tree/main/sample_data).

https://github.com/aelefebv/nellie/assets/26515909/05199fed-ed8c-4237-b3ba-0a3f4cdcb337

### General data preparation
- It is strongly recommended to have your data in a parsable format, such as .ome.tif, .nd2, or other raw data files from microscopes.
  - Importing into ImageJ/FIJI and saving via BioFormats with the proper image dimensions should do the trick.
  - If the metadata cannot be parsed, you will have to manually enter it.
- It is also recommended to crop your image as much as possible to reduce processing time and memory usage. But really, unless you have massive lightsheet data, it should be pretty fast.

https://github.com/aelefebv/nellie/assets/26515909/372d07a8-15a0-4926-8594-108dd4b97280

### Running Nellie's processing pipeline
1. Start Napari (open a Terminal and type napari)
    ```bash
    napari
    ```
2. Go to 
```Plugins > Nellie (nellie)``` then to the ```File select``` tab.
3. Click ```Select File``` of ```Select Folder``` to select your image(s).
   - If the metadata boxes do not fill in automatically and turn red, this means Nellie did not detect that metadata portion from your image, and you must manually enter it or reformat your image and try again.
     - The metadata slot will appear green if it is in the correct format.
   - *Note, if you are batch processing, the metadata must be the same for all images if any of them are in an incorrect format (this will be fixed eventually). If they are different, but all pass validation, then it will process fine.
   - You can preview 2 time points of your image via the ```Open preview``` button once the metadata is filled in to ensure it looks correct.
4. Click the ```Process``` tab.
   - If you have multiple fluorescence channels, select the channel you want to process/analyze.
   - If you only want to analyze up to a certain timepoint, you can set this in slider. By default it will run all timepoints.
   - If you have odd noise on the edges of your image, check the ```Remove image edges``` checkbox.
5. You can run the full pipeline with ```Run Nellie```, or run individual steps below.
    - Steps can only be run once its previous step has been run.
    - Likewise, visualizations in the ```Visualization``` tab can only be opened once its respective step has been run.
6. All intermediate files and output csvs will be saved to ```[image_directory]/nellie_output/```.
   - A separate .csv is created for each level of the organellar hierarchy.
7. Once features have been exported, Nellie will automatically detect this, and allow analysis via the ```Analyze``` tab.
   - Analysis at this point is optional, but can be helpful for visualizing, and selectively exporting data.

### Using Nellie's visualization plugin
1. Follow the previous processing steps, you only need to do this once per file as long as you don't move or delete the files.
2. Open the ```Visualization``` tab
3. Select a visualization from the list.
   1. ```Raw```: Visualize the raw data for the processed channel.
   2. ```Preprocessed```: Visualize the contrast-enhanced data.
   3. ```Segmentation```: Visualize the organelle and branch instance segmentation masks.
   4. ```Mocap Markers```: Visualize the mocap markers used for waypoints.
   5. ```Reassigned Labels```: Visualize the organelle and branch instance segmentation masks where voxels are reassigned based on the first timepoint.
4. To visualize tracks, open and select one of the segmentation layers.
5. ```Alt+Click``` on a label to visualize the track of that selected organelle/branch across all timepoints.
   - If the segmentation labels are selected, it will generate tracks for all voxels in the selected timepoint only.
   - If the reassigned labels are selected, you can choose to generate tracks for all voxels across all timepoints.
   - You can skip voxels to track so that the area is not too crowded by tracks.
   - *Note: If you have a 3D image, toggle to 2D mode via the ```Toggle 2D/3D view``` at the bottom left before ```Alt+Click```ing (eventually I'll get it to work while in 3D mode).

### Using Nellie's analysis plugin

https://github.com/aelefebv/nellie/assets/26515909/7f4f09a4-3687-4635-988d-e1d16ad2a4af

1. Follow the previous processing steps, you only need to do this once per file as long as you don't move or delete the files.
2. Open the ```Analyze``` tab, select the hierarchy level you want to visualize from the dropdown.
3. Select the level-specific feature you want to visualize from the new dropdown.
4. A histogram of all the data will be displayed.
   - This histogram can be directly exported via the ```Save graph``` button. A .png will be saved to ```[image_directory]/nellie_output/graphs/``` with the current datetime.
   - The values of the histogram can be exported via the ```Export graph data``` button. A .csv will be saved to ```[image_directory]/nellie_output/graphs/``` with the current datetime.
   - The histogram's x-axis can be viewed in log10 scale via the ```Log scale``` checkbox.
   - By default, the histogram shows lines at the mean +/- 1 standard deviation. This can instead be switched to median and quartiles via the ```Median view``` checkbox.
5. Press the ```Overlay mask``` button to colormap the organelle mask based on your selected feature.
   - Once overlaid, toggle the ```Timepoint data``` checkbox to allow you to select a specific timepoint to visualize via the slider.

## Other features
- Nellie's plugin offers an ```Easy screenshot``` feature:
  - Press the button under ```Easy screenshot``` or hit Ctrl/Cmd-Shift-E after clicking your image.
  - The .png will be saved to ```[image_directory]/nellie_output/screenshots/``` with the current datetime.

## Feedback / Getting Help
A few options are available for providing feedback or getting help with Nellie:

[Github Issues](https://github.com/aelefebv/nellie/issues/new) | [email](mailto:austin.e.lefebvre+nellie@gmail.com) | [X](https://twitter.com/Austin_Lefebvre) | wherever else you can find me!

To avoid any unnecessary back-and-forth, please include any/all (if possible) of the following information in your bug report:
- What kind of computer do you have, and what are its specs?
- Send me screenshots of what is not working.
- Send me any error logs in your terminal.
- Send me the file you ran (if possible).
- Any other information that might be helpful

## License
Nellie © 2024 by [Austin E. Y. T. Lefebvre](https://github.com/aelefebv) is licensed under [CC BY 4.0](https://creativecommons.org/licenses/by/4.0/)

## Reference
If you used Nelly or found this work useful in your own research, please cite our [arXiv preprint](https://arxiv.org/abs/2403.13214):

Lefebvre, A. E. Y. T., Sturm, G., et. al. Nellie: Automated organelle segmentation, tracking, and hierarchical feature extraction in 2D/3D live-cell microscopy, arXiv, 2024, https://arxiv.org/abs/2403.13214

```
@misc{lefebvre2024nellie,
      title={Nellie: Automated organelle segmentation, tracking, and hierarchical feature extraction in 2D/3D live-cell microscopy}, 
      author={Austin E. Y. T. Lefebvre and Gabriel Sturm and Ting-Yu Lin and Emily Stoops and Magdalena Preciado Lopez and Benjamin Kaufmann-Malaga and Kayley Hake},
      year={2024},
      eprint={2403.13214},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
```

## More fun examples
### Microtubule growing ends:

https://github.com/aelefebv/nellie/assets/26515909/88578dc9-f5c5-4188-a0e2-4e37037a44a9

### Endoplasmic reticulum:

https://github.com/aelefebv/nellie/assets/26515909/db76d388-a9cc-4650-b93d-69d357ace418

### Peroxisomes:

https://github.com/aelefebv/nellie/assets/26515909/58bda3cb-6489-4620-8584-a3728cd6b2ec

",['Framework :: napari'],,,,nellie.loader,,,,,https://pypi.org/project/nellie,,
364,nfinder,0.3,2022-02-04,2023-06-18,nfinder,Santiago N. Rodriguez Alvarez,rodriguezsantiago96@gmail.com,,https://github.com/santi-rodriguez/nfinder,Automatic inference of neighboring cells based on their Delaunay triangulation.,>=3.7,,"# Nfinder
Automatic inference of neighboring cells based on their Delaunay triangulation.

## Dependencies 
nfinder was tested with:

- python = 3.8.5
- napari = 0.4.12
- numpy = 1.21.2
- pandas = 1.3.4
- scikit-image = 0.18.3
- scipy = 1.7.1
- importlib-resources 5.4.0


## Installation

It can be installed with `pip` from PyPI:

```
pip install nfinder
```


## Usage
For usage examples, please check out the [notebook](https://github.com/santi-rodriguez/nfinder/blob/main/examples.ipynb) in our GitHub repository.



","['Development Status :: 4 - Beta', 'Programming Language :: Python :: 3.7', 'License :: OSI Approved :: MIT License', 'Operating System :: OS Independent', 'Framework :: napari']",,,,nfinder.find,,,,,https://pypi.org/project/nfinder,https://github.com/santi-rodriguez/nfinder,
365,Offset-Subtraction,0.0.5,2022-02-10,2023-06-18,Offset-Subtraction,"Marc Boucsein, Robin Koch",,BSD-3,https://github.com/MBPhys/Offset-Subtraction,A napari plugin in oder to subtract an intensity offset such as autofluorescence,>=3.7,"['napari-plugin-engine (>=0.1.4)', 'numpy', 'dask']","# Offset-Subtraction

[![License](https://img.shields.io/pypi/l/napari-medical-image-formats.svg?color=green)](https://github.com/MBPhys/Offset-Subtraction/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/Offset-Subtraction.svg?color=green)](https://pypi.org/project/Offset-Subtraction)
[![Python Version](https://img.shields.io/pypi/pyversions/Offset-Subtraction.svg?color=green)](https://python.org)


A napari plugin in oder to subtract an intensity offset such as autofluorescence

----------------------------------

## Installation

You can install `Offset-Subtraction` via [pip]:

    pip install Offset-Subtraction

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""Offset-Subtraction"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/MBPhys/Offset-Subtraction/issues
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/


","['Development Status :: 4 - Beta', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']",,,,Offset-Subtraction.Subtraction,,,,,https://pypi.org/project/Offset-Subtraction,https://github.com/MBPhys/Offset-Subtraction,
366,napari okapi-em,0.0.10,2023-04-04,2023-06-18,okapi-em,Luis Perdigao,luis.perdigao@rfi.ac.uk,Apache-2.0,https://pypi.org/project/okapi-em/,napari plugin to deal with charging artifacts in tomography electron microscopy data,>=3.7,"['numpy', 'magicgui', 'chafer', 'napari[all]', 'opencv-python', 'quoll >=0.0.4', ""imageio-ffmpeg ; extra == 'all'"", ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'""]","# okapi-em

https://github.com/rosalindfranklininstitute/okapi-em

<!--
[![License](https://img.shields.io/pypi/l/okapi-em.svg?color=green)](https://github.com/rosalindfranklininstitute/okapi-em/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/okapi-em.svg?color=green)](https://pypi.org/project/okapi-em)
[![Python Version](https://img.shields.io/pypi/pyversions/okapi-em.svg?color=green)](https://python.org)
[![tests](https://github.com/perdigao1/okapi-em/workflows/tests/badge.svg)](https://github.com/rosalindfranklininstitute/okapi-em/actions)
[![codecov](https://codecov.io/gh/perdigao1/okapi-em/branch/main/graph/badge.svg)](https://codecov.io/gh/rosalindfranklininstitute/okapi-em)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/okapi-em)](https://napari-hub.org/plugins/okapi-em)
-->

A napari plugin for processing serial-FIB-SEM data.

Powered by [chafer] and [quoll].


A full description of this software is presented in biorXiv preprint paper:

https://doi.org/10.1101/2022.12.15.520541

This [napari] plugin contains the following tools:

- slice alignment using constrained SIFT
- two charge artifact suppression filters
    - directional fourier bandapass filter
    - line-by-line filter function optimiser and subtraction (requires charge artifact labels) - uses [chafer]
- fourier ring correlation (FRC) resolution estimation - uses [quoll]

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/stable/index.html
-->

## Installation

You can install `okapi-em` via [pip]:

`>pip install okapi-em`

or using napari's plugin installation engine `Plugins->Install/Uninstall Plugins...` and filter for **Okapi-EM**.

For installing in development mode , clone this package then navigate to the cloned `okapi-em` folder and run:

`>pip install -e .`

Okapi-EM is a napari plugin. Launching napari is therefore required.

`>napari`

and then navigate `Menu->Plugins->Okapi-EM`

Note that to launch napari in older versions of python (<=3.7) you will need to use the command:

`>python -m napari`

## Computing requirements
Okapi-EM does not require powerful computers to run. None of the tools use GPU accelaration.

The minimum recommended RAM depends on the size of the data being used in napari. For a full image stack of 1Gb, it is recommended that user ensure that 3Gb of RAM is available or can be used. Modern OS's can extend physical RAM using `swap` memory (Linux) or cache (in Windows and also known as virtual memory), but processing can be significantly slower.

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [Apache Software License 2.0] license,
""okapi-em"" is free and open source software

## Citing

Please cite usage using the following reference.

Perdigão, L. M. A. et al. Okapi-EM – a napari plugin for processing and analysing cryogenic serial FIB/SEM images. 2022.12.15.520541 Preprint at https://doi.org/10.1101/2022.12.15.520541 (2022).


## Issues

There is currently a known issue with napari running in Linux machines, that it does not find the OpenGL driver correctly.
This will hopefully be resolved in the near future. If you bump into this issue we recommend trying to downgrade the python version. This is not an Okapi-EM problem.

If you encounter any problems, please file an issue along with a detailed description.

[quoll]: https://github.com/rosalindfranklininstitute/quoll
[chafer]: https://github.com/rosalindfranklininstitute/chafer
[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin


[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Operating System :: OS Independent', 'License :: OSI Approved :: Apache Software License']",,,,okapi-em.main_qwidget,,,,,https://pypi.org/project/okapi-em/,,
367,Infer sub-Cellular Object Npe2 plugin,0.0.5,,,organelle-segmenter-plugin,Andy Henrie,ergonyc@gmail.com,BSD-3,,"A plugin that enables organelle segmentation, forked from tools from Allen Institute for Cell Science",>=3.8,"['napari', 'napari-plugin-engine >=0.1.4', 'aicssegmentation', 'aicsimageio', 'numpy', 'scikit-image', 'aicsimageio >=4.7.0', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# organelle-segmenter-plugin

[![License BSD-3](https://img.shields.io/pypi/l/organelle-segmenter-plugin.svg?color=green)](https://github.com/ergonyc/organelle-segmenter-plugin/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/organelle-segmenter-plugin.svg?color=green)](https://pypi.org/project/organelle-segmenter-plugin)
[![Python Version](https://img.shields.io/pypi/pyversions/organelle-segmenter-plugin.svg?color=green)](https://python.org)
[![tests](https://github.com/ergonyc/organelle-segmenter-plugin/workflows/tests/badge.svg)](https://github.com/ergonyc/organelle-segmenter-plugin/actions)
[![codecov](https://codecov.io/gh/ergonyc/organelle-segmenter-plugin/branch/main/graph/badge.svg)](https://codecov.io/gh/ergonyc/organelle-segmenter-plugin)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/organelle-segmenter-plugin)](https://napari-hub.org/plugins/organelle-segmenter-plugin)

 🚧 WIP 🚧
A plugin that enables image segmentation of organelles from linearly-unmixed florescence images based on the segmenter tools provided by Allen Institute for Cell Science. 

A [napari](https://napari.org/stable/) plugin to infer subcellular components leveraging [infer-subc](https://github.com/ergonyc/infer-subc) and [aics-segmenter]( https://allencell.org/segmenter )

## GOAL
To measure shape, position, size, and interaction of  organelles/cellular components (Nuclei (nuc, NU), Nucleus (N1), Lysosomes (LS), Mitochondria (mito, MT), Golgi (GL), Peroxisomes (perox, PO), Endoplasmic Reticulum (ER), Lipid Droplet (LD), Cellmask (soma, cellmask), and cytoplasm (cyto, CT) ) during differentiation of iPSCs, in order to understand the Interactome / Spatiotemporal coordination.

🚧 WIP 🚧
 
### Forked from Allen Institute for Cell Science project
The Allen Cell & Structure Segmenter plugin for napari, from which this projects is forked, provides an intuitive graphical user interface to access the powerful segmentation capabilities of an open source 3D segmentation software package developed and maintained by the Allen Institute for Cell Science (classic workflows only with v1.0). ​[The Allen Cell & Structure Segmenter](https://allencell.org/segmenter) is a Python-based open source toolkit developed at the Allen Institute for Cell Science for 3D segmentation of intracellular structures in fluorescence microscope images. This toolkit brings together classic image segmentation and iterative deep learning workflows first to generate initial high-quality 3D intracellular structure segmentations and then to easily curate these results to generate the ground truths for building robust and accurate deep learning models. The toolkit takes advantage of the high replicate 3D live cell image data collected at the Allen Institute for Cell Science of over 30 endogenous fluorescently tagged human induced pluripotent stem cell (hiPSC) lines. Each cell line represents a different intracellular structure with one or more distinct localization patterns within undifferentiated hiPS cells and hiPSC-derived cardiomyocytes.

More details about Segmenter can be found at https://allencell.org/segmenter

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/docs/plugins/index.html
-->

## Installation 🚧 WIP 🚧

### Option 1 (recommended): 🚧 WIP 🚧
`organelle_segmenter_plugin` is  available on `PyPI` via: 

```bash
pip install organelle_segmenter_plugin
```
### Option 2 🚧 COMING SOON 🚧 (not yet available on napari hub)

After you installed the lastest version of napari, you can go to ""Plugins"" --> ""Install/Uninstall Package(s)"". Then, you will be able to see all available napari plugins and you can find us by name `organelle-segmenter-plugin`. Just click the ""install"" button to install the Segmenter plugin.

### Option 3: clone repo + editable install

```bash
git clone https://github.com/ndcn/organelle-segmenter-plugin.git
cd organelle-segmenter-plugin
pip install -e .
```
## Quick Start

In the current version, there are two parts in the plugin: **workflow editor** and **batch processing**. The **workflow editor** allows users adjusting parameters in all the existing workflows in the lookup table, so that the workflow can be optimized on users' data. The adjusted workflow can be saved and then applied to a large batch of files using the **batch processing** part of the plugin. 

1. Open a file in napari by dragging multi-channel .czi file onto napari which will import a multi-channel, multi-Z 'layer'. (Using the menu's defaults to `aicsIMAGEIO` reader which automatically splits mutliple channels into individual layers.  The plugin is able to support multi-dimensional data in .tiff, .tif. ome.tif, .ome.tiff, .czi)
2. Start the plugin (open napari, go to ""Plugins"" --> ""organelle-segmenter-plugin"" --> ""workflow editor"")
3. Select the image and channel to work on
4. Select a workflow based on the example image and target segmentation based on user's data. Ideally, it is recommend to start with the example with very similar morphology as user's data.
5. Click ""Run All"" to execute the whole workflow on the sample data.
6. Adjust the parameters of steps, based on the intermediate results.  A complete list of all functions can be found [here](https://github.com/ndcn/infer-subc/blob/main/infer_subc/organelles_config/function_params.md)🚧 WIP 🚧
7. Click ""Run All"" again after adjusting the parameters and repeat step 6 and 7 until the result is satisfactory.
8. Save the workflow
9. Close the plugin and open the **batch processing** part by (go to ""Plugins"" --> ""organelle-segmenter-plugin"" --> ""batch processing"")
10. Load the customized workflow saved above 
11. Load the folder with all the images to process
12. Click ""Run""
13. Follow the [examples](https://github.com/ndcn/infer-subc/blob/main/notebooks/14_final_workflow.ipynb) in the `infer_subc` [repo](https://github.com/ndcn/infer-subc/) for postprocessing of the saved segmentations and generating the statistics.  

## Contributing

Contributions are very welcome. 

## License

Distributed under the terms of the [BSD-3] license,
""organelle-segmenter-plugin"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/ndcn/organelle-segmenter-plugin/issues
[napari]: https://github.com/napari/napari
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 3 - Alpha', 'Intended Audience :: Science/Research', 'Framework :: napari', 'Topic :: Scientific/Engineering', 'Topic :: Scientific/Engineering :: Visualization', 'Topic :: Scientific/Engineering :: Information Analysis', 'Topic :: Scientific/Engineering :: Bio-Informatics', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/ndcn/organelle-segmenter-plugin/issues', 'Documentation, https://github.com/ndcn/organelle-segmenter-plugin#README.md', 'Source Code, https://github.com/ndcn/organelle-segmenter-plugin', 'User Support, https://github.com/ndcn/organelle-segmenter-plugin/issues']",organelle-segmenter-plugin.get_reader,,organelle-segmenter-plugin.make_batch_widget,,"['*.xyz', '*.czi', '*.tif', '*.tiff']",,,https://pypi.org/project/organelle-segmenter-plugin,,
368,ortho-view-napari,0.1.1,,,ortho-view-napari,Jordao Bragantini,jordao.bragantini@czbiohub.org,BSD-3,,It displays the lateral view of the current 3D stack. This could be a starting point for a orthorviewer.,>=3.7,"['napari-plugin-engine (>=0.1.4)', 'numpy']","# ortho-view-napari

[![License](https://img.shields.io/pypi/l/ortho-view-napari.svg?color=green)](https://github.com/JoOkuma/ortho-view-napari/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/ortho-view-napari.svg?color=green)](https://pypi.org/project/ortho-view-napari)
[![Python Version](https://img.shields.io/pypi/pyversions/ortho-view-napari.svg?color=green)](https://python.org)
[![tests](https://github.com/JoOkuma/ortho-view-napari/workflows/tests/badge.svg)](https://github.com/JoOkuma/ortho-view-napari/actions)
[![codecov](https://codecov.io/gh/JoOkuma/ortho-view-napari/branch/master/graph/badge.svg)](https://codecov.io/gh/JoOkuma/ortho-view-napari)

It displays the lateral view of the current 3D stack. This could be a starting point for a orthorviewer.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/docs/plugins/index.html
-->

## Installation

You can install `ortho-view-napari` via [pip]:

    pip install ortho-view-napari

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""ortho-view-napari"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/JoOkuma/ortho-view-napari/issues
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/


","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/JoOkuma/ortho-view-napari/issues', 'Documentation, https://github.com/JoOkuma/ortho-view-napari#README.md', 'Source Code, https://github.com/JoOkuma/ortho-view-napari', 'User Support, https://github.com/JoOkuma/ortho-view-napari/issues']",,,ortho-view-napari.Widget,,,,,https://pypi.org/project/ortho-view-napari,,
369,Palmari,0.3.0,2022-07-06,2023-06-18,palmari,Hippolyte Verdier,hverdier@pasteur.fr,"""CeCILL""",https://github.com/hippover/palmari,"Palmari provides a plugin to analyze PALM movies, as well as microscope recordings of other SMLM-based SPT modalities. Set up your pipeline on one file, run it on a folder !",>=3.8,"['click', 'dask (>=2022.1.0)', 'dask-image (>=2021.12.0)', 'imageio-ffmpeg', 'magicgui (>=0.5.0)', 'matplotlib (>=3.5)', 'munkres', 'napari', 'napari-aicsimageio', 'numpy', 'pandas', 'pyyaml', 'qtpy', 'scikit-image (>=0.18.3)', 'scikit-learn', 'toml', 'tqdm', 'trackpy (>=0.5.0)', ""tox ; extra == 'testing'"", ""PyQt5 ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'""]","# Palmari

[![Documentation Status](https://readthedocs.org/projects/palmari/badge/?version=latest)](https://palmari.readthedocs.io/en/latest/?badge=latest)
[![Python Version](https://img.shields.io/pypi/pyversions/palmari.svg?color=green)](https://python.org)
[![tests](https://github.com/hippover/palmari/workflows/tests/badge.svg)](https://github.com/hippover/palmari/actions)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/palmari)](https://napari-hub.org/plugins/palmari)
[![License](https://img.shields.io/pypi/l/palmari.svg?color=green)](https://github.com/hippover/palmari/raw/main/LICENSE)

A processing pipeline for PALM movies analysis (pre-processing, localization, drift correction, tracking).

Check out the [documentation] to get started.

![napari_plugin](https://github.com/hippover/palmari/raw/main/docs/images/plugin_steps.png ""Fine-tune your pipelines on a movie, run it on a batch easily !"")

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/stable/index.html
-->

## Installation

You can install `palmari` via [pip]:

    pip install palmari



To install latest development version :

    pip install git+https://github.com/hippover/palmari.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [CeCILL] license.

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/hippover/palmari/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
[CeCILL]: http://cecill.info/index.en.html
[documentation]: https://palmari.readthedocs.io/en/latest/
","['Development Status :: 4 - Beta', 'Intended Audience :: Science/Research', 'Framework :: napari', 'Environment :: Plugins', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing', 'Operating System :: OS Independent', 'License :: OSI Approved :: CEA CNRS Inria Logiciel Libre License, version 2.1 (CeCILL-2.1)']","['Bug Tracker, https://github.com/hippover/palmari/issues', 'Documentation, https://palmari.readthedocs.io/en/latest/', 'Source Code, https://github.com/hippover/palmari', 'User Support, https://github.com/hippover/palmari/issues']",,,palmari.make_qwidget,,,,,https://pypi.org/project/palmari,https://github.com/hippover/palmari,
370,Partial-Aligner,0.0.1,2022-01-28,2023-06-18,Partial-Aligner,"Marc Boucsein, Robin Koch",,BSD-3,https://github.com/DKFZ-TMTRR/Partial-Aligner,A napari plugin for manual registration of (a part of) an image,>=3.9,"['napari-plugin-engine (>=0.1.4)', 'numpy', 'packaging', 'dask']","# Partial-Aligner

[![License](https://img.shields.io/pypi/l/napari-medical-image-formats.svg?color=green)](https://github.com/MBPhys/Partial-Aligner/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/Partial-Aligner.svg?color=green)](https://pypi.org/project/Partial-Aligner)
[![Python Version](https://img.shields.io/pypi/pyversions/Partial-Aligner.svg?color=green)](https://python.org)


A napari plugin to affine transform images and parts of images in 2D and 3D. It was developed in the context of brain slice registration and solves multiple, related problems when working with histology slices.

----------------------------------

## Installation

You can install `Partial-Aligner` via [pip]:

    pip install Partial-Aligner
    
To make full use of this plugin, please also install the sister plugins:

    pip install Label-Creator
    pip install Layer-Data-Replace
    pip install World2Data

## Usage

It is important to note that this plugin is part of a group of plugins ([Label-Creator](https://github.com/DKFZ-TMTRR/Label-Creator, ""Creates Labels""), [Layer-Data-Replace](https://github.com/DKFZ-TMTRR/Layer-Data-Replace, ""Replaces the data of a layer with other data""), [World2Data](https://github.com/DKFZ-TMTRR/World2Data, ""Applies a transformation to an image"")) which are intended to be used together. 

The principle workflow with this plugin is as follows:

1. Load an image of interest (ioi) using standard napari.
2. Find out meaningful transformation parameters for the ioi (or part of it) based on what you see in the viewer.
3. (optional) Save the affine transformation matrix (can later be applied to other modalities)
4. Apply the transformation to create a new, altered version of the ioi (use plugin [World2Data](https://github.com/DKFZ-TMTRR/World2Data, ""Applies a transformation to an image""))

Decisions on the parameters (step 2) are made based on the problem at hand:

- Registration: You have a second (fixed) image and you want to align your ioi to that image? Transform your whole ioi! Just play with the transformation parameters until you are happy with the alignment of ioi and fixed image.

<p align=""center"">
    <img src=""https://user-images.githubusercontent.com/36212786/149524198-9a25b6dc-4169-4546-85b3-7c2f57fccc97.png"" width=""50%"" height=""50%"">  <br /> 
     <i>DAPI staining (red) before (left) and after (right) manual registration on an MRI image (green).</i> 
</p>

- Histology artifact repair: Parts of your histology slice are misplaced? Transform the misplaced parts! Label them and change the transformation parameters for the misplaced parts until you are happy with their alignment with the rest of the image.

<p align=""center"">
<img src=""https://user-images.githubusercontent.com/36212786/149526385-09aeebe2-d03e-4dd4-a424-d0f3af207529.png"" width=""50%"" height=""50%"">  <br /> 
     <i> Original slice with misplaced region (left), marked using the label function (middle) and after manual adjustment (right), where the misplaced region (green) was cut and newly positioned.</i> 
</p>

To make this plugin run reasonably fast, the affine transformations are not applied to the image data in real time. Instead, the internal napari viewing parameters are changed according to the transformation parameters. Therefore, to save transformed image data, the [World2Data](https://github.com/DKFZ-TMTRR/World2Data, ""Applies a transformation to an image"") plugin is used, which calculates and saves the resulting image based on the internal napari viewing parameters.


Here we showcase a resulting multimodal 3D alignment of a whole mouse brain. The modalities are CT, MRI, simulated radiation dose distributions, DAPI staining and DNA-damage repair foci, with a Nissl-staining mouse atlas as template.

https://user-images.githubusercontent.com/36212786/149530462-51a53631-bf74-459b-ab4e-572c52cf2692.mov







## Contributing

Contributions are very welcome. Tests can be run with [tox].

## License

Distributed under the terms of the [BSD-3] license,
""Partial-Aligner"" is free and open source software.

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/MBPhys/Partial-Aligner/issues
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/


","['Development Status :: 4 - Beta', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']",,,,Partial-Aligner.Aligner,,,,,https://pypi.org/project/Partial-Aligner,https://github.com/DKFZ-TMTRR/Partial-Aligner,
371,PartSeg,0.15.2,2022-04-01,2023-08-28,PartSeg,Grzegorz Bokota,g.bokota@cent.uw.edu.pl,BSD-3-Clause,https://4dnucleome.cent.uw.edu.pl/PartSeg/,"PartSeg is python GUI and set of napari plugins for bio imaging analysis especially nucleus analysis,",>=3.8,"['IPython >=7.7.0', 'PartSegCore-compiled-backend <0.16.0,>=0.13.11', 'PartSegData ==0.10.0', 'QtAwesome !=1.2.0,>=1.0.3', 'QtPy >=1.10.0', 'SimpleITK >=2.0.0', 'appdirs >=1.4.4', 'czifile >=2019.5.22', 'defusedxml >=0.6.0', 'fonticon-fontawesome6 >=6.1.1', 'h5py >=3.3.0', 'imagecodecs >=2020.5.30', 'imageio >=2.5.0', 'ipykernel >=5.2.0', 'local-migrator >=0.1.7', 'magicgui !=0.5.0,>=0.4.0', 'mahotas >=1.4.10', 'napari >=0.4.14', 'nme >=0.1.7', 'numpy >=1.18.5', 'oiffile >=2020.1.18', 'openpyxl >=2.5.7', 'packaging >=20.0', 'pandas >=1.1.0', 'psygnal >=0.3.1', 'pydantic <2,>=1.8.1', 'pygments >=2.4.0', 'qtconsole >=4.7.7', 'requests >=2.18.0', 'scipy >=1.4.1', 'sentry-sdk >=0.14.3', 'six >=1.11.0', 'superqt >=0.3.0', 'sympy >=1.1.1', 'tifffile >=2020.9.30', 'traceback-with-variables >=2.0.4', 'vispy >=0.9.4', 'xlrd >=1.1.0', 'xlsxwriter >=2.0.0', ""PyOpenGL-accelerate >=3.1.5 ; extra == 'accelerate'"", ""PyOpenGL-accelerate >=3.1.5 ; extra == 'all'"", ""PyQt5 !=5.15.0,>=5.12.3 ; extra == 'all'"", ""autodoc-pydantic ==1.7.2 ; extra == 'docs'"", ""sphinx !=3.0.0,!=3.5.0 ; extra == 'docs'"", ""sphinx-autodoc-typehints ==1.18.3 ; extra == 'docs'"", ""sphinx-qt-documentation ==0.4 ; extra == 'docs'"", ""PyOpenGL-accelerate >=3.1.5 ; extra == 'pyinstaller'"", ""PyQt5 !=5.15.0,>=5.12.3 ; extra == 'pyinstaller'"", ""PyInstaller ; extra == 'pyinstaller'"", ""pydantic <2 ; extra == 'pyinstaller'"", ""PyQt5 !=5.15.0,>=5.12.3 ; extra == 'pyqt'"", ""PyQt5 !=5.15.0,>=5.12.3 ; extra == 'pyqt5'"", ""PyQt6 ; extra == 'pyqt6'"", ""PySide2 !=5.15.0,>=5.12.3 ; extra == 'pyside'"", ""PySide2 !=5.15.0,>=5.12.3 ; extra == 'pyside2'"", ""PySide6 ; extra == 'pyside6'"", ""lxml ; extra == 'test'"", ""pytest >=7.0.0 ; extra == 'test'"", ""pytest-cov ; extra == 'test'"", ""pytest-qt ; extra == 'test'"", ""pytest-timeout ; extra == 'test'"", ""scikit-image ; extra == 'test'""]","# PartSeg

![Contributions](https://img.shields.io/badge/Contributions-Welcome-brightgreen.svg)
![Tests](https://github.com/4DNucleome/PartSeg/workflows/Tests/badge.svg?branch=develop)
[![PyPI version](https://badge.fury.io/py/PartSeg.svg)](https://badge.fury.io/py/PartSeg)
[![Anaconda version](https://anaconda.org/conda-forge/partseg/badges/version.svg)](https://anaconda.org/conda-forge/partseg)
[![Python Version](https://img.shields.io/pypi/pyversions/partseg.svg)](https://pypi.org/project/partseg)
[![Documentation Status](https://readthedocs.org/projects/partseg/badge/?version=latest)](https://partseg.readthedocs.io/en/latest/?badge=latest)
[![Azure Pipelines Build Status](https://dev.azure.com/PartSeg/PartSeg/_apis/build/status/4DNucleome.PartSeg?branchName=develop)](https://dev.azure.com/PartSeg/PartSeg/_build/latest?definitionId=1&branchName=develop)
[![DOI](https://zenodo.org/badge/166421141.svg)](https://zenodo.org/badge/latestdoi/166421141)
[![Publication DOI](https://img.shields.io/badge/Publication%20DOI-10.1186%2Fs12859--021--03984--1-blue)](https://doi.org/10.1186/s12859-021-03984-1)
[![Licence: BSD3](https://img.shields.io/github/license/4DNucleome/PartSeg)](https://github.com/4DNucleome/PartSeg/blob/master/License.txt)
[![pre-commit](https://img.shields.io/badge/pre--commit-enabled-brightgreen?logo=pre-commit&logoColor=white)](https://github.com/pre-commit/pre-commit)
[![Code Style](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)
[![Ruff](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/charliermarsh/ruff/main/assets/badge/v1.json)](https://github.com/charliermarsh/ruff)
[![CodeQL](https://github.com/4DNucleome/PartSeg/actions/workflows/codeql-analysis.yml/badge.svg?branch=develop)](https://github.com/4DNucleome/PartSeg/actions/workflows/codeql-analysis.yml)
[![Codacy Badge](https://app.codacy.com/project/badge/Grade/f9b0f1eb2c92486d9efd99ed5b2ef326)](https://www.codacy.com/gh/4DNucleome/PartSeg/dashboard?utm_source=github.com&utm_medium=referral&utm_content=4DNucleome/PartSeg&utm_campaign=Badge_Grade)
[![codecov](https://codecov.io/gh/4DNucleome/PartSeg/branch/develop/graph/badge.svg?token=nbAbkOAe1C)](https://codecov.io/gh/4DNucleome/PartSeg)
[![DeepSource](https://deepsource.io/gh/4DNucleome/PartSeg.svg/?label=active+issues&show_trend=true&token=RuuHPIzqyqGaU-bKtOKPFWTg)](https://deepsource.io/gh/4DNucleome/PartSeg/?ref=repository-badge)

PartSeg is a GUI and a library for segmentation algorithms. PartSeg also provide napari plugins for IO and labels measurement.

This application is designed to help biologist with segmentation based on threshold and connected components.

![interface](https://raw.githubusercontent.com/4DNucleome/PartSeg/master/images/roi_analysis.png)

## Tutorials

- Tutorial: **Chromosome 1 (as gui)** [link](https://github.com/4DNucleome/PartSeg/blob/master/tutorials/tutorial-chromosome-1/tutorial-chromosome1_16.md)
- Data for chromosome 1 tutorial [link](https://4dnucleome.cent.uw.edu.pl/PartSeg/Downloads/PartSeg_samples.zip)
- Tutorial: **Different neuron types (as library)** [link](https://github.com/4DNucleome/PartSeg/blob/master/tutorials/tutorial_neuron_types/Neuron_types_example.ipynb)

## Installation

- From binaries:

  - [Windows](https://4dnucleome.cent.uw.edu.pl/PartSeg/Downloads/PartSeg-0.15.2-windows.zip) (build on Windows 10)
  - [Linux](https://4dnucleome.cent.uw.edu.pl/PartSeg/Downloads/PartSeg-0.15.2-linux.zip) (build on Ubuntu 20.04)
  - [MacOS](https://4dnucleome.cent.uw.edu.pl/PartSeg/Downloads/PartSeg-0.15.2-macos.zip) (build on MacOS 11)
    There are reported problems with permissions systems on macOS. If you have problem with starting application please try to run it from terminal.

- With pip:

  - From pypi: `pip install PartSeg[all]`
  - From repository: `pip install git+https://github.com/4DNucleome/PartSeg.git`

- With conda:

  - `conda install -c conda-forge partseg`
  - `mamba install -c conda-forge partseg` - As mamba is faster than conda

- With napari:

  If you do not know how to setup python environment on your system you may use [napari](https://napari.org/) to run PartSeg.
  It is a GUI for scientific image analysis. PartSeg is also a plugin for napari so could be installed from plugin dialog.
  To install napari bundle please download it [napari bundle](https://github.com/napari/napari/releases/latest)
  and follow [installation instructions](https://napari.org/stable/tutorials/fundamentals/installation.html#install-as-a-bundled-app).

Installation troubleshooting information could be found in wiki: [wiki](https://github.com/4DNucleome/PartSeg/wiki/Instalation-troubleshoot).
If this information does not solve problem you can open [issue](https://github.com/4DNucleome/PartSeg/issues).

### Qt 6 support

PartSeg development branch support (and stable since 0.15.0) has experimental Qt6 support. Test are passing but not whole GUI code is covered by tests. Inf you Find any problem please report it.

## Running

If you downloaded binaries, run the `PartSeg` (or `PartSeg.exe` for Windows) file inside the `PartSeg` folder

If you installed from repository or from pip, you can run it with `PartSeg` command or `python -m PartSeg`.
First option does not work on Windows.

PartSeg export few commandline options:

- `--no_report` - disable error reporting
- `--no_dialog` - disable error reporting and error dialog. Use only when running from terminal.
- `roi` - skip launcher and start *ROI analysis* gui
- `mask`- skip launcher and start *ROI mask* gui

## napari plugin

PartSeg provides napari plugins for io to allow reading projects format in napari viewer.

## Save Format

Saved projects are tar files compressed with gzip or bz2.

Metadata is saved in data.json file (in json format).
Images/masks are saved as \*.npy (numpy array format).

## Interface

Launcher. Choose the program that you will launch:

![launcher](https://raw.githubusercontent.com/4DNucleome/PartSeg/master/images/launcher.png)

Main window of Segmentation Analysis:

![interface](https://raw.githubusercontent.com/4DNucleome/PartSeg/master/images/roi_analysis.png)

Main window of Segmentation Analysis with view on measurement result:

![interface](https://raw.githubusercontent.com/4DNucleome/PartSeg/master/images/roi_analysis2.png)

Window for creating a set of measurements:

![statistics](https://raw.githubusercontent.com/4DNucleome/PartSeg/master/images/measurement.png)

Main window of Mask Segmentation:

![mask interface](https://raw.githubusercontent.com/4DNucleome/PartSeg/master/images/roi_mask.png)

## Laboratory

Laboratory of Functional and Structural Genomics
[http://4dnucleome.cent.uw.edu.pl/](http://4dnucleome.cent.uw.edu.pl/)

## Cite as

Bokota, G., Sroka, J., Basu, S. et al. PartSeg: a tool for quantitative feature extraction
from 3D microscopy images for dummies. BMC Bioinformatics 22, 72 (2021).
[https://doi.org/10.1186/s12859-021-03984-1](https://doi.org/10.1186/s12859-021-03984-1)


## Changelog

### 0.15.2 - 2023-08-28

#### Bug Fixes

- Fix range threshold selection of algorithms (#1009)
- When run batch check if file extension is supported by loader (#1016)
- Do not allow to select and render corrupted batch plans (#1015)

#### Testing

- \[Automatic\] Constraints upgrades: `imagecodecs`, `ipykernel`, `magicgui`, `psygnal`, `scipy`, `superqt`, `tifffile` (#1011)
- \[Automatic\] Constraints upgrades: `imageio`, `pyinstaller`, `tifffile` (#1018)

#### Ci

- Use faster version of black (#1010)
- \[pre-commit.ci\] pre-commit autoupdate (#1013)

### 0.15.1 - 2023-08-09

#### Bug Fixes

- Fix possible problem of double registration napari plugin in PartSeg bundle (#974)
- Bump OS versions for part of testing workflows.  (#977)
- Bump os version for main tests workflow. (#979)
- Ensure that the module `PartSegCore.channel_class` is present in bundle (#980)
- Lower npe2 schema version to work with older napari version (#981)
- Generate test report per platfom (#978)
- Importing plugins in bundle keeping proper module names (#983)
- Fix napari repo workflow (#985)
- Fix bug in read tiff files with double `Q` in axes but one related to dummy dimmension (#992)
- Fix bug that lead to corupted state when saving calculation plan to excel file (#995)
- Enable python 3.11 test on CI, fix minor errors (#869)

#### Features

- Allow to save multiple napari image layers to single tiff file (#1000)
- Add option to export batch project with data (#996)

#### Testing

- \[Automatic\] Constraints upgrades: `imageio`, `ipython`, `psygnal`, `scipy`, `sentry-sdk` (#975)
- \[Automatic\] Constraints upgrades: `h5py`, `imagecodecs`, `imageio`, `ipykernel`, `napari`, `numpy`, `pandas`, `pydantic`, `pyinstaller`, `scipy`, `sentry-sdk`, `tifffile`, `vispy` (#986)
- \[Automatic\] Constraints upgrades: `imagecodecs`, `sentry-sdk`, `tifffile` (#997)
- \[Automatic\] Constraints upgrades: `ipykernel`, `pydantic` (#1002)
- \[Automatic\] Constraints upgrades: `numpy`, `pygments`, `sentry-sdk`, `superqt` (#1007)

#### Ci

- \[pre-commit.ci\] pre-commit autoupdate (#973)
- \[pre-commit.ci\] pre-commit autoupdate (#982)
- \[pre-commit.ci\] pre-commit autoupdate (#987)
- \[pre-commit.ci\] pre-commit autoupdate (#988)
- \[pre-commit.ci\] pre-commit autoupdate (#991)
- \[pre-commit.ci\] pre-commit autoupdate (#998)
- \[pre-commit.ci\] pre-commit autoupdate (#1004)
- Change markdown linter from pre-commit to mdformat (#1006)

### 0.15.0 - 2023-05-30

#### Bug Fixes

- Print all exceptions instead of the latest one in exception dialog (#799)
- Fix ROIExtractionResult `__str__`and `__repr__` to use `ROIExtractionResult` not `SegmentationResult` (#810)
- Fix code to address changes in the napari repository (#817)
- Fix the problem with resize of multiline widgets (#832)
- Fix tox configuration to run all required tests (#840)
- Fix MSO `step_limit` description in GUI (#843)
- Fix `redefined-while-unused`import code for python 3.9.7 (#844)
- Fix warnings reported by Deepsource (#846)
- Ensure that ""ROI"" layer is in the proper place for proper visualization (#856)
- Fix tests of napari widgets (#862)
- Fix build of the bundle for a new psygnal release (#863)
- Fix minimal requirements pipeline (#877)
- Fix bug with generation of form for the model with hidden field (#920)
- Update pyinstaller configuration (#926)
- Use text icon, not pixmap icon in colormap and labels list (#938)
- Resolve warnings when testing custom save dialog. (#941)
- Add padding zeros for component num when load Mask seg file to ROI GUI (#944)
- Proper calculate bounds for watershed napari widget (#969)
- Fix bug in the wrong order of axis saved in napari contribution (#972)

#### Dependency

- \[Automatic\] Dependency upgrades (#824)
- \[Automatic\] Dependency upgrades (#828)
- \[Automatic\] Dependency upgrades: `ipykernel`, `packaging` (#838)
- \[Automatic\] Dependency upgrades: `imageio`, `ipykernel`, `napari`, `numpy`, `sentry` (#850)
- \[Automatic\] Dependency upgrades: `imagecodecs`, `ipykernel`, `numpy`, `psygnal` (#859)
- \[Automatic\] Dependency upgrades: `pydantic`, `pygments`, `xlsxwriter` (#874)
- \[Automatic\] Dependency upgrades: `imageio`, `packaging`, `scipy`, `xlsxwriter` (#878)
- \[Automatic\] Dependency upgrades: `ipykernel`, `requests`, `sentry`, `xlsxwriter` (#884)
- \[Automatic\] Dependency upgrades: `h5py`, `imagecodecs`, `imageio`, `ipykernel`, `pandas`, `sentry`, `tifffile` (#889)
- \[Automatic\] Dependency upgrades: `ipython`, `pyqt5` (#893)
- \[Automatic\] Dependency upgrades: `imageio`, `ipykernel`, `ipython`, `numpy`, `openpyxl`, `psygnal`, `pydantic`, `pyinstaller`, `pyqt5`, `scipy`, `sentry-sdk`, `tifffile`, `xlsxwriter` (#897)
- \[Automatic\] Dependency upgrades: `imageio`, `psygnal` (#905)
- \[Automatic\] Dependency upgrades: `ipython`, `magicgui`, `scipy`, `sentry-sdk`, `tifffile` (#906)
- \[Automatic\] Dependency upgrades: `imagecodecs`, `imageio`, `ipykernel`, `openpyxl`, `pydantic`, `pyinstaller`, `qtawesome`, `qtconsole`, `sentry-sdk`, `tifffile`, `xlsxwriter` (#908)
- \[Automatic\] Dependency upgrades: `imageio`, `ipykernel`, `ipython`, `pandas`, `psygnal`, `pydantic`, `pygments`, `pyinstaller`, `qtpy`, `sentry-sdk`, `tifffile` (#917)

#### Documentation

- Update README and project metadata (#805)

#### Features

- Add `PARTSEG_SENTRY_URL` env variable support and basic documentation about error reporting (#802)
- Allow to see underlying exception when show warning caused by exception (#829)
- Add voxel size measurement and allow to overwrite voxel size in batch (#853)
- Add alpha support for Qt6 (#866)
- Add option to create projection alongside z-axis (#919)
- Add napari image custom representation for better error report via sentry (#861)
- Add import and export operation for labels and colormaps (#936)
- Implement napari widgets for colormap and lables control (#935)
- Add forget all button to multiple files widget (#942)
- Do not abort processing whole mask segmentation project during exception on single component (#943)
- Add distance based watersheed to flow methods (#915)
- Add napari widgets for all group of algoritms (#958)
- Add napari widget to copy lables along z-axis (#968)

#### Miscellaneous Tasks

- Improve ruff configuration, remove isort (#815)
- Use `fail_on_no_env` feature from `tox-gh-actions` (#842)
- Add python 3.11 to list of supported versions (#867)
- Disable python 3.11 test because of timeout (#870)
- Bump ruff to 0.0.218, remove flake8 from pre-commit (#880)
- Replace GabrielBB/xvfb-action@v1 by aganders3/headless-gui, part 2 (#887)
- Better minimal requirements test (#888)
- Improve regexp for proper generate list of packages in update report (#894)
- Add check for PR title (#933)
- Migrate from `nme` to `local_migrator` (#951)

#### Refactor

- Simplify and refactor github workflows. (#864)
- Better load Mask project in Roi Analysis (#921)
- Use more descriptive names in `pylint: disable` (#922)
- Remove `pkg_resources` usage as it is deprecated (#967)
- Convert napari plugin to npe2 (#966)

#### Security

- Bump peter-evans/create-pull-request from 4 to 5 (#928)

#### Styling

- Change default theme to dark, remove blinking windows on startup. (#809)

#### Testing

- \[Automatic\] Dependency upgrades: `packaging`, `pyinstaller`, `pyopengl-accelerate`, `tifffile`, `xlsxwriter` (#932)
- \[Automatic\] Constraints upgrades: `fonticon-fontawesome6`, `imageio`, `numpy`, `partsegcore-compiled-backend`, `pygments`, `sentry-sdk` (#937)
- \[Automatic\] Constraints upgrades: `imageio`, `ipython`, `pandas`, `requests`, `sentry-sdk` (#948)
- \[Automatic\] Constraints upgrades: `ipython`, `nme`, `qtconsole`, `requests`, `sentry-sdk` (#955)
- \[Automatic\] Constraints upgrades: `ipykernel`, `local-migrator`, `pyinstaller`, `sentry-sdk`, `sympy` (#957)
- \[Automatic\] Constraints upgrades: `sentry-sdk`, `xlsxwriter` (#959)
- \[Automatic\] Constraints upgrades: `requests` (#961)

#### Ci

- Update codecov configuration to wait on two reports before post information (#934)
- \[pre-commit.ci\] pre-commit autoupdate (#945)
- \[pre-commit.ci\] pre-commit autoupdate (#956)
- \[pre-commit.ci\] pre-commit autoupdate (#964)

### 0.14.6 - 2022-11-13

#### Bug Fixes

- Fix bug when loading already created project causing hide of ROI layer (#787)

#### Features

- Improve error message if segmentation do not fit in ROI Mask (#788)

### 0.14.5 - 2022-11-09

#### Bug Fixes

- Fix scalebar color (#774)
- Fix bug when saving segmentation parameters in mask analysis (#781)
- Fix multiple errors related to loading a new file in interactive mode (#784)

#### Features

- Add an option for ensuring type in EventedDict and use it to validate profiles structures (#776)
- Add an option to create an issue from the error report dialog (#782)
- Add option for the multiline field in algorithm parameters (#766)

#### Refactor

- Optimize CLI actions (#772)
- Clean warnings about threshold methods (#783)

#### Build

- Bump chanzuckerberg/napari-hub-preview-action from 0.1.5 to 0.1.6 (#775)

### 0.14.4 - 2022-10-24

#### Bug Fixes

- Fix `get_theme` calls to prepare for napari 0.4.17 (#729)
- Fix sentry tests (#742)
- Fix reporting error in load settings from the drive (#725)
- Fix saving pipeline from GUI (#756)
- Fix profile export/import dialogs (#761)
- Enable the ""Compare"" button if ROI is available (#765)
- Fix bug in cut with ROI to not make black artifacts (#767)

#### Features

- Load alternatives labeling when opening PartSeg projects in napari (#731)
- Add option to toggle scale bar (#733)
- Allow customizing the settings directory using the `PARTSEG_SETTINGS_DIR` environment variable (#751)
- Separate recent algorithms from general application settings (#752)
- Add multiple otsu as threshold method with selection range of components (#710)
- Add function to load components from Mask Segmentation with a background in ROI Analysis (#768)

#### Miscellaneous Tasks

- Prepare pyinstaller configuration for napari 0.4.17 (#748)
- Add ruff linter (#754)

#### Testing

- Add new build and inspect wheel action (#747)

#### Build

- Bump actions/checkout from 2 to 3 (#716)
- Bump actions/download-artifact from 1 to 3 (#709)

### 0.14.3 - 2022-08-18

#### Bug Fixes

- Fix lack of rendering ROI when load image from segmentation (#694)
- Fix running ROI extraction from napari widget (#695)
- Delay setting image if an algorithm is still running (#627)
- Wrong error report when no component is found in restartable segmentation algorithm. (#633)
- Fix the process of building documentation (#653)

#### Refactor

- Clean potential vulnerabilities  (#630)

#### Testing

- Add more tests for common GUI elements  (#622)
- Report coverage per package. (#639)
- Update conda environment to not use PyQt5 in test (#646)
- Add tests files to calculate coverage (#655)

### 0.14.2 - 2022-05-05

#### Bug Fixes

- Fix bug in save label colors between sessions (#610)
- Register PartSeg plugins before starting napari widgets. (#611)
- Mouse interaction with components works again after highlight. (#620)

#### Refactor

- Limit test run (#603)
- Filter and solve warnings in tests (#607)
- Use QAbstractSpinBox.AdaptiveDecimalStepType in SpinBox instead of hardcoded bounds (#616)
- Clean and test `PartSeg.common_gui.universal_gui_part` (#617)

#### Testing

- Speedup test by setup cache for pip (#604)
- Setup cache for azure pipelines workflows (#606)

### 0.14.1 - 2022-04-27

#### Bug Fixes

- Update build wheels and sdist to have proper version tag (#583)
- Fix removing the first measurement entry in the napari Measurement widget (#584)
- Fix compatibility bug for conda Pyside2 version (#595)
- Error when synchronization is loaded, and newly loaded image has different dimensionality than currently loaded. (#598)

#### Features

- Use pygments for coloring code in exception window (#591)
- Add option to calculate Measurement per Mask component (#590)

#### Refactor

- Refactor the creation batch plan widgets and add tests for it (#587)
- Drop napari bellow 0.4.12 (#592)
- Update the order of ROI Mask algorithms to be the same as in older PartSeg versions (#600)

### 0.14.0 - 2022-04-14

#### Bug Fixes

- Fix ""Show selected"" rendering mode in PartSeg ROI Mask (#565)
- Add access by operator `[]` to `pydantic.BaseModel` base structures for keeping backward compatibility (#579)

#### Features

- Allow setting zoom factor from the interface in Search Label napari plugin (#538)
- Add controlling of zoom factor of search ROI in main GUI (#540)
- Better serialization mechanism allow for declaration data structure migration locally (#462)
- Make \`\*.obsep"" file possible to load in PartSeg Analysis (#564)
- Add option to extract measurement profile or ROI extraction profile from the batch plan (#568)
- Allow import calculation plan from batch result excel file (#567)
- Improve error reporting when failing to deserialize data (#574)
- Launch PartSeg GUI from napari #581

#### Refactor

- Store PartSegImage.Image channels as separated arrays (#554)
- Remove deprecated modules. (#429)
- Switch serialization backend to `nme` (#569)

#### Testing

- Add test of creating AboutDialog (#539)
- Setup test for python 3.10. Disable `class_generator` test for this python (#570)

### 0.13.15

#### Bug Fixes

- Using `translation` instead of `translation_grid` for shifting layers. (#474)
- Bugs in napari plugins (#478)
- Missing mask when using roi extraction from napari (#479)
- Fix segmentation fault on macos machines (#487)
- Fixes for napari 0.4.13 (#506)

#### Documentation

- Create 0.13.15 release (#511)
- Add categories and preview page workflow for the napari hub (#489)

#### Features

- Assign properties to mask layer in napari measurement widget (#480)

#### Build

- Bump qtpy from 1.11.3 to 2.0.0 in /requirements (#498)
- Bump pydantic from 1.8.2 to 1.9.0 in /requirements (#496)
- Bump sentry-sdk from 1.5.1 to 1.5.2 in /requirements (#497)
- Bump sphinx from 4.3.1 to 4.3.2 in /requirements (#500)
- Bump pyinstaller from 4.7 to 4.8 in /requirements (#502)
- Bump pillow from 8.4.0 to 9.0.0 in /requirements (#501)
- Bump requests from 2.26.0 to 2.27.1 in /requirements (#495)
- Bump numpy from 1.21.4 to 1.22.0 in /requirements (#499)
- Bump numpy from 1.22.0 to 1.22.1 in /requirements (#509)
- Bump sphinx from 4.3.2 to 4.4.0 in /requirements (#510)

### 0.13.14

#### Bug Fixes

- ROI alternative representation (#471)
- Change additive to translucent in rendering ROI and Mask (#472)

#### Features

- Add morphological watershed segmentation (#469)
- Add Bilateral image filter (#470)

### 0.13.13

#### Bug Fixes

- Fix bugs in the generation process of the changelog for release. (#428)
- Restoring ROI on home button click in compare viewer (#443)
- Fix Measurement name prefix in bundled PartSeg. (#458)
- Napari widgets registration in pyinstaller bundle (#465)
- Hide points button if no points are loaded, hide Mask checkbox if no mask is set (#463)
- Replace Label data instead of adding/removing layers - fix blending layers (#464)

#### Features

- Add threshold information in layer annotation in the Multiple Otsu ROI extraction method (#430)
- Add option to select rendering method for ROI (#431)
- Add callback mechanism to ProfileDict, live update of ROI render parameters (#432)
- Move the info bar on the bottom of the viewer (#442)
- Add options to load recent files in multiple files widget (#444)
- Add ROI annotations as properties to napari labels layer created by ROI Extraction widgets (#445)
- Add signals to ProfileDict, remove redundant synchronization mechanisms (#449)
- Allow ignoring updates for 21 days (#453)
- Save all components if no components selected in mask segmentation (#456)
- Add modal dialog for search ROI components (#459)
- Add full measurement support as napari widget (#460)
- Add search labels as napari widget (#467)

#### Refactor

- Export common code for load/save dialog to one place (#437)
- Change most of call QFileDialog to more generic code (#440)

#### Testing

- Add test for `PartSeg.common_backend` module (#433)

### 0.13.12

#### Bug Fixes

- Importing the previous version of settings (#406)
- Cutting without masking data (#407)
- Save in subdirectory in batch plan (#414)
- Loading plugins for batch processing (#423)

#### Features

- Add randomization option for correlation calculation (#421)
- Add Imagej TIFF writter for image. (#405)
- Mask create widget for napari (#395)
- In napari roi extraction method show information from roi extraction method (#408)
- Add `*[0-9].tif` button in batch processing window (#412)
- Better label representation in 3d view (#418)

#### Refactor

- Use Font Awesome instead of custom symbols (#424)

### 0.13.11

#### Bug Fixes

- Adding mask in Prepare Plan for batch (#383)
- Set proper completion mode in SearchComboBox (#384)
- Showing warnings on the error with ROI load (#385)

#### Features

- Add CellFromNucleusFlow ""Cell from nucleus flow"" cell segmentation method  (#367)
- When cutting components in PartSeg ROI mask allow not masking outer data (#379)
- Theme selection in GUI (#381)
- Allow return points from ROI extraction algorithm (#382)
- Add measurement to get ROI annotation by name. (#386)
- PartSeg ROI extraction algorithms as napari plugins (#387)
- Add  Pearson, Mander's, Intensity, Spearman colocalization measurements (#392)
- Separate standalone napari settings from PartSeg embedded napari settings (#397)

#### Performance

- Use faster calc bound function (#375)

#### Refactor

- Remove CustomApplication (#389)

### 0.13.10

- change tiff save backend to ome-tiff
- add `DistanceROIROI` and `ROINeighbourhoodROI` measurements

### 0.13.9

- annotation show bugfix

### 0.13.8

- napari deprecation fixes
- speedup simple measurement
- bundle plugins initial support

### 0.13.7

- add measurements widget for napari
- fix bug in pipeline usage

### 0.13.6

- Hotfix release
- Prepare for a new napari version

### 0.13.5

- Small fixes for error reporting
- Fix mask segmentation

### 0.13.4

- Bugfix for outdated profile/pipeline preview

### 0.13.3

- Fix saving roi_info in multiple files and history

### 0.13.2

- Fix showing label in select label tab

### 0.13.1

- Add Haralick measurements
- Add obsep file support

### 0.13.0

- Add possibility of custom input widgets for algorithms
- Switch to napari Colormaps instead of custom one
- Add points visualization
- Synchronization widget for builtin (View menu) napari viewer
- Drop Python 3.6

### 0.12.7

- Fixes for napari 0.4.6

### 0.12.6

- Fix prev_mask_get
- Fix cache mechanism on mask change
- Update PyInstaller build

### 0.12.5

- Fix bug in pipeline execute

### 0.12.4

- Fix ROI Mask windows related build (signal not properly connected)

### 0.12.3

- Fix ROI Mask

### 0.12.2

- Fix windows bundle

### 0.12.1

- History of last opened files
- Add ROI annotation and ROI alternatives
- Minor bugfix

### 0.12.0

- Toggle multiple files widget in View menu
- Toggle Left panel in ROI Analysis in View Menu
- Rename Mask Segmentation to ROI Mask
- Add documentation for interface
- Add Batch processing tutorial
- Add information about errors to batch processing output file
- Load image from the batch prepare window
- Add search option in part of list and combo boxes
- Add drag and drop mechanism to load list of files to batch window.

### 0.11.5

- add side view to viewer
- fix horizontal view for Measurements result table

### 0.11.4

- bump to napari 0.3.8 in bundle
- fix bug with not presented segmentation loaded from project
- add frame (1 pix) to image cat from base one based on segmentation
- pin to Qt version to 5.14

### 0.11.3

- prepare for napari 0.3.7
- split napari io plugin on multiple part
- better reporting for numpy array via sentry
- fix setting color for mask marking

### 0.11.2

- Speedup image set in viewer using async calls
- Fix bug in long name of sheet with parameters

### 0.11.1

- Add screenshot option in View menu
- Add Voxels measurements

### 0.11.0

- Make sprawl algorithm name shorter
- Unify capitalisation of measurement names
- Add simple measurements to mask segmentation
- Use napari as viewer
- Add possibility to preview additional output of algorithms (In View menu)
- Update names of available Algorithm and Measurement to be more descriptive.

### 0.10.8

- fix synchronisation between viewers in Segmentation Analysis
- fix batch crash on error during batch run, add information about file on which calculation fails
- add changelog preview in Help > About

### 0.10.7

- in measurements, on empty list of components mean will return 0

### 0.10.6

- fix border rim preview
- fix problem with size of image preview
- zoom with scroll and moving if rectangle zoom is not marked

### 0.10.5

- make PartSeg PEP517 compatible.
- fix multiple files widget on Windows (path normalisation)

### 0.10.4

- fix slow zoom

### 0.10.3

- deterministic order of elements in batch processing.

### 0.10.2

- bugfixes

### 0.10.1

- bugfixes

### 0.10.0

- Add creating custom label coloring.
- Change execs interpreter to python 3.7.
- Add masking operation in Segmentation Mask.
- Change license to BSD.
- Allow select root type in batch processing.
- Add median filter in preview.

### 0.9.7

- fix bug in compare mask

### 0.9.6

- fix bug in loading project with mask
- upgrade PyInstaller version (bug  GHSA-7fcj-pq9j-wh2r)

### 0.9.5

- fix bug in loading project in ""Segmentation analysis""

### 0.9.4

- read mask segmentation projects
- choose source type in batch
- add initial support to OIF and CZI file format
- extract utils to PartSegCore module
- add automated tests of example notebook
- reversed mask
- load segmentation parameters in mask segmentation
- allow use sprawl in segmentation tool
- add radial split of mask for measurement
- add all measurement results in batch, per component sheet

### 0.9.3

- start automated build documentation
- change color map backend and allow for user to create custom color map.
- segmentation compare
- update test engines
- support of PySide2

### 0.9.2.3

- refactor code to make easier create plugin for mask segmentation
- create class base updater for update outdated algorithm description
- fix save functions
- fix different bugs

### 0.9.2.2

- extract static data to separated package
- update marker of fix range and add mark of gauss in channel control

### 0.9.2.1

- add VoteSmooth and add choosing of smooth algorithm

### 0.9.2

- add pypi base check for update

- remove resetting image state when change state in same image

- in stack segmentation add options to picking components from segmentation's

- in mask segmentation add:

  - preview of segmentation parameters per component,
  - save segmentation parameters in save file
  - new implementation of batch mode.

### 0.9.1

- Add multiple files widget

- Add Calculating distances between segmented object and mask

- Batch processing plan fixes:

  - Fix adding pipelines to plan
  - Redesign mask widget

- modify measurement backend to allow calculate multi channel measurements.

### 0.9

Begin of changelog
","['Development Status :: 3 - Alpha', 'Framework :: napari', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: Implementation :: CPython', 'Topic :: Scientific/Engineering :: Bio-Informatics', 'Topic :: Scientific/Engineering :: Image Processing', 'Topic :: Scientific/Engineering :: Visualization']","['Documentation, https://partseg.readthedocs.io/en/stable/', 'Source Code, https://github.com/4DNucleome/PartSeg', 'User Support, https://github.com/4DNucleome/PartSeg/issues', 'Bug Tracker, https://github.com/4DNucleome/PartSeg/issues']",PartSeg.load_roi_project,PartSeg.write_tiff_image,PartSeg.SearchLabel,,"['*.tgz', '*.tbz2', '*.gz', '*.bz2']","['.tif', '.tiff']","['.tif', '.tiff']",https://pypi.org/project/PartSeg,,https://4dnucleome.cent.uw.edu.pl/PartSeg/
372,PartSeg-smfish,0.1.3,2022-10-24,2023-06-18,PartSeg-smfish,Grzegorz Bokota,g.bokota@cent.uw.edu.pl,BSD-3-Clause,https://github.com/4DNucleome/PartSeg-smfish,PartSeg and napari plugin for smfish data,>=3.8,"['PartSeg (>=0.13.0)', 'numpy', 'napari', 'qtpy', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'""]","# PartSeg-smfish

[![License BSD-3](https://img.shields.io/pypi/l/PartSeg-smfish.svg?color=green)](https://github.com/4DNucleome/PartSeg-smfish/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/PartSeg-smfish.svg?color=green)](https://pypi.org/project/PartSeg-smfish)
[![Python Version](https://img.shields.io/pypi/pyversions/PartSeg-smfish.svg?color=green)](https://python.org)
[![tests](https://github.com/4DNucleome/PartSeg-smfish/workflows/tests/badge.svg)](https://github.com/4DNucleome/PartSeg-smfish/actions)
[![codecov](https://codecov.io/gh/4DNucleome/PartSeg-smfish/branch/main/graph/badge.svg)](https://codecov.io/gh/4DNucleome/PartSeg-smfish)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/PartSeg-smfish)](https://napari-hub.org/plugins/PartSeg-smfish)

PartSeg and napari plugin for smfish data

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `PartSeg-smfish` via [pip]:

    pip install PartSeg-smfish



To install latest development version :

    pip install git+https://github.com/4DNucleome/PartSeg-smfish.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""PartSeg-smfish"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/4DNucleome/PartSeg-smfish/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/4DNucleome/PartSeg-smfish/issues', 'Documentation, https://github.com/4DNucleome/PartSeg-smfish#README.md', 'Source Code, https://github.com/4DNucleome/PartSeg-smfish', 'User Support, https://github.com/4DNucleome/PartSeg-smfish/issues']",,,PartSeg-smfish.verify_points.verify_segmentation,,,,,https://pypi.org/project/PartSeg-smfish,https://github.com/4DNucleome/PartSeg-smfish,
373,platelet-unet-watershed,0.0.3,2022-02-05,2023-06-18,platelet-unet-watershed,Juan Nunez-Iglesias & Abigail McGovern,juan.nunez-iglesias@monash.edu,BSD-3,https://github.com/jni/platelet-unet-watershed,Segment platelets with pretrained unet and affinity watershed,>=3.7,"['magicgui >=0.2.11', 'napari >=0.4.11', 'napari-plugin-engine >=0.1.4', 'numba >=0.50', 'numpy', 'scikit-image', 'scipy', 'toolz', 'torch', 'torchvision', 'tqdm']","# platelet-unet-watershed

[![License](https://img.shields.io/pypi/l/platelet-unet-watershed.svg?color=green)](https://github.com/jni/platelet-unet-watershed/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/platelet-unet-watershed.svg?color=green)](https://pypi.org/project/platelet-unet-watershed)
[![Python Version](https://img.shields.io/pypi/pyversions/platelet-unet-watershed.svg?color=green)](https://python.org)
[![tests](https://github.com/jni/platelet-unet-watershed/workflows/tests/badge.svg)](https://github.com/jni/platelet-unet-watershed/actions)
[![codecov](https://codecov.io/gh/jni/platelet-unet-watershed/branch/master/graph/badge.svg)](https://codecov.io/gh/jni/platelet-unet-watershed)

Segment platelets with pretrained unet and affinity watershed

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/docs/plugins/index.html
-->

## Installation

You can install `platelet-unet-watershed` via [pip]:

    pip install platelet-unet-watershed

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""platelet-unet-watershed"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/jni/platelet-unet-watershed/issues
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/jni/platelet-unet-watershed/issues', 'Documentation, https://github.com/jni/platelet-unet-watershed#README.md', 'Source Code, https://github.com/jni/platelet-unet-watershed', 'User Support, https://github.com/jni/platelet-unet-watershed/issues']",,,platelet-unet-watershed.UNetPredictWidget,,,,,https://pypi.org/project/platelet-unet-watershed,https://github.com/jni/platelet-unet-watershed,
374,platetrack,0.0.7,,,platetrack,Abigail S McGovern,abigail_mcgovern@hotmail.com,BSD-3-Clause,,napari plugin for tracking platelets with trackpy,>=3.7,"['napari', 'numpy', 'trackpy', 'pandas', 'plateletanalysis']","# platetrack
A small napari plugin for tracking platelets. Platetrack requires a segmentation and an image containing raw data. We recomend trying the napari plugin iterseg to generate these. Platetrack uses trackpy for tracking and outputs a dataframe with platelet coordinates, tracking information, and several other variables, which provide information about each platelet. 


## Installation

There are three main ways to install platetrack:

### Install Using pip

Type the following into your terminal (MacOS or Ubuntu) or annaconda prompt (windows):

```bash
pip install platetrack
```

### Install via napari hub

Type the following into your terminal (MacOS or Ubuntu) or annaconda prompt (windows):

```bash
install napari
napari
```

Once napari has opened (this may take a second the first time you open it), go to the pannel at the top of the screen and select the 'plugins' dropdown. Then select install/uninstall plugins. A new window will open showing available plugins. Either scroll down to or search 'platetrack' and click 'install'. 

### Install from Source Code
*please use this for now*

Type the following into your terminal (MacOS or Ubuntu) or annaconda prompt (windows):

```bash
git clone <repository https or ssh>
cd platetrack
pip install .
```


## Opening Platetrack
Once annotrack is properly installed you will be able to open platetrack by opening napari. You can open napari through the command line (terminal (MacOS or Ubuntu) or annaconda prompt (windows)) as follows:

```bash
napari
```

You can find the platetrack widgets by selecting the dropdown 'plugins' at the pannel at the top of the screen and selecting the platetrack widget 'track_platelets'.  


## Tracking Platelets
You can track platelets and obtain a dataframe of information about platelet observation by providing an image/s (t, z, y, x) and a segmentation (t, z, y, x). There are no specific file format requirements, only that you first load the image and segmentation into napari. The napari plugin iterseg provides a widget that will help you load zarr format files. If you have an image with multiple channels (i.e., laser colours), load them into separate napari layers. Iterseg has an option for this called ""split channels"". Otherwise, refer to the napari website for instructions on using napari layers. 

### Parameters for widget

- **labels_layer**: The napari layer containing the segmentation.
- **image_layer**: The napari layer containing the image (you only need this if you don't want to use all image layers).
- **use_all_image_layers**: If you have several image channels selecting this will obtain information about each channel. The info about image intensity will be stored in columns of the data frame named *[layer name]*_max, *[layer name]*_mean_, 
- **sample_name**: what is the name of the sample (i.e., an identifyer for the biological sample including, for example, the animal number, date, experimental conditions, etc.). This is important if you are planning to combine data frames with different treatment groups. 
- **treatment_name**: name of treatement group or experimental condition (will be added as a categorical variable). This is important if you are planning to combine data frames with different treatment groups. 
- **x_microns**: How big are pixels in the x axis (probably in microns). We need this so that physical rather than pixel coordinates can be computed. 
- **y_microns**: How big are pixels in the y axis (probably in microns). We need this so that physical rather than pixel coordinates can be computed. 
- **z_microns**: How big are pixels in the z axis (probably in microns). We need this so that physical rather than pixel coordinates can be computed. 
- **save_dir**: Directory into which you want to save output data
- **save_file**: name to give the file, 
- **save_format**: There are two options for save format ""parquet"" or ""csv"".  
- **search_range**: This is a parameter for the tracking. The search range is how far away (in physical units, e.g., microns) the tracking algorithm will look for the same platelet at the next time point. This can be reduced if trackpy is running out of computational resources due to a high number of observations (platelets)  
- **xy_origin**: If you are rotating the data (e.g., you might want to align the blood flow with the y axis like we do) this parameter defines the centre of rotation. If you would like to use the geometric centre of the image just use ""centre"". Otherwise, provide a tuple (computer word – basically a list of numbers between brackets) of coordinates in physical units in yx format (e.g., (126, 148)). 
- **rotation**: The number of degrees by which to rotate the data counterclockwise. 



## Platelet data outputted
A number of variables are computed about the platelets alongside the tracking. Each variable is reported for every platelet observation (execpt veclocity, which is only reported for tracked platelets after the first observation). 

- Mean platelet intensity in each image channel
- Max platelet pixel intensity in each channel
- Platelet elongation (0-1, 0 being least elongated, 1 being most elongated)
- Platelet flatness (0-1, 0 being least flat, 1 being most flat)
- Platelet velocity (dv)
- Platelet coordinate velocities (dvx, dvy, dvz)
- Platelet local density (density of platlets in a 15 um radius around the platelet)
- Lists of platelet neighbours within 15 um radius
- Lists of distances of each platelet neighbours within 15 um radius


## Contributing and User Support

**User support:** If you have an issue with platetrack please add an issue (go to the Issues tab at the top of the GitHub page). If your issue is a bug, please include as much information as possible to help debug the problem. Examples of information include: details about the image and segmentation data (dimensions), number of images, number of samples you are trying to take. If you are requesting an improvement, try to be as clear as possible about what you need. 

**Contributing:** If you want to contribute to platetrack, please fork the repo and if you want to make changes make a pull request with as much detail about the change as possible. Please ensure any changes you want to make don't break the existing functions.
","['Framework :: napari', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License', 'Intended Audience :: Science/Research', 'Topic :: Scientific/Engineering', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/abigailmcgovern/platelet-tracking/issues', 'Documentation, https://github.com/abigailmcgovern/platelet-tracking#README.md', 'Source Code, https://github.com/abigailmcgovern/platelet-tracking', 'User Support, https://github.com/abigailmcgovern/platelet-tracking/issues']",platetrack.load_tracks,,platetrack.track_platelets,,"['*.csv', '*.parquet']",,,https://pypi.org/project/platetrack,,
375,PlatyMatch,0.0.3,2022-02-11,2023-06-18,PlatyMatch,Manan Lalit,lalit@mpi-cbg.de,BSD-3,https://github.com/juglab/PlatyMatch,PlatyMatch allows registration of volumetric images of embryos by establishing correspondences between cells,>=3.6,"['napari-plugin-engine (>=0.1.4)', 'numpy', 'scikit-image', 'scikit-learn', 'tqdm', 'simpleitk', 'napari[all]', 'pandas', 'pytest']","[![DOI:10.1007/978-3-030-66415-2_30](https://zenodo.org/badge/DOI/10.1007/978-3-030-66415-2_30.svg)](https://link.springer.com/chapter/10.1007/978-3-030-66415-2_30)
[![License: MIT](https://img.shields.io/badge/License-MIT-blue.svg)](https://opensource.org/licenses/MIT)
[![PyPI](https://img.shields.io/pypi/v/PlatyMatch.svg?color=green)](https://pypi.org/project/PlatyMatch)
[![Python Version](https://img.shields.io/pypi/pyversions/PlatyMatch.svg?color=green)](https://python.org)
[![tests](https://github.com/juglab/PlatyMatch/workflows/tests/badge.svg)](https://github.com/juglab/PlatyMatch/actions)
[![codecov](https://codecov.io/gh/juglab/PlatyMatch/branch/master/graph/badge.svg)](https://codecov.io/gh/juglab/PlatyMatch)


<p align=""center"">
  <img src=""https://user-images.githubusercontent.com/34229641/117537510-b26ee500-b001-11eb-9642-3baa461bfc94.png"" width=400 />
</p>
<h2 align=""center"">Registration of Multi-modal Volumetric Images by Establishing Cell Correspondence</h2>

## Table of Contents

- **[Introduction](#introduction)**
- **[Dependencies](#dependencies)**
- **[Getting Started](#getting-started)**
- **[Datasets](#datasets)**
- **[Registering your data](#registering-your-data)**
- **[Contributing](#contributing)**
- **[Issues](#issues)**
- **[Citation](#citation)**

### Introduction
This repository hosts the version of the code used for the **[publication](https://link.springer.com/chapter/10.1007/978-3-030-66415-2_30)** **Registration of Multi-modal Volumetric Images by Establishing Cell Correspondence**. 

We refer to the techniques elaborated in the publication, here as **PlatyMatch**. `PlatyMatch` performs a linear registration of volumetric, microscopy images of embryos by establishing correspondences between cells. 

`PlatyMatch` first detects nuclei in the two images being considered, next calculates unique `shape context` features for each nucleus detection which encapsulates the neighborhood as seen by that nucleus, and finally identifies pairs of matching nuclei through maximum bipartite matching applied to the pairwise distance matrix generated from these features. 

### Dependencies 

You can install `PlatyMatch` via **[pip]**:

```
conda create -y -n PlatyMatchEnv python==3.8
conda activate PlatyMatchEnv
python3 -m pip install PlatyMatch
```

### Getting Started

Type in the following commands in a new terminal window.

```
conda activate PlatyMatchEnv
napari
```

Next, select `PlatyMatch` from `Plugins> Add Dock Widget`.

### Datasets

Datasets are available in **`bic_eccv_data.zip`** as release assets **[here](https://github.com/juglab/PlatyMatch/releases/tag/v0.0.1)**.
These comprise of images, nuclei detections and keypoint locations for confocal images of 12 individual specimens under the `01-insitus` directory and static snapshots of a live embryo imaged through Light Sheet Microscopy under the `02-live` directory. 
Folders with the same name in these two directories correspond in their developmental age, for example, `01-insitus/02` corresponds to `02-live/02`, `01-insitus/03` corresponds to `02-live/03` and so on.   


### Registering your data

- **Detect Nuclei** 
	- Drag and drop your images in the viewer 
	- Click on `Sync with Viewer` button to refresh the drop-down menus 
	- Select the appropriate image in the drop down menu (for which nuclei detections are desired)
	- Select **`Detect Nuclei`** from the drop-down menu
	- Specify the anisotropy factor (`Anisotropy (Z)`) (i.e. the ratio of the size of the z pixel with respect to the x or y pixel. This factor is typically more than 1.0 because the z dimension is often undersampled)
	- Ideally min scales and max scales should be estimated from your data (`min_scale` should be set as `min_radius/sqrt(3)` and `max_scale` should be set as `max_radius/sqrt(3)`. The default values of `min_scale=5` and `max_scale=9` generally works well).  
	- Click `Run Scale Space Log` button. Please note that this step takes a few minutes.
	- Wait until a confirmation message suggesting that nuclei detection is over shows up on the terminal
	- Export the nuclei locations (`Export detections to csv`) to a csv file
	- Repeat this step for all images which need to be matched




https://user-images.githubusercontent.com/34229641/120660618-cd5d3980-c487-11eb-8996-326264a4df87.mp4


- **Estimate Transform**
	- In case, nuclei were exported to a csv in the `Detect Nuclei` panel, tick `csv` checkbox
	- If the nuclei detected were specified in the order id, z, y and x in the csv file, then tick `IZYXR` checkbox
	- Additionally if there is a header in the csv file, tick `Header` checkbox
	- Load the detections for the `Moving Image`, which is defined as the image which will be transformed to later match another `fixed` image
	- Load the detections for the `Fixed Image`
	- Click on `Run` pushbutton. Once the calculation is complete, a confirmation message shows up in the terminal. Export the transform matrix to a csv (Note that this step can take a few minutes)
	- It is also possible to estimate the transform in a `supervised` fashion. For this, upload the locations of a few matching keypoints in both images. These locations serve to provide a good starting point for the transform calculation. Once the keypoint files have been uploaded for both the images, then click `Run` and then export the transform matrix to a csv file 


https://user-images.githubusercontent.com/34229641/120685628-53857a00-c4a0-11eb-8f92-7ffac730e28a.mp4



- **Evaluate Metrics**
	- Drag images which need to be transformed, in the viewer
	- Click on `Sync with Viewer` button to refresh the drop-down menus
	- Specify the anisotropy factor (`Moving Image Anisotropy (Z)` and `Fixed Image Anisotropy (Z)`) (i.e. the ratio of the size of the z pixel with respect to the x or y pixel. This factor is typically more than 1.0 because the z dimension is often undersampled)
	- Load the transform which was calculated in the previous steps
	- If you simply wish to export a transformed version of the moving image, click on `Export Transformed Image`
	- Additionally, one could quantify metrics such as average registration error evaluated on a few keypoints. To do so, tick the `csv` checkbox, if keypoints and detections are available as a csv file. Then load the keypoints for the moving image (`Moving Kepoints`) and the fixed image (`Fixed Keypoints`)
	- Also, upload the detections calculated in the previous steps (`Detect Nuclei`)  by uploading the `Moving Detections` and the `Fixed Detections`
	- Click on the `Run` push button
	- The text fields such as `Matching Accuracy`(0 to 1, with 1 being the best) and `Average Registration Error` (the lower the better) should become populated once the results are available



https://user-images.githubusercontent.com/34229641/120685654-5b451e80-c4a0-11eb-8d7d-de58b8b8304d.mp4


### Contributing

Contributions are very welcome. Tests can be run with **[tox]**.

### Issues

If you encounter any problems, please **[file an issue]** along with a detailed description.

[file an issue]: https://github.com/juglab/PlatyMatch/issues
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/EmbedSeg/


### Citation
If you find our work useful in your research, please consider citing:

```bibtex
@InProceedings{10.1007/978-3-030-66415-2_30,
author=""Lalit, Manan and Handberg-Thorsager, Mette and Hsieh, Yu-Wen and Jug, Florian and Tomancak, Pavel"",
editor=""Bartoli, Adrien
and Fusiello, Andrea"",
title=""Registration of Multi-modal Volumetric Images by Establishing Cell Correspondence"",
booktitle=""Computer Vision -- ECCV 2020 Workshops"",
year=""2020"",
publisher=""Springer International Publishing"",
address=""Cham"",
pages=""458--473"",
isbn=""978-3-030-66415-2""
}
```

`PlatyMatch` plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/juglab/PlatyMatch/issues
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/


","['Development Status :: 4 - Beta', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']",,,,PlatyMatch.DetectNuclei,,,,,https://pypi.org/project/PlatyMatch,https://github.com/juglab/PlatyMatch,
376,PoseR,0.0.1b3,,,PoseR-napari,Pierce Mullen,pnm1@st-andrews.ac.uk,BSD-3-Clause,,A deep learning toolbox for decoding animal behaviour,>=3.10,"['numpy', 'magicgui', 'qtpy', 'napari', 'napari-video', 'napari-plot', 'tables', 'imageio-ffmpeg (==0.4.8)', 'pytorch-lightning', 'test-tube', 'scikit-learn', 'matplotlib', 'numba', 'networkx', 'seaborn', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# PoseR

[![License BSD-3](https://img.shields.io/pypi/l/PoseR.svg?color=green)](https://github.com/pnm4sfix/PoseR/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/PoseR-napari.svg?color=green)](https://pypi.org/project/PoseR-napari)
[![Python Version](https://img.shields.io/pypi/pyversions/PoseR-napari.svg?color=green)](https://python.org)
[![tests](https://github.com/pnm4sfix/PoseR/workflows/tests/badge.svg)](https://github.com/pnm4sfix/PoseR/actions)
[![codecov](https://codecov.io/gh/pnm4sfix/PoseR/branch/main/graph/badge.svg)](https://codecov.io/gh/pnm4sfix/PoseR)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/PoseR)](https://napari-hub.org/plugins/PoseR)

A deep learning toolbox for decoding animal behaviour

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->
![alt text](https://github.com/pnm4sfix/PoseR/blob/add-functionality/docs/logo.png?raw=true)

## Installation

Create an anaconda environment:

    conda create -n PoseR python=3.10

Activate PoseR environment:

    conda activate PoseR

Install CUDA if using NVIDIA GPU:

    conda install -c ""nvidia/label/cuda-11.7.0"" cuda

Install Pytorch:
For GPU:

    conda install pytorch torchvision torchaudio pytorch-cuda=11.7 -c pytorch -c nvidia

For CPU only version:

    conda install pytorch torchvision torchaudio cpuonly -c pytorch
    
Install napari:

    pip install napari[""all""]

You can install `PoseR` via [pip]:

    pip install PoseR-napari



To install latest development version :

    pip install git+https://github.com/pnm4sfix/PoseR.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""PoseR"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/pnm4sfix/PoseR/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/pnm4sfix/PoseR/issues', 'Documentation, https://github.com/pnm4sfix/PoseR#README.md', 'Source Code, https://github.com/pnm4sfix/PoseR', 'User Support, https://github.com/pnm4sfix/PoseR/issues']",,,PoseR-napari.make_qwidget,,,,,https://pypi.org/project/PoseR-napari,,
377,psfmodels,0.3.3,2022-07-07,2023-10-07,psfmodels,Talley Lambert,talley.lambert@gmail.com,GPL-3.0,https://github.com/tlambert03/psfmodels,Scalar and vectorial models of the microscope point spread function (PSF).,>=3.7,"['numpy', 'scipy (>=0.14.0)', 'typing-extensions', ""black ; extra == 'dev'"", ""flake8 ; extra == 'dev'"", ""flake8-docstrings ; extra == 'dev'"", ""flake8-typing-imports ; extra == 'dev'"", ""ipython ; extra == 'dev'"", ""isort ; extra == 'dev'"", ""mypy ; extra == 'dev'"", ""pre-commit ; extra == 'dev'"", ""pydocstyle ; extra == 'dev'"", ""pytest ; extra == 'dev'"", ""pytest-cov ; extra == 'dev'"", ""tox ; extra == 'dev'"", ""tox-conda ; extra == 'dev'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""jax ; extra == 'testing'"", 'magicgui ; (platform_system != ""Linux"") and extra == \'testing\'', 'qtpy ; (platform_system != ""Linux"") and extra == \'testing\'', 'pyside2 ; (platform_system != ""Linux"" and python_version < ""3.11"") and extra == \'testing\'']","# psfmodels

[![PyPI](https://img.shields.io/pypi/v/psfmodels.svg?color=green)](https://pypi.org/project/psfmodels)
[![Python
Version](https://img.shields.io/pypi/pyversions/psfmodels.svg?color=green)](https://python.org)
[![CI](https://github.com/tlambert03/psfmodels/actions/workflows/ci.yml/badge.svg)](https://github.com/tlambert03/psfmodels/actions/workflows/ci.yml)
[![codecov](https://codecov.io/gh/tlambert03/psfmodels/branch/main/graph/badge.svg)](https://codecov.io/gh/tlambert03/psfmodels)

Python bindings for scalar and vectorial models of the point spread function.

Original C++ code and MATLAB MEX bindings Copyright &copy; 2006-2013, [Francois
Aguet](http://www.francoisaguet.net/software.html), distributed under GPL-3.0
license. Python bindings by Talley Lambert

This package contains three models:

1. The vectorial model is described in Auget et al 2009<sup>1</sup>. For more
information and implementation details, see Francois' Thesis<sup>2</sup>.
2. A scalar model, based on Gibson & Lanni<sup>3</sup>.
3. A gaussian approximation (both paraxial and non-paraxial), using paramters from Zhang et al (2007)<sup>4</sup>.

<small>

<sup>1</sup> [F. Aguet et al., (2009) Opt. Express 17(8), pp.
6829-6848](https://doi.org/10.1364/OE.17.006829)

<sup>2</sup> [F. Aguet. (2009) Super-Resolution Fluorescence Microscopy Based on
Physical Models. Swiss Federal Institute of Technology Lausanne, EPFL Thesis no.
4418](http://bigwww.epfl.ch/publications/aguet0903.html)

<sup>3</sup> [F. Gibson and F. Lanni (1992) J. Opt. Soc. Am. A, vol. 9, no. 1, pp. 154-166](https://opg.optica.org/josaa/abstract.cfm?uri=josaa-9-1-154)

<sup>4</sup> [Zhang et al (2007). Appl Opt
. 2007 Apr 1;46(10):1819-29.](https://doi.org/10.1364/AO.46.001819)

</small>

### see also:

For a different (faster) scalar-based Gibson–Lanni PSF model, see the
[MicroscPSF](https://github.com/MicroscPSF) project, based on [Li et al
(2017)](https://doi.org/10.1364/JOSAA.34.001029) which has been implemented in
[Python](https://github.com/MicroscPSF/MicroscPSF-Py),
[MATLAB](https://github.com/MicroscPSF/MicroscPSF-Matlab), and
[ImageJ/Java](https://github.com/MicroscPSF/MicroscPSF-ImageJ)

## Install

```sh
pip install psfmodels
```

### from source

```sh
git clone https://github.com/tlambert03/PSFmodels.git
cd PSFmodels
pip install -e "".[dev]""  # will compile c code via pybind11
```

## Usage

There are two main functions in `psfmodels`: `vectorial_psf` and `scalar_psf`.
Additionally, each version has a helper function called `vectorial_psf_centered`
and `scalar_psf_centered` respectively. The main difference is that the `_psf`
functions accept a vector of Z positions `zv` (relative to coverslip) at which
PSF is calculated. As such, the point source may or may not actually be in the
center of the rendered volume. The `_psf_centered` variants, by contrast, do
_not_ accecpt `zv`, but rather accept `nz` (the number of z planes) and `dz`
(the z step size in microns), and always generates an output volume in which the
point source is positioned in the middle of the Z range, with planes equidistant
from each other. All functions accept an argument `pz`, specifying the position
of the point source relative to the coverslip. See additional keyword arguments
below

_Note, all output dimensions (`nx` and `nz`) should be odd._

```python
import psfmodels as psfm
import matplotlib.pyplot as plt
from matplotlib.colors import PowerNorm

# generate centered psf with a point source at `pz` microns from coverslip
# shape will be (127, 127, 127)
psf = psfm.make_psf(127, 127, dxy=0.05, dz=0.05, pz=0)
fig, (ax1, ax2) = plt.subplots(1, 2)
ax1.imshow(psf[nz//2], norm=PowerNorm(gamma=0.4))
ax2.imshow(psf[:, nx//2], norm=PowerNorm(gamma=0.4))
plt.show()
```

![Image of PSF](fig.png)

```python
# instead of nz and dz, you can directly specify a vector of z positions
import numpy as np

# generate 31 evenly spaced Z positions from -3 to 3 microns
psf = psfm.make_psf(np.linspace(-3, 3, 31), nx=127)
psf.shape  # (31, 127, 127)
```

**all** PSF functions accept the following parameters. Units should be provided
in microns unless otherwise stated. Python API may change slightly in the
future.  See function docstrings as well.

```
nx (int):       XY size of output PSF in pixels, must be odd.
dxy (float):    pixel size in sample space (microns) [default: 0.05]
pz (float):     depth of point source relative to coverslip (in microns) [default: 0]
ti0 (float):    working distance of the objective (microns) [default: 150.0]
ni0 (float):    immersion medium refractive index, design value [default: 1.515]
ni (float):     immersion medium refractive index, experimental value [default: 1.515]
tg0 (float):    coverslip thickness, design value (microns) [default: 170.0]
tg (float):     coverslip thickness, experimental value (microns) [default: 170.0]
ng0 (float):    coverslip refractive index, design value [default: 1.515]
ng (float):     coverslip refractive index, experimental value [default: 1.515]
ns (float):     sample refractive index [default: 1.47]
wvl (float):    emission wavelength (microns) [default: 0.6]
NA (float):     numerical aperture [default: 1.4]
```

## Comparison with other models

While these models are definitely slower than the one implemented in [Li et al
(2017)](https://doi.org/10.1364/JOSAA.34.001029) and
[MicroscPSF](https://github.com/MicroscPSF), there are some interesting
differences between the scalar and vectorial approximations, particularly with
higher NA lenses, non-ideal sample refractive index, and increasing spherical
aberration with depth from the coverslip.

For an interactive comparison, see the [examples.ipynb](notebooks/examples.ipynb) Jupyter
notebook.

## Lightsheet PSF utility function

The `psfmodels.tot_psf()` function provides a quick way to simulate the total
system PSF (excitation x detection) as might be observed on a light sheet
microscope (currently, only strictly orthogonal illumination and detection are
supported).  See the [lightsheet.ipynb](notebooks/lightsheet.ipynb) Jupyter notebook for
examples.
","['Development Status :: 3 - Alpha', 'Framework :: napari', 'License :: OSI Approved :: GNU General Public License v3 (GPLv3)', 'Natural Language :: English', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10']","['Source Code, https://github.com/tlambert03/psfmodels']",,,psfmodels.make_psf,,,,,https://pypi.org/project/psfmodels,https://github.com/tlambert03/psfmodels,
378,pyCUDAdecon,0.4.1,2021-05-31,2023-09-13,pycudadecon,Talley Lambert,Talley Lambert <talley.lambert@gmail.com>,MIT,https://github.com/tlambert03/pycudadecon,Python wrapper for CUDA-accelerated 3D deconvolution,>=3.7,"['numpy', 'tifffile', 'typing-extensions', 'importlib-metadata ; python_version < ""3.8""', ""black ; extra == 'dev'"", ""ipython ; extra == 'dev'"", ""mypy ; extra == 'dev'"", ""pdbpp ; extra == 'dev'"", ""pre-commit ; extra == 'dev'"", ""rich ; extra == 'dev'"", ""jupyter-book ==0.13.1 ; extra == 'docs'"", ""ghp-import ==2.1.0 ; extra == 'docs'"", ""sphinx-autodoc-typehints ==1.19.1 ; extra == 'docs'"", ""furo ==2022.9.29 ; extra == 'docs'"", ""pytest >=6.0 ; extra == 'test'"", ""pytest-cov ; extra == 'test'""]","# pyCUDAdecon

This package provides a python wrapper and convenience functions for
[cudaDecon](https://github.com/scopetools/cudaDecon), which is a CUDA/C++
implementation of an accelerated Richardson Lucy Deconvolution
algorithm<sup>1</sup>.

* CUDA accelerated deconvolution with a handful of artifact-reducing features.
* radially averaged OTF generation with interpolation for voxel size
  independence between PSF and data volumes
* 3D deskew, rotation, general affine transformations
* CUDA-based camera-correction for [sCMOS artifact correction](https://llspy.readthedocs.io/en/latest/camera.html)


### Install

The conda package includes the required pre-compiled libraries for Windows and Linux. See GPU driver requirements [below](#gpu-requirements)

```sh
conda install -c conda-forge pycudadecon
```

*macOS is not supported*

### 📖   &nbsp; [Documentation](http://www.talleylambert.com/pycudadecon)


### GPU requirements

This software requires a CUDA-compatible NVIDIA GPU. The underlying cudadecon
libraries have been compiled against different versions of the CUDA toolkit.
The required CUDA libraries are bundled in the conda distributions so you don't
need to install the CUDA toolkit separately.  If desired, you can pick which
version of CUDA you'd like based on your needs, but please note that different
versions of the CUDA toolkit have different GPU driver requirements:

To specify a specific cudatoolkit version, install as follows (for instance, to
use `cudatoolkit=10.2`)

```sh
conda install -c conda-forge pycudadecon cudatoolkit=10.2
```

| CUDA | Linux driver | Win driver |
| ---- | ------------ | ---------- |
| 10.2 | ≥ 440.33     | ≥ 441.22   |
| 11.0 | ≥ 450.36.06  | ≥ 451.22   |
| 11.1 | ≥ 455.23     | ≥ 456.38   |
| 11.2 | ≥ 460.27.03  | ≥ 460.82   |


If you run into trouble, feel free to [open an
issue](https://github.com/tlambert03/pycudadecon/issues) and describe your
setup.


## Usage


The [`pycudadecon.decon()`](https://www.talleylambert.com/pycudadecon/deconvolution.html#pycudadecon.decon) function is designed be able to handle most basic applications:

```python
from pycudadecon import decon

# pass filenames of an image and a PSF
result = decon('/path/to/3D_image.tif', '/path/to/3D_psf.tif')

# decon also accepts numpy arrays
result = decon(img_array, psf_array)

# the image source can also be a sequence of arrays or paths
result = decon([img_array, '/path/to/3D_image.tif'], psf_array)

# see docstrings for additional parameter options
```

For finer-tuned control, you may wish to make an OTF file from your PSF using [`pycudadecon.make_otf()`](https://www.talleylambert.com/pycudadecon/otf.html#pycudadecon.make_otf), and then use the [`pycudadecon.RLContext`](https://www.talleylambert.com/pycudadecon/deconvolution.html#pycudadecon.RLContext) context manager to setup the GPU for use with the [`pycudadecon.rl_decon()`](https://www.talleylambert.com/pycudadecon/deconvolution.html#pycudadecon.rl_decon) function.  (Note all images processed in the same context must have the same input shape).

```python
from pycudadecon import RLContext, rl_decon
from glob import glob
import tifffile

image_folder = '/path/to/some_images/'
imlist = glob(image_folder + '*488*.tif')
otf_path = '/path/to/pregenerated_otf.tif'

with tifffile.TiffFile(imlist[0]) as tf:
    imshape = tf.series[0].shape

with RLContext(imshape, otf_path, dz) as ctx:
    for impath in imlist:
        image = tifffile.imread(impath)
        result = rl_decon(image, ctx.out_shape)
        # do something with result...
```

If you have a 3D PSF volume, the [`pycudadecon.TemporaryOTF`](https://www.talleylambert.com/pycudadecon/otf.html#pycudadecon.TemporaryOTF) context manager facilitates temporary OTF generation...

```python
 # continuing with the variables from the previous example...
 psf_path = ""/path/to/psf_3D.tif""
 with TemporaryOTF(psf) as otf:
     with RLContext(imshape, otf.path, dz) as ctx:
         for impath in imlist:
             image = tifffile.imread(impath)
             result = rl_decon(image, ctx.out_shape)
             # do something with result...
```

... and that bit of code is essentially what the [`pycudadecon.decon()`](https://www.talleylambert.com/pycudadecon/deconvolution.html#pycudadecon.decon) function is doing, with a little bit of additional conveniences added in.

*Each of these functions has many options and accepts multiple keyword arguments. See the [documentation](https://www.talleylambert.com/pycudadecon/index.html) for further information on the respective functions.*

For examples and information on affine transforms, volume rotations, and deskewing (typical of light sheet volumes acquired with stage-scanning), see the [documentation on Affine Transformations](https://www.talleylambert.com/pycudadecon/affine.html)
___

<sup>1</sup> D.S.C. Biggs and M. Andrews, Acceleration of iterative image restoration algorithms, Applied Optics, Vol. 36, No. 8, 1997. https://doi.org/10.1364/AO.36.001766
","['Development Status :: 4 - Beta', 'Environment :: GPU :: NVIDIA CUDA', 'Framework :: napari', 'Intended Audience :: Science/Research', 'License :: OSI Approved :: MIT License', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Topic :: Scientific/Engineering']","['Documentation, https://pycudadecon.readthedocs.io/en/latest/', 'Source, https://github.com/tlambert03/pycudadecon', 'Tracker, https://github.com/tlambert03/pycudadecon/issues']",,,pycudadecon.deconvolve,,,,,https://pypi.org/project/pycudadecon,https://github.com/tlambert03/pycudadecon,
379,recOrder-napari,0.4.1,2022-07-11,2023-11-07,recOrder-napari,"Computational Microscopy Platform, CZ Biohub",shalin.mehta@czbiohub.org,BSD 3-Clause,https://github.com/mehta-lab/recOrder,Computational microscopy toolkit for label-free imaging,>=3.9,"['waveorder ==2.0.0rc3', 'pycromanager ==0.27.2', 'click >=8.0.1', 'natsort >=7.1.1', 'colorspacious >=1.1.2', 'pyqtgraph >=0.12.3', 'napari-ome-zarr >=0.3.2', 'napari[pyqt6_experimental]', 'importlib-metadata', 'iohub ==0.1.0.dev5', 'wget >=3.2', ""pytest >=5.0.0 ; extra == 'dev'"", ""pytest-cov ; extra == 'dev'"", ""pytest-qt ; extra == 'dev'"", ""tox ; extra == 'dev'"", ""pre-commit ; extra == 'dev'"", ""black ; extra == 'dev'"", ""hypothesis ; extra == 'dev'""]","# recOrder
![PyPI - Python Version](https://img.shields.io/pypi/pyversions/recOrder-napari)
[![Python package index download statistics](https://img.shields.io/pypi/dm/recOrder-napari.svg)](https://pypistats.org/packages/recOrder-napari)
[![Python package index](https://img.shields.io/pypi/v/recOrder-napari.svg)](https://pypi.org/project/recOrder-napari)
[![Development Status](https://img.shields.io/pypi/status/napari.svg)](https://en.wikipedia.org/wiki/Software_release_life_cycle#Alpha)

`recOrder` is a collection of computational imaging methods. It currently provides QLIPP (quantitative label-free imaging with phase and polarization), phase from defocus, and fluorescence deconvolution. 

[![Unveiling the invisible](https://github.com/mehta-lab/recOrder/blob/main/docs/images/comms_video_screenshot.png?raw=true)](https://www.youtube.com/watch?v=JEZAaPeZhck)

Acquisition, calibration, background correction, reconstruction, and applications of QLIPP are described in the following [E-Life Paper](https://elifesciences.org/articles/55502):

```bibtex
Syuan-Ming Guo, Li-Hao Yeh, Jenny Folkesson, Ivan E Ivanov, Anitha P Krishnan, Matthew G Keefe, Ezzat Hashemi, David Shin, Bryant B Chhun, Nathan H Cho, Manuel D Leonetti, May H Han, Tomasz J Nowakowski, Shalin B Mehta, ""Revealing architectural order with quantitative label-free imaging and deep learning,"" eLife 2020;9:e55502 DOI: 10.7554/eLife.55502 (2020).
```

These are the kinds of data you can acquire with `recOrder` and QLIPP:

https://user-images.githubusercontent.com/9554101/271128301-cc71da57-df6f-401b-a955-796750a96d88.mov

https://user-images.githubusercontent.com/9554101/271128510-aa2180af-607f-4c0c-912c-c18dc4f29432.mp4

## What do I need to use `recOrder`
`recOrder` is to be used alongside a conventional widefield microscope. For QLIPP, the microscope must be fitted with an analyzer and a universal polarizer: 

https://user-images.githubusercontent.com/9554101/273073475-70afb05a-1eb7-4019-9c42-af3e07bef723.mp4

For phase-from-defocus or fluorescence deconvolution methods, the universal polarizer is optional.

The overall structure of `recOrder` is shown in Panel B, highlighting the structure of the graphical user interface (GUI) through a napari plugin and the command-line interface (CLI) that allows users to perform reconstructions.

![Flow Chart](https://github.com/mehta-lab/recOrder/blob/main/docs/images/recOrder_Fig1_Overview.png?raw=true)



## Software Quick Start

(Optional but recommended) install [anaconda](https://www.anaconda.com/products/distribution) and create a virtual environment:

```sh
conda create -y -n recOrder python=3.9
conda activate recOrder
```

Install `recOrder-napari`:

```sh
pip install recOrder-napari
```

Open `napari` with `recOrder-napari`:

```sh
napari -w recOrder-napari
```

For more help, see [`recOrder`'s documentation](https://github.com/mehta-lab/recOrder/tree/main/docs). To install `recOrder` 
on a microscope, see the [microscope installation guide](https://github.com/mehta-lab/recOrder/blob/main/docs/microscope-installation-guide.md).

## Dataset

[Slides](https://doi.org/10.5281/zenodo.5135889) and a [dataset](https://doi.org/10.5281/zenodo.5178487) shared during a workshop on QLIPP and recOrder can be found on Zenodo, and the napari plugin's sample contributions (`File > Open Sample > recOrder-napari` in napari).

[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.5178487.svg)](https://doi.org/10.5281/zenodo.5178487)
[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.5135889.svg)](https://doi.org/10.5281/zenodo.5135889)
","['License :: OSI Approved :: BSD License', 'Programming Language :: Python', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering', 'Topic :: Scientific/Engineering :: Visualization', 'Topic :: Scientific/Engineering :: Information Analysis', 'Topic :: Scientific/Engineering :: Bio-Informatics', 'Topic :: Utilities', 'Framework :: napari', 'Operating System :: Microsoft :: Windows', 'Operating System :: POSIX', 'Operating System :: Unix', 'Operating System :: MacOS']","['Bug Tracker, https://github.com/mehta-lab/recOrder/issues', 'Documentation, https://github.com/mehta-lab/recOrder/wiki', 'Source Code, https://github.com/mehta-lab/recOrder/tree/main/recOrder', 'User Support, https://github.com/mehta-lab/recOrder/issues']",recOrder-napari.get_reader,,recOrder-napari.MainWidget,recOrder-napari.polarization_target_data,"['*.zarr', '*.tif']",,,https://pypi.org/project/recOrder-napari,https://github.com/mehta-lab/recOrder,
380,RedLionfish,0.10,2021-11-24,2024-03-22,RedLionfish,Luis Perdigao,luis.perdigao@rfi.ac.uk,"Apache License, Version 2.0",https://github.com/rosalindfranklininstitute/RedLionfish,Fast Richardson-Lucy deconvolution of 3D volume data using GPU or CPU with napari plugin.,,"['numpy', 'scipy', 'pyopencl', 'reikna']","![RedLionfish Logo](./redlionfish_logo.svg)

# RedLionfish (RL) deconvolution

*Richardson-Lucy deconvolution for fishes, scientists and engineers.*


This software is for filtering 3D data using the Richardson-Lucy deconvolution algorithm.

Richardson-Lucy is an iterative deconvolution algorithm that is used to remove
point spread function (PSF) or optical transfer function (OTF) artifacts from experimental images.

The method was originally developed for astronomy to remove optical effects and simultaneously reduce poisson noise in 2D images.

[Lucy, L. B. An iterative technique for the rectification of observed distributions. The Astronomical Journal 79, 745 (1974). DOI: 10.1086/111605](https://ui.adsabs.harvard.edu/abs/1974AJ.....79..745L/abstract)

The method can also be applied to 3D data. Nowadays this filtering technique is also widely used by microscopists.

The Richardson-Lucy deconvolution algorigthm is iterative. Each iteration involves the calculation of 2 convolutions, one element-wise multiplication and one element-wise division.

When dealing with 3D data, the Richardson-Lucy algorithm is quite computional intensive primarly due to the calculation of the convolution, and can take a while to complete depending on the resources available. Convolution is significantly sped up using FFT compared to raw convolution.

This software was developed with the aim to make the R-L computation faster by exploiting GPU resources, and with the use of FFT convolution.

To make RedLionfish easily accessible, it is available through PyPi and anaconda (conda-forge channel). A useful plugin for Napari is also available.

Please note that this software only works with 3D data. For 2D data there are many alternatives such as the DeconvolutionLab2 in Fiji (ImageJ) and sckikit-image.

## Napari plugin

You can now use the Napari's plugin installation in *Menu -> Plugins -> Install/Uninstall Plugins...*.
However, if you chose to use this method, GPU acceleration may not be available and it will use the CPU backend. Better check.

![](resources\imag1.jpg)

Alternatively, if you follow the installation instructions below, and install the napari in the same python environment
then the plugin should be immediately available in the *Menu -> Plugins -> RedLionfish*.


## Installation

Previously there was a problem in installing using `pip`, because no PyOpenCL wheels for windows were avaiable. It is now avaialble.

This package can be installed using pip or conda.

Napari plugin installation engine can also be used to install this package.


### Install from PyPi

```
pip install redlionfish
```


### Conda install

This package is available in conda-forge channel.
It contains the precompiled libraries and it will install all the requirments for GPU-accelerated RL calculations.

`conda install redlionfish -c conda-forge`

In Linux , the package `ocl-icd-system` may also be useful.

```
conda install reikna pyopencl ocl-icd-system -c conda-forge
```


#### Manual installation using the conda package file.

Download the appropriate conda package .bz2 at [https://github.com/rosalindfranklininstitute/RedLionfish/releases](https://github.com/rosalindfranklininstitute/RedLionfish/releases)

In the command line, successively run:
```
conda install <filename.bz2>
conda update --all -c conda-forge
```
The second line is needed because you are installing from a local file, conda installer will not install dependencies. Right after this you should run the update command given.


### Manual installation (advanced and for developers)

Please note that in order to use OpenCL GPU accelerations, PyOpenCL must be installed.
The best way to get it working is to install it under a conda environment.

The installation is similar to the previously described for PyPi.

`conda install reikna pyopencl`

or

`conda install reikna pyopencl ocl-icd-system -c conda-forge` (Linux)

Clone/download from source [https://github.com/rosalindfranklininstitute/RedLionfish/](https://github.com/rosalindfranklininstitute/RedLionfish/)

and run

`python setup.py install`


### Debug installation
If you want to test and modify the code then you should probably install in debug mode using:

`python setup.py develop`

or

`pip install -e .`


## More information

The software has algorithms for Richardson-Lucy deconvolution that use either CPU and GPU.

The CPU version is very similar to the [skimage.restoration.richardson_lucy](https://scikit-image.org/docs/dev/api/skimage.restoration.html#skimage.restoration.richardson_lucy) code, with improvments in speed.
major differences are:

- the convolution steps use FFT only.
- PSF and PSF-flipped FFTs are precalculated before starting iterations.

The GPU version, was written in to use Reikna package, which does FFT using OpenCL, via PyOpenCL.

Unfortunately, a major limitation in RAM usage exists with PyOpenCL.
Large 3D data volumes with cause out-of-memory error when trying to upload data to the GPU for FFT calculations.
As such, to overcome this problem, a block algorithm is used, which splits data into blocks with padded data.
The results are then combined together to give the final result.
This affects the perfomance of the calculation rather significantly, but with the advantage of being possible to handle large data volumes.

If Richardson-Lucy deconvolution using the GPU method fails, RedLionfish will fallback to CPU calculation. Check console output for messages.

If you are using the RedLionfish in your code, note that, by default, `def doRLDeconvolutionFromNpArrays()` method it uses the GPU OpenCL version.

## Testing

Use pytest to test the package. Test files are in `/test` folder

Many examples can be found in `/scripts' folder.

A useful way to test and benchmark the package installation can be run from the proect root using the command:

'python scripts/test_and_benchm.py'

or in windows

'python scripts\test_and_benchm.py'

This will print out information about your GPU device (if available) and run some deconvolutions.
It initially creates some data programatically, convolutes with a gaussian PSF, and add Poisson noise.
Then it executes executes the
Richardson-Lucy deconvolution calculation using CPU and GPU methods, for 10 iterations.
During the calculation it will print some information to the console/terminal, including the time it takes to run the calculation.


Computer generated data and an experimental PSF can be found in `scripts\testdata`

### Testing Redlionfish in napari

Here is an example testing the Redlionfish plugin in napari:

1. load data `scripts/testdata/gendata_psfconv_poiss_large.tif` (can use draga and drop)
2. load psf data `scripts/testdata/PSF_RFI_8bit.tif`
3. In the RedLionfish side window ensure that 'gendata_psfconv_poiss_large' is selected in data dropdown widget, and `PSF_RFI_8bit` is selected in psfdata widget.
4. Choose number of iterations (default=10)
5. Click 'Go' button and wait until result shows as a new data layer.
6. Use controls of the left panel to compare before and after RL deconvolution: select 'RL-deconvolution' layer and set colormap to red. Hide PSF_RFI_8bit. Make sure that both 'RL-deconvolution' and 'gendata-psfconv' are visible. Now, hide/unhide RL-deconvolution layer to see before and after deconvolution. Adjust contrast limits of each layer as desired.


## GPU vs CPU

You may notice that choosing GPU does not make RL-calculation much faster compared with CPU, and sometimes is slower.

Which method runs the R-L deconvolution faster. That depends on the computer configuration/architecture.

GPU calculations will be generally faster than CPU with bigger data volumes.

GPU calculation will be significantly faster if using a dedicated GPU card.

Please see benchmark values that highlights significant variability in calculation speeds.


[benchmark_results.md](benchmark_results.md)


## Coding

Please feel free to browse the `/scripts` folder for examples.

In order to use the functions, add the follwoing import to your code,

`import RedLionfishDeconv`

The most useful function is perhaps the following.

`def doRLDeconvolutionFromNpArrays(data_np , psf_np ,*, niter=10, method='gpu', useBlockAlgorithm=False, callbkTickFunc=None, resAsUint8 = False) `

This will do the Richardson-Lucy deconvolution on the data_np (numpy, 3 dimensional data volume) using the provided PSF data volume, for 10 iterations. GPU method is generally faster but it may fail. If it does fail, the program will automatically use the CPU version that uses the scipy fft package.



## Manually building the conda package

For this installation, ensure that the conda-build package is installed

`conda install conda-build`

In windows, simply execute

`conda-create-package.bat`


Or, execute the following command-line to create the installation package.

`conda-build --output-folder ./conda-built-packages -c conda-forge conda-recipe`

and the conda package will be created in folder *conda-built-packages*.

Otherwise, navigate to `conda-recipe`, and execute on the command-line `conda build .`

It will take a while to complete.

## Contact

Report issues and questions in project's github page, please. Please don't try to send emails as they may be igored or spam-filtered.

","['Development Status :: 4 - Beta ', 'License :: OSI Approved :: Apache Software License', 'Natural Language :: English', 'Programming Language :: Python :: 3.8', 'Operating System :: Microsoft :: Windows', 'Operating System :: MacOS', 'Operating System :: POSIX :: Linux', 'Topic :: Scientific/Engineering :: Image Processing', 'Framework :: napari']",,,,RedLionfish.RedLionfish_widget,,,,,https://pypi.org/project/RedLionfish,https://github.com/rosalindfranklininstitute/RedLionfish,
381,Calibration Tool,0.0.1,2023-11-18,2023-11-18,set-calibration,Clement H. Benedetti,clement.benedetti@mri.cnrs.fr,MIT,https://pypi.org/project/set-calibration,"""A tool allowing to modify the calibration (physical units) of images""",>=3.8,"['numpy', 'magicgui', 'qtpy', 'scikit-image', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# set-calibration

[![License MIT](https://img.shields.io/pypi/l/set-calibration.svg?color=green)](https://github.com/MontpellierRessourcesImagerie/set-calibration/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/set-calibration.svg?color=green)](https://pypi.org/project/set-calibration)
[![Python Version](https://img.shields.io/pypi/pyversions/set-calibration.svg?color=green)](https://python.org)
[![tests](https://github.com/MontpellierRessourcesImagerie/set-calibration/workflows/tests/badge.svg)](https://github.com/MontpellierRessourcesImagerie/set-calibration/actions)
[![codecov](https://codecov.io/gh/MontpellierRessourcesImagerie/set-calibration/branch/main/graph/badge.svg)](https://codecov.io/gh/MontpellierRessourcesImagerie/set-calibration)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/set-calibration)](https://napari-hub.org/plugins/set-calibration)

""A tool allowing to modify the calibration (physical units) of images""

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `set-calibration` via [pip]:

    pip install set-calibration



To install latest development version :

    pip install git+https://github.com/MontpellierRessourcesImagerie/set-calibration.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [MIT] license,
""set-calibration"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/MontpellierRessourcesImagerie/set-calibration/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: MIT License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/MontpellierRessourcesImagerie/set-calibration/issues', 'Documentation, https://github.com/MontpellierRessourcesImagerie/set-calibration#README.md', 'Source Code, https://github.com/MontpellierRessourcesImagerie/set-calibration', 'User Support, https://github.com/MontpellierRessourcesImagerie/set-calibration/issues']",,,set-calibration.create_scale_panel,,,,,https://pypi.org/project/set-calibration,,
382,skan,0.11.1,2021-05-03,2023-06-23,skan,Juan Nunez-Iglesias,juan.nunez-iglesias@monash.edu,BSD 3-Clause,http://github.com/jni/skan,Skeleton analysis in Python,>=3.8,"['imageio (>=2.10.1)', 'matplotlib (>=3.4)', 'networkx (>=2.7)', 'numba (>=0.53)', 'numpy (>=1.21)', 'pandas (>=2.0.2)', 'openpyxl (>=2.6)', 'scikit-image (>=0.17.1)', 'scipy (>=1.7)', 'toolz (>=0.10.0)', 'tqdm (>=4.57.0)', ""scikit-image[data] ; extra == 'all'"", ""napari[all] (<0.4.18) ; extra == 'docs'"", ""sphinx ; extra == 'docs'"", ""jupyter ; extra == 'docs'"", ""notebook ; extra == 'docs'"", ""seaborn (<1.0) ; extra == 'docs'"", ""sphinx-toggleprompt ; extra == 'docs'"", ""sphinx-copybutton ; extra == 'docs'"", ""sphinxcontrib-bibtex ; extra == 'docs'"", ""myst-nb ; extra == 'docs'"", ""zarr ; extra == 'docs'"", ""pydata-sphinx-theme (==0.8.1) ; extra == 'docs'"", ""coverage ; extra == 'testing'"", ""hypothesis ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""seaborn (<1.0) ; extra == 'testing'"", ""tifffile ; extra == 'testing'""]","# skan: skeleton analysis in Python
Python module to analyse skeleton (thin object) images

[![Binder](https://mybinder.org/badge.svg)](https://mybinder.org/v2/gh/jni/skan/main?filepath=doc%2Fgetting_started.ipynb)
[![Coverage Status](https://coveralls.io/repos/github/jni/skan/badge.svg?branch=main)](https://coveralls.io/github/jni/skan?branch=master)

See the documentation at [https://skeleton-analysis.org](https://skeleton-analysis.org).
","['Development Status :: 3 - Alpha', 'Environment :: Console', 'Intended Audience :: Developers', 'Intended Audience :: Education', 'Intended Audience :: Science/Research', 'License :: OSI Approved :: BSD License', 'Programming Language :: Python', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering', 'Operating System :: Microsoft :: Windows', 'Operating System :: POSIX', 'Operating System :: Unix', 'Operating System :: MacOS', 'Framework :: napari']",,,,skan.skeletonize_labels,,,,,https://pypi.org/project/skan,http://github.com/jni/skan,
383,smo,2.0.2,2022-01-28,2023-06-18,smo,Mauro Silberberg,maurosilber@gmail.com,MIT,https://github.com/maurosilber/smo,Implementation of the Silver Mountain Operator (SMO) for the estimation of background distributions.,,"['numpy', 'scipy', 'typing-extensions ; python_version < ""3.9""', ""pre-commit ; extra == 'dev'"", ""pytest ; extra == 'dev'"", ""tox ; extra == 'dev'""]","![PyPi](https://img.shields.io/pypi/pyversions/smo.svg)
[![License](https://img.shields.io/github/license/maurosilber/smo)](https://opensource.org/licenses/MIT)
[![PyPi](https://img.shields.io/pypi/v/smo.svg)](https://pypi.python.org/pypi/smo)
[![Conda](https://img.shields.io/conda/pn/conda-forge/smo)](https://anaconda.org/conda-forge/smo)

# SMO

SMO is a Python package that implements the Silver Mountain Operator (SMO), which allows to recover an unbiased estimation of the background intensity distribution in a robust way.

We provide an easy to use Python package and plugins for some of the major image processing softwares: [napari](https://napari.org), [CellProfiler](https://cellprofiler.org), and [ImageJ](https://imagej.net) / [FIJI](https://fiji.sc). See Plugins section below.

## Citation

To learn more about the theory behind SMO, you can read the [pre-print in BioRxiv](https://doi.org/10.1101/2021.11.09.467975).

If you use this software, please cite that pre-print.

## Usage

To obtain a background-corrected image, it is as straightforward as:

```python
import skimage.data
from smo import SMO

image = skimage.data.human_mitosis()
smo = SMO(sigma=0, size=7, shape=(1024, 1024))
background_corrected_image = smo.bg_corrected(image)
```

where we used a sample image from `scikit-image`.
By default,
the background correction subtracts the median value of the background distribution.
Note that the background regions will end up with negative values,
but with a median value of 0.

A notebook explaining in more detail the meaning of the parameters and other possible uses for SMO is available here: [smo/examples/usage.ipynb](https://github.com/maurosilber/SMO/blob/main/smo/examples/usage.ipynb) [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/maurosilber/SMO/blob/main/smo/examples/usage.ipynb).

## Installation

It can be installed with `pip` from PyPI:

```
pip install smo
```

or with `conda` from the conda-forge channel:

```
conda install -c conda-forge smo
```

## Plugins
### Napari

A [napari](https://napari.org) plugin is available.

To install:

- Option 1: in napari, go to `Plugins > Install/Uninstall Plugins...` in the top menu, search for `smo` and click on the install button.

- Option 2: just `pip` install this package in the napari environment.

It will appear in the `Plugins` menu.

### CellProfiler

A [CellProfiler](https://cellprofiler.org) plugin in available in the [smo/plugins/cellprofiler](smo/plugins/cellprofiler) folder.

![](images/CellProfiler_SMO.png)

To install, save [this file](https://raw.githubusercontent.com/maurosilber/SMO/main/smo/plugins/cellprofiler/smo.py) into your CellProfiler plugins folder. You can find (or change) the location of your plugins directory in `File > Preferences > CellProfiler plugins directory`.

### ImageJ / FIJI

An [ImageJ](https://imagej.net) / [FIJI](https://fiji.sc) plugin is available in the [smo/plugins/imagej](smo/plugins/imagej) folder.

![](images/ImageJ_SMO.png)

To install, download [this file](https://raw.githubusercontent.com/maurosilber/SMO/main/smo/plugins/imagej/smo.py) and:

- Option 1: in the ImageJ main window, click on `Plugins > Install... (Ctrl+Shift+M)`, which opens a file chooser dialog. Browse and select the downloaded file. It will prompt to restart ImageJ for changes to take effect.

- Option 2: copy into your ImageJ plugins folder (`File > Show Folder > Plugins`).

To use the plugin, type `smo` on the bottom right search box:

![](images/ImageJ_MainWindow.png)

select `smo` in the `Quick Search` window and click on the `Run` button.

![](images/ImageJ_QuickSearch.png)

Note: the ImageJ plugin does not check that saturated pixels are properly excluded.

## Development

Code style is enforced via pre-commit hooks. To set up a development environment, clone the repository, optionally create a virtual environment, install the [dev] extras and the pre-commit hooks:

```
git clone https://github.com/maurosilber/SMO
cd SMO
conda create -n smo python pip numpy scipy
pip install -e .[dev]
pre-commit install
```
","['Intended Audience :: Science/Research', 'License :: OSI Approved :: MIT License', 'Operating System :: MacOS :: MacOS X', 'Operating System :: Microsoft :: Windows', 'Operating System :: POSIX', 'Programming Language :: Python', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Topic :: Scientific/Engineering', 'Framework :: napari']",,,,smo.napari_experimental_provide_function,,,,,https://pypi.org/project/smo,https://github.com/maurosilber/smo,
384,Snouty Viewer,0.2.5,2023-04-13,2023-06-18,snouty-viewer,Austin E. Y. T. Lefebvre,austin.e.lefebvre@gmail.com,MIT,https://github.com/aelefebv/snouty-viewer,"A plugin to visualize, deskew, and combine Snouty data.",>=3.8,"['magicgui', 'napari', 'numpy', 'ome-types', 'tifffile', ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""tox ; extra == 'testing'""]","# snouty-viewer

[![License MIT](https://img.shields.io/pypi/l/snouty-viewer.svg?color=green)](https://github.com/aelefebv/snouty-viewer/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/snouty-viewer.svg?color=green)](https://pypi.org/project/snouty-viewer)
[![Python Version](https://img.shields.io/pypi/pyversions/snouty-viewer.svg?color=green)](https://python.org)
[![tests](https://github.com/aelefebv/snouty-viewer/workflows/tests/badge.svg)](https://github.com/aelefebv/snouty-viewer/actions/workflows/test_and_deploy.yml)
[![codecov](https://codecov.io/gh/aelefebv/snouty-viewer/branch/main/graph/badge.svg)](https://codecov.io/gh/aelefebv/snouty-viewer)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/snouty-viewer)](https://napari-hub.org/plugins/snouty-viewer)

## Description
Easy to use plugin for opening raw Snouty files and converting them to native view.

Allows for saving to ome.tif files with corresponding OME-XML based metadata.

Also allows for bulk deskewing and saving directories.

![Example](https://i.imgur.com/VirE5DM.gif)

## Intended Audience & Supported Data
This plugin is intended for those using a SOLS (Snouty) microscope collected via
[Alfred Millett-Sikking's code](https://github.com/amsikking/SOLS_microscope).

This plugin accepts a folder with at least subdirectories of data and metadata as an input.

## Quickstart

### A. Getting the plugin working (choose either a or b, you don't have to do both)
#### a. Through pip-install:
1. pip install snouty-viewer (within a virtual environment of Python 3.8, 3.9, or 3.10 recommended)
2. Open up napari
#### b. Through Napari:
1. Open up napari
2. Plugins > Install/Uninstall plugins
3. Search for ""snouty-viewer""
4. Install
5. (Maybe need to) reopen napari

### B. Viewing raw Snouty data
- Drag and drop a root folder of your Snouty data. This is the folder that includes the data and metadata subfolders.
- Select ""Snouty Viewer"" for opening.

### C. Converting raw Snouty data to its native view
1. Click plugins, snouty-viewer -> Native View
2. Select the file you want to convert
3. Press Deskew

### D. Saving your native view file
1. Select the channel (or multi-channel) layer you want to save
2. File > Save Selected Layer(s)...
3. Select where you want to save your file
4. Title your file, "".ome.tif"" will automatically be appended.
5. Save with ""Snouty Writer""
6. Wait (this could take a few minutes depending on your file's size and your hardware)

### E. Batch saving
1. Click plugins, snouty-viewer -> Batch Deskew & Save
2. Input a directory (without quotes) that contains 1 or more Snouty-acquired directories.
3. If you want to view your deskewed outputs, check the box.
4. If you want to automatically save the deskewed outputs, check the box.
5. Press Deskew and save
6. Wait (this could take a few minutes depending on your files' sizes and your hardware)
## Getting Help
- Open up an issue on [GitHub](https://github.com/aelefebv/snouty-viewer/issues).
- Start a thread on [image.sc](https://forum.image.sc/)

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/index.html
-->

## Installation

You can install `snouty-viewer` via [pip]:

    pip install snouty-viewer



To install latest development version :

    pip install git+https://github.com/aelefebv/snouty-viewer.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [MIT] license,
""snouty-viewer"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/aelefebv/snouty-viewer/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: MIT License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/aelefebv/snouty-viewer/issues', 'Documentation, https://github.com/aelefebv/snouty-viewer#README.md', 'Source Code, https://github.com/aelefebv/snouty-viewer', 'User Support, https://github.com/aelefebv/snouty-viewer/issues']",snouty-viewer.get_reader,snouty-viewer.write_single_image,snouty-viewer.get_native_view,,,['.ome.tif'],,https://pypi.org/project/snouty-viewer,https://github.com/aelefebv/snouty-viewer,
385,spots in yeasts,1.2.0,2023-12-04,2023-12-04,spots-in-yeasts,Clément H. Benedetti,clement.benedetti@mri.cnrs.fr,MIT,https://pypi.org/project/spots-in-yeasts/,A Napari plugin segmenting yeast cells and fluo spots to extract statistics.,>=3.8,"['numpy', 'magicgui', 'magic-class', 'qtpy', 'opencv-python', 'matplotlib', 'termcolor', 'scikit-image', 'tifffile', 'cellpose', 'napari', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# spots-in-yeasts

[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](https://github.com/MontpellierRessourcesImagerie/spots-in-yeasts/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/spots-in-yeasts.svg?color=green)](https://pypi.org/project/spots-in-yeasts)
[![Python Version](https://img.shields.io/pypi/pyversions/spots-in-yeasts.svg?color=green)](https://python.org)
[![tests](https://github.com/MontpellierRessourcesImagerie/spots-in-yeasts/workflows/tests/badge.svg)](https://github.com/MontpellierRessourcesImagerie/spots-in-yeasts/actions)
[![codecov](https://codecov.io/gh/MontpellierRessourcesImagerie/spots-in-yeasts/branch/master/graph/badge.svg)](https://codecov.io/gh/MontpellierRessourcesImagerie/spots-in-yeasts)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/spots-in-yeasts)](https://napari-hub.org/plugins/spots-in-yeasts)

A Napari plugin segmenting yeast cells and fluo spots to extract statistics.

----------------------------------

The skeleton on this [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.


## Introduction

> This Napari plugin's purpose is to extract statistics about fluo spots in yeast cells. We produce a segmentation of cells (based on the brightfield) and a segmentation of spots (based on the fluo channel). Then, we associate the measures to each cells.

Unless you use the `NapariJ` plugin to open images, or the `cast_extension.ijm` script to cast files, you can only launch this plugin on `.tif` images.

For now, the code produces JSON files compiling the metrics such as:
- The number of spots per cell.
- The average intensity of a spot.
- The area of each spot.
- The location of each spot.

We provide `cast_extension.ijm` which is another script meant to be used in Fiji/ImageJ. It is able to convert `.nd` and `.czi` images into basic `.tif` images so you can open them in Napari.

You can process your images either in __one-shot__ _(image per image)_ or in __batch mode__ _(by providing the path to a folder)_. In case you used batch mode, a control image is created so you can quickly check whether your segmentation was correctly performed.

Required packages in your environment:
- `napari`
- `cellpose`
- `numpy`
- `skimage`
- `termcolor`
- `matplotlib`
- `cv2`


## Installation

You can install `spots-in-yeasts` via [pip]:

    pip install spots-in-yeasts



To install latest development version :

    pip install git+https://github.com/MontpellierRessourcesImagerie/spots-in-yeasts.git


## Example

- Your images must have exactly two channels. The number of slices in each channel is totally up to you.
- __First channel__: fluo spots, __second channel__: brightfield.
- If you want to use the batch mode, you must use `.tif` images.

The two following images are the __brightfield__ and __fluo spots__ channels of the same image:

![Brightfield](https://dev.mri.cnrs.fr/attachments/download/3017/bf.png)
![Spots](https://dev.mri.cnrs.fr/attachments/download/3018/fluo.png)

The following images are the __cells labels__ and the __spots positions__:

![Labeled cells](https://dev.mri.cnrs.fr/attachments/download/3016/cells.png)
![Detected spots](https://dev.mri.cnrs.fr/attachments/download/3019/spots.png)

## Usage

### One-shot

- Open Napari. Keep the terminal opened, it provides lots of information.
- Before starting, make sure that no layer is currently open. You can clear your viewer with the `Clear layers` button.
- Drag'n'drop your image into the Napari viewer. It should show up in the left column.
- Click the `Split channels` button to separate the brightfield and the fluo on two different layers. Now, you should have two layers named ""brightfield"" and ""fluo-spots"".
- To segment yeast cells, click the `Segment cells` button. The interface will certainly freeze during a few seconds (~10/30s). A new layer should appear, containing a value of intensity for each individual cell.
- Click on the `Segment spots` button. This is a pretty fast operation. A new layer containing spots just appeared. Spots are represented as small white dots. You can change that in the layer's settings you struggle controling the result.
- Finally, you can use the `Extract stats` button to create a JSON file. This file will automatically be opened in your default text editor, but it is a __temporary file__, which means that it is not saved anywhere and will get lost if you don't save it yourself.
- Once you are done, you can press the `Clear layers` button again and pass to your next image, repeating the previous steps.

### Batch mode

- Before starting, you need a folder containing correctly formated `.tif` files.
- Open Napari, and keep the terminal opened to see provided information.
- Set the `input folder` field to your folder containing `.tif` images.
- Set the `output folder` field to the path of a folder (preferably empty) that will receive the control images and the JSON files generated by the script.
- You can click the `Run batch` button to launch the process.

__Note:__ In batch mode, your viewer won't show anything. You must rely on the terminal's content and the progress bar to know what is going on. To open the progress bar in Napari, click on `activity` in the lower-right corner.

## Messages:

- `Export directory set to: /some/path/to/output`: Folder provided by the user to receive produced files (JSON, controls)
- `===== Working on: d1-230421-11S_2 (1/32)====`: Name of the image currently processed and its rank. For example here, ""d1-230421-11S_2"" is being processed and it is the first image processed from a folder containing 32 images.
- `Selected slices: (4, 8). (11 slices available)`: The script doesn't use all the slices in the image. Instead, it detects the most is-focus slice and takes N slices before and after it. In this example, 11 slices were available in the image. We are using the slices 4, 5, 6, 7, 8 for processing, so the most in-focus one is the 6th.
- `Segmenting cells...`: Notification that the script started segmenting yeasts cells.
- `Cells segmentation done. 219 cells found.`: End of cells segmentation. This message also provides you with the number of indiviual detected. This number is displayed before labels touching the borders are removed.
- `Segmented cells from d1-230421-11S_2 in 10.0s.`: Operations are timed. This is just the time report of cells segmentation.
- `Starting spots segmentation...`: Notification that the script started segmenting spots in the fluo channel.
- `102 spots found .`: Number of spots detected during the segmentation.
- `Segmented spots from d1-230421-11S_2 in 1.0s.`: Duration elapsed during spots segmentation.
- `Spots exported to: /some/path/to/output/d1-230421-11S_2.json`: Path to the exported metrics.
- `Focused slice too far from center!`: We don't use all the slices available. We detect the most in-focus one and take N slices before and after. This message means that there isn't N slices available after (or before) the most in-focus one. The process won't get interupted, but you want to be more careful about the segmentation of this image.
- `The image d1-230421 BG- failed to be processed.`: A basic sanity check is applied to the results before they get exported to reduce the amount of manual checking to perform. This message simply means that either the cells segmentation, or the spots segmentation is so bad that this image will be skipped.
- `========= DONE. (288.0s) =========`: Indicates that all the images contained in your folder were processed, the batch is over. The total amount of time if also displayed.

----------------------------------

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [MIT] license,
""spots-in-yeasts"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.


[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/MontpellierRessourcesImagerie/spots-in-yeasts/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: MIT License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/MontpellierRessourcesImagerie/spots-in-yeasts/issues', 'Documentation, https://github.com/MontpellierRessourcesImagerie/spots-in-yeasts#README.md', 'Source Code, https://github.com/MontpellierRessourcesImagerie/spots-in-yeasts', 'User Support, https://github.com/MontpellierRessourcesImagerie/spots-in-yeasts/issues']",spots-in-yeasts.get_reader,,spots-in-yeasts.spots_in_yeasts,,['*.ysc'],,,https://pypi.org/project/spots-in-yeasts/,,
386,stardist-napari,2022.12.6,2022-06-08,2023-06-18,stardist-napari,"Uwe Schmidt, Martin Weigert","research@uweschmidt.org, martin.weigert@epfl.ch",BSD 3-Clause,https://github.com/stardist/stardist-napari,Object Detection with Star-convex Shapes,>=3.8,"['stardist (>=0.8.3)', 'napari (>=0.4.13)', 'magicgui (>=0.4.0)', 'tensorflow ; platform_system != ""Darwin"" or platform_machine != ""arm64""', 'tensorflow-macos ; platform_system == ""Darwin"" and platform_machine == ""arm64""', 'tensorflow-metal ; platform_system == ""Darwin"" and platform_machine == ""arm64""', ""pytest ; extra == 'test'"", ""pytest-qt ; extra == 'test'"", ""napari[pyqt] (>=0.4.13) ; extra == 'test'""]","# StarDist Napari Plugin

[![PyPI version](https://img.shields.io/pypi/v/stardist-napari.svg)](https://pypi.org/project/stardist-napari)
[![Anaconda-Server Badge](https://anaconda.org/conda-forge/stardist-napari/badges/version.svg)](https://anaconda.org/conda-forge/stardist-napari)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/stardist-napari)](https://napari-hub.org/plugins/stardist-napari)
[![Image.sc forum](https://img.shields.io/badge/dynamic/json.svg?label=forum&url=https%3A%2F%2Fforum.image.sc%2Ftags%2Fstardist.json&query=%24.topic_list.tags.0.topic_count&colorB=brightgreen&suffix=%20topics&logo=data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAA4AAAAOCAYAAAAfSC3RAAABPklEQVR42m3SyyqFURTA8Y2BER0TDyExZ+aSPIKUlPIITFzKeQWXwhBlQrmFgUzMMFLKZeguBu5y+//17dP3nc5vuPdee6299gohUYYaDGOyyACq4JmQVoFujOMR77hNfOAGM+hBOQqB9TjHD36xhAa04RCuuXeKOvwHVWIKL9jCK2bRiV284QgL8MwEjAneeo9VNOEaBhzALGtoRy02cIcWhE34jj5YxgW+E5Z4iTPkMYpPLCNY3hdOYEfNbKYdmNngZ1jyEzw7h7AIb3fRTQ95OAZ6yQpGYHMMtOTgouktYwxuXsHgWLLl+4x++Kx1FJrjLTagA77bTPvYgw1rRqY56e+w7GNYsqX6JfPwi7aR+Y5SA+BXtKIRfkfJAYgj14tpOF6+I46c4/cAM3UhM3JxyKsxiOIhH0IO6SH/A1Kb1WBeUjbkAAAAAElFTkSuQmCC)](https://forum.image.sc/tags/stardist)

This project provides the [napari](https://napari.org/) plugin for [StarDist](https://github.com/stardist/stardist), a deep learning based 2D and 3D object detection method with star-convex shapes. StarDist has originally been developed (see [papers](https://github.com/stardist/stardist#stardist---object-detection-with-star-convex-shapes)) for the segmentation of densely packed cell nuclei in challenging images with low signal-to-noise ratios. The plugin allows to apply pretrained and custom trained models from within napari.

If you use this plugin for your research, please [cite us](https://github.com/stardist/stardist#how-to-cite).

![Screenshot](https://github.com/stardist/stardist-napari/raw/main/images/stardist_napari_screenshot_small.png)


## Installation

Install the plugin with `pip install stardist-napari` or from within napari via `Plugins > Install/Uninstall Plugins…`. If you want GPU-accelerated prediction, please read the more detailed [installation instructions](https://github.com/stardist/stardist#installation) for StarDist.

- You can activate the plugin in napari via `Plugins > stardist-napari: StarDist`.
- Example images for testing are provided via `File > Open Sample > stardist-napari`.


## Documentation

The two main buttons at the bottom of the plugin are (see right side of screenshot above):

**Restore Defaults**: Restore default values for [inputs](#inputs) (exceptions: *Input Image*, *Image Axes*, *Custom Model*).

**Run**: Start the prediction with the selected inputs and create the [outputs](#outputs) when done.

All plugin activity is shown in the napari *activity dock*, which can be shown/hidden by clicking on the word `activity` next to the little arrow at the bottom right of the napari window.

### Inputs

The plugin does perform input validation, i.e. it will disable the `Run` button if it detects a problem with the selected inputs. Problematic input fields are highlighted with a ""lightcoral"" background color ![](https://via.placeholder.com/15/f08080/f08080.png), and their [*tooltips*](https://en.wikipedia.org/wiki/Tooltip) typically explain what the problem is. Some error messages are shown at the bottom in napari's status bar, such as for incompatibilities between multiple input fields. Input fields with warnings (also explained via tooltips) are highlighted with an orange background color ![](https://via.placeholder.com/15/ffa500/ffa500.png).

**Input Image**: Select a napari layer of type `Image` as the input.  
*Tooltip:* Shows the shape of the image.

**Image Axes**: String that describes the semantic image axes and their order, e.g. `YX` for a 2D image. This parameter is automatically chosen (i.e. guessed) when a new input image is selected and should work in most cases. Permissible axis values are: `X` (width/columns), `Y` (height/rows), `Z` (depth/planes), `C` (channels), `T` (frames/time).  
*Tooltip:* Shows the mapping of semantic axes to the shape of the selected input image.

**Predict on field of view (only for 2D models in 2D view)**: If enabled, the StarDist prediction is only applied to the current field of view of the napari viewer. As the name of this checkbox indicates, this only works for 2D StarDist models and when the napari viewer is in 2D viewing mode. The checkbox is not even shown if those conditions are not met.

#### *Neural Network Prediction*

**Model Type**: Choice whether to use registered pre-trained models (`2D`, `3D`) or provide a path to a model folder (`Custom 2D/3D`). Based on this choice, either the input for *Pre-trained Model* or *Custom Model* is shown below.  
(Further information regarding pre-trained models: [how to register your own model](https://nbviewer.org/github/CSBDeep/CSBDeep/blob/master/examples/other/technical.ipynb#Registry-for-pretrained-models), [model registration in StarDist](https://github.com/stardist/stardist/blob/f73cdc44f718d36844b38c1f1662dbb66d157182/stardist/models/__init__.py#L17-L29).)

**Pre-trained Model**: Select a registered pre-trained model from a list. The first time a model is selected, it is downloaded and cached locally.

**Custom Model**: Provide a path to a StarDist model folder, containing at least `config.json` and a compatible neural network weights file (with suffix `.h5` or `.hdf5`). If present, `thresholds.json` is also loaded and its values can be used via the button *Set optimized postprocessing thresholds (for selected model)*.

**Model Axes**: A read-only text field that shows the semantic axes that the currently selected model expects as input. Additionally, we show the number of expected input channels, e.g. `YXC[2]` to indicate that the model expects a 2D input image with 2 channels. Seeing the model axes is helpful to understand whether the axes of the input image are compatible or not.

**Normalize Image**: A checkbox to indicate whether to perform [percentile-based input image normalization](https://forum.image.sc/t/normalization-in-stardist/41696/2) or not. This should be checked if the input image wasn't [manually normalized](https://forum.image.sc/t/stardist-extension/37696/7) such that most pixel values are in the range 0 to 1. If unchecked, inputs *Percentile low* and *Percentile high* are hidden.

**Percentile low**: Percentile value of input pixel distribution that is mapped to 0 (~min value). If there aren't any outlier pixels in your image, you may use percentile `0` to do a standard [min-max image normalization](https://www.codecademy.com/article/normalization).

**Percentile high**: Percentile value of input pixel distribution that is mapped to 1 (~max value). If there aren't any outlier pixels in your image, you may use percentile `100` to do a standard [min-max image normalization](https://www.codecademy.com/article/normalization).

**Input image scaling**: Number or list of numbers (one per input axis) to scale the input image before prediction and rescale the output accordingly. For example, a value of `0.5` indicates that all spatial axes are downscaled to half their size before prediction, and that the outputs are scaled to double their size. This is useful to adapt to different object sizes in the input image.  
*Tooltip:* Shows the mapping of scale values to the semantic axes of the selected input image.

#### *NMS Postprocessing*

**Probability/Score Threshold**: Determine the number of object candidates to enter non-maximum suppression. Higher values lead to fewer segmented objects, but will likely avoid false positives. The selected model may have an associated threshold value, which can be loaded via the *Set optimized postprocessing thresholds (for selected model)* button.

**Overlap Threshold**: Determine when two objects are considered the same during non-maximum suppression. Higher values allow segmented objects to overlap substantially. The selected model may have an associated threshold value, which can be loaded via the *Set optimized postprocessing thresholds (for selected model)* button.

**Output Type**: Choose format of [outputs](#outputs) (see below for details). Selecting `Label Image` will create the outputs *StarDist labels* and *StarDist class labels* (for multi-class models only) as napari `Labels` layers. Selecting `Polygons / Polyhedra` will instead return the output *StarDist polygons* as a napari `Shapes` layer for a 2D model, or *StarDist polyhedra* as a napari `Surface` layer for a 3D model. Selecting `Both` will return both types of outputs.

#### *Advanced Options*

**Number of Tiles**: String `None` (to disable tiling) or list of integer numbers (one per axis of input image) to determine how the input image is tiled before the CNN prediction is computed on each tile individually. This is needed to avoid (GPU) memory issues that can occur for large input images. Note that the NMS postprocessing is still run only once with candidates from the predictions of all image tiles.  
*Tooltip:* Shows the mapping of tile values to the semantic axes of the selected input image.

**Normalization Axes**: String of semantic axes which are jointly normalized (if they are present in the input image). For example, the default value `ZYX` indicates that all spatial axes are always normalized together; if an image has multiple channels, the pixels will be normalized separately per channel (e.g. this is what typically makes sense for fluorescence microscopy where channels are independent). On the other hand, the channels in RGB color images typically need to be normalized jointly, hence using `ZYXC` makes sense in this case. Note: if an image is explicitly opened with `rgb=True` in napari, the channels are automatically normalized together.  
*Tooltip:* Shows a brief explanation.

**Time-lapse Labels**: If the input is a time-lapse/movie, each frame is first independently processed by StarDist. If `Separate per frame (no processing)` is chosen, the object ids in the label images of each frame are not modified, i.e. they are consecutive integers that always start at 1. Selecting `Unique through time` will cause object ids to be unique over time, i.e. the smallest object id in a given frame is larger than the largest object id of the previous frame. Finally, choosing `Match to previous frame (via overlap)` will perform a simple form of [greedy](https://en.wikipedia.org/wiki/Greedy_algorithm) matching/tracking, where object ids are propagated from one frame to the next based on object overlap.

**Show CNN Output**: Create additional [outputs](#outputs) (see below for details) *StarDist probability* and *StarDist distances* that show the direct results of the CNN prediction which are the inputs to the NMS postprocessing. Additionally, *StarDist class probabilities* is created for multi-class models.

**Set optimized postprocessing thresholds (for selected model)**: Button to set *Probability/Score Threshold* and *Overlap Threshold* to the values provided by the selected model. Nothing is changed if the model does not provide threshold values.

### Outputs

**StarDist polygons**: The detected/segmented 2D objects as polygons (napari `Shapes` layer).

**StarDist polyhedra**: The detected/segmented 3D objects as surfaces (napari `Surface` layer).

**StarDist labels**: The detected/segmented 2D/3D objects as a *label image* (napari `Labels` layer). In an integer-valued label image, the value of a given pixel denotes the id of the object that it belongs to. For example, all pixels with value 5 belong to the object with id 5. All background pixels (that don't belong to any object) have value 0.

**StarDist class labels** ([multi-class models](https://nbviewer.org/github/stardist/stardist/blob/master/examples/other2D/multiclass.ipynb) only): The classes of detected/segmented 2D/3D objects as a *semantic segmentation labeling* (napari `Labels` layer). The integer value of a given pixel denotes the class id of the object that it belongs to. For example, all pixels with value 3 belong to the object class 3. Note that all pixels that belong to a specific object instance (as returned by *StarDist labels*) do have the same object class here. All background pixels (that don't belong to an object class) have value 0.

**StarDist probability**: The object probabilities predicted by the neural network as a single-channel image (napari `Image` layer).

**StarDist distances**: The radial distances predicted by the neural network as a multi-channel image (napari `Image` layer).

**StarDist class probabilities** ([multi-class models](https://nbviewer.org/github/stardist/stardist/blob/master/examples/other2D/multiclass.ipynb) only): The object class probabilities predicted by the neural network as a multi-channel image (napari `Image` layer).


## Troubleshooting & Support

- The [image.sc forum](https://forum.image.sc/tag/stardist) is the best place to start getting help and support. Make sure to use the tag `stardist`, since we are monitoring all questions with this tag.
- For general questions about StarDist, it's worth taking a look at the [frequently asked questions (FAQ)]( https://stardist.net/docs/faq.html).
- If you have technical questions or found a bug, feel free to [open an issue](https://github.com/stardist/stardist-napari/issues).


## Other resources

A demonstration of an earlier version of the plugin is shown in [this video](https://www.youtube.com/watch?v=Km1_TnUQ4FM&list=PLilvrWT8aLuZCaOkjucLjvDu2YRtCS-JT&index=5).

Many of the parameters are identical to those of our [StarDist ImageJ/Fiji plugin](https://github.com/stardist/stardist-imagej), which are documented [here](https://imagej.net/plugins/stardist#usage).
","['Development Status :: 4 - Beta', 'Intended Audience :: Science/Research', 'Topic :: Scientific/Engineering', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Framework :: napari']","['Source Code, https://github.com/stardist/stardist-napari', 'Documentation, https://github.com/stardist/stardist-napari', 'Bug Tracker, https://github.com/stardist/stardist-napari/issues', 'User Support, https://forum.image.sc/tag/stardist', 'Twitter, https://twitter.com/martweig']",,,stardist-napari.widget,stardist-napari.data.nuclei_2d,,,,https://pypi.org/project/stardist-napari,https://github.com/stardist/stardist-napari,
387,Surforama,0.0.9,,,surforama,Kyle Harrington,surforama@kyleharrington.com,MIT,,a tool for using surfaces to explore volumetric data in napari,>=3.8,"['magicgui', 'mrcfile', 'numpy', 'pooch', 'qtpy', 'pyacvd', 'pyvista', 'rich', 'scikit-image', 'starfile', 'trimesh', 'typer', ""napari ; extra == 'dev'"", ""pyqt5 ; extra == 'dev'"", ""pytest ; extra == 'dev'"", ""pytest-cov ; extra == 'dev'"", ""pytest-qt ; extra == 'dev'"", ""tox ; extra == 'dev'"", ""pre-commit ; extra == 'dev'"", ""napari[all] ; extra == 'napari'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""tox ; extra == 'testing'""]","# surforama
a napari-based tool for using surfaces to explore volumetric data in napari

inspired by [membranorama](https://github.com/dtegunov/membranorama)

![Screenshot of surforama showing a surface in the slice of a tomogram](surforama_screenshot.png)

## installation
`surforama` requires the napari viewer. If you would like to install napari and surforama together in one line, you can use the following command:

```bash
pip install ""surforama[napari]""
```


If you already have napari installed, you can directly install surforama in the same environment:

```bash
pip install surforama
```

## usage
### launch with demo data
If you'd like to test surforama out, you can launch surforama with demo data:

```bash
surforama --demo
```

### launch without data
You can launch surforama using the command line interface. After you have installed surforama, you can launch it with the following command in your terminal:

```bash
surforama
```
After surforama launches, you can load your image and mesh into napari and get surfing!

### launch with data
If you have an MRC-formatted tomogram and an obj-formatted mesh, you can launch using the following command:

```bash
surforama --image-path /path/to/image.mrc --mesh-path /path/to/mesh.obj
```

## developer installation

If you would like to make changes to the surforama source code, you can install surformama with the developer tools as follows:

```bash
cd /path/to/your/surforama/source/code/folder
pip install -e "".[dev]""
```
We use pre-commit to keep the code tidy. Install the pre-commit hooks to activate the checks:

```bash
pre-commit install
```
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: MIT License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/cellcanvas/surforama/issues', 'Documentation, https://github.com/cellcanvas/surforama#README.md', 'Source Code, https://github.com/cellcanvas/surforama', 'User Support, https://github.com/cellcanvas/surforama/issues']",surforama.mesh_reader,,surforama.make_widget,surforama.thylakoid,['*.obj'],,,https://pypi.org/project/surforama,,
388,napari Detect Spots,0.0.1,,,test-detect-spots,Kevin Lai,klai@chanzuckerberg.com,BSD-3-Clause,,A dummy plugin to learn how to create plugins,>=3.8,"['numpy', 'magicgui', 'qtpy', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# test-detect-spots

[![License BSD-3](https://img.shields.io/pypi/l/test-detect-spots.svg?color=green)](https://github.com/klai95/test-detect-spots/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/test-detect-spots.svg?color=green)](https://pypi.org/project/test-detect-spots)
[![Python Version](https://img.shields.io/pypi/pyversions/test-detect-spots.svg?color=green)](https://python.org)
[![tests](https://github.com/klai95/test-detect-spots/workflows/tests/badge.svg)](https://github.com/klai95/test-detect-spots/actions)
[![codecov](https://codecov.io/gh/klai95/test-detect-spots/branch/main/graph/badge.svg)](https://codecov.io/gh/klai95/test-detect-spots)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/test-detect-spots)](https://napari-hub.org/plugins/test-detect-spots)

A dummy plugin to learn how to create plugins

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `test-detect-spots` via [pip]:

    pip install test-detect-spots




## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""test-detect-spots"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']",,,,test-detect-spots.make_func_widget,,,,,https://pypi.org/project/test-detect-spots,,
389,the-segmentation-game,0.2.0,2022-06-16,2023-06-18,the-segmentation-game,"Robert Haase, Martin Schätz",robert.haase@tu-dresden.de,BSD-3-Clause,https://github.com/haesleinhuepf/the-segmentation-game,Gamified image segmentation quality estimation,>=3.7,"['napari-plugin-engine (>=0.1.4)', 'numpy', 'napari-tools-menu', 'napari-skimage-regionprops', 'scikit-learn']","# The segmentation game - for napari

[![License](https://img.shields.io/pypi/l/the-segmentation-game.svg?color=green)](https://github.com/haesleinhuepf/the-segmentation-game/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/the-segmentation-game.svg?color=green)](https://pypi.org/project/the-segmentation-game)
[![Python Version](https://img.shields.io/pypi/pyversions/the-segmentation-game.svg?color=green)](https://python.org)
[![tests](https://github.com/haesleinhuepf/the-segmentation-game/workflows/tests/badge.svg)](https://github.com/haesleinhuepf/the-segmentation-game/actions)
[![codecov](https://codecov.io/gh/haesleinhuepf/the-segmentation-game/branch/main/graph/badge.svg)](https://codecov.io/gh/haesleinhuepf/the-segmentation-game)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/the-segmentation-game)](https://napari-hub.org/plugins/the-segmentation-game)
[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.6588373.svg)](https://doi.org/10.5281/zenodo.6588373)

Gamified image segmentation quality estimation

![img.png](https://github.com/haesleinhuepf/the-segmentation-game/raw/main/images/screencast.gif)

----------------------------------

## Usage

The Segmentation Game allows to quantitatively compare segmentation results to a given ground truth annotation.
This allows fine-tuning parameters of image processing workflows to get optimal segmentation quality. 
It also allows comparing different segmentation algorithms and identify which algorithm performs best objectively.

The game can be found in napari's `Tools > Games > The Segmentation Game` menu.

### Ground Truth Annotation

Before you can start playing the game, some annotated cells/nuclei are necessary to later compute segmentation quality from.
Depending on the used metric, it might be sufficient to annotate a hand full of objects. 
Use napari's annotation tools as shown below. 
Use the `+` and `-` keys on your keyboard to increase and decrease the label number that is currently drawn.
Note: Avoid label gaps. The labels must be continuously subsequent. If there are pixels annotated with value 2, there must be pixels annotated with value 1.

![](https://github.com/haesleinhuepf/the-segmentation-game/raw/main/images/annotation.gif)

### Parameter tuning

If you work with one of [napari's segmentation plugins](https://www.napari-hub.org/?search=segmentation&sort=relevance&page=1) that produce labels layers,
you can tune their parameters and see how this influences segmentation quality.

![](https://github.com/haesleinhuepf/the-segmentation-game/raw/main/images/parameter_tuning.gif)

### Segmentation algorithm comparison

If you aim at comparing different segmentation algorithms, you can collect their results in label layers in the napari viewer.
You can then select the segmentation result from the corresponding pulldown and save quantitative comparison results in the Highscore table.

![](https://github.com/haesleinhuepf/the-segmentation-game/raw/main/images/algorithm_comparison.gif)

## Metrics

Currently, these metrics are implemented:
* Jaccard Index (sparse): The [Jaccard Index](https://en.wikipedia.org/wiki/Jaccard_index) is a measure of overlap. 
  It lies between 0 (no overlap) and 1 (perfect overlap). 
  For each annotated ground truth label, the maximum overlap of any segmented label is determined. 
  The mean overlap of all annotated labels serves as metric result.
* Jaccard Index (binary): The annotated ground truth labels and the segmentation result are first binarized considering all annotated pixels as positive and all other labels as negative.
  Afterwards, the overlap between the two binary images is computed. This allows comparing binary segmentation algorithms, such as thresholding techniques.
* Jaccard Index (binary, sparse): The annotated ground truth image can contain values 1 (negative, false) and 2 (positive, true) and
  the segmentation result image will be binarized (0: False, otherwise: True). This allows comparing object/no-object annotations with label images.
 
 
Receiver operating characteristic ([ROC](https://en.wikipedia.org/wiki/Receiver_operating_characteristic))
  
Consider a two-class thresholding problem (binary pixel-wise classification object/background), in which the outcomes are labeled either as positive (p) or negative (n). There are four possible outcomes from a binary classifier. If the outcome from a prediction is p and the actual value is also p, then it is called a true positive (TP); however if the actual value is n then it is said to be a false positive (FP). Conversely, a true negative (TN) has occurred when both the prediction outcome and the actual value are n, and false negative (FN) is when the prediction outcome is n while the actual value is p. We can organize result in table called confusion matrix, based on positive/neagtive results in row and true and false result in columns. From the confucsion matrix we can get many metrics with various usefulness. The curently implemented used for classification evaluation are:

* Sensitivity, recall, hit rate, or true positive rate (TPR): (TP)/ (TP + FP), Sensitivity and specificity mathematically describe the accuracy of a test which reports the presence or absence of a condition. Individuals for which the condition is satisfied are considered ""positive"" and those for which it is not are considered ""negative"".
* Specificity, selectivity or true negative rate (TNR): (TN)/ (TN + FN), Sensitivity and specificity mathematically describe the accuracy of a test which reports the presence or absence of a condition. Individuals for which the condition is satisfied are considered ""positive"" and those for which it is not are considered ""negative"".
* Precision or positive predictive value (PPV): (TP)/ (TP + FP), in computing and information science is the process of obtaining information system resources that are relevant to an information need from a collection of those resources. It is quantification for the TP events.
* Accuracy: (TP + TN)/ (TP + FP + TN + FN), Accuracy measures observational error. Accuracy is how close or far off a given set of measurements are to their true value. However, it usually fails in imbalanced sets.
* Balanced Accuracy: (TP/(TP+FN) + TN/(TN+FP))/2, Balanced Accuracy is trying to even out problems of accuracy in imbalanced sets.
* F1 Score: 2*TP/(2*TP + FP + TN + FN), In statistical analysis of binary classification, the F-score or F-measure is a measure of a test's accuracy. It is calculated from the precision and recall of the test, where the precision is the number of true positive results divided by the number of all positive results, including those not identified.
* Threat score (TS) or critical success index (CSI): TP/(TP + FP + FN), TC is another name for Jaccard Index (binary).

The ROC measures or confusion matrix is invaluable in cases when when our binary classifier is not ideal (which is often) and we are aiming to not get a general good result but specified low error. In that case we usually need to decide for some trade off, for example we need all (as many as possible) classified true positive objects, but we do not mind getting (usually as few as possible) false positive objects.

**What we want to achieve**

![Precision-versus-accuracy, source: 10.13140/RG.2.1.1668.7603](https://github.com/martinschatz-cz/the-segmentation-game/blob/main/images/Precision-versus-accuracy.png)

When we are doing semantic segmentation, we are aiming to classify each pixel (ideally correctly) to each of our classes. But that can be hugr ammount of information, and our object might have significantly much less pixels then number of pixels belonging to background and/or other classes. Before choosing right metrics, we need to set up goal for our classification results. Idealy, we would like to have high accuracy and precission for ach class (as is on pictur above), but we might be happy getting high accuracy with good precision. Realisticaly we might need to be more specific, as to choose how big error we are prepared to accept, or decide if it is acceptable to have FN findings but no FP.

Picking up a metric for highly unbalanced classification as in semantic segmentation is challenging. Most of the classic metrics wil fail (but they are stil usable object-wise). And we usually stick up with Jaccard Index/Threat score, F1 Score or anything that will tell us result for TP rate (as we expect we will have less pixels for objects then background and/or other classes).

## Literature recommendation

How to choose the right metric for comparing segmentation results is explained in this paper:
* [Metrics reloaded: Pitfalls and recommendations for image analysis validation. Maier-Hein L. and Reinke A. et al.](https://arxiv.org/abs/2206.01653)

## Related plugins

If you aim at automatically optimizing segmentation quality, there are also napari plugins available with this capability:

* [napari-accelerated-pixel-and-object-classification](https://www.napari-hub.org/plugins/napari-accelerated-pixel-and-object-classification)
* [napari-workflow-optimizer](https://www.napari-hub.org/plugins/napari-workflow-optimizer)

## Installation

You can install `the-segmentation-game` via [pip]:

    pip install the-segmentation-game

## Contributing

Contributions - especially new image segmentation quality metrics - are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""the-segmentation-game"" is free and open source software

## Issues

If you encounter any problems, please open a thread on [image.sc](https://image.sc) along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/haesleinhuepf/the-segmentation-game/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Scientific/Engineering :: Image Processing', 'Topic :: Scientific/Engineering :: Information Analysis', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/haesleinhuepf/the-segmentation-game/issues', 'Documentation, https://github.com/haesleinhuepf/the-segmentation-game#README.md', 'Source Code, https://github.com/haesleinhuepf/the-segmentation-game', 'User Support, https://github.com/haesleinhuepf/the-segmentation-game/issues']",,,the-segmentation-game.TheSegmentationGameWidget,,,,,https://pypi.org/project/the-segmentation-game,https://github.com/haesleinhuepf/the-segmentation-game,
390,Tootapari,0.0.1,2023-08-02,2023-08-02,tootapari,Kyle Harrington,czi@kyleharrington.com,BSD-3-Clause,https://github.com/kephale/tootapari,A plugin to send Mastodon toots from napari,>=3.8,"['numpy', 'python-dotenv', 'Mastodon.py', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'""]","# tootapari

[![License BSD-3](https://img.shields.io/pypi/l/tootapari.svg?color=green)](https://github.com/kephale/tootapari/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/tootapari.svg?color=green)](https://pypi.org/project/tootapari)
[![Python Version](https://img.shields.io/pypi/pyversions/tootapari.svg?color=green)](https://python.org)
[![tests](https://github.com/kephale/tootapari/workflows/tests/badge.svg)](https://github.com/kephale/tootapari/actions)
[![codecov](https://codecov.io/gh/kephale/tootapari/branch/main/graph/badge.svg)](https://codecov.io/gh/kephale/tootapari)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/tootapari)](https://napari-hub.org/plugins/tootapari)

A plugin to send Mastodon toots from napari

----------------------------------

## Installation

You can install `tootapari` via [pip]:

    pip install tootapari



To install latest development version :

    pip install git+https://github.com/kephale/tootapari.git


## Setup

1. Setup your `.env` file in your XDG config directory. On MacOS this is `/Users/<username>/Library/Application\ Support/tootapari/`

It should include:

```
MASTODON_INSTANCE_URL=""https://mastodon.social""
MASTODON_ACCESS_TOKEN=""<your access token>""
```

2. You can generate your access token by following these instructions: https://learn.adafruit.com/intro-to-mastodon-api-circuitpython/generate-your-mastodon-token

TODO: someone should port these instructions to this readme.

3. Start tooting!

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""tootapari"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/kephale/tootapari/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/kephale/tootapari/issues', 'Documentation, https://github.com/kephale/tootapari#README.md', 'Source Code, https://github.com/kephale/tootapari', 'User Support, https://github.com/kephale/tootapari/issues']",,,tootapari.make_qwidget,,,,,https://pypi.org/project/tootapari,https://github.com/kephale/tootapari,
391,Tracking Challenge Solver,0.0.8,,,tracking-challenge-demo,Draga Doncila,ddoncila@gmail.com,BSD-3-Clause,,"A demo plugin to load, segment and save tracking challenge data.",>=3.8,"['dask[array]', 'imagecodecs', 'napari', 'napari-plugin-engine >=0.1.4', 'numpy', 'scikit-image', 'tifffile', ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""tox ; extra == 'testing'""]","# tracking-challenge-demo

[![License](https://img.shields.io/pypi/l/tracking-challenge-demo.svg?color=green)](https://github.com/DragaDoncila/tracking-challenge-demo/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/tracking-challenge-demo.svg?color=green)](https://pypi.org/project/tracking-challenge-demo)
[![Python Version](https://img.shields.io/pypi/pyversions/tracking-challenge-demo.svg?color=green)](https://python.org)
[![tests](https://github.com/DragaDoncila/tracking-challenge-demo/workflows/tests/badge.svg)](https://github.com/DragaDoncila/tracking-challenge-demo/actions)
[![codecov](https://codecov.io/gh/DragaDoncila/tracking-challenge-demo/branch/main/graph/badge.svg)](https://codecov.io/gh/DragaDoncila/tracking-challenge-demo)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/tracking-challenge-demo)](https://napari-hub.org/plugins/tracking-challenge-demo)

A demo plugin to load, segment and save tracking challenge data.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/index.html
-->

## Installation

You can install `tracking-challenge-demo` via [pip]:

    pip install tracking-challenge-demo



To install latest development version :

    pip install git+https://github.com/DragaDoncila/tracking-challenge-demo.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""tracking-challenge-demo"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/DragaDoncila/tracking-challenge-demo/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Software Development :: Testing']","['Bug Tracker, https://github.com/DragaDoncila/tracking-challenge-demo/issues', 'Documentation, https://github.com/DragaDoncila/tracking-challenge-demo#README.md', 'Source Code, https://github.com/DragaDoncila/tracking-challenge-demo', 'User Support, https://github.com/DragaDoncila/tracking-challenge-demo/issues']",tracking-challenge-demo.get_reader,tracking-challenge-demo.write_single_image,tracking-challenge-demo.make_qwidget,,,['.zip'],,https://pypi.org/project/tracking-challenge-demo,,
392,Tracktour,0.0.3rc1,,,tracktour,Draga Doncila Pop,Draga Doncila Pop <ddoncila@gmail.com>,BSD 3-Clause,,Network flow based tracker with guided error correction,>=3.8,"['gurobipy', 'imagecodecs', 'networkx', 'numpy', 'pandas', 'pydantic', 'scikit-image', 'scipy', 'tifffile', 'tqdm', 'typer', ""pre-commit; extra == 'dev'"", ""arboretum; extra == 'napari'"", ""napari; extra == 'napari'"", ""napari-graph; extra == 'napari'"", ""pytest>=6.0; extra == 'test'""]","# tracktour

[![License](https://img.shields.io/pypi/l/tracktour.svg?color=green)](https://github.com/DragaDoncila/tracktour/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/tracktour.svg?color=green)](https://pypi.org/project/tracktour)
[![Python Version](https://img.shields.io/pypi/pyversions/tracktour.svg?color=green)](https://python.org)
[![CI](https://github.com/DragaDoncila/tracktour/actions/workflows/ci.yml/badge.svg)](https://github.com/DragaDoncila/tracktour/actions/workflows/ci.yml)

tracktour is a simple object tracker based on a network flow linear model. tracktour takes a dataframe of detected objects and solves a linear program
(currently using Gurobi, but we will soon add an open source solver interface) to produce tracking results.

tracktour is rapidly changing and its API will change without deprecation warnings.

## Usage

The `Tracker` object is the interface for producing tracking solutions. Below is a toy example with explicitly defined detections.

```python
coords = [
    (0, 50.0, 50.0),
    (0, 40, 50),
    (0, 30, 57),
    (1, 50, 52),
    (1, 38, 51),
    (1, 29, 60),
    (2, 52, 53),
    (2, 37, 53),
    (2, 28, 64),
]
coords = pd.DataFrame(coords, columns=[""t"", ""y"", ""x""])

# initialize Tracker object
tracker = Tracker(
    im_shape=(100, 100),    # size of the image detections come from. Affects cost of detections appearing/disappearing
    k_neighbours=2          # number of neighbours to consider for assignment in the next frame (default=10)
)
# solve
tracked = tracker.solve(coords)
```

The `Tracked` object contains a copy of the detections, potentially reindexed, and a dataframe of edges that make up the solution.
Columns `u` and `v` in `tracked_edges` are direct indices into `tracked_detections`.

```python
print(tracked.tracked_detections)
print(tracked.tracked_edges)
```

You may want to convert the solution into a networkx graph for easier manipulation.

```python
solution_graph = tracked.as_nx_digraph()
```

### Extracting Detections

If you're starting from an image segmentation, you can use the `get_im_centers` or `extract_im_centers` functions.

If your segmentation is already loaded into a numpy array, use `extract_im_centers`. The returned `detections` DataFrame is ready for use with the `Tracker`.

```python
detections, min_t, max_t, corners = extract_im_centers(segmentation)
```

If your segmentation is in Cell Tracking Challenge format and lives in single tiffs per frame in a directory, use `get_im_centers`. This will also return
the segmentation as a numpy array.

```python
seg, detections, min_t, max_t, corners = get_im_centers('path/to/01_RES/')
```

### CLI Tool - Cell Tracking Challenge

If you're working with Cell Tracking Challenge formatted datasets, you can use the CLI to extract detections, run tracktour, and save output in CTC format.

```sh
$ tracktour ctc /path/to/seg/ /path/to/save/ -k 8
```

## Support

Please feel free to open issues with feature requests, bug reports, questions on usage, etc.
","['Framework :: napari', 'Intended Audience :: Science/Research', 'License :: OSI Approved :: GNU General Public License v3 (GPLv3)', 'Operating System :: OS Independent', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering', 'Topic :: Scientific/Engineering :: Bio-Informatics', 'Topic :: Scientific/Engineering :: Image Processing', 'Topic :: Scientific/Engineering :: Information Analysis', 'Topic :: Scientific/Engineering :: Visualization']","['homepage, https://github.com/DragaDoncila/tracktour', 'repository, https://github.com/DragaDoncila/tracktour']",,,tracktour.merge_explorer,,,,,https://pypi.org/project/tracktour,,
393,vessel-express-napari,0.0.9,2022-08-19,2023-07-26,vessel-express-napari,Lennart Kowitz,lennart.kowitz@isas.de,BSD-3-Clause,https://github.com/MMV-Lab/vessel-express-napari,A simple plugin for 3D vessel segmentation,>=3.7,"['napari-plugin-engine (>=0.1.4)', 'numpy', 'itk', 'scikit-image', 'aicssegmentation']","# vessel-express-napari

[![License](https://img.shields.io/pypi/l/vessel-express-napari.svg?color=green)](https://github.com/MMV-Lab/vessel-express-napari/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/vessel-express-napari.svg?color=green)](https://pypi.org/project/vessel-express-napari/)
[![Python Version](https://img.shields.io/pypi/pyversions/vessel-express-napari.svg?color=green)](https://python.org)
[![tests](https://github.com/MMV-Lab/vessel-express-napari/workflows/tests/badge.svg)](https://github.com/MMV-Lab/vessel-express-napari/actions)
[![codecov](https://codecov.io/gh/MMV-Lab/vessel-express-napari/branch/main/graph/badge.svg?token=mJPpDiioxu)](https://codecov.io/gh/MMV-Lab/vessel-express-napari)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/vessel-express-napari)](https://www.napari-hub.org/plugins/vessel-express-napari)

A simple plugin for 3D vessel segmentation of LSFM images

This [napari] plugin can be used to optimize the segmentation parameters for the [main VesselExpress software platform](https://github.com/RUB-Bioinf/VesselExpress).

----------------------------------


## Installation

The easiest way to install the plugin is to open napari, go to Plugins, then Install/Uninstall plugins. You will be able to find the plugin by name ""vessel-express-napari"". 

Or, you can install `vessel-express-napari` via [pip]:

    pip install vessel-express-napari


To install latest development version :

    pip install git+https://github.com/MMV-Lab/vessel-express-napari.git


## Documentation

We provide a [quick start guide] to explain the important pieces of this plugin. Suggestions and feature quests are very welcomed. 


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""vessel-express-napari"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/MMV-Lab/vessel-express-napari/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
[quick start guide]: https://github.com/MMV-Lab/vessel-express-napari/blob/main/quick_start.md

","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/MMV-Lab/vessel-express-napari/issues', 'Documentation, https://github.com/MMV-Lab/vessel-express-napari#README.md', 'Source Code, https://github.com/MMV-Lab/vessel-express-napari', 'User Support, https://github.com/MMV-Lab/vessel-express-napari/issues']",vessel-express-napari.napari_get_reader,,vessel-express-napari.ParameterTuning,,['*'],,,https://pypi.org/project/vessel-express-napari,https://github.com/MMV-Lab/vessel-express-napari,
394,vollseg-napari,2.4.7,2022-08-18,2023-06-18,vollseg-napari,Varun Kapoor,varun.kapoor@kapoorlabs.org,BSD 3-Clause,https://github.com/kapoorlab/vollseg-napari,Irregular cell shape segmentation using VollSeg,>=3.7,"['vollseg', 'napari >=0.4.13', 'magicgui >=0.4.0', 'pyqt6', 'pynvml', 'tensorflow ; platform_system != ""Darwin"" or platform_machine != ""arm64""', 'tensorflow-macos ; platform_system == ""Darwin"" and platform_machine == ""arm64""', ""pytest ; extra == 'test'"", ""pytest-qt ; extra == 'test'"", ""napari[pyqt] >=0.4.13 ; extra == 'test'""]","# VollSeg Napari Plugin



[![PyPI version](https://img.shields.io/pypi/v/vollseg-napari.svg)](https://pypi.org/project/vollseg-napari)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/vollseg-napari)](https://napari-hub.org/plugins/vollseg-napari)
[![License](https://img.shields.io/pypi/l/napari-metroid.svg?color=green)](https://github.com/kapoorlab/napari-vollseg/raw/main/LICENSE)
[![codecov](https://codecov.io/gh/kapoorlab/napari-vollseg/branch/main/graph/badge.svg)](https://codecov.io/gh/kapoorlab/napari-vollseg)
[![Twitter Badge](https://badgen.net/badge/icon/twitter?icon=twitter&label)](https://twitter.com/entracod)


VollSeg is more than just a single segmentation algorithm; it is a meticulously designed modular segmentation tool tailored to diverse model organisms and imaging methods. While a U-Net might suffice for certain image samples, others might benefit from utilizing StarDist, and some could require a blend of both, potentially coupled with denoising or region of interest models. The pivotal decision left to make is how to select the most appropriate VollSeg configuration for your dataset, a question we comprehensively address in our [documentation website](https://kapoorlabs-caped.github.io/vollseg-napari/).

This project provides the [napari](https://napari.org/) plugin for [VollSeg](https://github.com/kapoorlab/vollseg), a deep learning based 2D and 3D segmentation tool for irregular shaped cells. VollSeg has originally been developed (see [papers](http://conference.scipy.org/proceedings/scipy2021/varun_kapoor.html)) for the segmentation of densely packed membrane labelled cells in challenging images with low signal-to-noise ratios. The plugin allows to apply pretrained and custom trained models from within napari.
For detailed demo of the plugin see these [videos](https://www.youtube.com/watch?v=W_gKrLWKNpQ) and a short video about the [parameter selection](https://www.youtube.com/watch?v=7tQMn_u8_7s&t=1s) 


## Installation & Usage

Install the plugin with `pip install vollseg-napari` or from within napari via `Plugins > Install/Uninstall Package(s)…`. 

You can activate the plugin in napari via `Plugins > VollSeg: VollSeg`. Example images for testing are provided via `File > Open Sample > VollSeg`.

If you use this plugin for your research, please [cite us](http://conference.scipy.org/proceedings/scipy2021/varun_kapoor.html).


## Examples

VollSeg comes with different options to combine CARE based denoising with UNET, StarDist and segmentation in a region of interest (ROI). We present some examples which are represent optimal combination of these different modes for segmenting different cell types. We summarize this in the table below:

| Example Image | Description | Training Data | Trained Model | GT image | Optimal combination | Notebook Code | Model Prediction | Metrics |
| --- | --- | --- | --- | --- | --- | --- | --- | --- |
| ![Raw Ascadian Embryo](images/Ascadian_raw.png) | Light sheet fused from four angles 3D single channel | [Training Data ~320 GB](https://figshare.com/articles/dataset/Astec-half-Pm1_Cut_at_2-cell_stage_half_Phallusia_mammillata_embryo_live_SPIM_imaging_stages_6-16_/11309570?backTo=/s/765d4361d1b073beedd5) | [UNET model](https://zenodo.org/record/6337699) | ![GT Ascadian Embryo](images/Ascadian_GT.png) | UNET model, slice_merge = False | [Colab Notebook](https://github.com/kapoorlab/VollSeg/blob/main/examples/Predict/Colab_VollSeg_Ascadian_Embryo.ipynb) | ![Prediction Ascadian Embryo](images/Ascadian_pred.png) | ![Metrics Ascadian Embryo](images/Metrics_Ascadian.png) |
| ![Raw Carcinoma](images/Carcinoma_raw.png) | Confocal microscopy 3D single channel 8 bit | [Training Data](https://zenodo.org/record/5904082#.Yi8-BnrMJD8) | [Denoising Model](https://zenodo.org/record/5910645/) and [StarDist Model](https://zenodo.org/record/6354077/) | ![GT Carcinoma](images/Carcinoma_GT.png) | StarDist model + Denoising Model, dounet = False | [Colab Notebook](https://github.com/kapoorlab/VollSeg/blob/main/examples/Predict/Colab_VollSeg_Mamary_gland.ipynb) | ![Prediction Carcinoma Cells](images/Carcinoma_pred.png) | ![Metrics Carcinoma Cells](images/Metrics_carcinoma.png) |
| ![Raw Xenopus Tissue](images/Xenopus_tissue_raw.png) | LaserScanningConfocalMicroscopy 2D single channel | [Dataset](https://zenodo.org/record/6076614#.YjBaNnrMJD8) | [UNET Model](https://zenodo.org/record/6060378/) | ![GT Xenopus Tissue](images/Xenopus_tissue_GT.png) | UNET model | [Colab Notebook](https://github.com/kapoorlab/VollSeg/blob/main/examples/Predict/Colab_VollSeg_tissue_segmentation.ipynb) | ![Prediction Xenopus Tissue](images/Xenopus_tissue_pred.png) | No Metrics |
| ![Raw Microtubule Kymograph](images/microtubule_kymo_raw.png) | TIRF + MultiKymograph Fiji tool 2D single channel | [Training Dataset](https://zenodo.org/record/6355705/files/Microtubule_edgedetector_training.zip) | [UNET Model](https://zenodo.org/record/6355705/) | ![GT Microtubule Kymograph](images/microtubule_kymo_GT.png) | UNET model | [Colab Notebook](https://github.com/kapoorlab/VollSeg/blob/main/examples/Predict/Colab_Microtubule_kymo_segmentation.ipynb) | ![Prediction Microtubule Kymograph](images/microtubule_kymo_pred.png) | No Metrics |
| ![Raw Lung Xray](images/lung_xray_raw.png) | XRay of Lung 2D single channel | [Training Dataset](https://www.kaggle.com/nikhilpandey360/lung-segmentation-from-chest-x-ray-dataset) | [UNET Model](https://zenodo.org/record/6060177/) | ![GT Lung Xray](images/lung_xray_GT.png) | UNET model | [Colab Notebook](https://github.com/kapoorlab/VollSeg/blob/main/examples/Predict/Colab_Microtubule_kymo_segmentation.ipynb) | ![Prediction Lung Xray](images/lung_xray_pred.png) | ![Metrics Lung Xray](images/Metrics_lung_xray.png) |
| ![Raw Nuclei Mask](images/nuclei_mask_raw.png) | LaserScanningConfocalMicroscopy 2D single channel | [Test Dataset](https://zenodo.org/record/6359349/) | Private | ![GT Nuclei Mask](images/nuclei_mask_GT.png) | UNET model | [Colab Notebook](https://github.com/kapoorlab/VollSeg/blob/main/examples/Predict/Colab_Microtubule_kymo_segmentation.ipynb) | ![Prediction Nuclei Mask](images/nuclei_mask_pred.png) | No Metrics |
| ![Raw Nuclei](images/nuclei_raw.png) | LaserScanningConfocalMicroscopy 3D single channel | [Test Dataset](https://zenodo.org/record/6359295/) | Private | ![GT Nuclei](images/nuclei_GT.png) | UNET model + StarDist model + ROI model | [Colab Notebook](https://github.com/kapoorlab/VollSeg/blob/main/examples/Predict/Colab_VollSeg_star_roi.ipynb) | ![Prediction Nuclei](images/nuclei_pred.png) | ![Metrics Nuclei](images/Metrics_nuclei.png) |


## Troubleshooting & Support

- The [image.sc forum](https://forum.image.sc/tag/vollseg) is the best place to start getting help and support. Make sure to use the tag `vollseg`, since we are monitoring all questions with this tag.
- If you have technical questions or found a bug, feel free to [open an issue](https://github.com/kapoorlab/vollseg-napari/issues).

","['Development Status :: 4 - Beta', 'Intended Audience :: Science/Research', 'Topic :: Scientific/Engineering', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Framework :: napari']","['Source Code, https://github.com/kapoorlab/vollseg-napari', 'Documentation, https://github.com/kapoorlab/vollseg-napari', 'Bug Tracker, https://github.com/kapoorlab/vollseg-napari/issues', 'User Support, https://forum.image.sc/tag/vollseg-napari', 'Twitter, https://twitter.com/entracod']",,,vollseg-napari.widget,vollseg-napari.test_image_ascadian_3d,,,,https://pypi.org/project/vollseg-napari,https://github.com/kapoorlab/vollseg-napari,
395,VollSeg Napari MTrack Plugin,1.4.7,2023-04-11,2023-06-18,vollseg-napari-mtrack,Varun Kapoor,randomaccessiblekapoor@gmail.com,BSD-3-Clause,https://github.com/Kapoorlabs-CAPED/vollseg-napari-mtrack,"Segment kymographs of microtubules, actin filaments and perform Ransac based fits to compute dynamic instability parameters for individual kymographs and also in batch",>=3.8,"['numpy', 'magicgui', 'qtpy', 'caped-ai', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# vollseg-napari-mtrack

[![License BSD-3](https://img.shields.io/pypi/l/vollseg-napari-mtrack.svg?color=green)](https://github.com/Kapoorlabs-CAPED/vollseg-napari-mtrack/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/vollseg-napari-mtrack.svg?color=green)](https://pypi.org/project/vollseg-napari-mtrack)
[![Python Version](https://img.shields.io/pypi/pyversions/vollseg-napari-mtrack.svg?color=green)](https://python.org)
[![tests](https://github.com/Kapoorlabs-CAPED/vollseg-napari-mtrack/workflows/tests/badge.svg)](https://github.com/Kapoorlabs-CAPED/vollseg-napari-mtrack/actions)
[![codecov](https://codecov.io/gh/Kapoorlabs-CAPED/vollseg-napari-mtrack/branch/main/graph/badge.svg)](https://codecov.io/gh/Kapoorlabs-CAPED/vollseg-napari-mtrack)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/vollseg-napari-mtrack)](https://napari-hub.org/plugins/vollseg-napari-mtrack)

Segment kymographs of microtubules, actin filaments and perform Ransac based fits to compute dynamic instability parameters for individual kymographs and also in batch

----------------------------------

Elaborate documentation for users of this repository at this [documentation]

This [napari] plugin was generated with [Cookiecutter] using [@caped]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `vollseg-napari-mtrack` via [pip]:

    pip install vollseg-napari-mtrack



To install latest development version :

    pip install git+https://github.com/Kapoorlabs-CAPED/vollseg-napari-mtrack.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""vollseg-napari-mtrack"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[@caped]: https://github.com/Kapoorlabs-CAPED/
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/Kapoorlabs-CAPED/cookiecutter-kapoorlabs-napari-plugin
[documentation]: https://kapoorlabs-caped.github.io/vollseg-napari-mtrack
[file an issue]: https://github.com/Kapoorlabs-CAPED/vollseg-napari-mtrack/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/Kapoorlabs-CAPED/vollseg-napari-mtrack/issues', 'Documentation, https://github.com/Kapoorlabs-CAPED/vollseg-napari-mtrack#README.md', 'Source Code, https://github.com/Kapoorlabs-CAPED/vollseg-napari-mtrack', 'User Support, https://github.com/Kapoorlabs-CAPED/vollseg-napari-mtrack/issues']",vollseg-napari-mtrack.get_reader,,vollseg-napari-mtrack.widget,vollseg-napari-mtrack.get_microtubule_test_data,,,,https://pypi.org/project/vollseg-napari-mtrack,https://github.com/Kapoorlabs-CAPED/vollseg-napari-mtrack,
396,vollseg-napari-trackmate,2.5.9,,,vollseg-napari-trackmate,"Varun Kapoor, Mari Tolonen, Jakub Sedzinski",randomaccessiblekapoor@gmail.com,BSD-3-Clause,,Track analysis using TrackMate xml and csv generated tracks using NapaTrackMater as the base library,>=3.8,"['napari-plugin-engine >=0.1.4', 'caped-ai', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# vollseg-napari-trackmate

[![License BSD-3](https://img.shields.io/pypi/l/vollseg-napari-trackmate.svg?color=green)](https://github.com/Kapoorlabs-CAPED/vollseg-napari-trackmate/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/vollseg-napari-trackmate.svg?color=green)](https://pypi.org/project/vollseg-napari-trackmate)
[![Python Version](https://img.shields.io/pypi/pyversions/vollseg-napari-trackmate.svg?color=green)](https://python.org)
[![tests](https://github.com/Kapoorlabs-CAPED/vollseg-napari-trackmate/workflows/tests/badge.svg)](https://github.com/Kapoorlabs-CAPED/vollseg-napari-trackmate/actions)
[![codecov](https://codecov.io/gh/Kapoorlabs-CAPED/vollseg-napari-trackmate/branch/main/graph/badge.svg)](https://codecov.io/gh/Kapoorlabs-CAPED/vollseg-napari-trackmate)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/vollseg-napari-trackmate)](https://napari-hub.org/plugins/vollseg-napari-trackmate)

Track analysis using TrackMate xml and csv generated tracks using NapaTrackMater as the base library

----------------------------------

Elaborate documentation for users of this repository at this [documentation]

## Tutorial

- A detailed tutorial can be found at [Demo](https://youtu.be/7Yjd-Z3zJtk?si=_AksSBUJuEXbvIFM)

This [napari] plugin was generated with [Cookiecutter] using [@caped]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `vollseg-napari-trackmate` via [pip]:

    pip install vollseg-napari-trackmate



To install latest development version :

    pip install git+https://github.com/Kapoorlabs-CAPED/vollseg-napari-trackmate.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""vollseg-napari-trackmate"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[@caped]: https://github.com/Kapoorlabs-CAPED/
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/Kapoorlabs-CAPED/cookiecutter-kapoorlabs-napari-plugin
[documentation]: https://kapoorlabs-caped.github.io/vollseg-napari-trackmate
[file an issue]: https://github.com/Kapoorlabs-CAPED/vollseg-napari-mtrack/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/Kapoorlabs-CAPED/vollseg-napari-trackmate/issues', 'Documentation, https://github.com/Kapoorlabs-CAPED/vollseg-napari-trackmate#README.md', 'Source Code, https://github.com/Kapoorlabs-CAPED/vollseg-napari-trackmate', 'User Support, https://github.com/Kapoorlabs-CAPED/vollseg-napari-trackmate/issues']",,,vollseg-napari-trackmate.widget,vollseg-napari-trackmate.get_test_tracks_xenopus,,,,https://pypi.org/project/vollseg-napari-trackmate,,
397,waver,0.0.4,2021-09-21,2023-06-16,waver,Nicholas Sofroniew,sofroniewn@gmail.com,BSD-3,https://github.com/sofroniewn/waver,Wave simulations,>=3.7,"['magicgui (>=0.2.10)', 'napari (>=0.4.10)', 'napari-plugin-engine (>=0.1.4)', 'numpy', 'zarr']","# waver

[![License](https://img.shields.io/pypi/l/waver.svg?color=green)](https://github.com/sofroniewn/waver/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/waver.svg?color=green)](https://pypi.org/project/waver)
[![Python Version](https://img.shields.io/pypi/pyversions/waver.svg?color=green)](https://python.org)
[![tests](https://github.com/sofroniewn/waver/workflows/tests/badge.svg)](https://github.com/sofroniewn/waver/actions)
[![codecov](https://codecov.io/gh/sofroniewn/waver/branch/main/graph/badge.svg?token=QBP7K6YUT7)](https://codecov.io/gh/sofroniewn/waver)

Run simulations of the [wave equation](https://en.wikipedia.org/wiki/Wave_equation) in nD on grids of variable speed in Python. This library owes a lot of its design and approach to the [fdtd](https://github.com/flaport/fdtd) library, a Python 3D electromagnetic FDTD simulator.

This package allows for a fair amount of customization over your wave simulation. You can
 - specify the size and spacing of the grid
 - specify the time step for the simulation, which will be checked to ensure stability of the simulation
 - specify the duration of the simulation
 - setting a variable speed array (one value per grid point) to allow for ""objects"" in your environment
 - set the source of the wave, which can be a point, line, or any (n-1)D subarray
 - record the wave with a detector, which can be the full grid, the full boundary, or a particular boundary
 - use convenience methods to run many simulations with different sources on the same grid and detector combination

You can use [napari](https://napari.org/), a multi-dimensional image viewer for Python, to allow for easy visualization of the detected wave. Some functionality is also available as a napari plugin to allow for running simulations from a graphical user interface.

Results can look like

https://user-images.githubusercontent.com/6531703/128283012-a784ec06-4df9-4ddf-bf4f-e21b927fe4a3.mov

----------------------------------

## Installation

You can install `waver` via [pip]:

    pip install waver

## Usage

### Convenience Methods

The most convenient way to use waver is to use one of two convenience methods that will create and run a simulation
for you and return the results.

The first method `run_single_source` allows you to run a single simulation with a single source on one grid and 
record the results using a detector. For example

```python
from waver.simulation import run_single_source

single_sim_params = {
    'size': (12.8e-3, 12.8e-3),
    'spacing': 100e-6,
    'duration': 80e-6,
    'min_speed': 343,
    'max_speed': 686,
    'speed': 686,
    'time_step': 50e-9,
    'temporal_downsample': 2,
    'location': (6.4e-3, 6.4e-3),
    'period': 5e-6,
    'ncycles':1,
}

detected_wave, speed_grid = run_single_source(**single_sim_params)
```

The second method `run_multiple_sources` allows you to run multiple simulations with multiple sources on the same
grid and with the same detector and return the results. For example

```python
from waver.simulation import run_multiple_sources

multi_sim_params = {
    'size': (12.8e-3, 12.8e-3),
    'spacing': 100e-6,
    'duration': 80e-6,
    'min_speed': 343,
    'max_speed': 686,
    'speed': 686,
    'time_step': 50e-9,
    'temporal_downsample': 2,
    'sources': [{
        'location': (6.4e-3, 6.4e-3),
        'period': 5e-6,
        'ncycles':1,
    }]
}

detected_wave, speed_grid = run_multiple_sources(**multi_sim_params)
```

The main difference between these two methods is that `run_multiple_sources` takes a `sources` parameter which takes a list 
of dictionaries with keys corresponding to source related keyword arguments found in `run_single_source`.

### Visualization

If you want to quickly visualize the results of `run_multiple_sources`, you can use the `run_and_visualize` command which will 
run the simulation and then launch napari with the results, as seen in [examples/2D/point_source.py](./examples/2D/point_source.py)

```python
from waver.datasets import run_and_visualize

run_and_visualize(**multi_sim_params)
```

### Datasets

If you want to run simulations with on many different speed grids you can use the `generate_simulation_dataset` method as a convenience. The results will be saved to a [zarr](https://zarr.readthedocs.io/en/stable/) file of your chosing. You can then use the `load_simulation_dataset` to load the dataset.

```python
from waver.datasets import generate_simulation_dataset

# Define root path for simulation
path = './simulation_dataset.zarr'
runs = 5

# Define a simulation, 12.8mm, 100um spacing
dataset_sim_params = {
    'size': (12.8e-3, 12.8e-3),
    'spacing': 100e-6,
    'duration': 80e-6,
    'min_speed': 343,
    'max_speed': 686,
    'speed': 'mixed_random_ifft',
    'time_step': 50e-9,
    'sources': [{
        'location': (None, 0),
        'period': 5e-6,
        'ncycles':1,
    }],
    'temporal_downsample': 2,
    'boundary': 1,
    'edge': 1,
}

# Run and save simulation
generate_simulation_dataset(path, runs, **dataset_sim_params)
```

The `generate_simulation_dataset` allows the `speed` to be a string that will specify a particular method of randomly generating speed values for the simulation grid.

### The Simulation Object

If you'd like to understand in a little bit more detail how a simulation is defined then you might want to use the unerlying simulation object `Simulation` and manually set key objects like the `Source` and `Detector`. A full example of this is as follows

```python
# Create a simulation
sim = Simulation(size=size, spacing=spacing, max_speed=max_speed, time_step=time_step)

# Set speed array
sim.set_speed(speed=speed, min_speed=min_speed, max_speed=max_speed)

# Add source
sim.add_source(location=location, period=period, ncycles=ncycles, phase=phase)

# Add detector grid
sim.add_detector(spatial_downsample=spatial_downsample,
                    boundary=boundary, edge=edge)

# Run simulation
sim.run(duration=duration, temporal_downsample=temporal_downsample, progress=progress, leave=leave)

# Print simulation wave and speed data
print('wave: ', sim.detected_wave)
print('speed: ', sim.grid_speed)
```

Note these steps are done inside the `run_single_source` method for you as a convenience.

## Known Limitations

A [perfectly matched layer](https://en.wikipedia.org/wiki/Perfectly_matched_layer) boundary has recently been added, but might not perform well under all conditions. Additional contributions would be welcome here.

Right now the simulations are quite slow. I'd like to add a [JAX](https://github.com/google/jax) backend, but 
havn't done so yet. Contributions would be welcome.

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""waver"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/sofroniewn/waver/issues
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/


","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']",,waver.napari_get_reader,,waver.simulation,,['*'],,,https://pypi.org/project/waver,https://github.com/sofroniewn/waver,
398,workshop demo,0.0.2,2022-01-28,2023-06-18,workshop-demo,Draga Doncila Pop,ddoncilapop@contractor.chanzuckerberg.com,BSD-3-Clause,https://github.com/DragaDoncila/workshop-demo,"A demo napari plugin incorporating reader, writer and dock widget contributions using the new npe2 plugin architecture.",>=3.7,"['dask[array]', 'imagecodecs', 'napari', 'napari-plugin-engine (>=0.1.4)', 'npe2', 'numpy', 'scikit-image', 'tifffile']","# workshop-demo

[![License](https://img.shields.io/pypi/l/workshop-demo.svg?color=green)](https://github.com/DragaDoncila/workshop-demo/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/workshop-demo.svg?color=green)](https://pypi.org/project/workshop-demo)
[![Python Version](https://img.shields.io/pypi/pyversions/workshop-demo.svg?color=green)](https://python.org)
[![tests](https://github.com/DragaDoncila/workshop-demo/workflows/tests/badge.svg)](https://github.com/DragaDoncila/workshop-demo/actions)
[![codecov](https://codecov.io/gh/DragaDoncila/workshop-demo/branch/main/graph/badge.svg)](https://codecov.io/gh/DragaDoncila/workshop-demo)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/workshop-demo)](https://napari-hub.org/plugins/workshop-demo)

A demo napari plugin incorporating reader, writer and dock widget contributions using the new npe2 plugin architecture.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/docs/plugins/index.html
-->

## Installation

You can install `workshop-demo` via [pip]:

    pip install workshop-demo


To install latest development version :

    pip install git+https://github.com/DragaDoncila/workshop-demo.git

## What is this?

This plugin was created to serve as a semi-meaningful example of a plugin using
the new napari [npe2](https://pypi.org/project/npe2/) architecture.

It provides a reader, a writer and two dock widgets to support opening, processing
and writing out [cell tracking challenge](https://celltrackingchallenge.net/) data.

We've provided comments and example tests that can be used as a reference
when building your own plugin.

## Using this plugin

### Sample Data
You can download sample data for this plugin from the tracking challenge website. Any 2D+T
sequence should work, but this plugin has been tested only with the 
[Human hepatocarcinoma-derived cells expressing the fusion protein YFP-TIA-1](http://data.celltrackingchallenge.net/training-datasets/Fluo-C2DL-Huh7.zip) 
dataset.
### Reading Data
This plugin's reader is designed for tracking challenge segmentation gold standard ground truth
data conforming to the file format described in the [data specification](https://public.celltrackingchallenge.net/documents/Naming%20and%20file%20content%20conventions.pdf).

Ground truth data is only provided for a subset of the frames of the entire sequence. This
reader will attempt to find the number of frames of the associated sequence in a sister
directory of the ground truth data directory and open a labels layer with the same number
of frames, thus ensuring the labelled data is correctly overlaid onto the original sequence.



https://user-images.githubusercontent.com/17995243/146114062-36124c05-f44a-488e-8991-f39a702c917f.mov



### Segmenting Data
One of the dock widgets provided by this plugin is ""Segment by Threshold"". The widget
allows you to select a 2D+T image layer in the viewer (e.g. any of the sequences in the Human 
hepatocarcinoma dataset above) and segment it using a selection of scikit-image thresholding functions.

The segmentation is then returned as a `Labels` layer into the viewer.


https://user-images.githubusercontent.com/17995243/146114088-f6fb645e-8d78-4880-827b-2f0334dad859.mov



### Highlighting Segmentation Differences
The second dock widget provided by this plugin allows you to visually compare your segmentation
against the ground truth data by computing the difference between the two and adding this as a
layer in the napari viewer.

To use this widget, open it from the Plugins menu and select the two layers you wish to compare.



https://user-images.githubusercontent.com/17995243/146114112-c891723f-8640-4708-8014-c78731fb3396.mov



### Writing to Zip
Finally, you can save your segmentation to a zip file whose internal directory structure
will closely mimic that of the tracking challenge datasets, so that it may be opened 
again in the viewer.

To save your layer, choose File -> Save selected layer(s) with *one* labels layer selected,
then select label zipper from the dropdown choices.



https://user-images.githubusercontent.com/17995243/146114163-ee886990-979c-4756-97c5-aaf2c39dccde.mov



## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""workshop-demo"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/DragaDoncila/workshop-demo/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/


","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: MacOS :: MacOS X', 'Operating System :: POSIX :: Linux', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Software Development :: Testing']","['Bug Tracker, https://github.com/DragaDoncila/workshop-demo/issues', 'Documentation, https://github.com/DragaDoncila/workshop-demo#README.md', 'Source Code, https://github.com/DragaDoncila/workshop-demo', 'User Support, https://github.com/DragaDoncila/workshop-demo/issues']",workshop-demo.get_reader,workshop-demo.write_labels,workshop-demo.get_segment_widget,,,['.zip'],,https://pypi.org/project/workshop-demo,https://github.com/DragaDoncila/workshop-demo,
399,World2Data,0.0.3,2022-02-13,2023-06-18,World2Data,"Marc Boucsein, Robin Koch",,BSD-3,https://github.com/MBPhys/World2Data,A napari plugin in order to convert the world information to the data of a 2D/3D layer,>=3.7,"['napari-plugin-engine (>=0.1.4)', 'numpy', 'gryds', 'dask', 'scikit-image']","# World2Data

[![License](https://img.shields.io/pypi/l/napari-medical-image-formats.svg?color=green)](https://github.com/MBPhys/World2Data/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/World2Data.svg?color=green)](https://pypi.org/project/World2Data)
[![Python Version](https://img.shields.io/pypi/pyversions/World2Data.svg?color=green)](https://python.org)


A napari plugin in order to convert the world information to the data of a 2D/3D layer.

----------------------------------

## Installation

You can install `World2Data` via [pip]:

    pip install World2Data

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""World2Data"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/MBPhys/World2Data/issues
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/


","['Development Status :: 4 - Beta', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']",,,,World2Data.World2Data,,,,,https://pypi.org/project/World2Data,https://github.com/MBPhys/World2Data,
400,yt-napari,0.4.0,2022-06-16,2023-12-08,yt-napari,Chris Havlin,chris.havlin@gmail.com,BSD-3-Clause,https://github.com/data-exp-lab/yt-napari,A napari plugin for loading data from yt,>=3.8,"['magicgui >=0.6.1', 'napari >=0.4.19', 'numpy', 'packaging', 'pydantic >2.0', 'qtpy', 'unyt', 'yt >=4.0.1', ""pytest ; extra == 'dev'"", ""pytest-qt ; extra == 'dev'"", ""taskipy ; extra == 'dev'"", ""sphinx ; extra == 'docs'"", ""nbsphinx <0.8.8 ; extra == 'docs'"", ""sphinx-jsonschema <1.19.0 ; extra == 'docs'"", ""Jinja2 <3.1.0 ; extra == 'docs'"", ""dask[array,distributed] ; extra == 'full'""]","# yt-napari

[![License](https://img.shields.io/pypi/l/yt-napari.svg?color=green)](https://github.com/data-exp-lab/yt-napari/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/yt-napari.svg?color=green)](https://pypi.org/project/yt-napari)
[![Python Version](https://img.shields.io/pypi/pyversions/yt-napari.svg?color=green)](https://python.org)
[![tests](https://github.com/data-exp-lab/yt-napari/workflows/tests/badge.svg)](https://github.com/data-exp-lab/yt-napari/actions)
[![codecov](https://codecov.io/gh/data-exp-lab/yt-napari/branch/main/graph/badge.svg)](https://codecov.io/gh/data-exp-lab/yt-napari)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/yt-napari)](https://napari-hub.org/plugins/yt-napari)
[![Documentation Status](https://readthedocs.org/projects/yt-napari/badge/?version=latest)](https://yt-napari.readthedocs.io/en/latest/?badge=latest)

A [napari] plugin for loading data from [yt].

This readme provides a brief overview including:

1. [Installation](#Installation)
2. [Quick Start](#Quick-Start)
3. [Contributing](#Contributing)

Full documentation is available at [yt-napari.readthedocs.io].

## Installation

### 1. (optional) install `yt` and `napari`

If you skip this step, the installation in the following section will only install the minimal package requirements for `yt` or `napari`, in which case you will likely need to manually install some packages. So if you are new to either package, or if you are installing in a clean environment, it may be simpler to  install these packages first.

For `napari`,

    pip install napari[all]

will install `napari` with the default `Qt` backend (see [here](https://napari.org/tutorials/fundamentals/installation#choosing-a-different-qt-backend) for how to choose between `PyQt5` or `PySide2`).

For `yt`, you will need `yt>=4.0.1` and any of the optional dependencies for your particular workflow. If you know that you'll need more than the base `yt` install, you can install the full suite of dependent packages with

    pip install yt[full]

See the [`yt` documentation](https://yt-project.org/doc/installing.html#leveraging-optional-yt-runtime-dependencies) for more information. If you're not sure which packages you'll need but don't want the full yt installation, you can proceed to the next step and then install any packages as needed (you will receive error messages when a required package is missing).

### 2. install `yt-napari`

You can install the `yt-napari` plugin with:

    pip install yt-napari

If you are missing either `yt` or `napari` (or they need to be updated), the above installation will fetch and run a minimal installation for both.

To install the latest development version of the plugin instead, use:

    pip install git+https://github.com/data-exp-lab/yt-napari.git

Note that if you are working off the development version, be sure to use the latest documentation
for reference: https://yt-napari.readthedocs.io/en/latest/

## Quick Start

After [installation](#Installation), there are three modes of using `yt-napari`:

1. jupyter notebook interaction ([jump down](#jupyter-notebook-interaction))
2. loading a json file from the napari gui ([jump down](#loading-a-json-file-from-the-napari-gui))
3. napari widget plugins ([jump down](#napari-widget-plugins))

### jupyter notebook interaction

`yt-napari` provides a helper class, `yt_napari.viewer.Scene` that assists in properly aligning new yt selections in the napari viewer when working in a Jupyter notebook.

```python
import napari
import yt
from yt_napari.viewer import Scene
from napari.utils import nbscreenshot

viewer = napari.Viewer()
ds = yt.load(""IsolatedGalaxy/galaxy0030/galaxy0030"")
yt_scene = Scene()

left_edge = ds.domain_center - ds.arr([40, 40, 40], 'kpc')
right_edge = ds.domain_center + ds.arr([40, 40, 40], 'kpc')
res = (600, 600, 600)

yt_scene.add_region(viewer,
                    ds,
                    (""enzo"", ""Temperature""),
                    left_edge=left_edge,
                    right_edge=right_edge,
                    resolution=res)

yt_scene.add_region(viewer,
                    ds,
                    (""enzo"", ""Density""),
                    left_edge=left_edge,
                    right_edge=right_edge,
                    resolution=res)

nbscreenshot(viewer)
```

 ![Loading a subset of a yt dataset in napari from a Jupyter notebook](./assets/images/readme_ex_001.png)

`yt_scene.add_to_viewer` accepts any of the keyword arguments allowed by `viewer.add_image`. See the full documentation ([yt-napari.readthedocs.io]) for more examples, including additional helper methods for linking layer appearance.

Additionally, with `yt_napari`>= v0.2.0, you can use the `yt_napari.timeseries` module to help sample and load in selections from across datasets.

### loading a selection from a yt dataset interactively

`yt-napari` provides two ways to sample a yt dataset and load in an image layer into a Napari viewer: the yt Reader plugin and json file specification.

#### using the yt Reader plugin

To use the yt Reader plugin, click on `Plugins -> yt-napari: yt Reader`. From there, add a region or slice selector then specify a field type and field and bounds to sample  between and then simply click ""Load"":

![Loading a subset of a yt dataset from the napari viewer](./assets/images/readme_ex_003_gui_reader.gif)

You can add multiple selections and load them all at once or adjust values and click ""Load"" again.

#### using the yt Time Series Reader plugin

To use the yt Time Series Reader plugin, click on  `Plugins -> yt-napari: yt Time Series Reader`. Specify your file matching: use `file_pattern` to enter glob expressions or use `file_list` to enter a list of specific files.
Then add a slice or region to sample for each matched dataset file (note: be careful of memory here!):

![Loading timeseries selections from the napari viewer](./assets/images/readme_ex_004_gui_timeseries.gif)

#### using a json file and schema

`yt-napari` also provides the ability to load json that contain specifications for loading a file. Properly formatted files can be loaded from the napari GUI as you would load any image file (`File->Open`). The json file describes the selection process for a dataset as described by a json-schema. The following json file results in similar layers as the above examples:


```json
{""$schema"": ""https://raw.githubusercontent.com/data-exp-lab/yt-napari/main/src/yt_napari/schemas/yt-napari_0.0.1.json"",
 ""datasets"": [{""filename"": ""IsolatedGalaxy/galaxy0030/galaxy0030"",
               ""selections"": {""regions"": [{
                                ""fields"": [{""field_name"": ""Temperature"", ""field_type"": ""enzo"", ""take_log"": true},
                                           {""field_name"": ""Density"", ""field_type"": ""enzo"", ""take_log"": true}],
                                ""left_edge"": [460.0, 460.0, 460.0],
                                ""right_edge"": [560.0, 560.0, 560.0],
                                ""resolution"": [600, 600, 600]
                              }]},
               ""edge_units"": ""kpc""
             }]
}
```

To help in filling out a json file, it is recommended that you use an editor capable of parsing a json schema and displaying hints. For example, in vscode, you will see field suggestions after specifying the `yt-napari` schema:

![interactive json completion for yt-napari](./assets/images/readme_ex_002_json.png)

See the full documentation at [yt-napari.readthedocs.io] for a complete specification.


## Contributing

Contributions are very welcome! Development follows a fork and pull request workflow. To get started, you'll need a development installation and a testing environment.

### development environment

To start developing, fork the repository and clone your fork to get a local copy. You can then install in development mode with

    pip install -e .

### tests and style checks

Both bug fixes and new features will need to pass the existing test suite and style checks. While both will be run automatically when you submit a pull request, it is helpful to run the test suites locally and run style checks throughout development. For testing, you can use [tox] to test different python versions on your platform.

    pip install tox

And then from the top level of the `yt-napari` directory, run

    tox

Tox will then run a series of tests in isolated environments. In addition to checking the terminal output for test results, the tox run will generate a test coverage report: a `coverage.xml` file and a `htmlcov` folder -- to view the results, open `htmlcov/index.html` in a browser.

If you prefer a lighter weight test, you can also use `pytest` directly and rely on the Github CI to test different python versions and systems. To do so, first install `pytest` and some related plugins:

    pip install pytest pytest-qt pytest-cov

Now, to run the tests:

    pytest -v --cov=yt_napari --cov-report=html

In addition to telling you whether or not the tests pass, the above command will write out a code coverage report to the `htmlcov` directory. You can open up `htmlcov/index.html` in a browser and check out the lines of code that were missed by existing tests.

For style checks, you can use [pre-commit](https://pre-commit.com/) to run checks as you develop. To set up `pre-commit`:

    pip install pre-commit
    pre-commit install

after which, every time you run `git commit`, some automatic style adjustments and checks will run. The same style checks will run when you submit a pull request, but it's often easier to catch them early.

After submitting a pull request, the `pre-commit.ci` bot will run the style checks. If style checks fail, you can have the bot attempt to auto-fix the failures by adding the following in a comment on it's own:

    pre-commit.ci autofix

The bot will then commit changes to your pull request after which you will want to run `git pull` locally to update your local version of the branch before making further changes to the branch.

### building documentation locally

Documentation can be built using `sphinx` in two steps. First, update the api mapping with

    sphinx-apidoc -f -o docs/source src/yt_napari/

This will update the `rst` files in `docs/source/` with the latest docstrings in `yt_napari`. Next, build the html documentation with

    make html


### updating the pydantic models and schema

The schema versioning follows a `major.minor.micro` versioning pattern that matches the yt-napari versioning. Each yt-napari release should have an accompanying updated schema file, even if the  contents of the schema file have not changed. On-disk schema are stored in  `src/yt_napari/schemas/`, with copies in the documentation at `docs/_static`.

There are a number of utilities to help automate the management of schema in `repo_utilities/`. The easiest way to use these utitities is with `taskipy` from the command line. To list available scripts:

```commandline
task --list
```

Before a release, run

```commandline
task validate_release vX.X.X
```

where `vX.X.X` is the version of the upcoming release. This script will run through some checks that ensure:
* the on-disk schema matches the schema generated by the pydantic model
* the schema files in the documentation match the schema files in the package

If any of the checks fail, you will be advised to update the schema using `update_schema_docs`. If you
run without providing a version:

```commandline
task update_schema_docs
```

It will simply copy over the existing on-disk schema files to the documentation. If you run with a version:

```commandline
task update_schema_docs -v vX.X.X
```
It will write a schema file for the current pydantic model, overwriting any on-disk schema files for
the provided version.

## License

Distributed under the terms of the [BSD-3] license,
""yt-napari"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

## Funding

The yt-napari plugin project was funded with support from the Chan Zuckerberg Initiative through the napari Plugin Accelerator Grants project, [Enabling Access To Multi-resolution Data](https://chanzuckerberg.com/science/programs-resources/imaging/napari/enabling-access-to-multi-resolution-data/).

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/stable/index.html
-->

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[yt-napari.readthedocs.io]: https://yt-napari.readthedocs.io/en/stable/

[file an issue]: https://github.com/data-exp-lab/yt-napari/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
[yt]: https://yt-project.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Topic :: Software Development :: Testing']","['Bug Tracker, https://github.com/data-exp-lab/yt-napari/issues', 'Documentation, https://github.com/data-exp-lab/yt-napari#README.md', 'Source Code, https://github.com/data-exp-lab/yt-napari', 'User Support, https://github.com/data-exp-lab/yt-napari/issues']",yt-napari.get_reader,,yt-napari.reader_widget,,['*.json'],,,https://pypi.org/project/yt-napari,https://github.com/data-exp-lab/yt-napari,
401,zarpaint,0.3.1,2023-11-18,2023-11-18,zarpaint,Abigail McGovern and Juan Nunez-Iglesias,juan.nunez-iglesias@monash.edu,BSD-3,https://pypi.org/project/zarpaint,Paint segmentations directly to on-disk/remote zarr arrays,>=3.7,"['magicgui', 'napari >=0.4.11.dev80', 'napari-plugin-engine >=0.1.4', 'numpy', 'pyyaml', 'qtpy', 'scipy', 'scikit-image', 'toolz', 'zarr', ""tensorstore ; extra == 'all'"", ""coverage ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari[pyqt5] ; extra == 'testing'""]","# zarpaint

[![License](https://img.shields.io/pypi/l/zarpaint.svg?color=green)](https://github.com/jni/zarpaint/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/zarpaint.svg?color=green)](https://pypi.org/project/zarpaint)
[![Python Version](https://img.shields.io/pypi/pyversions/zarpaint.svg?color=green)](https://python.org)
[![tests](https://github.com/jni/zarpaint/workflows/tests/badge.svg)](https://github.com/jni/zarpaint/actions)
[![codecov](https://codecov.io/gh/jni/zarpaint/branch/main/graph/badge.svg)](https://codecov.io/gh/jni/zarpaint)

Paint segmentations directly to on-disk/remote zarr arrays

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/docs/plugins/index.html
-->

## Installation

You can install `zarpaint` via [pip]:

    pip install zarpaint

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""zarpaint"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/jni/zarpaint/issues
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 4 - Beta', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']",,zarpaint.get_reader,,zarpaint.add_points_3d_with_alt_click,,['*.zarr'],,,https://pypi.org/project/zarpaint,,
